{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "01 working trial tfhub multi BERT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNIAYpLwAw/7abi1Kv+xhwu",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BiancaStadl/ProjektarbeitML/blob/main/01_working_trial_tfhub_multi_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKrnlBJva28O"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwZIiSV2caVQ"
      },
      "source": [
        "Hier umgesetzt:\n",
        "laut Doku von https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/4 und https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNWyze032Y0j"
      },
      "source": [
        "general tutorial: https://www.tensorflow.org/text/tutorials/classify_text_with_bert?hl=en\n",
        "\n",
        "German pre-trained embeddings:\n",
        "* https://nlp.johnsnowlabs.com/2021/05/20/distilbert_base_multilingual_cased_xx.html -> maybe\n",
        "\n",
        "* multilingual https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/4 inklusive pre-processing (extra laden, siehe Tut) https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcWIFJ2iEX8T"
      },
      "source": [
        "Was passiert hier?\n",
        "Multilingual bert vom TensorFlowHub wird verwendet (noch nicht huggingface). Die Modelle vom TensorFlowHub sind leichter einzubinden, weil z. B. der eigenen PreProcessor geladen werden kann und man nicht händisch die Tokens CLS und SEP etc. hinzufügen muss, Masking passiert auch durch den PreProcessor, es wird demnach schon einfach viel im Vorhinein zur Verfügung gestellt, damit man ganz einfach fine-tunen kann. Damit beginne ich mal, bevor ich Huggingface mache.\n",
        "also, ganz simpel: https://www.tensorflow.org/text/tutorials/classify_text_with_bert?hl=zh-TW#the_preprocessing_model\n",
        "\n",
        "mit mehr Einstellungen: https://www.tensorflow.org/text/tutorials/fine_tune_bert?hl=zh-TW#preprocess_the_data und auch https://www.tensorflow.org/text/tutorials/bert_glue?hl=zh-TW\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3xfitNdliBI"
      },
      "source": [
        "\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import string\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from keras import losses\n",
        "from tensorflow import keras \n",
        "from keras import optimizers \n",
        "from keras import metrics \n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import preprocessing\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ubJfAzE27tk"
      },
      "source": [
        "import tensorflow_hub as hub"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVYBMvYSotTH"
      },
      "source": [
        "url = \"https://github.com/uds-lsv/GermEval-2018-Data/archive/master.zip\"\n",
        "\n",
        "dataset = tf.keras.utils.get_file(\"GermEval-2018-Data-master.zip\", url, \n",
        "                                   extract=True, cache_dir='.',\n",
        "                                    cache_subdir='')\n",
        "\n",
        "dataset_dir = os.path.join(os.path.dirname(dataset), 'GermEval-2018-Data-master')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cS14OUtfo34V"
      },
      "source": [
        "#os.listdir(dataset_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2X429K6hpOVm"
      },
      "source": [
        "training_file = os.path.join(dataset_dir, 'germeval2018.training.txt')\n",
        "#with open(training_file) as f:\n",
        " # print(f.read())\n",
        "\n",
        "#print()\n",
        "\n",
        "testing_file = os.path.join(dataset_dir, 'germeval2018.test.txt')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdLN99PVXSdj"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRqhP_Fx0cK3"
      },
      "source": [
        "def remove_clutter(string):\n",
        "   string = re.sub(\"@[^\\s]+\",\" \",string)\n",
        "   string = re.sub(\"#[^\\s]+\",\" \", string)\n",
        "   string = re.sub(\"\\u00a9\",\" \", string)\n",
        "   string = re.sub(\"\\u00ae\",\" \", string)\n",
        "   string = re.sub(\"[\\u2000-\\u3300]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83c[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83d[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83e[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"😜\", \" \",string)\n",
        "   string = re.sub(\"🍫\", \" \",string)\n",
        "   string = re.sub(\"😁\", \" \",string)\n",
        "   string = re.sub(\"🐖\", \" \",string)\n",
        "   string = re.sub(\"😡\", \" \",string)\n",
        "   string = re.sub(\"😇\", \" \",string)\n",
        "   string = re.sub(\"😬\", \" \",string)\n",
        "   string = re.sub(\"😃\", \" \",string)\n",
        "   string = re.sub(\"😂\", \" \",string)\n",
        "   string = re.sub(\"💙\", \" \",string)  \n",
        "   string = re.sub(\"😛\", \" \",string)\n",
        "   string = re.sub(\"🙏\", \" \",string)\n",
        "   string = re.sub(\"👍\", \" \",string)\n",
        "   string = re.sub(\"🖕\", \" \",string)\n",
        "   string = re.sub(\"😉\", \" \",string)\n",
        "   string = re.sub(\"💩\", \" \",string)\n",
        "   string = re.sub(\"🤢\", \" \",string)\n",
        "   string = re.sub(\"👏\", \" \",string)\n",
        "   string = re.sub(\"😨\", \" \",string)\n",
        "   string = re.sub(\"🤣\", \" \",string)\n",
        "   string = re.sub(\"🤡\", \" \",string)\n",
        "   string = re.sub(\"😈\", \" \",string)\n",
        "   string = re.sub(\"💃🏽\", \" \",string)\n",
        "   string = re.sub(\"👹\", \" \",string)\n",
        "   string = re.sub(\"🤘\", \" \",string)\n",
        "   string = re.sub(\"😱\", \" \",string)\n",
        "   string = re.sub(\"🤔\", \" \",string) \n",
        "   string = re.sub(\"🌈\", \" \",string) \n",
        "   string = re.sub(\"💕\", \" \",string) \n",
        "   string = re.sub(\"👩‍❤️‍👩\", \" \",string) \n",
        "   string = re.sub(\"😍\", \" \",string) \n",
        "   string = re.sub(\"👆\", \" \",string) \n",
        "   string = re.sub(\"😖\", \" \",string) \n",
        "   string = re.sub(\"👇\", \" \",string) \n",
        "   string = re.sub(\"🔥\", \" \",string) \n",
        "   string = re.sub(\"😘\", \" \",string) \n",
        "   string = re.sub(\"🎉\", \" \",string) \n",
        "   string = re.sub(\"🤬\", \" \",string) \n",
        "   string = re.sub(\"👊\", \" \",string)\n",
        "   string = re.sub(\"🇩🇪\", \" \",string)  \n",
        "   string = re.sub(\"💔\", \" \",string)\n",
        "   string = re.sub(\"🙈\", \" \",string)\n",
        "   string = re.sub(\"🤯\", \" \",string)\n",
        "   string = re.sub(\"🐟\", \" \",string)\n",
        "   string = re.sub(\"🛶\", \" \",string)\n",
        "   string = re.sub(\"😊\", \" \",string)\n",
        "   string = re.sub(\"😓\", \" \",string)\n",
        "   string = re.sub(\"😳\", \" \",string)\n",
        "   string = re.sub(\"🚀\", \" \",string)\n",
        "   string = re.sub(\"👎\", \" \",string)\n",
        "   string = re.sub(\"😎\", \" \",string)\n",
        "   string = re.sub(\"🐸\", \" \",string)\n",
        "   string = re.sub(\"📈\", \" \",string)\n",
        "   string = re.sub(\"🙂\", \" \",string)\n",
        "   string = re.sub(\"😅\", \" \",string)\n",
        "   string = re.sub(\"😆\", \" \",string)\n",
        "   string = re.sub(\"🙎🏿\", \" \",string)\n",
        "   string = re.sub(\"👎🏽\", \" \",string)\n",
        "   string = re.sub(\"🤭\", \" \",string)\n",
        "   string = re.sub(\"😤\", \" \",string)\n",
        "   string = re.sub(\"😚\", \" \",string)\n",
        "   string = re.sub(\"😊\", \" \",string)\n",
        "   string = re.sub(\"😲\", \" \",string)\n",
        "   string = re.sub(\"🤮\", \" \",string)\n",
        "   string = re.sub(\"🙄\", \" \",string)\n",
        "   string = re.sub(\"🤑\", \" \",string)\n",
        "   string = re.sub(\"🎅\", \" \",string)\n",
        "   string = re.sub(\"👋\", \" \",string)\n",
        "   string = re.sub(\"💪\", \" \",string)\n",
        "   string = re.sub(\"😄\", \" \",string)\n",
        "   string = re.sub(\"🧐\", \" \",string)\n",
        "   string = re.sub(\"😠\", \" \",string)\n",
        "   string = re.sub(\"🎈\", \" \",string)\n",
        "   string = re.sub(\"🚂\", \" \",string)\n",
        "   string = re.sub(\"😊\", \" \",string)\n",
        "   string = re.sub(\"🚇\", \" \",string)\n",
        "   string = re.sub(\"🚊\", \" \",string)\n",
        "   string = re.sub(\"🤷\", \" \",string)\n",
        "   string = re.sub(\"😥\", \" \",string)\n",
        "   string = re.sub(\"🙃\", \" \",string)\n",
        "   string = re.sub(\"🔩\", \" \",string)\n",
        "   string = re.sub(\"🔧\", \" \",string)\n",
        "   string = re.sub(\"🔨\", \" \",string)\n",
        "   string = re.sub(\"🛠\", \" \",string)\n",
        "   string = re.sub(\"💓\", \" \",string)\n",
        "   string = re.sub(\"💡\", \" \",string)\n",
        "   string = re.sub(\"🍸\", \" \",string)\n",
        "   string = re.sub(\"🥃\", \" \",string)\n",
        "   string = re.sub(\"🥂\", \" \",string)\n",
        "   string = re.sub(\"😷\", \" \",string)\n",
        "   string = re.sub(\"🤐\", \" \",string)\n",
        "   string = re.sub(\"🌎\", \" \",string)\n",
        "   string = re.sub(\"👑\", \" \",string)\n",
        "   string = re.sub(\"🤛\", \" \",string)\n",
        "   string = re.sub(\"😀\", \" \",string)\n",
        "   string = re.sub(\"🛤\", \" \",string)\n",
        "   string = re.sub(\"🎄\", \" \",string)\n",
        "   string = re.sub(\"📴\", \" \",string)\n",
        "   string = re.sub(\"🌭\", \" \",string)\n",
        "   string = re.sub(\"🤕\", \" \",string)\n",
        "   string = re.sub(\"😭\", \" \",string)\n",
        "   string = re.sub(\"🍾\", \" \",string)\n",
        "   string = re.sub(\"🍞\", \" \",string)\n",
        "   string = re.sub(\"🤦\", \" \",string)\n",
        "   string = re.sub(\"🤯\", \" \",string)\n",
        "   string = re.sub(\"🕯️\", \" \",string)\n",
        "\n",
        "   string = re.sub(\"OTHER|OFFENSE|ABUSE|INSULT\",\" \",string)\n",
        "   return string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5asMgo4LtnRg"
      },
      "source": [
        "statementsForTraining = []\n",
        "sentimentsForTraining = []\n",
        "\n",
        "fileToRead = open(training_file, 'r')\n",
        "\n",
        "while True:\n",
        "  #next line in file\n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  findSentiment = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "      \n",
        "\n",
        "  statementsForTraining.append(line)\n",
        "\n",
        "  if findSentiment.group(0) == \"OTHER\":  \n",
        "    sentimentsForTraining.append(0)\n",
        "  else:\n",
        "    sentimentsForTraining.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        " #print(\"{}: {}\".format(count,line.strip()))\n",
        "  \n",
        " # print(sentiment.group(0))\n",
        " \n",
        "fileToRead.close()\n",
        "\n",
        "training_sentences = statementsForTraining\n",
        "training_labels = sentimentsForTraining\n",
        "\n",
        "#print(training_sentences[0:100])\n",
        "#print(training_labels[9])  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsqZPENb98gD"
      },
      "source": [
        "\n",
        "statementsForTesting = []\n",
        "sentimentsForTesting = []\n",
        "\n",
        "fileToRead = open(testing_file, 'r')\n",
        "\n",
        "while True:\n",
        " \n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  sent = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "\n",
        "\n",
        "  statementsForTesting.append(line)\n",
        "  #print(len(line))\n",
        "\n",
        "  if sent.group(0) == \"OTHER\": \n",
        "    sentimentsForTesting.append(0)\n",
        "  else:\n",
        "    sentimentsForTesting.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        "\n",
        "fileToRead.close()\n",
        "\n",
        "\n",
        "testing_sentences = statementsForTesting\n",
        "testing_labels = sentimentsForTesting\n",
        "#print(len(testing_sentences))\n",
        "#print(testing_sentences)   \n",
        "#print(statementsForTesting)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEZFaS50r5BF"
      },
      "source": [
        "maybe also use this https://stackoverflow.com/questions/60120043/optimizer-and-scheduler-for-bert-fine-tuning "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-hm6yCCqUDJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c074e3f-de58-4e23-9633-132ea08f0277"
      },
      "source": [
        "#statt rein die Arrays zu verwenden -> dataset erstellen (brauch ich unter anderem später beim Optimizer?)\n",
        "#from https://www.tensorflow.org/tutorials/load_data/pandas_dataframe?hl=en#with_tfdata\n",
        "# and https://medium.com/when-i-work-data/converting-a-pandas-dataframe-into-a-tensorflow-dataset-752f3783c168\n",
        "#and https://stackoverflow.com/questions/46379095/convert-two-numpy-array-to-dataframe (zweite Antwort)\n",
        "import pandas as pd\n",
        "dataframe = pd.DataFrame({'tweet': training_sentences, 'predictions': training_labels}, columns=['tweet', 'predictions'])\n",
        "#whole_training_dataset = tf.data.Dataset.from_tensors((dataframe['tweet'], dataframe['predictions']))\n",
        "dataset = tf.data.Dataset.from_tensor_slices((dataframe['tweet'], dataframe['predictions']))\n",
        "\n",
        "\n",
        "\n",
        "#fit works with dataset -> from tensors, but not with from tensor_slices.. why?\n",
        "#not working later on -> dataset = tf.data.Dataset.from_tensor_slices((dataframe['tweet'], dataframe['predictions']))\n",
        "\n",
        "#print(whole_training_dataset)\n",
        "\n",
        "####from https://colab.research.google.com/github/tensorflow/text/blob/master/docs/tutorials/classify_text_with_bert.ipynb#scrollTo=6IwI_2bcIeX8\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "batch_size = 32\n",
        "seed = 42\n",
        "\n",
        "class_list=['neutral','neg']\n",
        "train_ds = dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "\n",
        "\n",
        "#val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "\n",
        "#test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "#####\n",
        "\n",
        "#dataframe.head()\n",
        "for elem in train_ds.take(5):\n",
        "  print (elem[1])\n",
        "  #reading form dataset https://stackoverflow.com/questions/57518079/retrieving-the-next-element-from-tf-data-dataset-in-tensorflow-2-0-beta"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(0, shape=(), dtype=int64)\n",
            "tf.Tensor(0, shape=(), dtype=int64)\n",
            "tf.Tensor(0, shape=(), dtype=int64)\n",
            "tf.Tensor(0, shape=(), dtype=int64)\n",
            "tf.Tensor(1, shape=(), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mZw0AL18j66"
      },
      "source": [
        "laut Doku von https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/4 und https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3\n",
        "\n",
        "Erster Versuch mit Multilingual"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dA0f3u5YjSYa",
        "outputId": "3c319059-be13-4a23-a62a-49a9216a3d04"
      },
      "source": [
        "for elem in train_ds.take(5):\n",
        "  print (elem[0])\n",
        "  #reading form dataset https://stackoverflow.com/questions/57518079/retrieving-the-next-element-from-tf-data-dataset-in-tensorflow-2-0-beta"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(b'  Liebe Corinna, wir w\\xc3\\xbcrden dich gerne als Moderatorin f\\xc3\\xbcr uns gewinnen! W\\xc3\\xa4rst du begeisterbar?\\t \\t \\n', shape=(), dtype=string)\n",
            "tf.Tensor(b'  Sie haben ja auch Recht. Unser Tweet war etwas missverst\\xc3\\xa4ndlich. Dass das BVerfG Sachleistungen nicht ausschlie\\xc3\\x9ft, kritisieren wir.\\t \\t \\n', shape=(), dtype=string)\n",
            "tf.Tensor(b'  fr\\xc3\\xb6hlicher gru\\xc3\\x9f aus der sch\\xc3\\xb6nsten stadt der welt theo  \\xef\\xb8\\x8f\\t \\t \\n', shape=(), dtype=string)\n",
            "tf.Tensor(b'  Amis h\\xc3\\xa4tten alles und jeden gew\\xc3\\xa4hlt...nur Hillary wollten sie nicht und eine Fortsetzung von Obama-Politik erst recht nicht..!\\t \\t \\n', shape=(), dtype=string)\n",
            "tf.Tensor(b'  kein verl\\xc3\\xa4\\xc3\\x9flicher Verhandlungspartner. Nachkarteln nach den Sondierzngsgespr\\xc3\\xa4chen - schickt diese St\\xc3\\xbcmper   in die Versenkung.\\t \\t \\n', shape=(), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ql6eKHyo9dZ"
      },
      "source": [
        "#print(whole_training_dataset.batch(3))\n",
        "#type(whole_training_dataset)\n",
        "\n",
        "#for text_batch, label_batch in whole_training_dataset.take(1):\n",
        " # for i in range(3):\n",
        "  #  print(f'Review: {text_batch.numpy()[i]}')\n",
        "   # label = label_batch.numpy()[i]\n",
        "    #print(f'Label : {label} )')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bq08Me5la_Cc"
      },
      "source": [
        "max_length = 60"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKDC3pXp8jTv",
        "outputId": "f06877a0-064e-404a-e25b-ea82bc34b5bd"
      },
      "source": [
        "!pip install tensorflow_text\n",
        "import tensorflow_text as text  # Registers the ops."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow_text in /usr/local/lib/python3.7/dist-packages (2.7.3)\n",
            "Requirement already satisfied: tensorflow<2.8,>=2.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text) (2.7.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text) (0.12.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (12.0.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (0.22.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (3.1.0)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (2.7.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (0.37.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (2.7.0)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.19.5)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (0.4.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (0.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (3.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.42.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (3.10.0.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.1.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.15.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.6.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.13.3)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (2.7.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.8.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (3.3.6)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.35.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (3.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSTC9iTU-4Wh"
      },
      "source": [
        "Für das Pre-Processing gibts Code in der Coku https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3 \n",
        "\n",
        "In meinem Fall: für mehrere Input-Segments und nicht nur ein einzelnes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRkqkLSY-8g6"
      },
      "source": [
        "preprocessor = hub.load(\n",
        "    \"https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3\")\n",
        "\n",
        "preprocessor = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSCAjTy7Bwmu"
      },
      "source": [
        "from keras.layers import Dense, Dropout, Activation\n",
        "from keras.layers import Embedding, LSTM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDHbeiOi_b7M"
      },
      "source": [
        "dieser Code ist direkt von der tfhub-Doku, Mischung aus Classify-Tut und multi-Documentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-tPQ3MG_fBM"
      },
      "source": [
        "def build_simple_sentiment_classifier_model():\n",
        "  text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='tweet')\n",
        "  preprocessor = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3\", name='preprocessing')\n",
        "  encoder_inputs = preprocessor(text_input)\n",
        "  encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/4\", trainable=True)\n",
        "  outputs = encoder(encoder_inputs)\n",
        "  pooled_output = outputs[\"pooled_output\"] \n",
        "  addedLayers = tf.keras.layers.Dropout(0.1)(pooled_output)#change me\n",
        "  #addedLayers = tf.keras.layers.Dense(1, activation=None, name='classifier')(addedLayers)#change me\n",
        "  addedLayers = tf.keras.layers.Dense(1, activation='sigmoid', name='classifier')(addedLayers)#change me\n",
        "  return tf.keras.Model(text_input, addedLayers)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyZ1-fcUZbVL"
      },
      "source": [
        "modelSimple = build_simple_sentiment_classifier_model()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "LcgvHiG8jXd_",
        "outputId": "e7a7d007-c69b-49ed-f079-a42ac7d71334"
      },
      "source": [
        "tf.keras.utils.plot_model(modelSimple)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ju9bFQgFt6s"
      },
      "source": [
        "als zusätzliche Evaluierungsmetrik -> f1 (Precision, Recall)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5qYC_xx_aTK"
      },
      "source": [
        "import keras.backend as K\n",
        "\n",
        "def metrics_recall(data_true, data_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(data_true,0,1)))\n",
        "\n",
        "    recall = true_positives / (possible_positives+K.epsilon())\n",
        "    return recall\n",
        "\n",
        "\n",
        "def metrics_precision(data_true, data_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "\n",
        "    positives_predicted = K.sum(K.round(K.clip(data_pred,0,1)))\n",
        "    precision = true_positives / (positives_predicted+K.epsilon())\n",
        "    return precision\n",
        "\n",
        "\n",
        "def metrics_f1(data_true, data_pred):\n",
        "    precision_data = metrics_precision(data_true, data_pred)\n",
        "    recall_data = metrics_recall(data_true, data_pred)\n",
        "    return 2*(precision_data*recall_data)/(precision_data+recall_data+K.epsilon())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4pISXM6N_hg"
      },
      "source": [
        "#print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZ-OF4Y5ie4R"
      },
      "source": [
        "#model.layers[1].get_weights()[0].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v88JJEqj4Crv"
      },
      "source": [
        "\n",
        "batch_size = 32\n",
        "validation_split=0.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRRsBiQkZBik"
      },
      "source": [
        "the following comes from https://colab.research.google.com/github/tensorflow/text/blob/master/docs/tutorials/classify_text_with_bert.ipynb#scrollTo=P9eP2y9dbw32"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gt-nIniSZbD9"
      },
      "source": [
        "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "metrics = tf.metrics.BinaryAccuracy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43XditrArW49"
      },
      "source": [
        "!pip install -q tf-models-official\n",
        "from official.nlp import optimization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaeiOJfzZB0F"
      },
      "source": [
        "training_epochs = 3\n",
        "\n",
        "steps_per_epoch = 32\n",
        "#steps_per_epoch = tf.data.experimental.cardinality(dataset).numpy()\n",
        "num_train_steps = steps_per_epoch * training_epochs\n",
        "num_warmup_steps = int(0.1*num_train_steps)\n",
        "\n",
        "#init_lr = 3e-5\n",
        "init_lr = 2e-5\n",
        "optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
        "                                          num_train_steps=num_train_steps,\n",
        "                                          num_warmup_steps=num_warmup_steps,\n",
        "                                          optimizer_type='adamw')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IuFfu-1LeDP"
      },
      "source": [
        "modelSimple.compile(loss=loss, optimizer=optimizer ,metrics=metrics)\n",
        "#modelSimple.compile(loss=loss, optimizer=optimizer ,metrics=metrics)#noch nicht probiert\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9NwPLrn8hI9"
      },
      "source": [
        "fit works with dataset -> from tensors, but not with from tensor_slices.. why?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "weZe8g7urGGu",
        "outputId": "ee98c216-d5a3-495c-af8b-f85228070c6e"
      },
      "source": [
        "modelSimple.fit(training_sentences[32:319], training_labels[32:319], batch_size=batch_size, epochs=training_epochs)\n",
        "#modelSimple.fit(whole_training_dataset.take(2), batch_size=batch_size, epochs=training_epochs)\n",
        "#modelSimple.fit(train_ds, batch_size=batch_size, epochs=training_epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 448s 47s/step - loss: 0.6756 - binary_accuracy: 0.5993\n",
            "Epoch 2/3\n",
            "3/9 [=========>....................] - ETA: 4:41 - loss: 0.6131 - binary_accuracy: 0.6562"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFtTag16cvJz"
      },
      "source": [
        "need to verify, if that still works..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iaakc1HMuHOI"
      },
      "source": [
        "#(loss,accuracy, metrics_recall, metrics_precision,\n",
        "#metrics_f1) = modelSimple.evaluate(testing_sentences, testing_labels, verbose=1)\n",
        "(metrics) = modelSimple.evaluate(testing_sentences[50:110], testing_labels[50:110], verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzjc-rMEuL16"
      },
      "source": [
        "BERTPredict=modelSimple.predict(x=testing_sentences[15:100])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qd_WGzTuMuYX"
      },
      "source": [
        "#for p in LSTM_predict80AE:\n",
        " # print(p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PluuAMv2MxlW"
      },
      "source": [
        "prediction_rounded = np.round(BERTPredict)\n",
        "\n",
        "for p in prediction_rounded:\n",
        "  print(p)\n",
        "\n",
        "\n",
        "#print(nptesting_labels[200:210])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfW_WcDlWsZv"
      },
      "source": [
        "https://deeplizard.com/learn/video/km7pxKy4UHU\n",
        "\n",
        "Quelle der def plot_confusion_matrix: https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZjt-y0-WrPZ"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5RUaFEcXmYc"
      },
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                        normalize=False,\n",
        "                        title='Confusion matrix',\n",
        "                        cmap=plt.cm.Blues):\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Mu7wle3Wr5S"
      },
      "source": [
        "cm = confusion_matrix(y_true=testing_labels[15:100], y_pred=prediction_rounded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcIt6FU7Wr_q"
      },
      "source": [
        "plot_labels = ['no hatespeech','hatespeech']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-K7cFJfWsGV"
      },
      "source": [
        "plot_confusion_matrix(cm=cm, classes=plot_labels, title='LSTM Confusion 60 with 9 epochs, batch size 40')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}