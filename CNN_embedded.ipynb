{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN embedded.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPQNPFg5xBZKPNINBCWYFAb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BiancaStadl/ProjektarbeitML/blob/main/CNN_embedded.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXDOlIBymF0V"
      },
      "source": [
        "GloVe embeddings taken from:\n",
        "\n",
        "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. [pdf] [bib]\n",
        "\n",
        "hatespeechdata taken from (https://hatespeechdata.com/): Wiegand, M., Siegel, M. and Ruppenhofer, J., 2018. Overview of the GermEval 2018 Shared Task on the Identification of Offensive Language. In: Proceedings of GermEval 2018, 14th Conference on Natural Language Processing (KONVENS 2018). Vienna, Austria: Research Gate. available on: https://github.com/uds-lsv/GermEval-2018-Data (last checked: 09.05.2021)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlBmABDxfqII"
      },
      "source": [
        "wiki detox..https://colab.research.google.com/github/tensorflow/fairness-indicators/blob/master/g3doc/tutorials/Fairness_Indicators_TFCO_Wiki_Case_Study.ipynb#scrollTo=y6T5tlXcdW7J "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3xfitNdliBI"
      },
      "source": [
        "#import matplotlib.pyplot as plt -> für evtl Visualisierungen\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import string\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from keras import losses \n",
        "from keras import optimizers \n",
        "from keras import metrics \n",
        "\n",
        "#!pip install Tokenizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "#!pip install pad_sequences\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import preprocessing\n",
        "#from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTWJQ1iga_vS"
      },
      "source": [
        "Maximale Satzlänge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bq08Me5la_Cc"
      },
      "source": [
        "\n",
        "max_length = 60"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVYBMvYSotTH"
      },
      "source": [
        "url = \"https://github.com/uds-lsv/GermEval-2018-Data/archive/master.zip\"\n",
        "\n",
        "dataset = tf.keras.utils.get_file(\"GermEval-2018-Data-master.zip\", url, \n",
        "                                   extract=True, cache_dir='.',\n",
        "                                    cache_subdir='')\n",
        "\n",
        "dataset_dir = os.path.join(os.path.dirname(dataset), 'GermEval-2018-Data-master')\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cS14OUtfo34V"
      },
      "source": [
        "#os.listdir(dataset_dir)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2X429K6hpOVm"
      },
      "source": [
        "training_file = os.path.join(dataset_dir, 'germeval2018.training.txt')\n",
        "\n",
        "testing_file = os.path.join(dataset_dir, 'germeval2018.test.txt')\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uq8fG3LNtn_m"
      },
      "source": [
        "###Aufbereitung\n",
        "txt-Dateien lesen, und dabei jede Zeile splitten und teilen\n",
        "Twitter-Handler entfernen?\n",
        "Labels von Sätzen trennen, Labels in eigenen Array packen.\n",
        "\n",
        "####Ressourcen\n",
        "* https://www.w3schools.com/python/gloss_python_if_statement.asp\n",
        "* https://stackabuse.com/using-regex-for-text-manipulation-in-python/\n",
        "* https://www.tutorialspoint.com/python/string_splitlines.htm \n",
        "* https://note.nkmk.me/en/python-split-rsplit-splitlines-re/ \n",
        "* https://www.w3schools.com/python/python_regex.asp \n",
        "\n",
        "gäbe bei keras tf.keras.preprocessing.text_dataset_from_directory, aber dafür müssten die Daten auf bestimmte Weise in Verzeichnis organisiert sein, hier nicht der Fall.\n",
        "\n",
        "\n",
        "Einteilung der Daten: Testdaten\n",
        "Trainingsdaten -> noch ca 500 für Validierungsdaten\n",
        "\n",
        "labels -> \"other\", also nicht-negative Aussagen bekommen \"0\", negative Aussagen bekommen \"1\"\n",
        "\n",
        " Regex für Emojis  ->\n",
        "\n",
        "(\\u00a9|\\u00ae|[\\u2000-\\u3300]|\\ud83c[\\ud000-\\udfff]|\\ud83d[\\ud000-\\udfff]|\\ud83e[\\ud000-\\udfff])\n",
        "\n",
        "genommen von https://www.regextester.com/106421 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Py_cwD4eZkXo"
      },
      "source": [
        "def remove_clutter(string):\n",
        "   string = re.sub(\"@[^\\s]+\",\" \",string)\n",
        "   string = re.sub(\"#[^\\s]+\",\" \", string)\n",
        "   string = re.sub(\"\\u00a9\",\" \", string)\n",
        "   string = re.sub(\"\\u00ae\",\" \", string)\n",
        "   string = re.sub(\"[\\u2000-\\u3300]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83c[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83d[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83e[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"😜\", \" \",string)\n",
        "   string = re.sub(\"🍫\", \" \",string)\n",
        "   string = re.sub(\"😁\", \" \",string)\n",
        "   string = re.sub(\"🐖\", \" \",string)\n",
        "   string = re.sub(\"😡\", \" \",string)\n",
        "   string = re.sub(\"😇\", \" \",string)\n",
        "   string = re.sub(\"😬\", \" \",string)\n",
        "   string = re.sub(\"😃\", \" \",string)\n",
        "   string = re.sub(\"😂\", \" \",string)\n",
        "   string = re.sub(\"💙\", \" \",string)  \n",
        "   string = re.sub(\"😛\", \" \",string)\n",
        "   string = re.sub(\"🙏\", \" \",string)\n",
        "   string = re.sub(\"👍\", \" \",string)\n",
        "   string = re.sub(\"🖕\", \" \",string)\n",
        "   string = re.sub(\"😉\", \" \",string)\n",
        "   string = re.sub(\"💩\", \" \",string)\n",
        "   string = re.sub(\"🤢\", \" \",string)\n",
        "   string = re.sub(\"👏\", \" \",string)\n",
        "   string = re.sub(\"😨\", \" \",string)\n",
        "   string = re.sub(\"🤣\", \" \",string)\n",
        "   string = re.sub(\"🤡\", \" \",string)\n",
        "   string = re.sub(\"😈\", \" \",string)\n",
        "   string = re.sub(\"💃🏽\", \" \",string)\n",
        "   string = re.sub(\"👹\", \" \",string)\n",
        "   string = re.sub(\"🤘\", \" \",string)\n",
        "   string = re.sub(\"😱\", \" \",string)\n",
        "   string = re.sub(\"🤔\", \" \",string) \n",
        "   string = re.sub(\"🌈\", \" \",string) \n",
        "   string = re.sub(\"💕\", \" \",string) \n",
        "   string = re.sub(\"👩‍❤️‍👩\", \" \",string) \n",
        "   string = re.sub(\"😍\", \" \",string) \n",
        "   string = re.sub(\"👆\", \" \",string) \n",
        "   string = re.sub(\"😖\", \" \",string) \n",
        "   string = re.sub(\"👇\", \" \",string) \n",
        "   string = re.sub(\"🔥\", \" \",string) \n",
        "   string = re.sub(\"😘\", \" \",string) \n",
        "   string = re.sub(\"🎉\", \" \",string) \n",
        "   string = re.sub(\"🤬\", \" \",string) \n",
        "   string = re.sub(\"👊\", \" \",string)\n",
        "   string = re.sub(\"🇩🇪\", \" \",string)  \n",
        "   string = re.sub(\"💔\", \" \",string)\n",
        "   string = re.sub(\"🙈\", \" \",string)\n",
        "   string = re.sub(\"🤯\", \" \",string)\n",
        "   string = re.sub(\"🐟\", \" \",string)\n",
        "   string = re.sub(\"🛶\", \" \",string)\n",
        "   string = re.sub(\"😊\", \" \",string)\n",
        "   string = re.sub(\"😓\", \" \",string)\n",
        "   string = re.sub(\"😳\", \" \",string)\n",
        "   string = re.sub(\"🚀\", \" \",string)\n",
        "   string = re.sub(\"👎\", \" \",string)\n",
        "   string = re.sub(\"😎\", \" \",string)\n",
        "   string = re.sub(\"🐸\", \" \",string)\n",
        "   string = re.sub(\"📈\", \" \",string)\n",
        "   string = re.sub(\"🙂\", \" \",string)\n",
        "   string = re.sub(\"😅\", \" \",string)\n",
        "   string = re.sub(\"😆\", \" \",string)\n",
        "   string = re.sub(\"🙎🏿\", \" \",string)\n",
        "   string = re.sub(\"👎🏽\", \" \",string)\n",
        "   string = re.sub(\"🤭\", \" \",string)\n",
        "   string = re.sub(\"😤\", \" \",string)\n",
        "   string = re.sub(\"😚\", \" \",string)\n",
        "   string = re.sub(\"😊\", \" \",string)\n",
        "   string = re.sub(\"😲\", \" \",string)\n",
        "   string = re.sub(\"🤮\", \" \",string)\n",
        "   string = re.sub(\"🙄\", \" \",string)\n",
        "   string = re.sub(\"🤑\", \" \",string)\n",
        "   string = re.sub(\"🎅\", \" \",string)\n",
        "   string = re.sub(\"👋\", \" \",string)\n",
        "   string = re.sub(\"💪\", \" \",string)\n",
        "   string = re.sub(\"😄\", \" \",string)\n",
        "   string = re.sub(\"🧐\", \" \",string)\n",
        "   string = re.sub(\"😠\", \" \",string)\n",
        "   string = re.sub(\"🎈\", \" \",string)\n",
        "   string = re.sub(\"🚂\", \" \",string)\n",
        "   string = re.sub(\"😊\", \" \",string)\n",
        "   string = re.sub(\"🚇\", \" \",string)\n",
        "   string = re.sub(\"🚊\", \" \",string)\n",
        "   string = re.sub(\"🤷\", \" \",string)\n",
        "   string = re.sub(\"😥\", \" \",string)\n",
        "   string = re.sub(\"🙃\", \" \",string)\n",
        "   string = re.sub(\"🔩\", \" \",string)\n",
        "   string = re.sub(\"🔧\", \" \",string)\n",
        "   string = re.sub(\"🔨\", \" \",string)\n",
        "   string = re.sub(\"🛠\", \" \",string)\n",
        "   string = re.sub(\"💓\", \" \",string)\n",
        "   string = re.sub(\"💡\", \" \",string)\n",
        "   string = re.sub(\"🍸\", \" \",string)\n",
        "   string = re.sub(\"🥃\", \" \",string)\n",
        "   string = re.sub(\"🥂\", \" \",string)\n",
        "   string = re.sub(\"😷\", \" \",string)\n",
        "   string = re.sub(\"🤐\", \" \",string)\n",
        "   string = re.sub(\"🌎\", \" \",string)\n",
        "   string = re.sub(\"👑\", \" \",string)\n",
        "   string = re.sub(\"🤛\", \" \",string)\n",
        "   string = re.sub(\"😀\", \" \",string)\n",
        "   string = re.sub(\"🛤\", \" \",string)\n",
        "   string = re.sub(\"🎄\", \" \",string)\n",
        "   string = re.sub(\"📴\", \" \",string)\n",
        "   string = re.sub(\"🌭\", \" \",string)\n",
        "   string = re.sub(\"🤕\", \" \",string)\n",
        "   string = re.sub(\"😭\", \" \",string)\n",
        "   string = re.sub(\"🍾\", \" \",string)\n",
        "   string = re.sub(\"🍞\", \" \",string)\n",
        "   string = re.sub(\"🤦\", \" \",string)\n",
        "   string = re.sub(\"🤯\", \" \",string)\n",
        "   string = re.sub(\"🕯️\", \" \",string)\n",
        "\n",
        "   string = re.sub(\"OTHER|OFFENSE|ABUSE|INSULT\",\" \",string)\n",
        "   return string"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5asMgo4LtnRg"
      },
      "source": [
        "statementsForTraining = []\n",
        "sentimentsForTraining = []\n",
        "\n",
        "\n",
        "fileToRead = open(training_file, 'r')\n",
        "\n",
        "while True:\n",
        "  #next line in file\n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  findSentiment = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "\n",
        "\n",
        "  statementsForTraining.append(line)\n",
        "   #sentimentsForTraining.append(findSentiment.group(0))\n",
        "\n",
        "  if findSentiment.group(0) == \"OTHER\":  \n",
        "    sentimentsForTraining.append(0)\n",
        "  else:\n",
        "    sentimentsForTraining.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        " #print(\"{}: {}\".format(count,line.strip()))\n",
        "  \n",
        " # print(sentiment.group(0))\n",
        " \n",
        "fileToRead.close()\n",
        "\n",
        "training_sentences = statementsForTraining\n",
        "training_labels = sentimentsForTraining\n",
        "\n",
        "#print(training_sentences[9])\n",
        "#print(training_labels[9])\n",
        "\n",
        "#print(len(training_sentences))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsqZPENb98gD"
      },
      "source": [
        "##do the same with testdata\n",
        "statementsForTesting = []\n",
        "sentimentsForTesting = []\n",
        "\n",
        "fileToRead = open(testing_file, 'r')\n",
        "\n",
        "while True:\n",
        "  #next line in file\n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  sent = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "\n",
        "    \n",
        "\n",
        "  statementsForTesting.append(line)\n",
        "  #print(len(line))\n",
        "  #sentimentsForTesting.append(sent.group(0))\n",
        "\n",
        "  if sent.group(0) == \"OTHER\": \n",
        "    sentimentsForTesting.append(0)\n",
        "  else:\n",
        "    sentimentsForTesting.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        "\n",
        "fileToRead.close()\n",
        "\n",
        "\n",
        "testing_sentences = statementsForTesting\n",
        "testing_labels = sentimentsForTesting\n",
        "#print(len(testing_sentences))\n",
        "#print(testing_sentences)   \n",
        "#print(testing_labels)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRUvDLD5bMbO"
      },
      "source": [
        "Padding -> im Prinzip die Sätze alle auf die gleiche Länge bringen (in Theorieteil näher drauf eingehen) -> maxlen-Paramter ist für pad_sequences vorhanden, wenn nicht gesetzt -> alles wird auf die Länge des längsten Satzes aufgefüllt -> print(padded(shape)) gibt aus, wie viele Datensätze padded wurden und gibt an, wie viele Tokens der längste Datensatz hat\n",
        "print(padded[x]) gibt einen Satz aus (bereits tokenisiert)\n",
        "\n",
        "Padding -> sowohl für Trainigs- als auch für Testdaten\n",
        "\n",
        "Und: Daten als numpy-Arrays speichern (notwendig für tensorflow).\n",
        "\n",
        " -> Tokenizer https://towardsdatascience.com/text-classification-in-keras-part-2-how-to-use-the-keras-tokenizer-word-representations-fd571674df23 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3hFi7waTv5m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa0dab69-f297-4ec5-facb-347ac1707f43"
      },
      "source": [
        "tokenizer = Tokenizer(oov_token=\"OOV\")\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "\n",
        "#creating a word index - nur die Trainigsdaten\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "validation_size = 500\n",
        "\n",
        "\n",
        "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "padded_training = pad_sequences(training_sequences, maxlen=max_length, padding='post')\n",
        "print(len(padded_training))\n",
        "\n",
        "validation_sequences = padded_training[0:validation_size]\n",
        "validation_labels = training_labels[0:validation_size]\n",
        "\n",
        "padded_training = padded_training[validation_size:]\n",
        "training_labels = training_labels[validation_size:]\n",
        "\n",
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
        "padded_testing = pad_sequences(testing_sequences, maxlen=max_length,  padding='post')\n",
        "\n",
        "#print(validation_sequences[499])\n",
        "print(padded_training[0])\n",
        "#print(len(validation_labels))\n",
        "#print(len(training_labels))\n",
        "\n",
        "\n",
        "nppadded_training = np.array(padded_training)\n",
        "nptraining_labels = np.array(training_labels)\n",
        "\n",
        "nppadded_validation = np.array(validation_sequences)\n",
        "npvalidation_labels = np.array(validation_labels)\n",
        "\n",
        "nppadded_testing = np.array(padded_testing)\n",
        "nptesting_labels = np.array(testing_labels)\n",
        "\n",
        "\n",
        "print(len(nppadded_training))\n",
        "print(len(nptraining_labels))\n",
        "print(len(word_index))\n",
        "\n",
        "#print(statementsForTraining[2])\n",
        "#print(nppadded_training[4])\n",
        "#print(nppadded_training.shape)\n",
        "#print(nptraining_labels[4])\n",
        "#print(nppadded_testing.shape)\n",
        "#print(word_index) \n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5009\n",
            "[  12 3982   11   41 6706 1040    4    5  202   39    3 2922   49 1360\n",
            "  810  495 3983    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0]\n",
            "4509\n",
            "4509\n",
            "15059\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tL3owrc8THkT"
      },
      "source": [
        "\n",
        "Dann: Embedding mit entweder word2vec oder glove\n",
        "Word2vec-Daten sind hier: http://vectors.nlpl.eu/repository/#\n",
        "Glove -> https://nlp.stanford.edu/projects/glove/ Da mal den Twitter-Vector runtergeladen\n",
        "Wenn Daten in GoogleDrive sind (wäre auch via url möglich..), muss Drive gemounted werden ( https://buomsoo-kim.github.io/colab/2020/05/09/Colab-mounting-google-drive.md/ ) aber auch hier https://enjoymachinelearning.com/posts/colab-with-google-drive/\n",
        "\n",
        "Die Word2vec vectors: http://vectors.nlpl.eu/repository/# \n",
        "\n",
        "glove-zitat:\n",
        "Citing GloVe\n",
        "\n",
        "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. [pdf] [bib]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zuO7T9ZTG57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f43b6303-f5b8-47cc-da94-ace9008fd9dc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "os.listdir(\"/content/drive/MyDrive/Colab Notebooks\")\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['germeval_training.txt',\n",
              " 'glove.twitter.27B.50d.txt',\n",
              " 'glove.twitter.27B.200d.txt',\n",
              " 'glove.6B.200d.txt',\n",
              " 'glove.840B.300d.txt',\n",
              " 'tensorboard.gdoc',\n",
              " 'keras.gdoc',\n",
              " 'Vectorization CNN embedded_limited_vocab.ipynb',\n",
              " 'glove.42B.300d.txt',\n",
              " 'Embedding Glove Vergleich.ipynb',\n",
              " 'LSTM.ipynb',\n",
              " 'CNN embedded_limited_vocab.ipynb',\n",
              " 'LSTM_limited_vocab.ipynb',\n",
              " 'CNN embedded.ipynb']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7ToKO-sZLHK"
      },
      "source": [
        "\n",
        "Keras-Doc : https://keras.io/examples/nlp/pretrained_word_embeddings/#load-pretrained-word-embeddings \n",
        "embedding mit initializers.. weights müsste auch funktionieren\n",
        "\n",
        "Diese erstellte Matrix mit Embedding dann in die Embedding-Schicht einbinden,  Trainable auf False, weil sich die Werte nicht durch Training anpassen sollen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AShIVfC7ZQAH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c62379c4-444f-41b4-a048-d7195fbb1c9b"
      },
      "source": [
        "#Größe Vokabel -> wordindex + 2 (weil padding + OOV) \n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "vocabulary_size = len(word_index)+2\n",
        "\n",
        "# dann erstell ich ein Wörterbuch mit Namen \"embedding_vector\", dort sind dann\n",
        "#die keys drinnen, die in glove-Datei drinnen sind mit dem entsprechenden Key\n",
        "\n",
        "embedding_index_glove = {}\n",
        "f = open('/content/drive/MyDrive/Colab Notebooks/glove.twitter.27B.200d.txt')\n",
        "for line in f:\n",
        "  value = line.split()\n",
        "  word = value[0]\n",
        "  coef = np.asarray(value[1:],dtype='float32')\n",
        "  embedding_index_glove[word] = coef\n",
        "\n",
        "print(\"%d gefunden: \"% len(embedding_index_glove))\n",
        "\n",
        "#Dann noch eine Embedding-Matrix erstellen\n",
        "#zweiter Wert = Embedding-Dimension der Datei, in dem Fall 200\n",
        "\n",
        "glove_matrix = np.zeros((vocabulary_size,200))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    embedding_value = embedding_index_glove.get(word)\n",
        "    if embedding_value is not None:\n",
        "      glove_matrix[index] = embedding_value\n",
        "      hits+=1\n",
        "    else:\n",
        "      misses+=1\n",
        "\n",
        "print(\"hits %d and %d misses\"%(hits,misses))\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1193514 gefunden: \n",
            "hits 6747 and 8312 misses\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZmvOfwhV4N5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fd5dbf8-2ecb-43b8-d788-cefc5589b05c"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "print(\"vocab size: %d\"%vocabulary_size)\n",
        "CNN16052102 = tf.keras.Sequential()\n",
        "#Embedding -> hier dann auf das embedding verweisen, Input_dim -> die Anzahl der Wörter im word_index, output -> in dem Fall passend zum verwendeten Vektor\n",
        "#input-length -> auf 60  gepadded, trainable -> nein, weil nichts verändert werden soll\n",
        "#embeddings_initializer=keras.initializers.Constant(glove_matrix) vs weights = [glove_matrix]\n",
        "#Convolutional layers => filters = neurons.. mit 100? 265?\n",
        "CNN16052102.add(tf.keras.layers.Embedding(vocabulary_size, output_dim=200, input_length=60, embeddings_initializer = keras.initializers.Constant(glove_matrix), trainable= False))\n",
        "CNN16052102.add(tf.keras.layers.Dropout(0.4))\n",
        "CNN16052102.add(tf.keras.layers.Conv1D(filters=90, kernel_size=3, padding=\"valid\", activation=\"relu\"))\n",
        "CNN16052102.add(tf.keras.layers.MaxPooling1D())\n",
        "CNN16052102.add(tf.keras.layers.Conv1D(filters=90, kernel_size=3, padding=\"valid\", activation=\"relu\"))\n",
        "CNN16052102.add(tf.keras.layers.GlobalAveragePooling1D())\n",
        "CNN16052102.add(tf.keras.layers.Flatten())\n",
        "CNN16052102.add(tf.keras.layers.Dense(260, activation=\"relu\"))\n",
        "CNN16052102.add(tf.keras.layers.Dropout(0.4))\n",
        "CNN16052102.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "CNN16052102.summary()\n",
        "\n",
        "#nppadded_training = np.asmatrix(nppadded_training) not necessary\n",
        "#nppadded_testing = np.asmatrix(nppadded_testing)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab size: 15061\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 60, 200)           3012200   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 60, 200)           0         \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 58, 90)            54090     \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 29, 90)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 27, 90)            24390     \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 90)                0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 90)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 260)               23660     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 260)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 261       \n",
            "=================================================================\n",
            "Total params: 3,114,601\n",
            "Trainable params: 102,401\n",
            "Non-trainable params: 3,012,200\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEr4OzT-iHDe"
      },
      "source": [
        "#model.layers[2].get_weights()[0].shape\n",
        "#weights=np.random.rand(5,200,100)\n",
        "#bias=np.random.rand(100)\n",
        "#model.layers[2].set_weights([weights, bias])\n",
        "\n",
        "#model.layers[2].get_weights()[0]\n",
        "#https://androidkt.com/set-custom-weights-keras-using-numpy-array/"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UB7_3VPYesr9"
      },
      "source": [
        "F1-Score für jede Epoche https://aakashgoel12.medium.com/how-to-add-user-defined-function-get-f1-score-in-keras-metrics-3013f979ce0d\n",
        "\n",
        "Sehr gute Ressource für die verschiedenen Scores und Metriken https://neptune.ai/blog/evaluation-metrics-binary-classification#10  das und aakas verwendet\n",
        "\n",
        "hier: je eine Funktion für Recall, Precision, f1 https://neptune.ai/blog/keras-metrics \n",
        "\n",
        "https://keras.rstudio.com/reference/k_ones_like.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygyrbFJaMV9B"
      },
      "source": [
        "import keras.backend as K\n",
        "\n",
        "def metrics_recall(data_true, data_pred):\n",
        "    data_true = K.ones_like(data_true)\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(data_true,0,1)))\n",
        "\n",
        "    recall = true_positives / (possible_positives+K.epsilon())\n",
        "    return recall\n",
        "\n",
        "\n",
        "def metrics_precision(data_true, data_pred):\n",
        "    data_true = K.ones_like(data_true)\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "\n",
        "    positives_predicted = K.sum(K.round(K.clip(data_pred,0,1)))\n",
        "    precision = true_positives / (positives_predicted+K.epsilon())\n",
        "    return precision\n",
        "\n",
        "\n",
        "def metrics_f1(data_true, data_pred):\n",
        "    precision_data = metrics_precision(data_true, data_pred)\n",
        "    recall_data = metrics_recall(data_true, data_pred)\n",
        "    return 2*(precision_data*recall_data)/(precision_data+recall_data+K.epsilon())"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AfPD3_bWCm0"
      },
      "source": [
        "CNN16052102.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',metrics_recall,metrics_precision,metrics_f1])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpChKUY-QEWI"
      },
      "source": [
        "https://www.tensorflow.org/tensorboard/tensorboard_in_notebooks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJfMgUhHBoD1"
      },
      "source": [
        "#%reload_ext tensorboard\n",
        "#nur einmal pro Sitzung notwendig\n",
        "\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ISmMXLqP8Hc"
      },
      "source": [
        "\n",
        "logs_base_dir = \"./logs\"\n",
        "callbackForTB = tf.keras.callbacks.TensorBoard(logs_base_dir)\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2CHbXiP1LsF"
      },
      "source": [
        "training_epochs = 30\n",
        "batch_size = 40\n",
        "validation_split=0.2"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abV-QAxfW48r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "941cc211-6a7f-463e-d0e4-0863803f907b"
      },
      "source": [
        "#Werte der Convolutional-Schichten variieren (Filter), Batch-Size variieren, kernel-size..\n",
        "CNN16052102.fit(nppadded_training, nptraining_labels, batch_size=batch_size, validation_split=validation_split, epochs=training_epochs, callbacks=[callbackForTB])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "91/91 [==============================] - 4s 36ms/step - loss: 0.6597 - accuracy: 0.6435 - metrics_recall: 0.0448 - metrics_precision: 0.0719 - metrics_f1: 0.0501 - val_loss: 0.6361 - val_accuracy: 0.6718 - val_metrics_recall: 0.0000e+00 - val_metrics_precision: 0.0000e+00 - val_metrics_f1: 0.0000e+00\n",
            "Epoch 2/30\n",
            "91/91 [==============================] - 3s 31ms/step - loss: 0.6428 - accuracy: 0.6515 - metrics_recall: 6.3668e-04 - metrics_precision: 0.0187 - metrics_f1: 0.0012 - val_loss: 0.6059 - val_accuracy: 0.6729 - val_metrics_recall: 0.0163 - val_metrics_precision: 0.4783 - val_metrics_f1: 0.0313\n",
            "Epoch 3/30\n",
            "91/91 [==============================] - 3s 31ms/step - loss: 0.6036 - accuracy: 0.6695 - metrics_recall: 0.0698 - metrics_precision: 0.5484 - metrics_f1: 0.1139 - val_loss: 0.5864 - val_accuracy: 0.6929 - val_metrics_recall: 0.0498 - val_metrics_precision: 0.9130 - val_metrics_f1: 0.0929\n",
            "Epoch 4/30\n",
            "91/91 [==============================] - 3s 30ms/step - loss: 0.5891 - accuracy: 0.6698 - metrics_recall: 0.1240 - metrics_precision: 0.8795 - metrics_f1: 0.2059 - val_loss: 0.6068 - val_accuracy: 0.6763 - val_metrics_recall: 0.3010 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.4568\n",
            "Epoch 5/30\n",
            "91/91 [==============================] - 3s 30ms/step - loss: 0.5704 - accuracy: 0.7025 - metrics_recall: 0.1765 - metrics_precision: 0.9705 - metrics_f1: 0.2811 - val_loss: 0.5825 - val_accuracy: 0.6918 - val_metrics_recall: 0.3424 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.5040\n",
            "Epoch 6/30\n",
            "91/91 [==============================] - 3s 31ms/step - loss: 0.5420 - accuracy: 0.7220 - metrics_recall: 0.1952 - metrics_precision: 0.9799 - metrics_f1: 0.3066 - val_loss: 0.5741 - val_accuracy: 0.6818 - val_metrics_recall: 0.4013 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.5687\n",
            "Epoch 7/30\n",
            "91/91 [==============================] - 3s 31ms/step - loss: 0.5349 - accuracy: 0.7257 - metrics_recall: 0.2363 - metrics_precision: 0.9998 - metrics_f1: 0.3645 - val_loss: 0.5421 - val_accuracy: 0.7173 - val_metrics_recall: 0.1542 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.2612\n",
            "Epoch 8/30\n",
            "91/91 [==============================] - 3s 30ms/step - loss: 0.4961 - accuracy: 0.7575 - metrics_recall: 0.2397 - metrics_precision: 0.9998 - metrics_f1: 0.3767 - val_loss: 0.5564 - val_accuracy: 0.7195 - val_metrics_recall: 0.1099 - val_metrics_precision: 0.9565 - val_metrics_f1: 0.1934\n",
            "Epoch 9/30\n",
            "91/91 [==============================] - 3s 31ms/step - loss: 0.4738 - accuracy: 0.7721 - metrics_recall: 0.2578 - metrics_precision: 1.0000 - metrics_f1: 0.3954 - val_loss: 0.5423 - val_accuracy: 0.7328 - val_metrics_recall: 0.3026 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.4587\n",
            "Epoch 10/30\n",
            "91/91 [==============================] - 3s 31ms/step - loss: 0.4303 - accuracy: 0.7966 - metrics_recall: 0.2966 - metrics_precision: 1.0000 - metrics_f1: 0.4458 - val_loss: 0.5397 - val_accuracy: 0.7251 - val_metrics_recall: 0.2289 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.3666\n",
            "Epoch 11/30\n",
            "91/91 [==============================] - 3s 31ms/step - loss: 0.4276 - accuracy: 0.8082 - metrics_recall: 0.2987 - metrics_precision: 1.0000 - metrics_f1: 0.4475 - val_loss: 0.5433 - val_accuracy: 0.7284 - val_metrics_recall: 0.2852 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.4382\n",
            "Epoch 12/30\n",
            "91/91 [==============================] - 3s 30ms/step - loss: 0.3723 - accuracy: 0.8298 - metrics_recall: 0.2976 - metrics_precision: 1.0000 - metrics_f1: 0.4538 - val_loss: 0.5647 - val_accuracy: 0.7262 - val_metrics_recall: 0.2308 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.3690\n",
            "Epoch 13/30\n",
            "91/91 [==============================] - 3s 31ms/step - loss: 0.3819 - accuracy: 0.8269 - metrics_recall: 0.3103 - metrics_precision: 1.0000 - metrics_f1: 0.4610 - val_loss: 0.5736 - val_accuracy: 0.7251 - val_metrics_recall: 0.1901 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.3136\n",
            "Epoch 14/30\n",
            "91/91 [==============================] - 3s 30ms/step - loss: 0.3302 - accuracy: 0.8509 - metrics_recall: 0.2932 - metrics_precision: 1.0000 - metrics_f1: 0.4443 - val_loss: 0.5517 - val_accuracy: 0.7317 - val_metrics_recall: 0.2493 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.3924\n",
            "Epoch 15/30\n",
            "91/91 [==============================] - 3s 31ms/step - loss: 0.3233 - accuracy: 0.8563 - metrics_recall: 0.2957 - metrics_precision: 0.9998 - metrics_f1: 0.4486 - val_loss: 0.6054 - val_accuracy: 0.7206 - val_metrics_recall: 0.1950 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.3197\n",
            "Epoch 16/30\n",
            "91/91 [==============================] - 3s 31ms/step - loss: 0.3002 - accuracy: 0.8645 - metrics_recall: 0.2876 - metrics_precision: 1.0000 - metrics_f1: 0.4372 - val_loss: 0.6164 - val_accuracy: 0.7317 - val_metrics_recall: 0.2763 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.4267\n",
            "Epoch 17/30\n",
            "91/91 [==============================] - 3s 31ms/step - loss: 0.2639 - accuracy: 0.8904 - metrics_recall: 0.3109 - metrics_precision: 1.0000 - metrics_f1: 0.4682 - val_loss: 0.5975 - val_accuracy: 0.7262 - val_metrics_recall: 0.2978 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.4535\n",
            "Epoch 18/30\n",
            "91/91 [==============================] - 3s 31ms/step - loss: 0.2660 - accuracy: 0.8905 - metrics_recall: 0.3220 - metrics_precision: 1.0000 - metrics_f1: 0.4797 - val_loss: 0.6585 - val_accuracy: 0.7018 - val_metrics_recall: 0.4300 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.5951\n",
            "Epoch 19/30\n",
            "91/91 [==============================] - 3s 31ms/step - loss: 0.2657 - accuracy: 0.8916 - metrics_recall: 0.3419 - metrics_precision: 1.0000 - metrics_f1: 0.5007 - val_loss: 0.6497 - val_accuracy: 0.7051 - val_metrics_recall: 0.3458 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.5088\n",
            "Epoch 20/30\n",
            "91/91 [==============================] - 3s 31ms/step - loss: 0.2609 - accuracy: 0.8897 - metrics_recall: 0.3132 - metrics_precision: 1.0000 - metrics_f1: 0.4689 - val_loss: 0.6480 - val_accuracy: 0.7350 - val_metrics_recall: 0.2517 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.3974\n",
            "Epoch 21/30\n",
            "91/91 [==============================] - 3s 31ms/step - loss: 0.2302 - accuracy: 0.9049 - metrics_recall: 0.3146 - metrics_precision: 1.0000 - metrics_f1: 0.4729 - val_loss: 0.6246 - val_accuracy: 0.7118 - val_metrics_recall: 0.3158 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.4768\n",
            "Epoch 22/30\n",
            "91/91 [==============================] - 3s 31ms/step - loss: 0.2258 - accuracy: 0.9107 - metrics_recall: 0.3390 - metrics_precision: 1.0000 - metrics_f1: 0.5017 - val_loss: 0.6864 - val_accuracy: 0.7195 - val_metrics_recall: 0.3444 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.5056\n",
            "Epoch 23/30\n",
            "91/91 [==============================] - 3s 31ms/step - loss: 0.1949 - accuracy: 0.9243 - metrics_recall: 0.3344 - metrics_precision: 0.9998 - metrics_f1: 0.4951 - val_loss: 0.7226 - val_accuracy: 0.7106 - val_metrics_recall: 0.2377 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.3791\n",
            "Epoch 24/30\n",
            "91/91 [==============================] - 3s 31ms/step - loss: 0.2124 - accuracy: 0.9038 - metrics_recall: 0.3223 - metrics_precision: 1.0000 - metrics_f1: 0.4790 - val_loss: 0.7081 - val_accuracy: 0.7140 - val_metrics_recall: 0.3154 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.4734\n",
            "Epoch 25/30\n",
            "91/91 [==============================] - 3s 32ms/step - loss: 0.1836 - accuracy: 0.9292 - metrics_recall: 0.3237 - metrics_precision: 1.0000 - metrics_f1: 0.4831 - val_loss: 0.8064 - val_accuracy: 0.6774 - val_metrics_recall: 0.4722 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.6372\n",
            "Epoch 26/30\n",
            "91/91 [==============================] - 3s 31ms/step - loss: 0.2074 - accuracy: 0.9098 - metrics_recall: 0.3509 - metrics_precision: 1.0000 - metrics_f1: 0.5112 - val_loss: 0.7147 - val_accuracy: 0.7140 - val_metrics_recall: 0.3719 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.5388\n",
            "Epoch 27/30\n",
            "91/91 [==============================] - 3s 31ms/step - loss: 0.1632 - accuracy: 0.9321 - metrics_recall: 0.3210 - metrics_precision: 1.0000 - metrics_f1: 0.4807 - val_loss: 0.7546 - val_accuracy: 0.7040 - val_metrics_recall: 0.3339 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.4958\n",
            "Epoch 28/30\n",
            "91/91 [==============================] - 3s 31ms/step - loss: 0.1753 - accuracy: 0.9294 - metrics_recall: 0.3137 - metrics_precision: 1.0000 - metrics_f1: 0.4719 - val_loss: 0.8009 - val_accuracy: 0.7007 - val_metrics_recall: 0.4159 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.5835\n",
            "Epoch 29/30\n",
            "91/91 [==============================] - 3s 31ms/step - loss: 0.1712 - accuracy: 0.9281 - metrics_recall: 0.3405 - metrics_precision: 1.0000 - metrics_f1: 0.5034 - val_loss: 0.8061 - val_accuracy: 0.6973 - val_metrics_recall: 0.3953 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.5614\n",
            "Epoch 30/30\n",
            "91/91 [==============================] - 3s 31ms/step - loss: 0.1480 - accuracy: 0.9417 - metrics_recall: 0.3247 - metrics_precision: 1.0000 - metrics_f1: 0.4850 - val_loss: 0.7511 - val_accuracy: 0.7206 - val_metrics_recall: 0.3380 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.5015\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5068ffb710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJVL4SBLPB2P"
      },
      "source": [
        "#%tensorboard --logdir {logs_base_dir}"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_LnvWBcnoak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5963f250-6411-4290-c956-02521091229d"
      },
      "source": [
        "#results = model.evaluate(nppadded_testing, nptesting_labels, batch_size=batch_size)\n",
        "#print(\"test loss, test acc:\",results)\n",
        "\n",
        "(loss,accuracy, metrics_recall, metrics_precision,\n",
        "metrics_f1) = CNN16052102.evaluate(nppadded_testing, nptesting_labels, verbose=1)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "111/111 [==============================] - 1s 8ms/step - loss: 0.8243 - accuracy: 0.6789 - metrics_recall: 0.2743 - metrics_precision: 1.0000 - metrics_f1: 0.4234\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KgjIkhpKmHc"
      },
      "source": [
        "make some predictions of test data and save it to variable. verbose=0 -> do not generate output\n",
        "Gute Quelle: https://deeplizard.com/learn/video/2f-NjDUvZIE "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89GWuxryKlcM"
      },
      "source": [
        "CNN_predictions = CNN16052102.predict(x=nppadded_testing)\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3jPDaDJK_cN"
      },
      "source": [
        "#for p in CNN_predictions:\n",
        " # print(p)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eC9efJy4Lp21"
      },
      "source": [
        "rounded predictions: give prediction value of most likely prediction (0 or 1). Printing the output of rounded prediction shows the prediction made by the model on the data (which output is most likely)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsG-TJuQLvtk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e4546ff-ab63-4b6a-8188-f81cfea8410a"
      },
      "source": [
        "prediction_rounded = np.round(CNN_predictions)\n",
        "#np.argmax(CNN_predictions,axis=-1)\n",
        "\n",
        "#for p in prediction_rounded:\n",
        " # print(p)\n",
        "\n",
        "\n",
        "print(nptesting_labels[500:520])\n",
        "print(prediction_rounded[500:520])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1]\n",
            "[[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egTtgpXgg8a2"
      },
      "source": [
        "https://deeplizard.com/learn/video/km7pxKy4UHU\n",
        "\n",
        "Quelle der def plot_confusion_matrix: https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSDXf7-_MITy"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0AMs1EzhBU1"
      },
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                        normalize=False,\n",
        "                        title='Confusion matrix',\n",
        "                        cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2JgEnlghCtl"
      },
      "source": [
        "cm = confusion_matrix(y_true=nptesting_labels, y_pred=prediction_rounded)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckmF29whhFmX"
      },
      "source": [
        "plot_labels = ['no hatespeech','hatespeech']"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "2mpSE96rhK7K",
        "outputId": "02eb79c1-db8b-4a1b-fd98-a960c3518901"
      },
      "source": [
        "plot_confusion_matrix(cm=cm, classes=plot_labels, title='CNN Confusion 90')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix, without normalization\n",
            "[[1881  449]\n",
            " [ 685  517]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}