{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN embedded.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNNw83HY9QI0ys4tN8pjbCQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BiancaStadl/ProjektarbeitML/blob/main/CNN_embedded.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXDOlIBymF0V"
      },
      "source": [
        "GloVe embeddings taken from:\n",
        "\n",
        "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. [pdf] [bib]\n",
        "\n",
        "hatespeechdata taken from (https://hatespeechdata.com/): Wiegand, M., Siegel, M. and Ruppenhofer, J., 2018. Overview of the GermEval 2018 Shared Task on the Identification of Offensive Language. In: Proceedings of GermEval 2018, 14th Conference on Natural Language Processing (KONVENS 2018). Vienna, Austria: Research Gate. available on: https://github.com/uds-lsv/GermEval-2018-Data (last checked: 09.05.2021)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlBmABDxfqII"
      },
      "source": [
        "wiki detox..https://colab.research.google.com/github/tensorflow/fairness-indicators/blob/master/g3doc/tutorials/Fairness_Indicators_TFCO_Wiki_Case_Study.ipynb#scrollTo=y6T5tlXcdW7J "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3xfitNdliBI"
      },
      "source": [
        "#import matplotlib.pyplot as plt -> für evtl Visualisierungen\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import string\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from keras import losses \n",
        "from keras import optimizers \n",
        "from keras import metrics \n",
        "\n",
        "#!pip install Tokenizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "#!pip install pad_sequences\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import preprocessing\n",
        "#from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTWJQ1iga_vS"
      },
      "source": [
        "Maximale Satzlänge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bq08Me5la_Cc"
      },
      "source": [
        "\n",
        "max_length = 60"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVYBMvYSotTH"
      },
      "source": [
        "url = \"https://github.com/uds-lsv/GermEval-2018-Data/archive/master.zip\"\n",
        "\n",
        "dataset = tf.keras.utils.get_file(\"GermEval-2018-Data-master.zip\", url, \n",
        "                                   extract=True, cache_dir='.',\n",
        "                                    cache_subdir='')\n",
        "\n",
        "dataset_dir = os.path.join(os.path.dirname(dataset), 'GermEval-2018-Data-master')\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cS14OUtfo34V"
      },
      "source": [
        "#os.listdir(dataset_dir)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2X429K6hpOVm"
      },
      "source": [
        "training_file = os.path.join(dataset_dir, 'germeval2018.training.txt')\n",
        "\n",
        "testing_file = os.path.join(dataset_dir, 'germeval2018.test.txt')\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uq8fG3LNtn_m"
      },
      "source": [
        "###Aufbereitung\n",
        "txt-Dateien lesen, und dabei jede Zeile splitten und teilen\n",
        "Twitter-Handler entfernen?\n",
        "Labels von Sätzen trennen, Labels in eigenen Array packen.\n",
        "\n",
        "####Ressourcen\n",
        "* https://www.w3schools.com/python/gloss_python_if_statement.asp\n",
        "* https://stackabuse.com/using-regex-for-text-manipulation-in-python/\n",
        "* https://www.tutorialspoint.com/python/string_splitlines.htm \n",
        "* https://note.nkmk.me/en/python-split-rsplit-splitlines-re/ \n",
        "* https://www.w3schools.com/python/python_regex.asp \n",
        "\n",
        "gäbe bei keras tf.keras.preprocessing.text_dataset_from_directory, aber dafür müssten die Daten auf bestimmte Weise in Verzeichnis organisiert sein, hier nicht der Fall.\n",
        "\n",
        "\n",
        "Einteilung der Daten: Testdaten\n",
        "Trainingsdaten -> noch ca 500 für Validierungsdaten\n",
        "\n",
        "labels -> \"other\", also nicht-negative Aussagen bekommen \"0\", negative Aussagen bekommen \"1\"\n",
        "\n",
        " Regex für Emojis  ->\n",
        "\n",
        "(\\u00a9|\\u00ae|[\\u2000-\\u3300]|\\ud83c[\\ud000-\\udfff]|\\ud83d[\\ud000-\\udfff]|\\ud83e[\\ud000-\\udfff])\n",
        "\n",
        "genommen von https://www.regextester.com/106421 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Py_cwD4eZkXo"
      },
      "source": [
        "def remove_clutter(string):\n",
        "   string = re.sub(\"@[^\\s]+\",\" \",string)\n",
        "   string = re.sub(\"#[^\\s]+\",\" \", string)\n",
        "   string = re.sub(\"\\u00a9\",\" \", string)\n",
        "   string = re.sub(\"\\u00ae\",\" \", string)\n",
        "   string = re.sub(\"[\\u2000-\\u3300]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83c[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83d[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83e[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"😜\", \" \",string)\n",
        "   string = re.sub(\"🍫\", \" \",string)\n",
        "   string = re.sub(\"😁\", \" \",string)\n",
        "   string = re.sub(\"🐖\", \" \",string)\n",
        "   string = re.sub(\"😡\", \" \",string)\n",
        "   string = re.sub(\"😇\", \" \",string)\n",
        "   string = re.sub(\"😬\", \" \",string)\n",
        "   string = re.sub(\"😃\", \" \",string)\n",
        "   string = re.sub(\"😂\", \" \",string)\n",
        "   string = re.sub(\"💙\", \" \",string)  \n",
        "   string = re.sub(\"😛\", \" \",string)\n",
        "   string = re.sub(\"🙏\", \" \",string)\n",
        "   string = re.sub(\"👍\", \" \",string)\n",
        "   string = re.sub(\"🖕\", \" \",string)\n",
        "   string = re.sub(\"😉\", \" \",string)\n",
        "   string = re.sub(\"💩\", \" \",string)\n",
        "   string = re.sub(\"🤢\", \" \",string)\n",
        "   string = re.sub(\"👏\", \" \",string)\n",
        "   string = re.sub(\"😨\", \" \",string)\n",
        "   string = re.sub(\"🤣\", \" \",string)\n",
        "   string = re.sub(\"🤡\", \" \",string)\n",
        "   string = re.sub(\"😈\", \" \",string)\n",
        "   string = re.sub(\"💃🏽\", \" \",string)\n",
        "   string = re.sub(\"👹\", \" \",string)\n",
        "   string = re.sub(\"🤘\", \" \",string)\n",
        "   string = re.sub(\"😱\", \" \",string)\n",
        "   string = re.sub(\"🤔\", \" \",string) \n",
        "   string = re.sub(\"🌈\", \" \",string) \n",
        "   string = re.sub(\"💕\", \" \",string) \n",
        "   string = re.sub(\"👩‍❤️‍👩\", \" \",string) \n",
        "   string = re.sub(\"😍\", \" \",string) \n",
        "   string = re.sub(\"👆\", \" \",string) \n",
        "   string = re.sub(\"😖\", \" \",string) \n",
        "   string = re.sub(\"👇\", \" \",string) \n",
        "   string = re.sub(\"🔥\", \" \",string) \n",
        "   string = re.sub(\"😘\", \" \",string) \n",
        "   string = re.sub(\"🎉\", \" \",string) \n",
        "   string = re.sub(\"🤬\", \" \",string) \n",
        "   string = re.sub(\"👊\", \" \",string)\n",
        "   string = re.sub(\"🇩🇪\", \" \",string)  \n",
        "   string = re.sub(\"💔\", \" \",string)\n",
        "   string = re.sub(\"🙈\", \" \",string)\n",
        "   string = re.sub(\"🤯\", \" \",string)\n",
        "   string = re.sub(\"🐟\", \" \",string)\n",
        "   string = re.sub(\"🛶\", \" \",string)\n",
        "   string = re.sub(\"😊\", \" \",string)\n",
        "   string = re.sub(\"😓\", \" \",string)\n",
        "   string = re.sub(\"😳\", \" \",string)\n",
        "   string = re.sub(\"🚀\", \" \",string)\n",
        "   string = re.sub(\"👎\", \" \",string)\n",
        "   string = re.sub(\"😎\", \" \",string)\n",
        "   string = re.sub(\"🐸\", \" \",string)\n",
        "   string = re.sub(\"📈\", \" \",string)\n",
        "   string = re.sub(\"🙂\", \" \",string)\n",
        "   string = re.sub(\"😅\", \" \",string)\n",
        "   string = re.sub(\"😆\", \" \",string)\n",
        "   string = re.sub(\"🙎🏿\", \" \",string)\n",
        "   string = re.sub(\"👎🏽\", \" \",string)\n",
        "   string = re.sub(\"🤭\", \" \",string)\n",
        "   string = re.sub(\"😤\", \" \",string)\n",
        "   string = re.sub(\"😚\", \" \",string)\n",
        "   string = re.sub(\"😊\", \" \",string)\n",
        "   string = re.sub(\"😲\", \" \",string)\n",
        "   string = re.sub(\"🤮\", \" \",string)\n",
        "   string = re.sub(\"🙄\", \" \",string)\n",
        "   string = re.sub(\"🤑\", \" \",string)\n",
        "   string = re.sub(\"🎅\", \" \",string)\n",
        "   string = re.sub(\"👋\", \" \",string)\n",
        "   string = re.sub(\"💪\", \" \",string)\n",
        "   string = re.sub(\"😄\", \" \",string)\n",
        "   string = re.sub(\"🧐\", \" \",string)\n",
        "   string = re.sub(\"😠\", \" \",string)\n",
        "   string = re.sub(\"🎈\", \" \",string)\n",
        "   string = re.sub(\"🚂\", \" \",string)\n",
        "   string = re.sub(\"😊\", \" \",string)\n",
        "   string = re.sub(\"🚇\", \" \",string)\n",
        "   string = re.sub(\"🚊\", \" \",string)\n",
        "   string = re.sub(\"🤷\", \" \",string)\n",
        "   string = re.sub(\"😥\", \" \",string)\n",
        "   string = re.sub(\"🙃\", \" \",string)\n",
        "   string = re.sub(\"🔩\", \" \",string)\n",
        "   string = re.sub(\"🔧\", \" \",string)\n",
        "   string = re.sub(\"🔨\", \" \",string)\n",
        "   string = re.sub(\"🛠\", \" \",string)\n",
        "   string = re.sub(\"💓\", \" \",string)\n",
        "   string = re.sub(\"💡\", \" \",string)\n",
        "   string = re.sub(\"🍸\", \" \",string)\n",
        "   string = re.sub(\"🥃\", \" \",string)\n",
        "   string = re.sub(\"🥂\", \" \",string)\n",
        "   string = re.sub(\"😷\", \" \",string)\n",
        "   string = re.sub(\"🤐\", \" \",string)\n",
        "   string = re.sub(\"🌎\", \" \",string)\n",
        "   string = re.sub(\"👑\", \" \",string)\n",
        "   string = re.sub(\"🤛\", \" \",string)\n",
        "   string = re.sub(\"😀\", \" \",string)\n",
        "   string = re.sub(\"🛤\", \" \",string)\n",
        "   string = re.sub(\"🎄\", \" \",string)\n",
        "   string = re.sub(\"📴\", \" \",string)\n",
        "   string = re.sub(\"🌭\", \" \",string)\n",
        "   string = re.sub(\"🤕\", \" \",string)\n",
        "   string = re.sub(\"😭\", \" \",string)\n",
        "   string = re.sub(\"🍾\", \" \",string)\n",
        "   string = re.sub(\"🍞\", \" \",string)\n",
        "   string = re.sub(\"🤦\", \" \",string)\n",
        "   string = re.sub(\"🤯\", \" \",string)\n",
        "   string = re.sub(\"🕯️\", \" \",string)\n",
        "\n",
        "   string = re.sub(\"OTHER|OFFENSE|ABUSE|INSULT\",\" \",string)\n",
        "   return string"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5asMgo4LtnRg"
      },
      "source": [
        "statementsForTraining = []\n",
        "sentimentsForTraining = []\n",
        "\n",
        "\n",
        "fileToRead = open(training_file, 'r')\n",
        "\n",
        "while True:\n",
        "  #next line in file\n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  findSentiment = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "\n",
        "\n",
        "  statementsForTraining.append(line)\n",
        "   #sentimentsForTraining.append(findSentiment.group(0))\n",
        "\n",
        "  if findSentiment.group(0) == \"OTHER\":  \n",
        "    sentimentsForTraining.append(0)\n",
        "  else:\n",
        "    sentimentsForTraining.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        " #print(\"{}: {}\".format(count,line.strip()))\n",
        "  \n",
        " # print(sentiment.group(0))\n",
        " \n",
        "fileToRead.close()\n",
        "\n",
        "training_sentences = statementsForTraining\n",
        "training_labels = sentimentsForTraining\n",
        "\n",
        "#print(training_sentences[9])\n",
        "#print(training_labels[9])\n",
        "\n",
        "#print(len(training_sentences))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsqZPENb98gD"
      },
      "source": [
        "##do the same with testdata\n",
        "statementsForTesting = []\n",
        "sentimentsForTesting = []\n",
        "\n",
        "fileToRead = open(testing_file, 'r')\n",
        "\n",
        "while True:\n",
        "  #next line in file\n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  sent = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "\n",
        "    \n",
        "\n",
        "  statementsForTesting.append(line)\n",
        "  #print(len(line))\n",
        "  #sentimentsForTesting.append(sent.group(0))\n",
        "\n",
        "  if sent.group(0) == \"OTHER\": \n",
        "    sentimentsForTesting.append(0)\n",
        "  else:\n",
        "    sentimentsForTesting.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        "\n",
        "fileToRead.close()\n",
        "\n",
        "\n",
        "testing_sentences = statementsForTesting\n",
        "testing_labels = sentimentsForTesting\n",
        "#print(len(testing_sentences))\n",
        "#print(testing_sentences)   \n",
        "#print(testing_labels)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRUvDLD5bMbO"
      },
      "source": [
        "Padding -> im Prinzip die Sätze alle auf die gleiche Länge bringen (in Theorieteil näher drauf eingehen) -> maxlen-Paramter ist für pad_sequences vorhanden, wenn nicht gesetzt -> alles wird auf die Länge des längsten Satzes aufgefüllt -> print(padded(shape)) gibt aus, wie viele Datensätze padded wurden und gibt an, wie viele Tokens der längste Datensatz hat\n",
        "print(padded[x]) gibt einen Satz aus (bereits tokenisiert)\n",
        "\n",
        "Padding -> sowohl für Trainigs- als auch für Testdaten\n",
        "\n",
        "Und: Daten als numpy-Arrays speichern (notwendig für tensorflow).\n",
        "\n",
        " -> Tokenizer https://towardsdatascience.com/text-classification-in-keras-part-2-how-to-use-the-keras-tokenizer-word-representations-fd571674df23 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3hFi7waTv5m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d3fc584-0574-498b-c395-faac6de33d5a"
      },
      "source": [
        "tokenizer = Tokenizer(oov_token=\"OOV\")\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "\n",
        "#creating a word index - nur die Trainigsdaten\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "validation_size = 500\n",
        "\n",
        "\n",
        "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "padded_training = pad_sequences(training_sequences, maxlen=max_length, padding='post')\n",
        "print(len(padded_training))\n",
        "\n",
        "validation_sequences = padded_training[0:validation_size]\n",
        "validation_labels = training_labels[0:validation_size]\n",
        "\n",
        "padded_training = padded_training[validation_size:]\n",
        "training_labels = training_labels[validation_size:]\n",
        "\n",
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
        "padded_testing = pad_sequences(testing_sequences, maxlen=max_length,  padding='post')\n",
        "\n",
        "#print(validation_sequences[499])\n",
        "print(padded_training[0])\n",
        "#print(len(validation_labels))\n",
        "#print(len(training_labels))\n",
        "\n",
        "\n",
        "nppadded_training = np.array(padded_training)\n",
        "nptraining_labels = np.array(training_labels)\n",
        "\n",
        "nppadded_validation = np.array(validation_sequences)\n",
        "npvalidation_labels = np.array(validation_labels)\n",
        "\n",
        "nppadded_testing = np.array(padded_testing)\n",
        "nptesting_labels = np.array(testing_labels)\n",
        "\n",
        "\n",
        "print(len(nppadded_training))\n",
        "print(len(nptraining_labels))\n",
        "print(len(word_index))\n",
        "\n",
        "#print(statementsForTraining[2])\n",
        "#print(nppadded_training[4])\n",
        "#print(nppadded_training.shape)\n",
        "#print(nptraining_labels[4])\n",
        "#print(nppadded_testing.shape)\n",
        "#print(word_index) \n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5009\n",
            "[  12 3982   11   41 6706 1040    4    5  202   39    3 2922   49 1360\n",
            "  810  495 3983    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0]\n",
            "4509\n",
            "4509\n",
            "15059\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tL3owrc8THkT"
      },
      "source": [
        "\n",
        "Dann: Embedding mit entweder word2vec oder glove\n",
        "Word2vec-Daten sind hier: http://vectors.nlpl.eu/repository/#\n",
        "Glove -> https://nlp.stanford.edu/projects/glove/ Da mal den Twitter-Vector runtergeladen\n",
        "Wenn Daten in GoogleDrive sind (wäre auch via url möglich..), muss Drive gemounted werden ( https://buomsoo-kim.github.io/colab/2020/05/09/Colab-mounting-google-drive.md/ ) aber auch hier https://enjoymachinelearning.com/posts/colab-with-google-drive/\n",
        "\n",
        "Die Word2vec vectors: http://vectors.nlpl.eu/repository/# \n",
        "\n",
        "glove-zitat:\n",
        "Citing GloVe\n",
        "\n",
        "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. [pdf] [bib]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zuO7T9ZTG57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a263ec0b-daf5-4c8d-ca68-bdc0fe6fb794"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "os.listdir(\"/content/drive/MyDrive/Colab Notebooks\")\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['germeval_training.txt',\n",
              " 'glove.twitter.27B.50d.txt',\n",
              " 'glove.twitter.27B.200d.txt',\n",
              " 'glove.6B.200d.txt',\n",
              " 'glove.840B.300d.txt',\n",
              " 'tensorboard.gdoc',\n",
              " 'keras.gdoc',\n",
              " 'Vectorization CNN embedded_limited_vocab.ipynb',\n",
              " 'glove.42B.300d.txt',\n",
              " 'Embedding Glove Vergleich.ipynb',\n",
              " 'CNN embedded_limited_vocab.ipynb',\n",
              " 'LSTM_limited_vocab.ipynb',\n",
              " 'LSTM.ipynb',\n",
              " 'CNN embedded.ipynb']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7ToKO-sZLHK"
      },
      "source": [
        "\n",
        "Keras-Doc : https://keras.io/examples/nlp/pretrained_word_embeddings/#load-pretrained-word-embeddings \n",
        "embedding mit initializers.. weights müsste auch funktionieren\n",
        "\n",
        "Diese erstellte Matrix mit Embedding dann in die Embedding-Schicht einbinden,  Trainable auf False, weil sich die Werte nicht durch Training anpassen sollen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AShIVfC7ZQAH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25a47eab-db35-4437-badd-fb0ac10b5432"
      },
      "source": [
        "#Größe Vokabel -> wordindex + 2 (weil padding + OOV) \n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "vocabulary_size = len(word_index)+2\n",
        "\n",
        "# dann erstell ich ein Wörterbuch mit Namen \"embedding_vector\", dort sind dann\n",
        "#die keys drinnen, die in glove-Datei drinnen sind mit dem entsprechenden Key\n",
        "\n",
        "embedding_index_glove = {}\n",
        "f = open('/content/drive/MyDrive/Colab Notebooks/glove.twitter.27B.200d.txt')\n",
        "for line in f:\n",
        "  value = line.split()\n",
        "  word = value[0]\n",
        "  coef = np.asarray(value[1:],dtype='float32')\n",
        "  embedding_index_glove[word] = coef\n",
        "\n",
        "print(\"%d gefunden: \"% len(embedding_index_glove))\n",
        "\n",
        "#Dann noch eine Embedding-Matrix erstellen\n",
        "#zweiter Wert = Embedding-Dimension der Datei, in dem Fall 200\n",
        "\n",
        "glove_matrix = np.zeros((vocabulary_size,200))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    embedding_value = embedding_index_glove.get(word)\n",
        "    if embedding_value is not None:\n",
        "      glove_matrix[index] = embedding_value\n",
        "      hits+=1\n",
        "    else:\n",
        "      misses+=1\n",
        "\n",
        "print(\"hits %d and %d misses\"%(hits,misses))\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1193514 gefunden: \n",
            "hits 6747 and 8312 misses\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZmvOfwhV4N5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6a02ad4-76e0-4f14-b240-cedbf2770b3a"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "print(\"vocab size: %d\"%vocabulary_size)\n",
        "CNN16052102EIEM03 = tf.keras.Sequential()\n",
        "#Embedding -> hier dann auf das embedding verweisen, Input_dim -> die Anzahl der Wörter im word_index, output -> in dem Fall passend zum verwendeten Vektor\n",
        "#input-length -> auf 60  gepadded, trainable -> nein, weil nichts verändert werden soll\n",
        "#embeddings_initializer=keras.initializers.Constant(glove_matrix) vs weights = [glove_matrix]\n",
        "#Convolutional layers => filters = neurons.. mit 100? 265?\n",
        "CNN16052102EIEM03.add(tf.keras.layers.Embedding(input_dim=vocabulary_size, output_dim=200, input_length=max_length))\n",
        "#CNN16052102EIEM03.add(tf.keras.layers.Embedding(vocabulary_size, output_dim=200, input_length=60, embeddings_initializer = keras.initializers.Constant(glove_matrix), trainable= False))\n",
        "CNN16052102EIEM03.add(tf.keras.layers.Dropout(0.4))\n",
        "CNN16052102EIEM03.add(tf.keras.layers.Conv1D(filters=50, kernel_size=3, padding=\"valid\", activation=\"relu\"))\n",
        "CNN16052102EIEM03.add(tf.keras.layers.MaxPooling1D())\n",
        "CNN16052102EIEM03.add(tf.keras.layers.Conv1D(filters=50, kernel_size=3, padding=\"valid\", activation=\"relu\"))\n",
        "CNN16052102EIEM03.add(tf.keras.layers.GlobalAveragePooling1D())\n",
        "CNN16052102EIEM03.add(tf.keras.layers.Flatten())\n",
        "CNN16052102EIEM03.add(tf.keras.layers.Dense(260, activation=\"relu\"))\n",
        "CNN16052102EIEM03.add(tf.keras.layers.Dropout(0.4))\n",
        "CNN16052102EIEM03.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "CNN16052102EIEM03.summary()\n",
        "\n",
        "#nppadded_training = np.asmatrix(nppadded_training) not necessary\n",
        "#nppadded_testing = np.asmatrix(nppadded_testing)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab size: 15061\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 60, 200)           3012200   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 60, 200)           0         \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 58, 50)            30050     \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 29, 50)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 27, 50)            7550      \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 260)               13260     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 260)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 261       \n",
            "=================================================================\n",
            "Total params: 3,063,321\n",
            "Trainable params: 3,063,321\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEr4OzT-iHDe"
      },
      "source": [
        "#model.layers[2].get_weights()[0].shape\n",
        "#weights=np.random.rand(5,200,100)\n",
        "#bias=np.random.rand(100)\n",
        "#model.layers[2].set_weights([weights, bias])\n",
        "\n",
        "#model.layers[2].get_weights()[0]\n",
        "#https://androidkt.com/set-custom-weights-keras-using-numpy-array/"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UB7_3VPYesr9"
      },
      "source": [
        "F1-Score für jede Epoche https://aakashgoel12.medium.com/how-to-add-user-defined-function-get-f1-score-in-keras-metrics-3013f979ce0d\n",
        "\n",
        "Sehr gute Ressource für die verschiedenen Scores und Metriken https://neptune.ai/blog/evaluation-metrics-binary-classification#10  das und aakas verwendet\n",
        "\n",
        "hier: je eine Funktion für Recall, Precision, f1 https://neptune.ai/blog/keras-metrics \n",
        "\n",
        "https://keras.rstudio.com/reference/k_ones_like.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygyrbFJaMV9B"
      },
      "source": [
        "import keras.backend as K\n",
        "\n",
        "def metrics_recall(data_true, data_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(data_true,0,1)))\n",
        "\n",
        "    recall = true_positives / (possible_positives+K.epsilon())\n",
        "    return recall\n",
        "\n",
        "\n",
        "def metrics_precision(data_true, data_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "\n",
        "    positives_predicted = K.sum(K.round(K.clip(data_pred,0,1)))\n",
        "    precision = true_positives / (positives_predicted+K.epsilon())\n",
        "    return precision\n",
        "\n",
        "\n",
        "def metrics_f1(data_true, data_pred):\n",
        "    precision_data = metrics_precision(data_true, data_pred)\n",
        "    recall_data = metrics_recall(data_true, data_pred)\n",
        "    return 2*(precision_data*recall_data)/(precision_data+recall_data+K.epsilon())"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1ctlBrnuYJz"
      },
      "source": [
        "https://aakashgoel12.medium.com/how-to-add-user-defined-function-get-f1-score-in-keras-metrics-3013f979ce0d"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AfPD3_bWCm0"
      },
      "source": [
        "CNN16052102EIEM03.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',metrics_recall,metrics_precision,metrics_f1])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpChKUY-QEWI"
      },
      "source": [
        "https://www.tensorflow.org/tensorboard/tensorboard_in_notebooks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJfMgUhHBoD1"
      },
      "source": [
        "#%load_ext tensorboard\n",
        "#nur einmal pro Sitzung notwendig\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ISmMXLqP8Hc"
      },
      "source": [
        "\n",
        "logs_base_dir = \"./logs\"\n",
        "callbackForTB = tf.keras.callbacks.TensorBoard(logs_base_dir)\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ehh-EMXUQh8r"
      },
      "source": [
        "Early Stopping as defined in keras tensorflow documentation\n",
        "https://www.tensorflow.org/guide/keras/train_and_evaluate "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BY_t-PeQEjy"
      },
      "source": [
        "callbackEarlyStopping = [\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_loss\",\n",
        "        mode=\"min\",\n",
        "        patience=3,\n",
        "        verbose=1,\n",
        "    )\n",
        "]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2CHbXiP1LsF"
      },
      "source": [
        "training_epochs = 30\n",
        "batch_size = 40\n",
        "validation_split=0.2"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abV-QAxfW48r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfb7dfc0-47c8-4371-d8d8-1372de545859"
      },
      "source": [
        "#Werte der Convolutional-Schichten variieren (Filter), Batch-Size variieren, kernel-size..\n",
        "CNN16052102EIEM03.fit(nppadded_training, nptraining_labels, batch_size=batch_size, validation_split=validation_split, epochs=6, callbacks=[callbackForTB])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "91/91 [==============================] - 7s 65ms/step - loss: 0.6510 - accuracy: 0.6434 - metrics_recall: 0.0317 - metrics_precision: 0.0096 - metrics_f1: 0.0148 - val_loss: 0.6449 - val_accuracy: 0.6718 - val_metrics_recall: 0.0000e+00 - val_metrics_precision: 0.0000e+00 - val_metrics_f1: 0.0000e+00\n",
            "Epoch 2/6\n",
            "91/91 [==============================] - 5s 58ms/step - loss: 0.6364 - accuracy: 0.6561 - metrics_recall: 0.0041 - metrics_precision: 0.0212 - metrics_f1: 0.0058 - val_loss: 0.5646 - val_accuracy: 0.7184 - val_metrics_recall: 0.2027 - val_metrics_precision: 0.7735 - val_metrics_f1: 0.3066\n",
            "Epoch 3/6\n",
            "91/91 [==============================] - 5s 58ms/step - loss: 0.3383 - accuracy: 0.8454 - metrics_recall: 0.6461 - metrics_precision: 0.8802 - metrics_f1: 0.7107 - val_loss: 0.6473 - val_accuracy: 0.7029 - val_metrics_recall: 0.6650 - val_metrics_precision: 0.5287 - val_metrics_f1: 0.5783\n",
            "Epoch 4/6\n",
            "91/91 [==============================] - 5s 58ms/step - loss: 0.1151 - accuracy: 0.9612 - metrics_recall: 0.9325 - metrics_precision: 0.9523 - metrics_f1: 0.9398 - val_loss: 0.9127 - val_accuracy: 0.7373 - val_metrics_recall: 0.5507 - val_metrics_precision: 0.5976 - val_metrics_f1: 0.5637\n",
            "Epoch 5/6\n",
            "91/91 [==============================] - 5s 58ms/step - loss: 0.0398 - accuracy: 0.9878 - metrics_recall: 0.9729 - metrics_precision: 0.9881 - metrics_f1: 0.9797 - val_loss: 1.1495 - val_accuracy: 0.7239 - val_metrics_recall: 0.5867 - val_metrics_precision: 0.5734 - val_metrics_f1: 0.5642\n",
            "Epoch 6/6\n",
            "91/91 [==============================] - 5s 58ms/step - loss: 0.0138 - accuracy: 0.9976 - metrics_recall: 0.9959 - metrics_precision: 0.9975 - metrics_f1: 0.9966 - val_loss: 1.4618 - val_accuracy: 0.7395 - val_metrics_recall: 0.5247 - val_metrics_precision: 0.6095 - val_metrics_f1: 0.5509\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f996eb5cc50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJVL4SBLPB2P"
      },
      "source": [
        "#%tensorboard --logdir {logs_base_dir}"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_LnvWBcnoak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a277dec4-6587-4154-cd7b-87f52caa1247"
      },
      "source": [
        "#results = model.evaluate(nppadded_testing, nptesting_labels, batch_size=batch_size)\n",
        "#print(\"test loss, test acc:\",results)\n",
        "\n",
        "(loss,accuracy, metrics_recall,metrics_precision,\n",
        "metrics_f1) = CNN16052102EIEM03.evaluate(nppadded_testing, nptesting_labels, verbose=1)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "111/111 [==============================] - 1s 5ms/step - loss: 1.3928 - accuracy: 0.6971 - metrics_recall: 0.4615 - metrics_precision: 0.5682 - metrics_f1: 0.4980\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KgjIkhpKmHc"
      },
      "source": [
        "make some predictions of test data and save it to variable. verbose=0 -> do not generate output\n",
        "Gute Quelle: https://deeplizard.com/learn/video/2f-NjDUvZIE "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89GWuxryKlcM"
      },
      "source": [
        "CNN_predictions08 = CNN16052102EIEM03.predict(x=nppadded_testing)\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3jPDaDJK_cN"
      },
      "source": [
        "#for p in CNN_predictions08:\n",
        " # print(p)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eC9efJy4Lp21"
      },
      "source": [
        "rounded predictions: give prediction value of most likely prediction (0 or 1). Printing the output of rounded prediction shows the prediction made by the model on the data (which output is most likely)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsG-TJuQLvtk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be0b2496-4421-4ff8-f42e-0b58361fc1e8"
      },
      "source": [
        "prediction_rounded08 = np.round(CNN_predictions08)\n",
        "#np.argmax(CNN_predictions08,axis=-1)\n",
        "\n",
        "#for p in prediction_rounded08:\n",
        " # print(p)\n",
        "\n",
        "\n",
        "print(nptesting_labels[500:520])\n",
        "print(prediction_rounded08[500:520])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1]\n",
            "[[0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egTtgpXgg8a2"
      },
      "source": [
        "https://deeplizard.com/learn/video/km7pxKy4UHU\n",
        "\n",
        "Quelle der def plot_confusion_matrix: https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSDXf7-_MITy"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0AMs1EzhBU1"
      },
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                        normalize=False,\n",
        "                        title='Confusion matrix',\n",
        "                        cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2JgEnlghCtl"
      },
      "source": [
        "cm = confusion_matrix(y_true=nptesting_labels, y_pred=prediction_rounded08)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckmF29whhFmX"
      },
      "source": [
        "plot_labels = ['no hatespeech','hatespeech']"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "2mpSE96rhK7K",
        "outputId": "50e70453-2595-4593-fd1b-e0615d21abca"
      },
      "source": [
        "plot_confusion_matrix(cm=cm, classes=plot_labels, title='CNN Confusion 50 eigenes Embedding')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix, without normalization\n",
            "[[1915  415]\n",
            " [ 655  547]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}