{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN embedded.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMXHNPvEN31aG1sY8xUyUrC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BiancaStadl/ProjektarbeitML/blob/main/CNN_embedded.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXDOlIBymF0V"
      },
      "source": [
        "GloVe embeddings taken from:\n",
        "\n",
        "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. [pdf] [bib]\n",
        "\n",
        "hatespeechdata taken from (https://hatespeechdata.com/): Wiegand, M., Siegel, M. and Ruppenhofer, J., 2018. Overview of the GermEval 2018 Shared Task on the Identification of Offensive Language. In: Proceedings of GermEval 2018, 14th Conference on Natural Language Processing (KONVENS 2018). Vienna, Austria: Research Gate. available on: https://github.com/uds-lsv/GermEval-2018-Data (last checked: 09.05.2021)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlBmABDxfqII"
      },
      "source": [
        "wiki detox..https://colab.research.google.com/github/tensorflow/fairness-indicators/blob/master/g3doc/tutorials/Fairness_Indicators_TFCO_Wiki_Case_Study.ipynb#scrollTo=y6T5tlXcdW7J "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3xfitNdliBI"
      },
      "source": [
        "#import matplotlib.pyplot as plt -> für evtl Visualisierungen\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import string\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from keras import losses \n",
        "from keras import optimizers \n",
        "from keras import metrics \n",
        "\n",
        "#!pip install Tokenizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "#!pip install pad_sequences\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import preprocessing\n",
        "#from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTWJQ1iga_vS"
      },
      "source": [
        "Maximale Satzlänge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bq08Me5la_Cc"
      },
      "source": [
        "\n",
        "max_length = 60"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVYBMvYSotTH"
      },
      "source": [
        "url = \"https://github.com/uds-lsv/GermEval-2018-Data/archive/master.zip\"\n",
        "\n",
        "dataset = tf.keras.utils.get_file(\"GermEval-2018-Data-master.zip\", url, \n",
        "                                   extract=True, cache_dir='.',\n",
        "                                    cache_subdir='')\n",
        "\n",
        "dataset_dir = os.path.join(os.path.dirname(dataset), 'GermEval-2018-Data-master')\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cS14OUtfo34V"
      },
      "source": [
        "#os.listdir(dataset_dir)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2X429K6hpOVm"
      },
      "source": [
        "training_file = os.path.join(dataset_dir, 'germeval2018.training.txt')\n",
        "\n",
        "testing_file = os.path.join(dataset_dir, 'germeval2018.test.txt')\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uq8fG3LNtn_m"
      },
      "source": [
        "###Aufbereitung\n",
        "txt-Dateien lesen, und dabei jede Zeile splitten und teilen\n",
        "Twitter-Handler entfernen?\n",
        "Labels von Sätzen trennen, Labels in eigenen Array packen.\n",
        "\n",
        "####Ressourcen\n",
        "* https://www.w3schools.com/python/gloss_python_if_statement.asp\n",
        "* https://stackabuse.com/using-regex-for-text-manipulation-in-python/\n",
        "* https://www.tutorialspoint.com/python/string_splitlines.htm \n",
        "* https://note.nkmk.me/en/python-split-rsplit-splitlines-re/ \n",
        "* https://www.w3schools.com/python/python_regex.asp \n",
        "\n",
        "gäbe bei keras tf.keras.preprocessing.text_dataset_from_directory, aber dafür müssten die Daten auf bestimmte Weise in Verzeichnis organisiert sein, hier nicht der Fall.\n",
        "\n",
        "\n",
        "Einteilung der Daten: Testdaten\n",
        "Trainingsdaten -> noch ca 500 für Validierungsdaten\n",
        "\n",
        "labels -> \"other\", also nicht-negative Aussagen bekommen \"0\", negative Aussagen bekommen \"1\"\n",
        "\n",
        " Regex für Emojis  ->\n",
        "\n",
        "(\\u00a9|\\u00ae|[\\u2000-\\u3300]|\\ud83c[\\ud000-\\udfff]|\\ud83d[\\ud000-\\udfff]|\\ud83e[\\ud000-\\udfff])\n",
        "\n",
        "genommen von https://www.regextester.com/106421 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Py_cwD4eZkXo"
      },
      "source": [
        "def remove_clutter(string):\n",
        "   string = re.sub(\"@[^\\s]+\",\" \",string)\n",
        "   string = re.sub(\"#[^\\s]+\",\" \", string)\n",
        "   string = re.sub(\"\\u00a9\",\" \", string)\n",
        "   string = re.sub(\"\\u00ae\",\" \", string)\n",
        "   string = re.sub(\"[\\u2000-\\u3300]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83c[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83d[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83e[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"😜\", \" \",string)\n",
        "   string = re.sub(\"🍫\", \" \",string)\n",
        "   string = re.sub(\"😁\", \" \",string)\n",
        "   string = re.sub(\"🐖\", \" \",string)\n",
        "   string = re.sub(\"😡\", \" \",string)\n",
        "   string = re.sub(\"😇\", \" \",string)\n",
        "   string = re.sub(\"😬\", \" \",string)\n",
        "   string = re.sub(\"😃\", \" \",string)\n",
        "   string = re.sub(\"😂\", \" \",string)\n",
        "   string = re.sub(\"💙\", \" \",string)  \n",
        "   string = re.sub(\"😛\", \" \",string)\n",
        "   string = re.sub(\"🙏\", \" \",string)\n",
        "   string = re.sub(\"👍\", \" \",string)\n",
        "   string = re.sub(\"🖕\", \" \",string)\n",
        "   string = re.sub(\"😉\", \" \",string)\n",
        "   string = re.sub(\"💩\", \" \",string)\n",
        "   string = re.sub(\"🤢\", \" \",string)\n",
        "   string = re.sub(\"👏\", \" \",string)\n",
        "   string = re.sub(\"😨\", \" \",string)\n",
        "   string = re.sub(\"🤣\", \" \",string)\n",
        "   string = re.sub(\"🤡\", \" \",string)\n",
        "   string = re.sub(\"😈\", \" \",string)\n",
        "   string = re.sub(\"💃🏽\", \" \",string)\n",
        "   string = re.sub(\"👹\", \" \",string)\n",
        "   string = re.sub(\"🤘\", \" \",string)\n",
        "   string = re.sub(\"😱\", \" \",string)\n",
        "   string = re.sub(\"🤔\", \" \",string) \n",
        "   string = re.sub(\"🌈\", \" \",string) \n",
        "   string = re.sub(\"💕\", \" \",string) \n",
        "   string = re.sub(\"👩‍❤️‍👩\", \" \",string) \n",
        "   string = re.sub(\"😍\", \" \",string) \n",
        "   string = re.sub(\"👆\", \" \",string) \n",
        "   string = re.sub(\"😖\", \" \",string) \n",
        "   string = re.sub(\"👇\", \" \",string) \n",
        "   string = re.sub(\"🔥\", \" \",string) \n",
        "   string = re.sub(\"😘\", \" \",string) \n",
        "   string = re.sub(\"🎉\", \" \",string) \n",
        "   string = re.sub(\"🤬\", \" \",string) \n",
        "   string = re.sub(\"👊\", \" \",string)\n",
        "   string = re.sub(\"🇩🇪\", \" \",string)  \n",
        "   string = re.sub(\"💔\", \" \",string)\n",
        "   string = re.sub(\"🙈\", \" \",string)\n",
        "   string = re.sub(\"🤯\", \" \",string)\n",
        "   string = re.sub(\"🐟\", \" \",string)\n",
        "   string = re.sub(\"🛶\", \" \",string)\n",
        "   string = re.sub(\"😊\", \" \",string)\n",
        "   string = re.sub(\"😓\", \" \",string)\n",
        "   string = re.sub(\"😳\", \" \",string)\n",
        "   string = re.sub(\"🚀\", \" \",string)\n",
        "   string = re.sub(\"👎\", \" \",string)\n",
        "   string = re.sub(\"😎\", \" \",string)\n",
        "   string = re.sub(\"🐸\", \" \",string)\n",
        "   string = re.sub(\"📈\", \" \",string)\n",
        "   string = re.sub(\"🙂\", \" \",string)\n",
        "   string = re.sub(\"😅\", \" \",string)\n",
        "   string = re.sub(\"😆\", \" \",string)\n",
        "   string = re.sub(\"🙎🏿\", \" \",string)\n",
        "   string = re.sub(\"👎🏽\", \" \",string)\n",
        "   string = re.sub(\"🤭\", \" \",string)\n",
        "   string = re.sub(\"😤\", \" \",string)\n",
        "   string = re.sub(\"😚\", \" \",string)\n",
        "   string = re.sub(\"😊\", \" \",string)\n",
        "   string = re.sub(\"😲\", \" \",string)\n",
        "   string = re.sub(\"🤮\", \" \",string)\n",
        "   string = re.sub(\"🙄\", \" \",string)\n",
        "   string = re.sub(\"🤑\", \" \",string)\n",
        "   string = re.sub(\"🎅\", \" \",string)\n",
        "   string = re.sub(\"👋\", \" \",string)\n",
        "   string = re.sub(\"💪\", \" \",string)\n",
        "   string = re.sub(\"😄\", \" \",string)\n",
        "   string = re.sub(\"🧐\", \" \",string)\n",
        "   string = re.sub(\"😠\", \" \",string)\n",
        "   string = re.sub(\"🎈\", \" \",string)\n",
        "   string = re.sub(\"🚂\", \" \",string)\n",
        "   string = re.sub(\"😊\", \" \",string)\n",
        "   string = re.sub(\"🚇\", \" \",string)\n",
        "   string = re.sub(\"🚊\", \" \",string)\n",
        "   string = re.sub(\"🤷\", \" \",string)\n",
        "   string = re.sub(\"😥\", \" \",string)\n",
        "   string = re.sub(\"🙃\", \" \",string)\n",
        "   string = re.sub(\"🔩\", \" \",string)\n",
        "   string = re.sub(\"🔧\", \" \",string)\n",
        "   string = re.sub(\"🔨\", \" \",string)\n",
        "   string = re.sub(\"🛠\", \" \",string)\n",
        "   string = re.sub(\"💓\", \" \",string)\n",
        "   string = re.sub(\"💡\", \" \",string)\n",
        "   string = re.sub(\"🍸\", \" \",string)\n",
        "   string = re.sub(\"🥃\", \" \",string)\n",
        "   string = re.sub(\"🥂\", \" \",string)\n",
        "   string = re.sub(\"😷\", \" \",string)\n",
        "   string = re.sub(\"🤐\", \" \",string)\n",
        "   string = re.sub(\"🌎\", \" \",string)\n",
        "   string = re.sub(\"👑\", \" \",string)\n",
        "   string = re.sub(\"🤛\", \" \",string)\n",
        "   string = re.sub(\"😀\", \" \",string)\n",
        "   string = re.sub(\"🛤\", \" \",string)\n",
        "   string = re.sub(\"🎄\", \" \",string)\n",
        "   string = re.sub(\"📴\", \" \",string)\n",
        "   string = re.sub(\"🌭\", \" \",string)\n",
        "   string = re.sub(\"🤕\", \" \",string)\n",
        "   string = re.sub(\"😭\", \" \",string)\n",
        "   string = re.sub(\"🍾\", \" \",string)\n",
        "   string = re.sub(\"🍞\", \" \",string)\n",
        "   string = re.sub(\"🤦\", \" \",string)\n",
        "   string = re.sub(\"🤯\", \" \",string)\n",
        "   string = re.sub(\"🕯️\", \" \",string)\n",
        "\n",
        "   string = re.sub(\"OTHER|OFFENSE|ABUSE|INSULT\",\" \",string)\n",
        "   return string"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5asMgo4LtnRg"
      },
      "source": [
        "statementsForTraining = []\n",
        "sentimentsForTraining = []\n",
        "\n",
        "\n",
        "fileToRead = open(training_file, 'r')\n",
        "\n",
        "while True:\n",
        "  #next line in file\n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  findSentiment = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "\n",
        "\n",
        "  statementsForTraining.append(line)\n",
        "   #sentimentsForTraining.append(findSentiment.group(0))\n",
        "\n",
        "  if findSentiment.group(0) == \"OTHER\":  \n",
        "    sentimentsForTraining.append(0)\n",
        "  else:\n",
        "    sentimentsForTraining.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        " #print(\"{}: {}\".format(count,line.strip()))\n",
        "  \n",
        " # print(sentiment.group(0))\n",
        " \n",
        "fileToRead.close()\n",
        "\n",
        "training_sentences = statementsForTraining\n",
        "training_labels = sentimentsForTraining\n",
        "\n",
        "#print(training_sentences[9])\n",
        "#print(training_labels[9])\n",
        "\n",
        "#print(len(training_sentences))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsqZPENb98gD"
      },
      "source": [
        "##do the same with testdata\n",
        "statementsForTesting = []\n",
        "sentimentsForTesting = []\n",
        "\n",
        "fileToRead = open(testing_file, 'r')\n",
        "\n",
        "while True:\n",
        "  #next line in file\n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  sent = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "\n",
        "    \n",
        "\n",
        "  statementsForTesting.append(line)\n",
        "  #print(len(line))\n",
        "  #sentimentsForTesting.append(sent.group(0))\n",
        "\n",
        "  if sent.group(0) == \"OTHER\": \n",
        "    sentimentsForTesting.append(0)\n",
        "  else:\n",
        "    sentimentsForTesting.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        "\n",
        "fileToRead.close()\n",
        "\n",
        "\n",
        "testing_sentences = statementsForTesting\n",
        "testing_labels = sentimentsForTesting\n",
        "#print(len(testing_sentences))\n",
        "#print(testing_sentences)   \n",
        "#print(testing_labels)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRUvDLD5bMbO"
      },
      "source": [
        "Padding -> im Prinzip die Sätze alle auf die gleiche Länge bringen (in Theorieteil näher drauf eingehen) -> maxlen-Paramter ist für pad_sequences vorhanden, wenn nicht gesetzt -> alles wird auf die Länge des längsten Satzes aufgefüllt -> print(padded(shape)) gibt aus, wie viele Datensätze padded wurden und gibt an, wie viele Tokens der längste Datensatz hat\n",
        "print(padded[x]) gibt einen Satz aus (bereits tokenisiert)\n",
        "\n",
        "Padding -> sowohl für Trainigs- als auch für Testdaten\n",
        "\n",
        "Und: Daten als numpy-Arrays speichern (notwendig für tensorflow).\n",
        "\n",
        " -> Tokenizer https://towardsdatascience.com/text-classification-in-keras-part-2-how-to-use-the-keras-tokenizer-word-representations-fd571674df23 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3hFi7waTv5m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14a70e10-797f-4352-8278-e4b715f72ecd"
      },
      "source": [
        "tokenizer = Tokenizer(oov_token=\"OOV\")\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "\n",
        "#creating a word index - nur die Trainigsdaten\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "validation_size = 500\n",
        "\n",
        "\n",
        "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "padded_training = pad_sequences(training_sequences, maxlen=max_length, padding='post')\n",
        "print(len(padded_training))\n",
        "\n",
        "validation_sequences = padded_training[0:validation_size]\n",
        "validation_labels = training_labels[0:validation_size]\n",
        "\n",
        "padded_training = padded_training[validation_size:]\n",
        "training_labels = training_labels[validation_size:]\n",
        "\n",
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
        "padded_testing = pad_sequences(testing_sequences, maxlen=max_length,  padding='post')\n",
        "\n",
        "#print(validation_sequences[499])\n",
        "print(padded_training[0])\n",
        "#print(len(validation_labels))\n",
        "#print(len(training_labels))\n",
        "\n",
        "\n",
        "nppadded_training = np.array(padded_training)\n",
        "nptraining_labels = np.array(training_labels)\n",
        "\n",
        "nppadded_validation = np.array(validation_sequences)\n",
        "npvalidation_labels = np.array(validation_labels)\n",
        "\n",
        "nppadded_testing = np.array(padded_testing)\n",
        "nptesting_labels = np.array(testing_labels)\n",
        "\n",
        "\n",
        "print(len(nppadded_training))\n",
        "print(len(nptraining_labels))\n",
        "print(len(word_index))\n",
        "\n",
        "#print(statementsForTraining[2])\n",
        "#print(nppadded_training[4])\n",
        "#print(nppadded_training.shape)\n",
        "#print(nptraining_labels[4])\n",
        "#print(nppadded_testing.shape)\n",
        "#print(word_index) \n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5009\n",
            "[  12 3982   11   41 6706 1040    4    5  202   39    3 2922   49 1360\n",
            "  810  495 3983    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0]\n",
            "4509\n",
            "4509\n",
            "15059\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tL3owrc8THkT"
      },
      "source": [
        "\n",
        "Dann: Embedding mit entweder word2vec oder glove\n",
        "Word2vec-Daten sind hier: http://vectors.nlpl.eu/repository/#\n",
        "Glove -> https://nlp.stanford.edu/projects/glove/ Da mal den Twitter-Vector runtergeladen\n",
        "Wenn Daten in GoogleDrive sind (wäre auch via url möglich..), muss Drive gemounted werden ( https://buomsoo-kim.github.io/colab/2020/05/09/Colab-mounting-google-drive.md/ ) aber auch hier https://enjoymachinelearning.com/posts/colab-with-google-drive/\n",
        "\n",
        "Die Word2vec vectors: http://vectors.nlpl.eu/repository/# \n",
        "\n",
        "glove-zitat:\n",
        "Citing GloVe\n",
        "\n",
        "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. [pdf] [bib]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zuO7T9ZTG57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e067119c-6617-4da7-f601-63e1fb93ef3c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "os.listdir(\"/content/drive/MyDrive/Colab Notebooks\")\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['germeval_training.txt',\n",
              " 'glove.twitter.27B.50d.txt',\n",
              " 'glove.twitter.27B.200d.txt',\n",
              " 'glove.6B.200d.txt',\n",
              " 'glove.840B.300d.txt',\n",
              " 'tensorboard.gdoc',\n",
              " 'keras.gdoc',\n",
              " 'Vectorization CNN embedded_limited_vocab.ipynb',\n",
              " 'glove.42B.300d.txt',\n",
              " 'Embedding Glove Vergleich.ipynb',\n",
              " 'CNN embedded_limited_vocab.ipynb',\n",
              " 'LSTM_limited_vocab.ipynb',\n",
              " 'LSTM.ipynb',\n",
              " 'CNN embedded.ipynb']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7ToKO-sZLHK"
      },
      "source": [
        "\n",
        "Keras-Doc : https://keras.io/examples/nlp/pretrained_word_embeddings/#load-pretrained-word-embeddings \n",
        "embedding mit initializers.. weights müsste auch funktionieren\n",
        "\n",
        "Diese erstellte Matrix mit Embedding dann in die Embedding-Schicht einbinden,  Trainable auf False, weil sich die Werte nicht durch Training anpassen sollen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AShIVfC7ZQAH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20bac297-dbe5-4878-dc08-de26790292bc"
      },
      "source": [
        "#Größe Vokabel -> wordindex + 2 (weil padding + OOV) \n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "vocabulary_size = len(word_index)+2\n",
        "\n",
        "# dann erstell ich ein Wörterbuch mit Namen \"embedding_vector\", dort sind dann\n",
        "#die keys drinnen, die in glove-Datei drinnen sind mit dem entsprechenden Key\n",
        "\n",
        "embedding_index_glove = {}\n",
        "f = open('/content/drive/MyDrive/Colab Notebooks/glove.twitter.27B.200d.txt')\n",
        "for line in f:\n",
        "  value = line.split()\n",
        "  word = value[0]\n",
        "  coef = np.asarray(value[1:],dtype='float32')\n",
        "  embedding_index_glove[word] = coef\n",
        "\n",
        "print(\"%d gefunden: \"% len(embedding_index_glove))\n",
        "\n",
        "#Dann noch eine Embedding-Matrix erstellen\n",
        "#zweiter Wert = Embedding-Dimension der Datei, in dem Fall 200\n",
        "\n",
        "glove_matrix = np.zeros((vocabulary_size,200))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    embedding_value = embedding_index_glove.get(word)\n",
        "    if embedding_value is not None:\n",
        "      glove_matrix[index] = embedding_value\n",
        "      hits+=1\n",
        "    else:\n",
        "      misses+=1\n",
        "\n",
        "print(\"hits %d and %d misses\"%(hits,misses))\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1193514 gefunden: \n",
            "hits 6747 and 8312 misses\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZmvOfwhV4N5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b09e621-583b-41c9-fd40-558bd8cacf40"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "print(\"vocab size: %d\"%vocabulary_size)\n",
        "CNN16052106 = tf.keras.Sequential()\n",
        "#Embedding -> hier dann auf das embedding verweisen, Input_dim -> die Anzahl der Wörter im word_index, output -> in dem Fall passend zum verwendeten Vektor\n",
        "#input-length -> auf 60  gepadded, trainable -> nein, weil nichts verändert werden soll\n",
        "#embeddings_initializer=keras.initializers.Constant(glove_matrix) vs weights = [glove_matrix]\n",
        "#Convolutional layers => filters = neurons.. mit 100? 265?\n",
        "CNN16052106.add(tf.keras.layers.Embedding(vocabulary_size, output_dim=200, input_length=60, embeddings_initializer = keras.initializers.Constant(glove_matrix), trainable= False))\n",
        "CNN16052106.add(tf.keras.layers.Dropout(0.4))\n",
        "CNN16052106.add(tf.keras.layers.Conv1D(filters=90, kernel_size=3, padding=\"valid\", activation=\"relu\"))\n",
        "CNN16052106.add(tf.keras.layers.MaxPooling1D())\n",
        "CNN16052106.add(tf.keras.layers.Conv1D(filters=90, kernel_size=3, padding=\"valid\", activation=\"relu\"))\n",
        "CNN16052106.add(tf.keras.layers.GlobalAveragePooling1D())\n",
        "CNN16052106.add(tf.keras.layers.Flatten())\n",
        "CNN16052106.add(tf.keras.layers.Dense(90, activation=\"relu\"))\n",
        "CNN16052106.add(tf.keras.layers.Dropout(0.4))\n",
        "CNN16052106.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "CNN16052106.summary()\n",
        "\n",
        "#nppadded_training = np.asmatrix(nppadded_training) not necessary\n",
        "#nppadded_testing = np.asmatrix(nppadded_testing)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab size: 15061\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 60, 200)           3012200   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 60, 200)           0         \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 58, 90)            54090     \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 29, 90)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 27, 90)            24390     \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 90)                0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 90)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 90)                8190      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 90)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 91        \n",
            "=================================================================\n",
            "Total params: 3,098,961\n",
            "Trainable params: 86,761\n",
            "Non-trainable params: 3,012,200\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEr4OzT-iHDe"
      },
      "source": [
        "#model.layers[2].get_weights()[0].shape\n",
        "#weights=np.random.rand(5,200,100)\n",
        "#bias=np.random.rand(100)\n",
        "#model.layers[2].set_weights([weights, bias])\n",
        "\n",
        "#model.layers[2].get_weights()[0]\n",
        "#https://androidkt.com/set-custom-weights-keras-using-numpy-array/"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UB7_3VPYesr9"
      },
      "source": [
        "F1-Score für jede Epoche https://aakashgoel12.medium.com/how-to-add-user-defined-function-get-f1-score-in-keras-metrics-3013f979ce0d\n",
        "\n",
        "Sehr gute Ressource für die verschiedenen Scores und Metriken https://neptune.ai/blog/evaluation-metrics-binary-classification#10  das und aakas verwendet\n",
        "\n",
        "hier: je eine Funktion für Recall, Precision, f1 https://neptune.ai/blog/keras-metrics \n",
        "\n",
        "https://keras.rstudio.com/reference/k_ones_like.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygyrbFJaMV9B"
      },
      "source": [
        "import keras.backend as K\n",
        "\n",
        "def metrics_recall(data_true, data_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(data_true,0,1)))\n",
        "\n",
        "    recall = true_positives / (possible_positives+K.epsilon())\n",
        "    return recall\n",
        "\n",
        "\n",
        "def metrics_precision(data_true, data_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "\n",
        "    positives_predicted = K.sum(K.round(K.clip(data_pred,0,1)))\n",
        "    precision = true_positives / (positives_predicted+K.epsilon())\n",
        "    return precision\n",
        "\n",
        "\n",
        "def metrics_f1(data_true, data_pred):\n",
        "    precision_data = metrics_precision(data_true, data_pred)\n",
        "    recall_data = metrics_recall(data_true, data_pred)\n",
        "    return 2*(precision_data*recall_data)/(precision_data+recall_data+K.epsilon())"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1ctlBrnuYJz"
      },
      "source": [
        "https://aakashgoel12.medium.com/how-to-add-user-defined-function-get-f1-score-in-keras-metrics-3013f979ce0d"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AfPD3_bWCm0"
      },
      "source": [
        "CNN16052106.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',metrics_recall,metrics_precision,metrics_f1])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpChKUY-QEWI"
      },
      "source": [
        "https://www.tensorflow.org/tensorboard/tensorboard_in_notebooks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJfMgUhHBoD1"
      },
      "source": [
        "#%reload_ext tensorboard\n",
        "#nur einmal pro Sitzung notwendig\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ISmMXLqP8Hc"
      },
      "source": [
        "\n",
        "logs_base_dir = \"./logs\"\n",
        "callbackForTB = tf.keras.callbacks.TensorBoard(logs_base_dir)\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2CHbXiP1LsF"
      },
      "source": [
        "training_epochs = 30\n",
        "batch_size = 40\n",
        "validation_split=0.2"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abV-QAxfW48r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf6c9ca4-707f-4156-c459-cf86a7083b5f"
      },
      "source": [
        "#Werte der Convolutional-Schichten variieren (Filter), Batch-Size variieren, kernel-size..\n",
        "CNN16052106.fit(nppadded_training, nptraining_labels, batch_size=batch_size, validation_split=validation_split, epochs=training_epochs, callbacks=[callbackForTB])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "91/91 [==============================] - 5s 40ms/step - loss: 0.6596 - accuracy: 0.6485 - metrics_recall: 0.0662 - metrics_precision: 0.0487 - metrics_f1: 0.0512 - val_loss: 0.6443 - val_accuracy: 0.6718 - val_metrics_recall: 0.0000e+00 - val_metrics_precision: 0.0000e+00 - val_metrics_f1: 0.0000e+00\n",
            "Epoch 2/30\n",
            "91/91 [==============================] - 3s 33ms/step - loss: 0.6390 - accuracy: 0.6638 - metrics_recall: 0.0088 - metrics_precision: 0.0740 - metrics_f1: 0.0155 - val_loss: 0.6258 - val_accuracy: 0.6718 - val_metrics_recall: 0.0000e+00 - val_metrics_precision: 0.0000e+00 - val_metrics_f1: 0.0000e+00\n",
            "Epoch 3/30\n",
            "91/91 [==============================] - 3s 34ms/step - loss: 0.6267 - accuracy: 0.6563 - metrics_recall: 0.0521 - metrics_precision: 0.2215 - metrics_f1: 0.0783 - val_loss: 0.5900 - val_accuracy: 0.6885 - val_metrics_recall: 0.0728 - val_metrics_precision: 0.6232 - val_metrics_f1: 0.1262\n",
            "Epoch 4/30\n",
            "91/91 [==============================] - 3s 33ms/step - loss: 0.5862 - accuracy: 0.6821 - metrics_recall: 0.2171 - metrics_precision: 0.5952 - metrics_f1: 0.2936 - val_loss: 0.5655 - val_accuracy: 0.7184 - val_metrics_recall: 0.2498 - val_metrics_precision: 0.7557 - val_metrics_f1: 0.3573\n",
            "Epoch 5/30\n",
            "91/91 [==============================] - 3s 33ms/step - loss: 0.5487 - accuracy: 0.7137 - metrics_recall: 0.3498 - metrics_precision: 0.6333 - metrics_f1: 0.4318 - val_loss: 0.5647 - val_accuracy: 0.7284 - val_metrics_recall: 0.4044 - val_metrics_precision: 0.6463 - val_metrics_f1: 0.4800\n",
            "Epoch 6/30\n",
            "91/91 [==============================] - 3s 33ms/step - loss: 0.5237 - accuracy: 0.7397 - metrics_recall: 0.4372 - metrics_precision: 0.6698 - metrics_f1: 0.5109 - val_loss: 0.5689 - val_accuracy: 0.6863 - val_metrics_recall: 0.5075 - val_metrics_precision: 0.5270 - val_metrics_f1: 0.5032\n",
            "Epoch 7/30\n",
            "91/91 [==============================] - 3s 33ms/step - loss: 0.5235 - accuracy: 0.7362 - metrics_recall: 0.4304 - metrics_precision: 0.7070 - metrics_f1: 0.4835 - val_loss: 0.5457 - val_accuracy: 0.7162 - val_metrics_recall: 0.4938 - val_metrics_precision: 0.5913 - val_metrics_f1: 0.5167\n",
            "Epoch 8/30\n",
            "91/91 [==============================] - 3s 34ms/step - loss: 0.4823 - accuracy: 0.7739 - metrics_recall: 0.5049 - metrics_precision: 0.7211 - metrics_f1: 0.5625 - val_loss: 0.5442 - val_accuracy: 0.7140 - val_metrics_recall: 0.5282 - val_metrics_precision: 0.5782 - val_metrics_f1: 0.5334\n",
            "Epoch 9/30\n",
            "91/91 [==============================] - 3s 34ms/step - loss: 0.4616 - accuracy: 0.7744 - metrics_recall: 0.5543 - metrics_precision: 0.7081 - metrics_f1: 0.6026 - val_loss: 0.5397 - val_accuracy: 0.7095 - val_metrics_recall: 0.5202 - val_metrics_precision: 0.5751 - val_metrics_f1: 0.5234\n",
            "Epoch 10/30\n",
            "91/91 [==============================] - 3s 33ms/step - loss: 0.4327 - accuracy: 0.7961 - metrics_recall: 0.5728 - metrics_precision: 0.7704 - metrics_f1: 0.6382 - val_loss: 0.5438 - val_accuracy: 0.7084 - val_metrics_recall: 0.5379 - val_metrics_precision: 0.5662 - val_metrics_f1: 0.5328\n",
            "Epoch 11/30\n",
            "91/91 [==============================] - 3s 33ms/step - loss: 0.4253 - accuracy: 0.8048 - metrics_recall: 0.6502 - metrics_precision: 0.7601 - metrics_f1: 0.6865 - val_loss: 0.5591 - val_accuracy: 0.7228 - val_metrics_recall: 0.3650 - val_metrics_precision: 0.6334 - val_metrics_f1: 0.4496\n",
            "Epoch 12/30\n",
            "91/91 [==============================] - 3s 34ms/step - loss: 0.3988 - accuracy: 0.8206 - metrics_recall: 0.6676 - metrics_precision: 0.8005 - metrics_f1: 0.7081 - val_loss: 0.5599 - val_accuracy: 0.7073 - val_metrics_recall: 0.6020 - val_metrics_precision: 0.5536 - val_metrics_f1: 0.5581\n",
            "Epoch 13/30\n",
            "91/91 [==============================] - 3s 34ms/step - loss: 0.3754 - accuracy: 0.8358 - metrics_recall: 0.6523 - metrics_precision: 0.8321 - metrics_f1: 0.7132 - val_loss: 0.5636 - val_accuracy: 0.7317 - val_metrics_recall: 0.3689 - val_metrics_precision: 0.6916 - val_metrics_f1: 0.4558\n",
            "Epoch 14/30\n",
            "91/91 [==============================] - 3s 34ms/step - loss: 0.3512 - accuracy: 0.8444 - metrics_recall: 0.7024 - metrics_precision: 0.8256 - metrics_f1: 0.7427 - val_loss: 0.6242 - val_accuracy: 0.7206 - val_metrics_recall: 0.2781 - val_metrics_precision: 0.6738 - val_metrics_f1: 0.3679\n",
            "Epoch 15/30\n",
            "91/91 [==============================] - 3s 33ms/step - loss: 0.3667 - accuracy: 0.8279 - metrics_recall: 0.6535 - metrics_precision: 0.8486 - metrics_f1: 0.6987 - val_loss: 0.6102 - val_accuracy: 0.6885 - val_metrics_recall: 0.6913 - val_metrics_precision: 0.5205 - val_metrics_f1: 0.5801\n",
            "Epoch 16/30\n",
            "91/91 [==============================] - 3s 33ms/step - loss: 0.2974 - accuracy: 0.8698 - metrics_recall: 0.7765 - metrics_precision: 0.8256 - metrics_f1: 0.7892 - val_loss: 0.5832 - val_accuracy: 0.7184 - val_metrics_recall: 0.4719 - val_metrics_precision: 0.5993 - val_metrics_f1: 0.5064\n",
            "Epoch 17/30\n",
            "91/91 [==============================] - 3s 34ms/step - loss: 0.2815 - accuracy: 0.8856 - metrics_recall: 0.7839 - metrics_precision: 0.8640 - metrics_f1: 0.8119 - val_loss: 0.5848 - val_accuracy: 0.7195 - val_metrics_recall: 0.5019 - val_metrics_precision: 0.5877 - val_metrics_f1: 0.5256\n",
            "Epoch 18/30\n",
            "91/91 [==============================] - 3s 34ms/step - loss: 0.2700 - accuracy: 0.8859 - metrics_recall: 0.7955 - metrics_precision: 0.8655 - metrics_f1: 0.8156 - val_loss: 0.6113 - val_accuracy: 0.7239 - val_metrics_recall: 0.5158 - val_metrics_precision: 0.5985 - val_metrics_f1: 0.5374\n",
            "Epoch 19/30\n",
            "91/91 [==============================] - 3s 34ms/step - loss: 0.2566 - accuracy: 0.8840 - metrics_recall: 0.7902 - metrics_precision: 0.8624 - metrics_f1: 0.8154 - val_loss: 0.7021 - val_accuracy: 0.6541 - val_metrics_recall: 0.7200 - val_metrics_precision: 0.4858 - val_metrics_f1: 0.5677\n",
            "Epoch 20/30\n",
            "91/91 [==============================] - 3s 33ms/step - loss: 0.2348 - accuracy: 0.9038 - metrics_recall: 0.8554 - metrics_precision: 0.8671 - metrics_f1: 0.8516 - val_loss: 0.6485 - val_accuracy: 0.7029 - val_metrics_recall: 0.6252 - val_metrics_precision: 0.5522 - val_metrics_f1: 0.5695\n",
            "Epoch 21/30\n",
            "91/91 [==============================] - 3s 33ms/step - loss: 0.2220 - accuracy: 0.9096 - metrics_recall: 0.8583 - metrics_precision: 0.8762 - metrics_f1: 0.8573 - val_loss: 0.6530 - val_accuracy: 0.6962 - val_metrics_recall: 0.6177 - val_metrics_precision: 0.5422 - val_metrics_f1: 0.5604\n",
            "Epoch 22/30\n",
            "91/91 [==============================] - 3s 33ms/step - loss: 0.2200 - accuracy: 0.9107 - metrics_recall: 0.8510 - metrics_precision: 0.8760 - metrics_f1: 0.8572 - val_loss: 0.6506 - val_accuracy: 0.7095 - val_metrics_recall: 0.5570 - val_metrics_precision: 0.5681 - val_metrics_f1: 0.5421\n",
            "Epoch 23/30\n",
            "91/91 [==============================] - 3s 34ms/step - loss: 0.2264 - accuracy: 0.9062 - metrics_recall: 0.8268 - metrics_precision: 0.8859 - metrics_f1: 0.8473 - val_loss: 0.7170 - val_accuracy: 0.7007 - val_metrics_recall: 0.6035 - val_metrics_precision: 0.5433 - val_metrics_f1: 0.5574\n",
            "Epoch 24/30\n",
            "91/91 [==============================] - 3s 34ms/step - loss: 0.2010 - accuracy: 0.9092 - metrics_recall: 0.8479 - metrics_precision: 0.8876 - metrics_f1: 0.8599 - val_loss: 0.8089 - val_accuracy: 0.6508 - val_metrics_recall: 0.7102 - val_metrics_precision: 0.4805 - val_metrics_f1: 0.5625\n",
            "Epoch 25/30\n",
            "91/91 [==============================] - 3s 33ms/step - loss: 0.2215 - accuracy: 0.9097 - metrics_recall: 0.8500 - metrics_precision: 0.8723 - metrics_f1: 0.8503 - val_loss: 0.8761 - val_accuracy: 0.6308 - val_metrics_recall: 0.7899 - val_metrics_precision: 0.4620 - val_metrics_f1: 0.5728\n",
            "Epoch 26/30\n",
            "91/91 [==============================] - 3s 34ms/step - loss: 0.2334 - accuracy: 0.8984 - metrics_recall: 0.8500 - metrics_precision: 0.8696 - metrics_f1: 0.8500 - val_loss: 0.7453 - val_accuracy: 0.6818 - val_metrics_recall: 0.6975 - val_metrics_precision: 0.5160 - val_metrics_f1: 0.5806\n",
            "Epoch 27/30\n",
            "91/91 [==============================] - 3s 34ms/step - loss: 0.2144 - accuracy: 0.9143 - metrics_recall: 0.8515 - metrics_precision: 0.8853 - metrics_f1: 0.8612 - val_loss: 0.7514 - val_accuracy: 0.7118 - val_metrics_recall: 0.5151 - val_metrics_precision: 0.5729 - val_metrics_f1: 0.5272\n",
            "Epoch 28/30\n",
            "91/91 [==============================] - 3s 35ms/step - loss: 0.1534 - accuracy: 0.9362 - metrics_recall: 0.8875 - metrics_precision: 0.9131 - metrics_f1: 0.8941 - val_loss: 0.7538 - val_accuracy: 0.6996 - val_metrics_recall: 0.6626 - val_metrics_precision: 0.5370 - val_metrics_f1: 0.5768\n",
            "Epoch 29/30\n",
            "91/91 [==============================] - 3s 35ms/step - loss: 0.1722 - accuracy: 0.9290 - metrics_recall: 0.8810 - metrics_precision: 0.9052 - metrics_f1: 0.8876 - val_loss: 0.7731 - val_accuracy: 0.6973 - val_metrics_recall: 0.5773 - val_metrics_precision: 0.5378 - val_metrics_f1: 0.5443\n",
            "Epoch 30/30\n",
            "91/91 [==============================] - 3s 35ms/step - loss: 0.1509 - accuracy: 0.9394 - metrics_recall: 0.9184 - metrics_precision: 0.9088 - metrics_f1: 0.9102 - val_loss: 0.7569 - val_accuracy: 0.7018 - val_metrics_recall: 0.4744 - val_metrics_precision: 0.5617 - val_metrics_f1: 0.4972\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f43515bab50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJVL4SBLPB2P"
      },
      "source": [
        "#%tensorboard --logdir {logs_base_dir}"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_LnvWBcnoak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23bfef0f-8225-4e8b-9240-680a990e930a"
      },
      "source": [
        "#results = model.evaluate(nppadded_testing, nptesting_labels, batch_size=batch_size)\n",
        "#print(\"test loss, test acc:\",results)\n",
        "\n",
        "(loss,accuracy, metrics_recall,metrics_precision,\n",
        "metrics_f1) = CNN16052106.evaluate(nppadded_testing, nptesting_labels, verbose=1)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "111/111 [==============================] - 1s 9ms/step - loss: 0.7815 - accuracy: 0.6863 - metrics_recall: 0.4323 - metrics_precision: 0.5562 - metrics_f1: 0.4720\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KgjIkhpKmHc"
      },
      "source": [
        "make some predictions of test data and save it to variable. verbose=0 -> do not generate output\n",
        "Gute Quelle: https://deeplizard.com/learn/video/2f-NjDUvZIE "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89GWuxryKlcM"
      },
      "source": [
        "CNN_predictions06 = CNN16052106.predict(x=nppadded_testing)\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3jPDaDJK_cN"
      },
      "source": [
        "#for p in CNN_predictions06:\n",
        " # print(p)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eC9efJy4Lp21"
      },
      "source": [
        "rounded predictions: give prediction value of most likely prediction (0 or 1). Printing the output of rounded prediction shows the prediction made by the model on the data (which output is most likely)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsG-TJuQLvtk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0db3f48-dd45-4ded-dd08-ff5584ba8e61"
      },
      "source": [
        "prediction_rounded06 = np.round(CNN_predictions06)\n",
        "#np.argmax(CNN_predictions06,axis=-1)\n",
        "\n",
        "#for p in prediction_rounded06:\n",
        " # print(p)\n",
        "\n",
        "\n",
        "print(nptesting_labels[500:520])\n",
        "print(prediction_rounded06[500:520])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1]\n",
            "[[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egTtgpXgg8a2"
      },
      "source": [
        "https://deeplizard.com/learn/video/km7pxKy4UHU\n",
        "\n",
        "Quelle der def plot_confusion_matrix: https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSDXf7-_MITy"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0AMs1EzhBU1"
      },
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                        normalize=False,\n",
        "                        title='Confusion matrix',\n",
        "                        cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2JgEnlghCtl"
      },
      "source": [
        "cm = confusion_matrix(y_true=nptesting_labels, y_pred=prediction_rounded06)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckmF29whhFmX"
      },
      "source": [
        "plot_labels = ['no hatespeech','hatespeech']"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "2mpSE96rhK7K",
        "outputId": "5ae12e87-c4b2-4b24-e0fc-7bdd5f2ad0f4"
      },
      "source": [
        "plot_confusion_matrix(cm=cm, classes=plot_labels, title='CNN Confusion 90Dense90')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix, without normalization\n",
            "[[1909  421]\n",
            " [ 687  515]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}