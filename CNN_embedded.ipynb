{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN embedded.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPji4R2Pg0Zy/g4DT0YsFwe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BiancaStadl/ProjektarbeitML/blob/main/CNN_embedded.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXDOlIBymF0V"
      },
      "source": [
        "GloVe embeddings taken from:\n",
        "\n",
        "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. [pdf] [bib]\n",
        "\n",
        "hatespeechdata taken from (https://hatespeechdata.com/): Wiegand, M., Siegel, M. and Ruppenhofer, J., 2018. Overview of the GermEval 2018 Shared Task on the Identification of Offensive Language. In: Proceedings of GermEval 2018, 14th Conference on Natural Language Processing (KONVENS 2018). Vienna, Austria: Research Gate. available on: https://github.com/uds-lsv/GermEval-2018-Data (last checked: 09.05.2021)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlBmABDxfqII"
      },
      "source": [
        "wiki detox..https://colab.research.google.com/github/tensorflow/fairness-indicators/blob/master/g3doc/tutorials/Fairness_Indicators_TFCO_Wiki_Case_Study.ipynb#scrollTo=y6T5tlXcdW7J "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3xfitNdliBI"
      },
      "source": [
        "#import matplotlib.pyplot as plt -> f√ºr evtl Visualisierungen\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import string\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from keras import losses \n",
        "from keras import optimizers \n",
        "from keras import metrics \n",
        "\n",
        "#!pip install Tokenizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "#!pip install pad_sequences\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import preprocessing\n",
        "#from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTWJQ1iga_vS"
      },
      "source": [
        "Maximale Satzl√§nge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bq08Me5la_Cc"
      },
      "source": [
        "\n",
        "max_length = 60"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVYBMvYSotTH"
      },
      "source": [
        "url = \"https://github.com/uds-lsv/GermEval-2018-Data/archive/master.zip\"\n",
        "\n",
        "dataset = tf.keras.utils.get_file(\"GermEval-2018-Data-master.zip\", url, \n",
        "                                   extract=True, cache_dir='.',\n",
        "                                    cache_subdir='')\n",
        "\n",
        "dataset_dir = os.path.join(os.path.dirname(dataset), 'GermEval-2018-Data-master')\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cS14OUtfo34V"
      },
      "source": [
        "#os.listdir(dataset_dir)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2X429K6hpOVm"
      },
      "source": [
        "training_file = os.path.join(dataset_dir, 'germeval2018.training.txt')\n",
        "\n",
        "testing_file = os.path.join(dataset_dir, 'germeval2018.test.txt')\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uq8fG3LNtn_m"
      },
      "source": [
        "###Aufbereitung\n",
        "txt-Dateien lesen, und dabei jede Zeile splitten und teilen\n",
        "Twitter-Handler entfernen?\n",
        "Labels von S√§tzen trennen, Labels in eigenen Array packen.\n",
        "\n",
        "####Ressourcen\n",
        "* https://www.w3schools.com/python/gloss_python_if_statement.asp\n",
        "* https://stackabuse.com/using-regex-for-text-manipulation-in-python/\n",
        "* https://www.tutorialspoint.com/python/string_splitlines.htm \n",
        "* https://note.nkmk.me/en/python-split-rsplit-splitlines-re/ \n",
        "* https://www.w3schools.com/python/python_regex.asp \n",
        "\n",
        "g√§be bei keras tf.keras.preprocessing.text_dataset_from_directory, aber daf√ºr m√ºssten die Daten auf bestimmte Weise in Verzeichnis organisiert sein, hier nicht der Fall.\n",
        "\n",
        "\n",
        "Einteilung der Daten: Testdaten\n",
        "Trainingsdaten -> noch ca 500 f√ºr Validierungsdaten\n",
        "\n",
        "labels -> \"other\", also nicht-negative Aussagen bekommen \"0\", negative Aussagen bekommen \"1\"\n",
        "\n",
        " Regex f√ºr Emojis  ->\n",
        "\n",
        "(\\u00a9|\\u00ae|[\\u2000-\\u3300]|\\ud83c[\\ud000-\\udfff]|\\ud83d[\\ud000-\\udfff]|\\ud83e[\\ud000-\\udfff])\n",
        "\n",
        "genommen von https://www.regextester.com/106421 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Py_cwD4eZkXo"
      },
      "source": [
        "def remove_clutter(string):\n",
        "   string = re.sub(\"@[^\\s]+\",\" \",string)\n",
        "   string = re.sub(\"#[^\\s]+\",\" \", string)\n",
        "   string = re.sub(\"\\u00a9\",\" \", string)\n",
        "   string = re.sub(\"\\u00ae\",\" \", string)\n",
        "   string = re.sub(\"[\\u2000-\\u3300]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83c[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83d[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83e[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"üòú\", \" \",string)\n",
        "   string = re.sub(\"üç´\", \" \",string)\n",
        "   string = re.sub(\"üòÅ\", \" \",string)\n",
        "   string = re.sub(\"üêñ\", \" \",string)\n",
        "   string = re.sub(\"üò°\", \" \",string)\n",
        "   string = re.sub(\"üòá\", \" \",string)\n",
        "   string = re.sub(\"üò¨\", \" \",string)\n",
        "   string = re.sub(\"üòÉ\", \" \",string)\n",
        "   string = re.sub(\"üòÇ\", \" \",string)\n",
        "   string = re.sub(\"üíô\", \" \",string)  \n",
        "   string = re.sub(\"üòõ\", \" \",string)\n",
        "   string = re.sub(\"üôè\", \" \",string)\n",
        "   string = re.sub(\"üëç\", \" \",string)\n",
        "   string = re.sub(\"üñï\", \" \",string)\n",
        "   string = re.sub(\"üòâ\", \" \",string)\n",
        "   string = re.sub(\"üí©\", \" \",string)\n",
        "   string = re.sub(\"ü§¢\", \" \",string)\n",
        "   string = re.sub(\"üëè\", \" \",string)\n",
        "   string = re.sub(\"üò®\", \" \",string)\n",
        "   string = re.sub(\"ü§£\", \" \",string)\n",
        "   string = re.sub(\"ü§°\", \" \",string)\n",
        "   string = re.sub(\"üòà\", \" \",string)\n",
        "   string = re.sub(\"üíÉüèΩ\", \" \",string)\n",
        "   string = re.sub(\"üëπ\", \" \",string)\n",
        "   string = re.sub(\"ü§ò\", \" \",string)\n",
        "   string = re.sub(\"üò±\", \" \",string)\n",
        "   string = re.sub(\"ü§î\", \" \",string) \n",
        "   string = re.sub(\"üåà\", \" \",string) \n",
        "   string = re.sub(\"üíï\", \" \",string) \n",
        "   string = re.sub(\"üë©‚Äç‚ù§Ô∏è‚Äçüë©\", \" \",string) \n",
        "   string = re.sub(\"üòç\", \" \",string) \n",
        "   string = re.sub(\"üëÜ\", \" \",string) \n",
        "   string = re.sub(\"üòñ\", \" \",string) \n",
        "   string = re.sub(\"üëá\", \" \",string) \n",
        "   string = re.sub(\"üî•\", \" \",string) \n",
        "   string = re.sub(\"üòò\", \" \",string) \n",
        "   string = re.sub(\"üéâ\", \" \",string) \n",
        "   string = re.sub(\"ü§¨\", \" \",string) \n",
        "   string = re.sub(\"üëä\", \" \",string)\n",
        "   string = re.sub(\"üá©üá™\", \" \",string)  \n",
        "   string = re.sub(\"üíî\", \" \",string)\n",
        "   string = re.sub(\"üôà\", \" \",string)\n",
        "   string = re.sub(\"ü§Ø\", \" \",string)\n",
        "   string = re.sub(\"üêü\", \" \",string)\n",
        "   string = re.sub(\"üõ∂\", \" \",string)\n",
        "   string = re.sub(\"üòä\", \" \",string)\n",
        "   string = re.sub(\"üòì\", \" \",string)\n",
        "   string = re.sub(\"üò≥\", \" \",string)\n",
        "   string = re.sub(\"üöÄ\", \" \",string)\n",
        "   string = re.sub(\"üëé\", \" \",string)\n",
        "   string = re.sub(\"üòé\", \" \",string)\n",
        "   string = re.sub(\"üê∏\", \" \",string)\n",
        "   string = re.sub(\"üìà\", \" \",string)\n",
        "   string = re.sub(\"üôÇ\", \" \",string)\n",
        "   string = re.sub(\"üòÖ\", \" \",string)\n",
        "   string = re.sub(\"üòÜ\", \" \",string)\n",
        "   string = re.sub(\"üôéüèø\", \" \",string)\n",
        "   string = re.sub(\"üëéüèΩ\", \" \",string)\n",
        "   string = re.sub(\"ü§≠\", \" \",string)\n",
        "   string = re.sub(\"üò§\", \" \",string)\n",
        "   string = re.sub(\"üòö\", \" \",string)\n",
        "   string = re.sub(\"üòä\", \" \",string)\n",
        "   string = re.sub(\"üò≤\", \" \",string)\n",
        "   string = re.sub(\"ü§Æ\", \" \",string)\n",
        "   string = re.sub(\"üôÑ\", \" \",string)\n",
        "   string = re.sub(\"ü§ë\", \" \",string)\n",
        "   string = re.sub(\"üéÖ\", \" \",string)\n",
        "   string = re.sub(\"üëã\", \" \",string)\n",
        "   string = re.sub(\"üí™\", \" \",string)\n",
        "   string = re.sub(\"üòÑ\", \" \",string)\n",
        "   string = re.sub(\"üßê\", \" \",string)\n",
        "   string = re.sub(\"üò†\", \" \",string)\n",
        "   string = re.sub(\"üéà\", \" \",string)\n",
        "   string = re.sub(\"üöÇ\", \" \",string)\n",
        "   string = re.sub(\"üòä\", \" \",string)\n",
        "   string = re.sub(\"üöá\", \" \",string)\n",
        "   string = re.sub(\"üöä\", \" \",string)\n",
        "   string = re.sub(\"ü§∑\", \" \",string)\n",
        "   string = re.sub(\"üò•\", \" \",string)\n",
        "   string = re.sub(\"üôÉ\", \" \",string)\n",
        "   string = re.sub(\"üî©\", \" \",string)\n",
        "   string = re.sub(\"üîß\", \" \",string)\n",
        "   string = re.sub(\"üî®\", \" \",string)\n",
        "   string = re.sub(\"üõ†\", \" \",string)\n",
        "   string = re.sub(\"üíì\", \" \",string)\n",
        "   string = re.sub(\"üí°\", \" \",string)\n",
        "   string = re.sub(\"üç∏\", \" \",string)\n",
        "   string = re.sub(\"ü•É\", \" \",string)\n",
        "   string = re.sub(\"ü•Ç\", \" \",string)\n",
        "   string = re.sub(\"üò∑\", \" \",string)\n",
        "   string = re.sub(\"ü§ê\", \" \",string)\n",
        "   string = re.sub(\"üåé\", \" \",string)\n",
        "   string = re.sub(\"üëë\", \" \",string)\n",
        "   string = re.sub(\"ü§õ\", \" \",string)\n",
        "   string = re.sub(\"üòÄ\", \" \",string)\n",
        "   string = re.sub(\"üõ§\", \" \",string)\n",
        "   string = re.sub(\"üéÑ\", \" \",string)\n",
        "   string = re.sub(\"üì¥\", \" \",string)\n",
        "   string = re.sub(\"üå≠\", \" \",string)\n",
        "   string = re.sub(\"ü§ï\", \" \",string)\n",
        "   string = re.sub(\"üò≠\", \" \",string)\n",
        "   string = re.sub(\"üçæ\", \" \",string)\n",
        "   string = re.sub(\"üçû\", \" \",string)\n",
        "   string = re.sub(\"ü§¶\", \" \",string)\n",
        "   string = re.sub(\"ü§Ø\", \" \",string)\n",
        "   string = re.sub(\"üïØÔ∏è\", \" \",string)\n",
        "\n",
        "   string = re.sub(\"OTHER|OFFENSE|ABUSE|INSULT\",\" \",string)\n",
        "   return string"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5asMgo4LtnRg"
      },
      "source": [
        "statementsForTraining = []\n",
        "sentimentsForTraining = []\n",
        "\n",
        "\n",
        "fileToRead = open(training_file, 'r')\n",
        "\n",
        "while True:\n",
        "  #next line in file\n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  findSentiment = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "\n",
        "\n",
        "  statementsForTraining.append(line)\n",
        "   #sentimentsForTraining.append(findSentiment.group(0))\n",
        "\n",
        "  if findSentiment.group(0) == \"OTHER\":  \n",
        "    sentimentsForTraining.append(0)\n",
        "  else:\n",
        "    sentimentsForTraining.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        " #print(\"{}: {}\".format(count,line.strip()))\n",
        "  \n",
        " # print(sentiment.group(0))\n",
        " \n",
        "fileToRead.close()\n",
        "\n",
        "training_sentences = statementsForTraining\n",
        "training_labels = sentimentsForTraining\n",
        "\n",
        "#print(training_sentences[9])\n",
        "#print(training_labels[9])\n",
        "\n",
        "#print(len(training_sentences))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsqZPENb98gD"
      },
      "source": [
        "##do the same with testdata\n",
        "statementsForTesting = []\n",
        "sentimentsForTesting = []\n",
        "\n",
        "fileToRead = open(testing_file, 'r')\n",
        "\n",
        "while True:\n",
        "  #next line in file\n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  sent = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "\n",
        "    \n",
        "\n",
        "  statementsForTesting.append(line)\n",
        "  #print(len(line))\n",
        "  #sentimentsForTesting.append(sent.group(0))\n",
        "\n",
        "  if sent.group(0) == \"OTHER\": \n",
        "    sentimentsForTesting.append(0)\n",
        "  else:\n",
        "    sentimentsForTesting.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        "\n",
        "fileToRead.close()\n",
        "\n",
        "\n",
        "testing_sentences = statementsForTesting\n",
        "testing_labels = sentimentsForTesting\n",
        "#print(len(testing_sentences))\n",
        "#print(testing_sentences)   \n",
        "#print(testing_labels)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRUvDLD5bMbO"
      },
      "source": [
        "Padding -> im Prinzip die S√§tze alle auf die gleiche L√§nge bringen (in Theorieteil n√§her drauf eingehen) -> maxlen-Paramter ist f√ºr pad_sequences vorhanden, wenn nicht gesetzt -> alles wird auf die L√§nge des l√§ngsten Satzes aufgef√ºllt -> print(padded(shape)) gibt aus, wie viele Datens√§tze padded wurden und gibt an, wie viele Tokens der l√§ngste Datensatz hat\n",
        "print(padded[x]) gibt einen Satz aus (bereits tokenisiert)\n",
        "\n",
        "Padding -> sowohl f√ºr Trainigs- als auch f√ºr Testdaten\n",
        "\n",
        "Und: Daten als numpy-Arrays speichern (notwendig f√ºr tensorflow).\n",
        "\n",
        " -> Tokenizer https://towardsdatascience.com/text-classification-in-keras-part-2-how-to-use-the-keras-tokenizer-word-representations-fd571674df23 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3hFi7waTv5m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b19a288-3bf2-4dde-c082-2893bca0c3cf"
      },
      "source": [
        "tokenizer = Tokenizer(oov_token=\"OOV\")\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "\n",
        "#creating a word index - nur die Trainigsdaten\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "validation_size = 500\n",
        "\n",
        "\n",
        "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "padded_training = pad_sequences(training_sequences, maxlen=max_length, padding='post')\n",
        "print(len(padded_training))\n",
        "\n",
        "validation_sequences = padded_training[0:validation_size]\n",
        "validation_labels = training_labels[0:validation_size]\n",
        "\n",
        "padded_training = padded_training[validation_size:]\n",
        "training_labels = training_labels[validation_size:]\n",
        "\n",
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
        "padded_testing = pad_sequences(testing_sequences, maxlen=max_length,  padding='post')\n",
        "\n",
        "#print(validation_sequences[499])\n",
        "print(padded_training[0])\n",
        "#print(len(validation_labels))\n",
        "#print(len(training_labels))\n",
        "\n",
        "\n",
        "nppadded_training = np.array(padded_training)\n",
        "nptraining_labels = np.array(training_labels)\n",
        "\n",
        "nppadded_validation = np.array(validation_sequences)\n",
        "npvalidation_labels = np.array(validation_labels)\n",
        "\n",
        "nppadded_testing = np.array(padded_testing)\n",
        "nptesting_labels = np.array(testing_labels)\n",
        "\n",
        "\n",
        "print(len(nppadded_training))\n",
        "print(len(nptraining_labels))\n",
        "print(len(word_index))\n",
        "\n",
        "#print(statementsForTraining[2])\n",
        "#print(nppadded_training[4])\n",
        "#print(nppadded_training.shape)\n",
        "#print(nptraining_labels[4])\n",
        "#print(nppadded_testing.shape)\n",
        "#print(word_index) \n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5009\n",
            "[  12 3982   11   41 6706 1040    4    5  202   39    3 2922   49 1360\n",
            "  810  495 3983    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0]\n",
            "4509\n",
            "4509\n",
            "15059\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tL3owrc8THkT"
      },
      "source": [
        "\n",
        "Dann: Embedding mit entweder word2vec oder glove\n",
        "Word2vec-Daten sind hier: http://vectors.nlpl.eu/repository/#\n",
        "Glove -> https://nlp.stanford.edu/projects/glove/ Da mal den Twitter-Vector runtergeladen\n",
        "Wenn Daten in GoogleDrive sind (w√§re auch via url m√∂glich..), muss Drive gemounted werden ( https://buomsoo-kim.github.io/colab/2020/05/09/Colab-mounting-google-drive.md/ ) aber auch hier https://enjoymachinelearning.com/posts/colab-with-google-drive/\n",
        "\n",
        "Die Word2vec vectors: http://vectors.nlpl.eu/repository/# \n",
        "\n",
        "glove-zitat:\n",
        "Citing GloVe\n",
        "\n",
        "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. [pdf] [bib]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zuO7T9ZTG57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8253a7d-68ab-413b-c3ff-c22a7e8d3c9e"
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount(\"/content/drive\")\n",
        "os.listdir(\"/content/drive/MyDrive/Colab Notebooks\")\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['germeval_training.txt',\n",
              " 'glove.twitter.27B.50d.txt',\n",
              " 'glove.twitter.27B.200d.txt',\n",
              " 'glove.6B.200d.txt',\n",
              " 'glove.840B.300d.txt',\n",
              " 'tensorboard.gdoc',\n",
              " 'keras.gdoc',\n",
              " 'Vectorization CNN embedded_limited_vocab.ipynb',\n",
              " 'glove.42B.300d.txt',\n",
              " 'Embedding Glove Vergleich.ipynb',\n",
              " 'CNN embedded_limited_vocab.ipynb',\n",
              " 'LSTM_limited_vocab.ipynb',\n",
              " 'LSTM.ipynb',\n",
              " 'CNN embedded.ipynb']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7ToKO-sZLHK"
      },
      "source": [
        "\n",
        "Keras-Doc : https://keras.io/examples/nlp/pretrained_word_embeddings/#load-pretrained-word-embeddings \n",
        "embedding mit initializers.. weights m√ºsste auch funktionieren\n",
        "\n",
        "Diese erstellte Matrix mit Embedding dann in die Embedding-Schicht einbinden,  Trainable auf False, weil sich die Werte nicht durch Training anpassen sollen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AShIVfC7ZQAH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14a226d3-92e3-4ffb-ead8-57d9312f8336"
      },
      "source": [
        "#Gr√∂√üe Vokabel -> wordindex + 2 (weil padding + OOV) \n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "vocabulary_size = len(word_index)+2\n",
        "\n",
        "# dann erstell ich ein W√∂rterbuch mit Namen \"embedding_vector\", dort sind dann\n",
        "#die keys drinnen, die in glove-Datei drinnen sind mit dem entsprechenden Key\n",
        "\n",
        "embedding_index_glove = {}\n",
        "f = open('/content/drive/MyDrive/Colab Notebooks/glove.twitter.27B.200d.txt')\n",
        "for line in f:\n",
        "  value = line.split()\n",
        "  word = value[0]\n",
        "  coef = np.asarray(value[1:],dtype='float32')\n",
        "  embedding_index_glove[word] = coef\n",
        "\n",
        "print(\"%d gefunden: \"% len(embedding_index_glove))\n",
        "\n",
        "#Dann noch eine Embedding-Matrix erstellen\n",
        "#zweiter Wert = Embedding-Dimension der Datei, in dem Fall 200\n",
        "\n",
        "glove_matrix = np.zeros((vocabulary_size,200))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    embedding_value = embedding_index_glove.get(word)\n",
        "    if embedding_value is not None:\n",
        "      glove_matrix[index] = embedding_value\n",
        "      hits+=1\n",
        "    else:\n",
        "      misses+=1\n",
        "\n",
        "print(\"hits %d and %d misses\"%(hits,misses))\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1193514 gefunden: \n",
            "hits 6747 and 8312 misses\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZmvOfwhV4N5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bd2794a-a43c-441d-9c8b-d952ec4fc993"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "print(\"vocab size: %d\"%vocabulary_size)\n",
        "CNN1605210230AE = tf.keras.Sequential()\n",
        "#Embedding -> hier dann auf das embedding verweisen, Input_dim -> die Anzahl der W√∂rter im word_index, output -> in dem Fall passend zum verwendeten Vektor\n",
        "#input-length -> auf 60  gepadded, trainable -> nein, weil nichts ver√§ndert werden soll\n",
        "#embeddings_initializer=keras.initializers.Constant(glove_matrix) vs weights = [glove_matrix]\n",
        "#Convolutional layers => filters = neurons.. mit 100? 265?\n",
        "#CNN1605210230AE.add(tf.keras.layers.Embedding(input_dim=vocabulary_size, output_dim=200, input_length=max_length))\n",
        "CNN1605210230AE.add(tf.keras.layers.Embedding(vocabulary_size, output_dim=200, input_length=60, embeddings_initializer = keras.initializers.Constant(glove_matrix), trainable= False))\n",
        "CNN1605210230AE.add(tf.keras.layers.Dropout(0.4))\n",
        "CNN1605210230AE.add(tf.keras.layers.Conv1D(filters=30, kernel_size=3, padding=\"valid\", activation=\"relu\"))\n",
        "CNN1605210230AE.add(tf.keras.layers.MaxPooling1D())\n",
        "CNN1605210230AE.add(tf.keras.layers.Conv1D(filters=30, kernel_size=3, padding=\"valid\", activation=\"relu\"))\n",
        "CNN1605210230AE.add(tf.keras.layers.GlobalAveragePooling1D())\n",
        "CNN1605210230AE.add(tf.keras.layers.Flatten())\n",
        "CNN1605210230AE.add(tf.keras.layers.Dense(260, activation=\"relu\"))\n",
        "CNN1605210230AE.add(tf.keras.layers.Dropout(0.4))\n",
        "CNN1605210230AE.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "CNN1605210230AE.summary()\n",
        "\n",
        "#nppadded_training = np.asmatrix(nppadded_training) not necessary\n",
        "#nppadded_testing = np.asmatrix(nppadded_testing)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab size: 15061\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 60, 200)           3012200   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 60, 200)           0         \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 58, 30)            18030     \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 29, 30)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 27, 30)            2730      \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 30)                0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 30)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 260)               8060      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 260)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 261       \n",
            "=================================================================\n",
            "Total params: 3,041,281\n",
            "Trainable params: 29,081\n",
            "Non-trainable params: 3,012,200\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEr4OzT-iHDe"
      },
      "source": [
        "#model.layers[2].get_weights()[0].shape\n",
        "#weights=np.random.rand(5,200,100)\n",
        "#bias=np.random.rand(100)\n",
        "#model.layers[2].set_weights([weights, bias])\n",
        "\n",
        "#model.layers[2].get_weights()[0]\n",
        "#https://androidkt.com/set-custom-weights-keras-using-numpy-array/"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UB7_3VPYesr9"
      },
      "source": [
        "F1-Score f√ºr jede Epoche https://aakashgoel12.medium.com/how-to-add-user-defined-function-get-f1-score-in-keras-metrics-3013f979ce0d\n",
        "\n",
        "Sehr gute Ressource f√ºr die verschiedenen Scores und Metriken https://neptune.ai/blog/evaluation-metrics-binary-classification#10  das und aakas verwendet\n",
        "\n",
        "hier: je eine Funktion f√ºr Recall, Precision, f1 https://neptune.ai/blog/keras-metrics \n",
        "\n",
        "https://keras.rstudio.com/reference/k_ones_like.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygyrbFJaMV9B"
      },
      "source": [
        "import keras.backend as K\n",
        "\n",
        "def metrics_recall(data_true, data_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(data_true,0,1)))\n",
        "\n",
        "    recall = true_positives / (possible_positives+K.epsilon())\n",
        "    return recall\n",
        "\n",
        "\n",
        "def metrics_precision(data_true, data_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "\n",
        "    positives_predicted = K.sum(K.round(K.clip(data_pred,0,1)))\n",
        "    precision = true_positives / (positives_predicted+K.epsilon())\n",
        "    return precision\n",
        "\n",
        "\n",
        "def metrics_f1(data_true, data_pred):\n",
        "    precision_data = metrics_precision(data_true, data_pred)\n",
        "    recall_data = metrics_recall(data_true, data_pred)\n",
        "    return 2*(precision_data*recall_data)/(precision_data+recall_data+K.epsilon())"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1ctlBrnuYJz"
      },
      "source": [
        "https://aakashgoel12.medium.com/how-to-add-user-defined-function-get-f1-score-in-keras-metrics-3013f979ce0d"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AfPD3_bWCm0"
      },
      "source": [
        "#CNN1605210230AE.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',metrics_recall,metrics_precision,metrics_f1])\n",
        "CNN1605210230AE.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',metrics_recall,metrics_precision,metrics_f1])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpChKUY-QEWI"
      },
      "source": [
        "https://www.tensorflow.org/tensorboard/tensorboard_in_notebooks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJfMgUhHBoD1"
      },
      "source": [
        "#%load_ext tensorboard\n",
        "#nur einmal pro Sitzung notwendig\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ISmMXLqP8Hc"
      },
      "source": [
        "\n",
        "logs_base_dir = \"./logs\"\n",
        "callbackForTB = tf.keras.callbacks.TensorBoard(logs_base_dir)\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ehh-EMXUQh8r"
      },
      "source": [
        "Early Stopping as defined in keras tensorflow documentation\n",
        "https://www.tensorflow.org/guide/keras/train_and_evaluate "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BY_t-PeQEjy"
      },
      "source": [
        "callbackEarlyStopping = [\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_loss\",\n",
        "        mode=\"min\",\n",
        "        patience=3,\n",
        "        verbose=1,\n",
        "    )\n",
        "]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2CHbXiP1LsF"
      },
      "source": [
        "training_epochs = 13\n",
        "batch_size = 40\n",
        "validation_split=0.2"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abV-QAxfW48r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "531ef22b-d588-46f8-9a0e-f892533fdccb"
      },
      "source": [
        "#Werte der Convolutional-Schichten variieren (Filter), Batch-Size variieren, kernel-size..\n",
        "CNN1605210230AE.fit(nppadded_training, nptraining_labels, batch_size=batch_size, validation_split=validation_split, epochs=training_epochs, callbacks=[callbackForTB])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/13\n",
            "91/91 [==============================] - 4s 29ms/step - loss: 0.6509 - accuracy: 0.6537 - metrics_recall: 0.0207 - metrics_precision: 0.0135 - metrics_f1: 0.0148 - val_loss: 0.6389 - val_accuracy: 0.6718 - val_metrics_recall: 0.0000e+00 - val_metrics_precision: 0.0000e+00 - val_metrics_f1: 0.0000e+00\n",
            "Epoch 2/13\n",
            "91/91 [==============================] - 3s 28ms/step - loss: 0.6372 - accuracy: 0.6626 - metrics_recall: 0.0000e+00 - metrics_precision: 0.0000e+00 - metrics_f1: 0.0000e+00 - val_loss: 0.6199 - val_accuracy: 0.6718 - val_metrics_recall: 0.0000e+00 - val_metrics_precision: 0.0000e+00 - val_metrics_f1: 0.0000e+00\n",
            "Epoch 3/13\n",
            "91/91 [==============================] - 3s 28ms/step - loss: 0.6211 - accuracy: 0.6609 - metrics_recall: 0.0165 - metrics_precision: 0.0562 - metrics_f1: 0.0225 - val_loss: 0.5965 - val_accuracy: 0.6718 - val_metrics_recall: 0.0000e+00 - val_metrics_precision: 0.0000e+00 - val_metrics_f1: 0.0000e+00\n",
            "Epoch 4/13\n",
            "91/91 [==============================] - 2s 27ms/step - loss: 0.6001 - accuracy: 0.6670 - metrics_recall: 0.0997 - metrics_precision: 0.4301 - metrics_f1: 0.1452 - val_loss: 0.6216 - val_accuracy: 0.6630 - val_metrics_recall: 0.5081 - val_metrics_precision: 0.4870 - val_metrics_f1: 0.4848\n",
            "Epoch 5/13\n",
            "91/91 [==============================] - 4s 47ms/step - loss: 0.5800 - accuracy: 0.6792 - metrics_recall: 0.2181 - metrics_precision: 0.5734 - metrics_f1: 0.2870 - val_loss: 0.5817 - val_accuracy: 0.7062 - val_metrics_recall: 0.3783 - val_metrics_precision: 0.5837 - val_metrics_f1: 0.4463\n",
            "Epoch 6/13\n",
            "91/91 [==============================] - 5s 52ms/step - loss: 0.5628 - accuracy: 0.7025 - metrics_recall: 0.3256 - metrics_precision: 0.6171 - metrics_f1: 0.4019 - val_loss: 0.5757 - val_accuracy: 0.7073 - val_metrics_recall: 0.4544 - val_metrics_precision: 0.5685 - val_metrics_f1: 0.4909\n",
            "Epoch 7/13\n",
            "91/91 [==============================] - 3s 28ms/step - loss: 0.5535 - accuracy: 0.7078 - metrics_recall: 0.3839 - metrics_precision: 0.6325 - metrics_f1: 0.4440 - val_loss: 0.5825 - val_accuracy: 0.6951 - val_metrics_recall: 0.5558 - val_metrics_precision: 0.5359 - val_metrics_f1: 0.5321\n",
            "Epoch 8/13\n",
            "91/91 [==============================] - 2s 27ms/step - loss: 0.5410 - accuracy: 0.7214 - metrics_recall: 0.4271 - metrics_precision: 0.6425 - metrics_f1: 0.4868 - val_loss: 0.5601 - val_accuracy: 0.7206 - val_metrics_recall: 0.3251 - val_metrics_precision: 0.6616 - val_metrics_f1: 0.4179\n",
            "Epoch 9/13\n",
            "91/91 [==============================] - 3s 28ms/step - loss: 0.5257 - accuracy: 0.7377 - metrics_recall: 0.4700 - metrics_precision: 0.6783 - metrics_f1: 0.5309 - val_loss: 0.5496 - val_accuracy: 0.7228 - val_metrics_recall: 0.4336 - val_metrics_precision: 0.6140 - val_metrics_f1: 0.4945\n",
            "Epoch 10/13\n",
            "91/91 [==============================] - 3s 28ms/step - loss: 0.5067 - accuracy: 0.7533 - metrics_recall: 0.5114 - metrics_precision: 0.6695 - metrics_f1: 0.5638 - val_loss: 0.5431 - val_accuracy: 0.7217 - val_metrics_recall: 0.4407 - val_metrics_precision: 0.5929 - val_metrics_f1: 0.4922\n",
            "Epoch 11/13\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.4964 - accuracy: 0.7491 - metrics_recall: 0.4997 - metrics_precision: 0.6784 - metrics_f1: 0.5596 - val_loss: 0.5736 - val_accuracy: 0.6829 - val_metrics_recall: 0.6721 - val_metrics_precision: 0.5135 - val_metrics_f1: 0.5704\n",
            "Epoch 12/13\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.4969 - accuracy: 0.7569 - metrics_recall: 0.5658 - metrics_precision: 0.6815 - metrics_f1: 0.5816 - val_loss: 0.5340 - val_accuracy: 0.7217 - val_metrics_recall: 0.4266 - val_metrics_precision: 0.5906 - val_metrics_f1: 0.4812\n",
            "Epoch 13/13\n",
            "91/91 [==============================] - 3s 28ms/step - loss: 0.4794 - accuracy: 0.7641 - metrics_recall: 0.5422 - metrics_precision: 0.6931 - metrics_f1: 0.5809 - val_loss: 0.5357 - val_accuracy: 0.7162 - val_metrics_recall: 0.4795 - val_metrics_precision: 0.5638 - val_metrics_f1: 0.5074\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1000e80bd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJVL4SBLPB2P"
      },
      "source": [
        "#%tensorboard --logdir {logs_base_dir}"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_LnvWBcnoak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cc1e689-29fb-47c0-fa8b-c6e27558148a"
      },
      "source": [
        "#results = model.evaluate(nppadded_testing, nptesting_labels, batch_size=batch_size)\n",
        "#print(\"test loss, test acc:\",results)\n",
        "\n",
        "(loss,accuracy, metrics_recall,metrics_precision,\n",
        "metrics_f1) = CNN1605210230AE.evaluate(nppadded_testing, nptesting_labels, verbose=1)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5859 - accuracy: 0.6869 - metrics_recall: 0.3823 - metrics_precision: 0.5591 - metrics_f1: 0.4418\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KgjIkhpKmHc"
      },
      "source": [
        "make some predictions of test data and save it to variable. verbose=0 -> do not generate output\n",
        "Gute Quelle: https://deeplizard.com/learn/video/2f-NjDUvZIE "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89GWuxryKlcM"
      },
      "source": [
        "CNN_predictions30AE = CNN1605210230AE.predict(x=nppadded_testing)\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3jPDaDJK_cN"
      },
      "source": [
        "#for p in CNN_predictions30AE:\n",
        " # print(p)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eC9efJy4Lp21"
      },
      "source": [
        "rounded predictions: give prediction value of most likely prediction (0 or 1). Printing the output of rounded prediction shows the prediction made by the model on the data (which output is most likely)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsG-TJuQLvtk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a337d649-d7a7-4622-bc86-5ae3194a9146"
      },
      "source": [
        "prediction_rounded30AE = np.round(CNN_predictions30AE)\n",
        "#np.argmax(CNN_predictions30AE,axis=-1)\n",
        "\n",
        "#for p in prediction_rounded30AE:\n",
        " # print(p)\n",
        "\n",
        "\n",
        "print(nptesting_labels[500:520])\n",
        "print(prediction_rounded30AE[500:520])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1]\n",
            "[[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egTtgpXgg8a2"
      },
      "source": [
        "https://deeplizard.com/learn/video/km7pxKy4UHU\n",
        "\n",
        "Quelle der def plot_confusion_matrix: https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSDXf7-_MITy"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0AMs1EzhBU1"
      },
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                        normalize=False,\n",
        "                        title='Confusion matrix',\n",
        "                        cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2JgEnlghCtl"
      },
      "source": [
        "cm = confusion_matrix(y_true=nptesting_labels, y_pred=prediction_rounded30AE)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckmF29whhFmX"
      },
      "source": [
        "plot_labels = ['no hatespeech','hatespeech']"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mpSE96rhK7K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "outputId": "5fb60581-a60e-445d-b92d-354f51051fb3"
      },
      "source": [
        "plot_confusion_matrix(cm=cm, classes=plot_labels, title='CNN Confusion 30 13 Epochs')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix, without normalization\n",
            "[[1965  365]\n",
            " [ 741  461]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}