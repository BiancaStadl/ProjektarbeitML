{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN embedded.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMgzpmFGdZHW+0kzB1Yfeni",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BiancaStadl/ProjektarbeitML/blob/main/CNN_embedded.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXDOlIBymF0V"
      },
      "source": [
        "GloVe embeddings taken from:\n",
        "\n",
        "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. [pdf] [bib]\n",
        "\n",
        "hatespeechdata taken from (https://hatespeechdata.com/): Wiegand, M., Siegel, M. and Ruppenhofer, J., 2018. Overview of the GermEval 2018 Shared Task on the Identification of Offensive Language. In: Proceedings of GermEval 2018, 14th Conference on Natural Language Processing (KONVENS 2018). Vienna, Austria: Research Gate. available on: https://github.com/uds-lsv/GermEval-2018-Data (last checked: 09.05.2021)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlBmABDxfqII"
      },
      "source": [
        "wiki detox..https://colab.research.google.com/github/tensorflow/fairness-indicators/blob/master/g3doc/tutorials/Fairness_Indicators_TFCO_Wiki_Case_Study.ipynb#scrollTo=y6T5tlXcdW7J "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3xfitNdliBI"
      },
      "source": [
        "#import matplotlib.pyplot as plt -> für evtl Visualisierungen\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import string\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from keras import losses \n",
        "from keras import optimizers \n",
        "from keras import metrics \n",
        "\n",
        "#!pip install Tokenizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "#!pip install pad_sequences\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import preprocessing\n",
        "#from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTWJQ1iga_vS"
      },
      "source": [
        "Maximale Satzlänge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bq08Me5la_Cc"
      },
      "source": [
        "\n",
        "max_length = 60"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVYBMvYSotTH"
      },
      "source": [
        "url = \"https://github.com/uds-lsv/GermEval-2018-Data/archive/master.zip\"\n",
        "\n",
        "dataset = tf.keras.utils.get_file(\"GermEval-2018-Data-master.zip\", url, \n",
        "                                   extract=True, cache_dir='.',\n",
        "                                    cache_subdir='')\n",
        "\n",
        "dataset_dir = os.path.join(os.path.dirname(dataset), 'GermEval-2018-Data-master')\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cS14OUtfo34V"
      },
      "source": [
        "#os.listdir(dataset_dir)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2X429K6hpOVm"
      },
      "source": [
        "training_file = os.path.join(dataset_dir, 'germeval2018.training.txt')\n",
        "\n",
        "testing_file = os.path.join(dataset_dir, 'germeval2018.test.txt')\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uq8fG3LNtn_m"
      },
      "source": [
        "###Aufbereitung\n",
        "txt-Dateien lesen, und dabei jede Zeile splitten und teilen\n",
        "Twitter-Handler entfernen?\n",
        "Labels von Sätzen trennen, Labels in eigenen Array packen.\n",
        "\n",
        "####Ressourcen\n",
        "* https://www.w3schools.com/python/gloss_python_if_statement.asp\n",
        "* https://stackabuse.com/using-regex-for-text-manipulation-in-python/\n",
        "* https://www.tutorialspoint.com/python/string_splitlines.htm \n",
        "* https://note.nkmk.me/en/python-split-rsplit-splitlines-re/ \n",
        "* https://www.w3schools.com/python/python_regex.asp \n",
        "\n",
        "gäbe bei keras tf.keras.preprocessing.text_dataset_from_directory, aber dafür müssten die Daten auf bestimmte Weise in Verzeichnis organisiert sein, hier nicht der Fall.\n",
        "\n",
        "\n",
        "Einteilung der Daten: Testdaten\n",
        "Trainingsdaten -> noch ca 500 für Validierungsdaten\n",
        "\n",
        "labels -> \"other\", also nicht-negative Aussagen bekommen \"0\", negative Aussagen bekommen \"1\"\n",
        "\n",
        " Regex für Emojis  ->\n",
        "\n",
        "(\\u00a9|\\u00ae|[\\u2000-\\u3300]|\\ud83c[\\ud000-\\udfff]|\\ud83d[\\ud000-\\udfff]|\\ud83e[\\ud000-\\udfff])\n",
        "\n",
        "genommen von https://www.regextester.com/106421 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Py_cwD4eZkXo"
      },
      "source": [
        "def remove_clutter(string):\n",
        "   string = re.sub(\"@[^\\s]+\",\" \",string)\n",
        "   string = re.sub(\"#[^\\s]+\",\" \", string)\n",
        "   string = re.sub(\"\\u00a9\",\" \", string)\n",
        "   string = re.sub(\"\\u00ae\",\" \", string)\n",
        "   string = re.sub(\"[\\u2000-\\u3300]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83c[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83d[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83e[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"😜\", \" \",string)\n",
        "   string = re.sub(\"🍫\", \" \",string)\n",
        "   string = re.sub(\"😁\", \" \",string)\n",
        "   string = re.sub(\"🐖\", \" \",string)\n",
        "   string = re.sub(\"😡\", \" \",string)\n",
        "   string = re.sub(\"😇\", \" \",string)\n",
        "   string = re.sub(\"😬\", \" \",string)\n",
        "   string = re.sub(\"😃\", \" \",string)\n",
        "   string = re.sub(\"😂\", \" \",string)\n",
        "   string = re.sub(\"💙\", \" \",string)  \n",
        "   string = re.sub(\"😛\", \" \",string)\n",
        "   string = re.sub(\"🙏\", \" \",string)\n",
        "   string = re.sub(\"👍\", \" \",string)\n",
        "   string = re.sub(\"🖕\", \" \",string)\n",
        "   string = re.sub(\"😉\", \" \",string)\n",
        "   string = re.sub(\"💩\", \" \",string)\n",
        "   string = re.sub(\"🤢\", \" \",string)\n",
        "   string = re.sub(\"👏\", \" \",string)\n",
        "   string = re.sub(\"😨\", \" \",string)\n",
        "   string = re.sub(\"🤣\", \" \",string)\n",
        "   string = re.sub(\"🤡\", \" \",string)\n",
        "   string = re.sub(\"😈\", \" \",string)\n",
        "   string = re.sub(\"💃🏽\", \" \",string)\n",
        "   string = re.sub(\"👹\", \" \",string)\n",
        "   string = re.sub(\"🤘\", \" \",string)\n",
        "   string = re.sub(\"😱\", \" \",string)\n",
        "   string = re.sub(\"🤔\", \" \",string) \n",
        "   string = re.sub(\"🌈\", \" \",string) \n",
        "   string = re.sub(\"💕\", \" \",string) \n",
        "   string = re.sub(\"👩‍❤️‍👩\", \" \",string) \n",
        "   string = re.sub(\"😍\", \" \",string) \n",
        "   string = re.sub(\"👆\", \" \",string) \n",
        "   string = re.sub(\"😖\", \" \",string) \n",
        "   string = re.sub(\"👇\", \" \",string) \n",
        "   string = re.sub(\"🔥\", \" \",string) \n",
        "   string = re.sub(\"😘\", \" \",string) \n",
        "   string = re.sub(\"🎉\", \" \",string) \n",
        "   string = re.sub(\"🤬\", \" \",string) \n",
        "   string = re.sub(\"👊\", \" \",string)\n",
        "   string = re.sub(\"🇩🇪\", \" \",string)  \n",
        "   string = re.sub(\"💔\", \" \",string)\n",
        "   string = re.sub(\"🙈\", \" \",string)\n",
        "   string = re.sub(\"🤯\", \" \",string)\n",
        "   string = re.sub(\"🐟\", \" \",string)\n",
        "   string = re.sub(\"🛶\", \" \",string)\n",
        "   string = re.sub(\"😊\", \" \",string)\n",
        "   string = re.sub(\"😓\", \" \",string)\n",
        "   string = re.sub(\"😳\", \" \",string)\n",
        "   string = re.sub(\"🚀\", \" \",string)\n",
        "   string = re.sub(\"👎\", \" \",string)\n",
        "   string = re.sub(\"😎\", \" \",string)\n",
        "   string = re.sub(\"🐸\", \" \",string)\n",
        "   string = re.sub(\"📈\", \" \",string)\n",
        "   string = re.sub(\"🙂\", \" \",string)\n",
        "   string = re.sub(\"😅\", \" \",string)\n",
        "   string = re.sub(\"😆\", \" \",string)\n",
        "   string = re.sub(\"🙎🏿\", \" \",string)\n",
        "   string = re.sub(\"👎🏽\", \" \",string)\n",
        "   string = re.sub(\"🤭\", \" \",string)\n",
        "   string = re.sub(\"😤\", \" \",string)\n",
        "   string = re.sub(\"😚\", \" \",string)\n",
        "   string = re.sub(\"😊\", \" \",string)\n",
        "   string = re.sub(\"😲\", \" \",string)\n",
        "   string = re.sub(\"🤮\", \" \",string)\n",
        "   string = re.sub(\"🙄\", \" \",string)\n",
        "   string = re.sub(\"🤑\", \" \",string)\n",
        "   string = re.sub(\"🎅\", \" \",string)\n",
        "   string = re.sub(\"👋\", \" \",string)\n",
        "   string = re.sub(\"💪\", \" \",string)\n",
        "   string = re.sub(\"😄\", \" \",string)\n",
        "   string = re.sub(\"🧐\", \" \",string)\n",
        "   string = re.sub(\"😠\", \" \",string)\n",
        "   string = re.sub(\"🎈\", \" \",string)\n",
        "   string = re.sub(\"🚂\", \" \",string)\n",
        "   string = re.sub(\"😊\", \" \",string)\n",
        "   string = re.sub(\"🚇\", \" \",string)\n",
        "   string = re.sub(\"🚊\", \" \",string)\n",
        "   string = re.sub(\"🤷\", \" \",string)\n",
        "   string = re.sub(\"😥\", \" \",string)\n",
        "   string = re.sub(\"🙃\", \" \",string)\n",
        "   string = re.sub(\"🔩\", \" \",string)\n",
        "   string = re.sub(\"🔧\", \" \",string)\n",
        "   string = re.sub(\"🔨\", \" \",string)\n",
        "   string = re.sub(\"🛠\", \" \",string)\n",
        "   string = re.sub(\"💓\", \" \",string)\n",
        "   string = re.sub(\"💡\", \" \",string)\n",
        "   string = re.sub(\"🍸\", \" \",string)\n",
        "   string = re.sub(\"🥃\", \" \",string)\n",
        "   string = re.sub(\"🥂\", \" \",string)\n",
        "   string = re.sub(\"😷\", \" \",string)\n",
        "   string = re.sub(\"🤐\", \" \",string)\n",
        "   string = re.sub(\"🌎\", \" \",string)\n",
        "   string = re.sub(\"👑\", \" \",string)\n",
        "   string = re.sub(\"🤛\", \" \",string)\n",
        "   string = re.sub(\"😀\", \" \",string)\n",
        "   string = re.sub(\"🛤\", \" \",string)\n",
        "   string = re.sub(\"🎄\", \" \",string)\n",
        "   string = re.sub(\"📴\", \" \",string)\n",
        "   string = re.sub(\"🌭\", \" \",string)\n",
        "   string = re.sub(\"🤕\", \" \",string)\n",
        "   string = re.sub(\"😭\", \" \",string)\n",
        "   string = re.sub(\"🍾\", \" \",string)\n",
        "   string = re.sub(\"🍞\", \" \",string)\n",
        "   string = re.sub(\"🤦\", \" \",string)\n",
        "   string = re.sub(\"🤯\", \" \",string)\n",
        "   string = re.sub(\"🕯️\", \" \",string)\n",
        "\n",
        "   string = re.sub(\"OTHER|OFFENSE|ABUSE|INSULT\",\" \",string)\n",
        "   return string"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5asMgo4LtnRg"
      },
      "source": [
        "statementsForTraining = []\n",
        "sentimentsForTraining = []\n",
        "\n",
        "\n",
        "fileToRead = open(training_file, 'r')\n",
        "\n",
        "while True:\n",
        "  #next line in file\n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  findSentiment = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "\n",
        "\n",
        "  statementsForTraining.append(line)\n",
        "   #sentimentsForTraining.append(findSentiment.group(0))\n",
        "\n",
        "  if findSentiment.group(0) == \"OTHER\":  \n",
        "    sentimentsForTraining.append(0)\n",
        "  else:\n",
        "    sentimentsForTraining.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        " #print(\"{}: {}\".format(count,line.strip()))\n",
        "  \n",
        " # print(sentiment.group(0))\n",
        " \n",
        "fileToRead.close()\n",
        "\n",
        "training_sentences = statementsForTraining\n",
        "training_labels = sentimentsForTraining\n",
        "\n",
        "#print(training_sentences[9])\n",
        "#print(training_labels[9])\n",
        "\n",
        "#print(len(training_sentences))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsqZPENb98gD"
      },
      "source": [
        "##do the same with testdata\n",
        "statementsForTesting = []\n",
        "sentimentsForTesting = []\n",
        "\n",
        "fileToRead = open(testing_file, 'r')\n",
        "\n",
        "while True:\n",
        "  #next line in file\n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  sent = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "\n",
        "    \n",
        "\n",
        "  statementsForTesting.append(line)\n",
        "  #print(len(line))\n",
        "  #sentimentsForTesting.append(sent.group(0))\n",
        "\n",
        "  if sent.group(0) == \"OTHER\": \n",
        "    sentimentsForTesting.append(0)\n",
        "  else:\n",
        "    sentimentsForTesting.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        "\n",
        "fileToRead.close()\n",
        "\n",
        "\n",
        "testing_sentences = statementsForTesting\n",
        "testing_labels = sentimentsForTesting\n",
        "#print(len(testing_sentences))\n",
        "#print(testing_sentences)   \n",
        "#print(testing_labels)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRUvDLD5bMbO"
      },
      "source": [
        "Padding -> im Prinzip die Sätze alle auf die gleiche Länge bringen (in Theorieteil näher drauf eingehen) -> maxlen-Paramter ist für pad_sequences vorhanden, wenn nicht gesetzt -> alles wird auf die Länge des längsten Satzes aufgefüllt -> print(padded(shape)) gibt aus, wie viele Datensätze padded wurden und gibt an, wie viele Tokens der längste Datensatz hat\n",
        "print(padded[x]) gibt einen Satz aus (bereits tokenisiert)\n",
        "\n",
        "Padding -> sowohl für Trainigs- als auch für Testdaten\n",
        "\n",
        "Und: Daten als numpy-Arrays speichern (notwendig für tensorflow).\n",
        "\n",
        " -> Tokenizer https://towardsdatascience.com/text-classification-in-keras-part-2-how-to-use-the-keras-tokenizer-word-representations-fd571674df23 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3hFi7waTv5m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32c02bc2-d1a4-4ec6-bf45-602c6e2e0dc1"
      },
      "source": [
        "tokenizer = Tokenizer(oov_token=\"OOV\")\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "\n",
        "#creating a word index - nur die Trainigsdaten\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "validation_size = 500\n",
        "\n",
        "\n",
        "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "padded_training = pad_sequences(training_sequences, maxlen=max_length, padding='post')\n",
        "print(len(padded_training))\n",
        "\n",
        "validation_sequences = padded_training[0:validation_size]\n",
        "validation_labels = training_labels[0:validation_size]\n",
        "\n",
        "padded_training = padded_training[validation_size:]\n",
        "training_labels = training_labels[validation_size:]\n",
        "\n",
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
        "padded_testing = pad_sequences(testing_sequences, maxlen=max_length,  padding='post')\n",
        "\n",
        "#print(validation_sequences[499])\n",
        "print(padded_training[0])\n",
        "#print(len(validation_labels))\n",
        "#print(len(training_labels))\n",
        "\n",
        "\n",
        "nppadded_training = np.array(padded_training)\n",
        "nptraining_labels = np.array(training_labels)\n",
        "\n",
        "nppadded_validation = np.array(validation_sequences)\n",
        "npvalidation_labels = np.array(validation_labels)\n",
        "\n",
        "nppadded_testing = np.array(padded_testing)\n",
        "nptesting_labels = np.array(testing_labels)\n",
        "\n",
        "\n",
        "print(len(nppadded_training))\n",
        "print(len(nptraining_labels))\n",
        "print(len(word_index))\n",
        "\n",
        "#print(statementsForTraining[2])\n",
        "#print(nppadded_training[4])\n",
        "#print(nppadded_training.shape)\n",
        "#print(nptraining_labels[4])\n",
        "#print(nppadded_testing.shape)\n",
        "#print(word_index) \n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5009\n",
            "[  12 3982   11   41 6706 1040    4    5  202   39    3 2922   49 1360\n",
            "  810  495 3983    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0]\n",
            "4509\n",
            "4509\n",
            "15059\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tL3owrc8THkT"
      },
      "source": [
        "\n",
        "Dann: Embedding mit entweder word2vec oder glove\n",
        "Word2vec-Daten sind hier: http://vectors.nlpl.eu/repository/#\n",
        "Glove -> https://nlp.stanford.edu/projects/glove/ Da mal den Twitter-Vector runtergeladen\n",
        "Wenn Daten in GoogleDrive sind (wäre auch via url möglich..), muss Drive gemounted werden ( https://buomsoo-kim.github.io/colab/2020/05/09/Colab-mounting-google-drive.md/ ) aber auch hier https://enjoymachinelearning.com/posts/colab-with-google-drive/\n",
        "\n",
        "Die Word2vec vectors: http://vectors.nlpl.eu/repository/# \n",
        "\n",
        "glove-zitat:\n",
        "Citing GloVe\n",
        "\n",
        "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. [pdf] [bib]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zuO7T9ZTG57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f59b86b1-bc2b-4c2f-fe54-484ed866c190"
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount(\"/content/drive\")\n",
        "os.listdir(\"/content/drive/MyDrive/Colab Notebooks\")\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['germeval_training.txt',\n",
              " 'glove.twitter.27B.50d.txt',\n",
              " 'glove.twitter.27B.200d.txt',\n",
              " 'glove.6B.200d.txt',\n",
              " 'glove.840B.300d.txt',\n",
              " 'tensorboard.gdoc',\n",
              " 'keras.gdoc',\n",
              " 'Vectorization CNN embedded_limited_vocab.ipynb',\n",
              " 'glove.42B.300d.txt',\n",
              " 'Embedding Glove Vergleich.ipynb',\n",
              " 'CNN embedded_limited_vocab.ipynb',\n",
              " 'LSTM_limited_vocab.ipynb',\n",
              " 'LSTM.ipynb',\n",
              " 'CNN embedded.ipynb']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7ToKO-sZLHK"
      },
      "source": [
        "\n",
        "Keras-Doc : https://keras.io/examples/nlp/pretrained_word_embeddings/#load-pretrained-word-embeddings \n",
        "embedding mit initializers.. weights müsste auch funktionieren\n",
        "\n",
        "Diese erstellte Matrix mit Embedding dann in die Embedding-Schicht einbinden,  Trainable auf False, weil sich die Werte nicht durch Training anpassen sollen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AShIVfC7ZQAH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61081046-468f-4f7c-877a-92213d891653"
      },
      "source": [
        "#Größe Vokabel -> wordindex + 2 (weil padding + OOV) \n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "vocabulary_size = len(word_index)+2\n",
        "\n",
        "# dann erstell ich ein Wörterbuch mit Namen \"embedding_vector\", dort sind dann\n",
        "#die keys drinnen, die in glove-Datei drinnen sind mit dem entsprechenden Key\n",
        "\n",
        "embedding_index_glove = {}\n",
        "f = open('/content/drive/MyDrive/Colab Notebooks/glove.twitter.27B.200d.txt')\n",
        "for line in f:\n",
        "  value = line.split()\n",
        "  word = value[0]\n",
        "  coef = np.asarray(value[1:],dtype='float32')\n",
        "  embedding_index_glove[word] = coef\n",
        "\n",
        "print(\"%d gefunden: \"% len(embedding_index_glove))\n",
        "\n",
        "#Dann noch eine Embedding-Matrix erstellen\n",
        "#zweiter Wert = Embedding-Dimension der Datei, in dem Fall 200\n",
        "\n",
        "glove_matrix = np.zeros((vocabulary_size,200))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    embedding_value = embedding_index_glove.get(word)\n",
        "    if embedding_value is not None:\n",
        "      glove_matrix[index] = embedding_value\n",
        "      hits+=1\n",
        "    else:\n",
        "      misses+=1\n",
        "\n",
        "print(\"hits %d and %d misses\"%(hits,misses))\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1193514 gefunden: \n",
            "hits 6747 and 8312 misses\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZmvOfwhV4N5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1b731db-50f3-4a10-e320-15ba2ee243a1"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "print(\"vocab size: %d\"%vocabulary_size)\n",
        "CNN1605210290AEBN = tf.keras.Sequential()\n",
        "#Embedding -> hier dann auf das embedding verweisen, Input_dim -> die Anzahl der Wörter im word_index, output -> in dem Fall passend zum verwendeten Vektor\n",
        "#input-length -> auf 60  gepadded, trainable -> nein, weil nichts verändert werden soll\n",
        "#embeddings_initializer=keras.initializers.Constant(glove_matrix) vs weights = [glove_matrix]\n",
        "#Convolutional layers => filters = neurons.. mit 100? 265?\n",
        "#CNN1605210290AEBN.add(tf.keras.layers.Embedding(input_dim=vocabulary_size, output_dim=200, input_length=max_length))\n",
        "CNN1605210290AEBN.add(tf.keras.layers.Embedding(vocabulary_size, output_dim=200, input_length=60, embeddings_initializer = keras.initializers.Constant(glove_matrix), trainable= False))\n",
        "CNN1605210290AEBN.add(tf.keras.layers.Dropout(0.4))\n",
        "CNN1605210290AEBN.add(tf.keras.layers.Conv1D(filters=50, kernel_size=3, padding=\"valid\", activation=\"relu\"))\n",
        "CNN1605210290AEBN.add(tf.keras.layers.MaxPooling1D())\n",
        "CNN1605210290AEBN.add(tf.keras.layers.Conv1D(filters=50, kernel_size=3, padding=\"valid\", activation=\"relu\"))\n",
        "CNN1605210290AEBN.add(tf.keras.layers.GlobalAveragePooling1D())\n",
        "CNN1605210290AEBN.add(tf.keras.layers.Flatten())\n",
        "CNN1605210290AEBN.add(tf.keras.layers.Dense(260, activation=\"relu\"))\n",
        "CNN1605210290AEBN.add(tf.keras.layers.Dropout(0.4))\n",
        "CNN1605210290AEBN.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "CNN1605210290AEBN.summary()\n",
        "\n",
        "#nppadded_training = np.asmatrix(nppadded_training) not necessary\n",
        "#nppadded_testing = np.asmatrix(nppadded_testing)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab size: 15061\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 60, 200)           3012200   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 60, 200)           0         \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 58, 50)            30050     \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 29, 50)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 27, 50)            7550      \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 260)               13260     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 260)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 261       \n",
            "=================================================================\n",
            "Total params: 3,063,321\n",
            "Trainable params: 51,121\n",
            "Non-trainable params: 3,012,200\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEr4OzT-iHDe"
      },
      "source": [
        "#model.layers[2].get_weights()[0].shape\n",
        "#weights=np.random.rand(5,200,100)\n",
        "#bias=np.random.rand(100)\n",
        "#model.layers[2].set_weights([weights, bias])\n",
        "\n",
        "#model.layers[2].get_weights()[0]\n",
        "#https://androidkt.com/set-custom-weights-keras-using-numpy-array/"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UB7_3VPYesr9"
      },
      "source": [
        "F1-Score für jede Epoche https://aakashgoel12.medium.com/how-to-add-user-defined-function-get-f1-score-in-keras-metrics-3013f979ce0d\n",
        "\n",
        "Sehr gute Ressource für die verschiedenen Scores und Metriken https://neptune.ai/blog/evaluation-metrics-binary-classification#10  das und aakas verwendet\n",
        "\n",
        "hier: je eine Funktion für Recall, Precision, f1 https://neptune.ai/blog/keras-metrics \n",
        "\n",
        "https://keras.rstudio.com/reference/k_ones_like.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygyrbFJaMV9B"
      },
      "source": [
        "import keras.backend as K\n",
        "\n",
        "def metrics_recall(data_true, data_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(data_true,0,1)))\n",
        "\n",
        "    recall = true_positives / (possible_positives+K.epsilon())\n",
        "    return recall\n",
        "\n",
        "\n",
        "def metrics_precision(data_true, data_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "\n",
        "    positives_predicted = K.sum(K.round(K.clip(data_pred,0,1)))\n",
        "    precision = true_positives / (positives_predicted+K.epsilon())\n",
        "    return precision\n",
        "\n",
        "\n",
        "def metrics_f1(data_true, data_pred):\n",
        "    precision_data = metrics_precision(data_true, data_pred)\n",
        "    recall_data = metrics_recall(data_true, data_pred)\n",
        "    return 2*(precision_data*recall_data)/(precision_data+recall_data+K.epsilon())"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1ctlBrnuYJz"
      },
      "source": [
        "https://aakashgoel12.medium.com/how-to-add-user-defined-function-get-f1-score-in-keras-metrics-3013f979ce0d"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AfPD3_bWCm0"
      },
      "source": [
        "#CNN1605210290AEBN.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',metrics_recall,metrics_precision,metrics_f1])\n",
        "CNN1605210290AEBN.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',metrics_recall,metrics_precision,metrics_f1])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpChKUY-QEWI"
      },
      "source": [
        "https://www.tensorflow.org/tensorboard/tensorboard_in_notebooks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJfMgUhHBoD1"
      },
      "source": [
        "#%load_ext tensorboard\n",
        "#nur einmal pro Sitzung notwendig\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ISmMXLqP8Hc"
      },
      "source": [
        "\n",
        "logs_base_dir = \"./logs\"\n",
        "callbackForTB = tf.keras.callbacks.TensorBoard(logs_base_dir)\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ehh-EMXUQh8r"
      },
      "source": [
        "Early Stopping as defined in keras tensorflow documentation\n",
        "https://www.tensorflow.org/guide/keras/train_and_evaluate "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BY_t-PeQEjy"
      },
      "source": [
        "callbackEarlyStopping = [\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_loss\",\n",
        "        mode=\"min\",\n",
        "        patience=3,\n",
        "        verbose=1,\n",
        "    )\n",
        "]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2CHbXiP1LsF"
      },
      "source": [
        "training_epochs = 15\n",
        "batch_size = 40\n",
        "validation_split=0.2"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abV-QAxfW48r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a76b7d69-6e08-4281-a495-b2d799f2c1bc"
      },
      "source": [
        "#Werte der Convolutional-Schichten variieren (Filter), Batch-Size variieren, kernel-size..\n",
        "CNN1605210290AEBN.fit(nppadded_training, nptraining_labels, batch_size=batch_size, validation_split=validation_split, epochs=training_epochs, callbacks=[callbackForTB])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "91/91 [==============================] - 5s 39ms/step - loss: 0.6496 - accuracy: 0.6637 - metrics_recall: 0.0041 - metrics_precision: 0.0161 - metrics_f1: 0.0064 - val_loss: 0.6378 - val_accuracy: 0.6718 - val_metrics_recall: 0.0000e+00 - val_metrics_precision: 0.0000e+00 - val_metrics_f1: 0.0000e+00\n",
            "Epoch 2/15\n",
            "91/91 [==============================] - 3s 30ms/step - loss: 0.6403 - accuracy: 0.6626 - metrics_recall: 0.0000e+00 - metrics_precision: 0.0000e+00 - metrics_f1: 0.0000e+00 - val_loss: 0.6269 - val_accuracy: 0.6718 - val_metrics_recall: 0.0000e+00 - val_metrics_precision: 0.0000e+00 - val_metrics_f1: 0.0000e+00\n",
            "Epoch 3/15\n",
            "91/91 [==============================] - 3s 32ms/step - loss: 0.6180 - accuracy: 0.6626 - metrics_recall: 0.0271 - metrics_precision: 0.0888 - metrics_f1: 0.0368 - val_loss: 0.5913 - val_accuracy: 0.6696 - val_metrics_recall: 0.0000e+00 - val_metrics_precision: 0.0000e+00 - val_metrics_f1: 0.0000e+00\n",
            "Epoch 4/15\n",
            "91/91 [==============================] - 3s 36ms/step - loss: 0.5970 - accuracy: 0.6604 - metrics_recall: 0.1082 - metrics_precision: 0.3880 - metrics_f1: 0.1497 - val_loss: 0.5843 - val_accuracy: 0.6929 - val_metrics_recall: 0.1639 - val_metrics_precision: 0.7052 - val_metrics_f1: 0.2545\n",
            "Epoch 5/15\n",
            "91/91 [==============================] - 3s 37ms/step - loss: 0.5773 - accuracy: 0.6809 - metrics_recall: 0.2431 - metrics_precision: 0.5886 - metrics_f1: 0.3092 - val_loss: 0.5718 - val_accuracy: 0.6951 - val_metrics_recall: 0.3471 - val_metrics_precision: 0.5662 - val_metrics_f1: 0.4171\n",
            "Epoch 6/15\n",
            "91/91 [==============================] - 3s 35ms/step - loss: 0.5551 - accuracy: 0.7114 - metrics_recall: 0.3805 - metrics_precision: 0.6178 - metrics_f1: 0.4509 - val_loss: 0.5607 - val_accuracy: 0.7062 - val_metrics_recall: 0.3625 - val_metrics_precision: 0.5906 - val_metrics_f1: 0.4355\n",
            "Epoch 7/15\n",
            "91/91 [==============================] - 3s 32ms/step - loss: 0.5380 - accuracy: 0.7214 - metrics_recall: 0.4433 - metrics_precision: 0.6432 - metrics_f1: 0.4953 - val_loss: 0.5505 - val_accuracy: 0.7129 - val_metrics_recall: 0.3142 - val_metrics_precision: 0.6553 - val_metrics_f1: 0.4072\n",
            "Epoch 8/15\n",
            "91/91 [==============================] - 3s 35ms/step - loss: 0.5198 - accuracy: 0.7383 - metrics_recall: 0.4868 - metrics_precision: 0.6655 - metrics_f1: 0.5365 - val_loss: 0.5490 - val_accuracy: 0.7106 - val_metrics_recall: 0.4778 - val_metrics_precision: 0.5762 - val_metrics_f1: 0.5035\n",
            "Epoch 9/15\n",
            "91/91 [==============================] - 3s 33ms/step - loss: 0.5047 - accuracy: 0.7491 - metrics_recall: 0.5067 - metrics_precision: 0.6848 - metrics_f1: 0.5608 - val_loss: 0.5404 - val_accuracy: 0.7151 - val_metrics_recall: 0.4908 - val_metrics_precision: 0.5840 - val_metrics_f1: 0.5159\n",
            "Epoch 10/15\n",
            "91/91 [==============================] - 3s 34ms/step - loss: 0.4839 - accuracy: 0.7574 - metrics_recall: 0.5621 - metrics_precision: 0.6825 - metrics_f1: 0.5933 - val_loss: 0.5406 - val_accuracy: 0.7129 - val_metrics_recall: 0.5161 - val_metrics_precision: 0.5605 - val_metrics_f1: 0.5230\n",
            "Epoch 11/15\n",
            "91/91 [==============================] - 3s 30ms/step - loss: 0.4558 - accuracy: 0.7796 - metrics_recall: 0.5846 - metrics_precision: 0.7211 - metrics_f1: 0.6261 - val_loss: 0.5306 - val_accuracy: 0.7251 - val_metrics_recall: 0.5061 - val_metrics_precision: 0.5857 - val_metrics_f1: 0.5304\n",
            "Epoch 12/15\n",
            "91/91 [==============================] - 3s 30ms/step - loss: 0.4528 - accuracy: 0.7810 - metrics_recall: 0.5990 - metrics_precision: 0.7233 - metrics_f1: 0.6255 - val_loss: 0.5312 - val_accuracy: 0.7184 - val_metrics_recall: 0.4764 - val_metrics_precision: 0.5915 - val_metrics_f1: 0.5099\n",
            "Epoch 13/15\n",
            "91/91 [==============================] - 3s 33ms/step - loss: 0.4314 - accuracy: 0.8029 - metrics_recall: 0.6485 - metrics_precision: 0.7565 - metrics_f1: 0.6761 - val_loss: 0.5460 - val_accuracy: 0.7306 - val_metrics_recall: 0.3602 - val_metrics_precision: 0.6546 - val_metrics_f1: 0.4486\n",
            "Epoch 14/15\n",
            "91/91 [==============================] - 3s 34ms/step - loss: 0.4127 - accuracy: 0.8120 - metrics_recall: 0.6420 - metrics_precision: 0.7649 - metrics_f1: 0.6758 - val_loss: 0.5379 - val_accuracy: 0.7073 - val_metrics_recall: 0.5072 - val_metrics_precision: 0.5591 - val_metrics_f1: 0.5152\n",
            "Epoch 15/15\n",
            "91/91 [==============================] - 3s 31ms/step - loss: 0.3884 - accuracy: 0.8270 - metrics_recall: 0.6791 - metrics_precision: 0.7744 - metrics_f1: 0.7088 - val_loss: 0.5661 - val_accuracy: 0.7095 - val_metrics_recall: 0.6233 - val_metrics_precision: 0.5470 - val_metrics_f1: 0.5703\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb9b12ed490>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJVL4SBLPB2P"
      },
      "source": [
        "#%tensorboard --logdir {logs_base_dir}"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_LnvWBcnoak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8570bce1-9211-43fd-ed50-8d8c91cf3065"
      },
      "source": [
        "#results = model.evaluate(nppadded_testing, nptesting_labels, batch_size=batch_size)\n",
        "#print(\"test loss, test acc:\",results)\n",
        "\n",
        "(loss,accuracy, metrics_recall,metrics_precision,\n",
        "metrics_f1) = CNN1605210290AEBN.evaluate(nppadded_testing, nptesting_labels, verbose=1)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "111/111 [==============================] - 1s 8ms/step - loss: 0.6155 - accuracy: 0.6639 - metrics_recall: 0.4701 - metrics_precision: 0.5038 - metrics_f1: 0.4733\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KgjIkhpKmHc"
      },
      "source": [
        "make some predictions of test data and save it to variable. verbose=0 -> do not generate output\n",
        "Gute Quelle: https://deeplizard.com/learn/video/2f-NjDUvZIE "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89GWuxryKlcM"
      },
      "source": [
        "CNN_predictions90AEBN = CNN1605210290AEBN.predict(x=nppadded_testing)\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3jPDaDJK_cN"
      },
      "source": [
        "#for p in CNN_predictions90AEBN:\n",
        " # print(p)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eC9efJy4Lp21"
      },
      "source": [
        "rounded predictions: give prediction value of most likely prediction (0 or 1). Printing the output of rounded prediction shows the prediction made by the model on the data (which output is most likely)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsG-TJuQLvtk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3639b71a-842e-4b1b-e759-079489901b67"
      },
      "source": [
        "prediction_rounded90AEBN = np.round(CNN_predictions90AEBN)\n",
        "#np.argmax(CNN_predictions90AEBN,axis=-1)\n",
        "\n",
        "#for p in prediction_rounded90AEBN:\n",
        " # print(p)\n",
        "\n",
        "\n",
        "print(nptesting_labels[500:520])\n",
        "print(prediction_rounded90AEBN[500:520])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1]\n",
            "[[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egTtgpXgg8a2"
      },
      "source": [
        "https://deeplizard.com/learn/video/km7pxKy4UHU\n",
        "\n",
        "Quelle der def plot_confusion_matrix: https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSDXf7-_MITy"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0AMs1EzhBU1"
      },
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                        normalize=False,\n",
        "                        title='Confusion matrix',\n",
        "                        cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2JgEnlghCtl"
      },
      "source": [
        "cm = confusion_matrix(y_true=nptesting_labels, y_pred=prediction_rounded90AEBN)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckmF29whhFmX"
      },
      "source": [
        "plot_labels = ['no hatespeech','hatespeech']"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mpSE96rhK7K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "outputId": "42c24e3b-ff3e-47c1-8e21-597e5d727628"
      },
      "source": [
        "plot_confusion_matrix(cm=cm, classes=plot_labels, title='CNN Confusion 50 15 Epochs Batch size 40, kernel size 3, with second dropout')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix, without normalization\n",
            "[[1790  540]\n",
            " [ 647  555]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}