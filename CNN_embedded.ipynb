{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN embedded.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMPfsaZZlw9OkNOcpBaY+/s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BiancaStadl/ProjektarbeitML/blob/main/CNN_embedded.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXDOlIBymF0V"
      },
      "source": [
        "GloVe embeddings taken from:\n",
        "\n",
        "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. [pdf] [bib]\n",
        "\n",
        "hatespeechdata taken from (https://hatespeechdata.com/): Wiegand, M., Siegel, M. and Ruppenhofer, J., 2018. Overview of the GermEval 2018 Shared Task on the Identification of Offensive Language. In: Proceedings of GermEval 2018, 14th Conference on Natural Language Processing (KONVENS 2018). Vienna, Austria: Research Gate. available on: https://github.com/uds-lsv/GermEval-2018-Data (last checked: 09.05.2021)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlBmABDxfqII"
      },
      "source": [
        "wiki detox..https://colab.research.google.com/github/tensorflow/fairness-indicators/blob/master/g3doc/tutorials/Fairness_Indicators_TFCO_Wiki_Case_Study.ipynb#scrollTo=y6T5tlXcdW7J "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3xfitNdliBI"
      },
      "source": [
        "#import matplotlib.pyplot as plt -> für evtl Visualisierungen\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import string\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from keras import losses \n",
        "from keras import optimizers \n",
        "from keras import metrics \n",
        "\n",
        "#!pip install Tokenizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "#!pip install pad_sequences\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import preprocessing\n",
        "#from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTWJQ1iga_vS"
      },
      "source": [
        "Maximale Satzlänge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bq08Me5la_Cc"
      },
      "source": [
        "\n",
        "max_length = 60"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVYBMvYSotTH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "589b1eba-c05f-41d3-857b-78c3ae0fa2e6"
      },
      "source": [
        "url = \"https://github.com/uds-lsv/GermEval-2018-Data/archive/master.zip\"\n",
        "\n",
        "dataset = tf.keras.utils.get_file(\"GermEval-2018-Data-master.zip\", url, \n",
        "                                   extract=True, cache_dir='.',\n",
        "                                    cache_subdir='')\n",
        "\n",
        "dataset_dir = os.path.join(os.path.dirname(dataset), 'GermEval-2018-Data-master')\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/uds-lsv/GermEval-2018-Data/archive/master.zip\n",
            "12386304/Unknown - 1s 0us/step"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cS14OUtfo34V"
      },
      "source": [
        "#os.listdir(dataset_dir)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2X429K6hpOVm"
      },
      "source": [
        "training_file = os.path.join(dataset_dir, 'germeval2018.training.txt')\n",
        "\n",
        "testing_file = os.path.join(dataset_dir, 'germeval2018.test.txt')\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uq8fG3LNtn_m"
      },
      "source": [
        "###Aufbereitung\n",
        "txt-Dateien lesen, und dabei jede Zeile splitten und teilen\n",
        "Twitter-Handler entfernen?\n",
        "Labels von Sätzen trennen, Labels in eigenen Array packen.\n",
        "\n",
        "####Ressourcen\n",
        "* https://www.w3schools.com/python/gloss_python_if_statement.asp\n",
        "* https://stackabuse.com/using-regex-for-text-manipulation-in-python/\n",
        "* https://www.tutorialspoint.com/python/string_splitlines.htm \n",
        "* https://note.nkmk.me/en/python-split-rsplit-splitlines-re/ \n",
        "* https://www.w3schools.com/python/python_regex.asp \n",
        "\n",
        "gäbe bei keras tf.keras.preprocessing.text_dataset_from_directory, aber dafür müssten die Daten auf bestimmte Weise in Verzeichnis organisiert sein, hier nicht der Fall.\n",
        "\n",
        "\n",
        "Einteilung der Daten: Testdaten\n",
        "Trainingsdaten -> noch ca 500 für Validierungsdaten\n",
        "\n",
        "labels -> \"other\", also nicht-negative Aussagen bekommen \"0\", negative Aussagen bekommen \"1\"\n",
        "\n",
        " Regex für Emojis  ->\n",
        "\n",
        "(\\u00a9|\\u00ae|[\\u2000-\\u3300]|\\ud83c[\\ud000-\\udfff]|\\ud83d[\\ud000-\\udfff]|\\ud83e[\\ud000-\\udfff])\n",
        "\n",
        "genommen von https://www.regextester.com/106421 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Py_cwD4eZkXo"
      },
      "source": [
        "def remove_clutter(string):\n",
        "   string = re.sub(\"@[^\\s]+\",\" \",string)\n",
        "   string = re.sub(\"#[^\\s]+\",\" \", string)\n",
        "   string = re.sub(\"\\u00a9\",\" \", string)\n",
        "   string = re.sub(\"\\u00ae\",\" \", string)\n",
        "   string = re.sub(\"[\\u2000-\\u3300]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83c[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83d[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83e[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"😜\", \" \",string)\n",
        "   string = re.sub(\"🍫\", \" \",string)\n",
        "   string = re.sub(\"😁\", \" \",string)\n",
        "   string = re.sub(\"🐖\", \" \",string)\n",
        "   string = re.sub(\"😡\", \" \",string)\n",
        "   string = re.sub(\"😇\", \" \",string)\n",
        "   string = re.sub(\"😬\", \" \",string)\n",
        "   string = re.sub(\"😃\", \" \",string)\n",
        "   string = re.sub(\"😂\", \" \",string)\n",
        "   string = re.sub(\"💙\", \" \",string)  \n",
        "   string = re.sub(\"😛\", \" \",string)\n",
        "   string = re.sub(\"🙏\", \" \",string)\n",
        "   string = re.sub(\"👍\", \" \",string)\n",
        "   string = re.sub(\"🖕\", \" \",string)\n",
        "   string = re.sub(\"😉\", \" \",string)\n",
        "   string = re.sub(\"💩\", \" \",string)\n",
        "   string = re.sub(\"🤢\", \" \",string)\n",
        "   string = re.sub(\"👏\", \" \",string)\n",
        "   string = re.sub(\"😨\", \" \",string)\n",
        "   string = re.sub(\"🤣\", \" \",string)\n",
        "   string = re.sub(\"🤡\", \" \",string)\n",
        "   string = re.sub(\"😈\", \" \",string)\n",
        "   string = re.sub(\"💃🏽\", \" \",string)\n",
        "   string = re.sub(\"👹\", \" \",string)\n",
        "   string = re.sub(\"🤘\", \" \",string)\n",
        "   string = re.sub(\"😱\", \" \",string)\n",
        "   string = re.sub(\"🤔\", \" \",string) \n",
        "   string = re.sub(\"🌈\", \" \",string) \n",
        "   string = re.sub(\"💕\", \" \",string) \n",
        "   string = re.sub(\"👩‍❤️‍👩\", \" \",string) \n",
        "   string = re.sub(\"😍\", \" \",string) \n",
        "   string = re.sub(\"👆\", \" \",string) \n",
        "   string = re.sub(\"😖\", \" \",string) \n",
        "   string = re.sub(\"👇\", \" \",string) \n",
        "   string = re.sub(\"🔥\", \" \",string) \n",
        "   string = re.sub(\"😘\", \" \",string) \n",
        "   string = re.sub(\"🎉\", \" \",string) \n",
        "   string = re.sub(\"🤬\", \" \",string) \n",
        "   string = re.sub(\"👊\", \" \",string)\n",
        "   string = re.sub(\"🇩🇪\", \" \",string)  \n",
        "   string = re.sub(\"💔\", \" \",string)\n",
        "   string = re.sub(\"🙈\", \" \",string)\n",
        "   string = re.sub(\"🤯\", \" \",string)\n",
        "   string = re.sub(\"🐟\", \" \",string)\n",
        "   string = re.sub(\"🛶\", \" \",string)\n",
        "   string = re.sub(\"😊\", \" \",string)\n",
        "   string = re.sub(\"😓\", \" \",string)\n",
        "   string = re.sub(\"😳\", \" \",string)\n",
        "   string = re.sub(\"🚀\", \" \",string)\n",
        "   string = re.sub(\"👎\", \" \",string)\n",
        "   string = re.sub(\"😎\", \" \",string)\n",
        "   string = re.sub(\"🐸\", \" \",string)\n",
        "   string = re.sub(\"📈\", \" \",string)\n",
        "   string = re.sub(\"🙂\", \" \",string)\n",
        "   string = re.sub(\"😅\", \" \",string)\n",
        "   string = re.sub(\"😆\", \" \",string)\n",
        "   string = re.sub(\"🙎🏿\", \" \",string)\n",
        "   string = re.sub(\"👎🏽\", \" \",string)\n",
        "   string = re.sub(\"🤭\", \" \",string)\n",
        "   string = re.sub(\"😤\", \" \",string)\n",
        "   string = re.sub(\"😚\", \" \",string)\n",
        "   string = re.sub(\"😊\", \" \",string)\n",
        "   string = re.sub(\"😲\", \" \",string)\n",
        "   string = re.sub(\"🤮\", \" \",string)\n",
        "   string = re.sub(\"🙄\", \" \",string)\n",
        "   string = re.sub(\"🤑\", \" \",string)\n",
        "   string = re.sub(\"🎅\", \" \",string)\n",
        "   string = re.sub(\"👋\", \" \",string)\n",
        "   string = re.sub(\"💪\", \" \",string)\n",
        "   string = re.sub(\"😄\", \" \",string)\n",
        "   string = re.sub(\"🧐\", \" \",string)\n",
        "   string = re.sub(\"😠\", \" \",string)\n",
        "   string = re.sub(\"🎈\", \" \",string)\n",
        "   string = re.sub(\"🚂\", \" \",string)\n",
        "   string = re.sub(\"😊\", \" \",string)\n",
        "   string = re.sub(\"🚇\", \" \",string)\n",
        "   string = re.sub(\"🚊\", \" \",string)\n",
        "   string = re.sub(\"🤷\", \" \",string)\n",
        "   string = re.sub(\"😥\", \" \",string)\n",
        "   string = re.sub(\"🙃\", \" \",string)\n",
        "   string = re.sub(\"🔩\", \" \",string)\n",
        "   string = re.sub(\"🔧\", \" \",string)\n",
        "   string = re.sub(\"🔨\", \" \",string)\n",
        "   string = re.sub(\"🛠\", \" \",string)\n",
        "   string = re.sub(\"💓\", \" \",string)\n",
        "   string = re.sub(\"💡\", \" \",string)\n",
        "   string = re.sub(\"🍸\", \" \",string)\n",
        "   string = re.sub(\"🥃\", \" \",string)\n",
        "   string = re.sub(\"🥂\", \" \",string)\n",
        "   string = re.sub(\"😷\", \" \",string)\n",
        "   string = re.sub(\"🤐\", \" \",string)\n",
        "   string = re.sub(\"🌎\", \" \",string)\n",
        "   string = re.sub(\"👑\", \" \",string)\n",
        "   string = re.sub(\"🤛\", \" \",string)\n",
        "   string = re.sub(\"😀\", \" \",string)\n",
        "   string = re.sub(\"🛤\", \" \",string)\n",
        "   string = re.sub(\"🎄\", \" \",string)\n",
        "   string = re.sub(\"📴\", \" \",string)\n",
        "   string = re.sub(\"🌭\", \" \",string)\n",
        "   string = re.sub(\"🤕\", \" \",string)\n",
        "   string = re.sub(\"😭\", \" \",string)\n",
        "   string = re.sub(\"🍾\", \" \",string)\n",
        "   string = re.sub(\"🍞\", \" \",string)\n",
        "   string = re.sub(\"🤦\", \" \",string)\n",
        "   string = re.sub(\"🤯\", \" \",string)\n",
        "   string = re.sub(\"🕯️\", \" \",string)\n",
        "\n",
        "   string = re.sub(\"OTHER|OFFENSE|ABUSE|INSULT\",\" \",string)\n",
        "   return string"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5asMgo4LtnRg"
      },
      "source": [
        "statementsForTraining = []\n",
        "sentimentsForTraining = []\n",
        "\n",
        "\n",
        "fileToRead = open(training_file, 'r')\n",
        "\n",
        "while True:\n",
        "  #next line in file\n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  findSentiment = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "\n",
        "\n",
        "  statementsForTraining.append(line)\n",
        "   #sentimentsForTraining.append(findSentiment.group(0))\n",
        "\n",
        "  if findSentiment.group(0) == \"OTHER\":  \n",
        "    sentimentsForTraining.append(0)\n",
        "  else:\n",
        "    sentimentsForTraining.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        " #print(\"{}: {}\".format(count,line.strip()))\n",
        "  \n",
        " # print(sentiment.group(0))\n",
        " \n",
        "fileToRead.close()\n",
        "\n",
        "training_sentences = statementsForTraining\n",
        "training_labels = sentimentsForTraining\n",
        "\n",
        "#print(training_sentences[9])\n",
        "#print(training_labels[9])\n",
        "\n",
        "#print(len(training_sentences))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsqZPENb98gD"
      },
      "source": [
        "##do the same with testdata\n",
        "statementsForTesting = []\n",
        "sentimentsForTesting = []\n",
        "\n",
        "fileToRead = open(testing_file, 'r')\n",
        "\n",
        "while True:\n",
        "  #next line in file\n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  sent = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "\n",
        "    \n",
        "\n",
        "  statementsForTesting.append(line)\n",
        "  #print(len(line))\n",
        "  #sentimentsForTesting.append(sent.group(0))\n",
        "\n",
        "  if sent.group(0) == \"OTHER\": \n",
        "    sentimentsForTesting.append(0)\n",
        "  else:\n",
        "    sentimentsForTesting.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        "\n",
        "fileToRead.close()\n",
        "\n",
        "\n",
        "testing_sentences = statementsForTesting\n",
        "testing_labels = sentimentsForTesting\n",
        "#print(len(testing_sentences))\n",
        "#print(testing_sentences)   \n",
        "#print(testing_labels)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRUvDLD5bMbO"
      },
      "source": [
        "Padding -> im Prinzip die Sätze alle auf die gleiche Länge bringen (in Theorieteil näher drauf eingehen) -> maxlen-Paramter ist für pad_sequences vorhanden, wenn nicht gesetzt -> alles wird auf die Länge des längsten Satzes aufgefüllt -> print(padded(shape)) gibt aus, wie viele Datensätze padded wurden und gibt an, wie viele Tokens der längste Datensatz hat\n",
        "print(padded[x]) gibt einen Satz aus (bereits tokenisiert)\n",
        "\n",
        "Padding -> sowohl für Trainigs- als auch für Testdaten\n",
        "\n",
        "Und: Daten als numpy-Arrays speichern (notwendig für tensorflow).\n",
        "\n",
        " -> Tokenizer https://towardsdatascience.com/text-classification-in-keras-part-2-how-to-use-the-keras-tokenizer-word-representations-fd571674df23 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3hFi7waTv5m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df5a4c50-94aa-4a35-8777-c35c8c88a14c"
      },
      "source": [
        "tokenizer = Tokenizer(oov_token=\"OOV\")\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "\n",
        "#creating a word index - nur die Trainigsdaten\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "validation_size = 500\n",
        "\n",
        "\n",
        "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "padded_training = pad_sequences(training_sequences, maxlen=max_length, padding='post')\n",
        "print(len(padded_training))\n",
        "\n",
        "validation_sequences = padded_training[0:validation_size]\n",
        "validation_labels = training_labels[0:validation_size]\n",
        "\n",
        "padded_training = padded_training[validation_size:]\n",
        "training_labels = training_labels[validation_size:]\n",
        "\n",
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
        "padded_testing = pad_sequences(testing_sequences, maxlen=max_length,  padding='post')\n",
        "\n",
        "#print(validation_sequences[499])\n",
        "print(padded_training[0])\n",
        "#print(len(validation_labels))\n",
        "#print(len(training_labels))\n",
        "\n",
        "\n",
        "nppadded_training = np.array(padded_training)\n",
        "nptraining_labels = np.array(training_labels)\n",
        "\n",
        "nppadded_validation = np.array(validation_sequences)\n",
        "npvalidation_labels = np.array(validation_labels)\n",
        "\n",
        "nppadded_testing = np.array(padded_testing)\n",
        "nptesting_labels = np.array(testing_labels)\n",
        "\n",
        "\n",
        "print(len(nppadded_training))\n",
        "print(len(nptraining_labels))\n",
        "print(len(word_index))\n",
        "\n",
        "#print(statementsForTraining[2])\n",
        "#print(nppadded_training[4])\n",
        "#print(nppadded_training.shape)\n",
        "#print(nptraining_labels[4])\n",
        "#print(nppadded_testing.shape)\n",
        "#print(word_index) \n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5009\n",
            "[  12 3982   11   41 6706 1040    4    5  202   39    3 2922   49 1360\n",
            "  810  495 3983    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0]\n",
            "4509\n",
            "4509\n",
            "15059\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tL3owrc8THkT"
      },
      "source": [
        "\n",
        "Dann: Embedding mit entweder word2vec oder glove\n",
        "Word2vec-Daten sind hier: http://vectors.nlpl.eu/repository/#\n",
        "Glove -> https://nlp.stanford.edu/projects/glove/ Da mal den Twitter-Vector runtergeladen\n",
        "Wenn Daten in GoogleDrive sind (wäre auch via url möglich..), muss Drive gemounted werden ( https://buomsoo-kim.github.io/colab/2020/05/09/Colab-mounting-google-drive.md/ ) aber auch hier https://enjoymachinelearning.com/posts/colab-with-google-drive/\n",
        "\n",
        "Die Word2vec vectors: http://vectors.nlpl.eu/repository/# \n",
        "\n",
        "glove-zitat:\n",
        "Citing GloVe\n",
        "\n",
        "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. [pdf] [bib]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zuO7T9ZTG57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b9952e6-cead-4c3a-c041-a3c6c65bd4e7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "os.listdir(\"/content/drive/MyDrive/Colab Notebooks\")\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['germeval_training.txt',\n",
              " 'glove.twitter.27B.50d.txt',\n",
              " 'glove.twitter.27B.200d.txt',\n",
              " 'glove.6B.200d.txt',\n",
              " 'glove.840B.300d.txt',\n",
              " 'tensorboard.gdoc',\n",
              " 'keras.gdoc',\n",
              " 'Vectorization CNN embedded_limited_vocab.ipynb',\n",
              " 'glove.42B.300d.txt',\n",
              " 'Embedding Glove Vergleich.ipynb',\n",
              " 'LSTM.ipynb',\n",
              " 'CNN embedded_limited_vocab.ipynb',\n",
              " 'LSTM_limited_vocab.ipynb',\n",
              " 'CNN embedded.ipynb']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7ToKO-sZLHK"
      },
      "source": [
        "\n",
        "Keras-Doc : https://keras.io/examples/nlp/pretrained_word_embeddings/#load-pretrained-word-embeddings \n",
        "embedding mit initializers.. weights müsste auch funktionieren\n",
        "\n",
        "Diese erstellte Matrix mit Embedding dann in die Embedding-Schicht einbinden,  Trainable auf False, weil sich die Werte nicht durch Training anpassen sollen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AShIVfC7ZQAH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5ad4936-5fe5-4dee-861c-6fff32ae5800"
      },
      "source": [
        "#Größe Vokabel -> wordindex + 2 (weil padding + OOV) \n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "vocabulary_size = len(word_index)+2\n",
        "\n",
        "# dann erstell ich ein Wörterbuch mit Namen \"embedding_vector\", dort sind dann\n",
        "#die keys drinnen, die in glove-Datei drinnen sind mit dem entsprechenden Key\n",
        "\n",
        "embedding_index_glove = {}\n",
        "f = open('/content/drive/MyDrive/Colab Notebooks/glove.twitter.27B.200d.txt')\n",
        "for line in f:\n",
        "  value = line.split()\n",
        "  word = value[0]\n",
        "  coef = np.asarray(value[1:],dtype='float32')\n",
        "  embedding_index_glove[word] = coef\n",
        "\n",
        "print(\"%d gefunden: \"% len(embedding_index_glove))\n",
        "\n",
        "#Dann noch eine Embedding-Matrix erstellen\n",
        "#zweiter Wert = Embedding-Dimension der Datei, in dem Fall 200\n",
        "\n",
        "glove_matrix = np.zeros((vocabulary_size,200))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    embedding_value = embedding_index_glove.get(word)\n",
        "    if embedding_value is not None:\n",
        "      glove_matrix[index] = embedding_value\n",
        "      hits+=1\n",
        "    else:\n",
        "      misses+=1\n",
        "\n",
        "print(\"hits %d and %d misses\"%(hits,misses))\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1193514 gefunden: \n",
            "hits 6747 and 8312 misses\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZmvOfwhV4N5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f97b652-2aae-4d58-a5ad-8d1b6d9922f0"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "print(\"vocab size: %d\"%vocabulary_size)\n",
        "CNN16052106 = tf.keras.Sequential()\n",
        "#Embedding -> hier dann auf das embedding verweisen, Input_dim -> die Anzahl der Wörter im word_index, output -> in dem Fall passend zum verwendeten Vektor\n",
        "#input-length -> auf 60  gepadded, trainable -> nein, weil nichts verändert werden soll\n",
        "#embeddings_initializer=keras.initializers.Constant(glove_matrix) vs weights = [glove_matrix]\n",
        "#Convolutional layers => filters = neurons.. mit 100? 265?\n",
        "CNN16052106.add(tf.keras.layers.Embedding(vocabulary_size, output_dim=200, input_length=60, embeddings_initializer = keras.initializers.Constant(glove_matrix), trainable= False))\n",
        "CNN16052106.add(tf.keras.layers.Dropout(0.4))\n",
        "CNN16052106.add(tf.keras.layers.Conv1D(filters=90, kernel_size=3, padding=\"valid\", activation=\"relu\"))\n",
        "CNN16052106.add(tf.keras.layers.MaxPooling1D())\n",
        "CNN16052106.add(tf.keras.layers.Conv1D(filters=90, kernel_size=3, padding=\"valid\", activation=\"relu\"))\n",
        "CNN16052106.add(tf.keras.layers.GlobalAveragePooling1D())\n",
        "CNN16052106.add(tf.keras.layers.Flatten())\n",
        "CNN16052106.add(tf.keras.layers.Dense(90, activation=\"relu\"))\n",
        "CNN16052106.add(tf.keras.layers.Dropout(0.4))\n",
        "CNN16052106.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "CNN16052106.summary()\n",
        "\n",
        "#nppadded_training = np.asmatrix(nppadded_training) not necessary\n",
        "#nppadded_testing = np.asmatrix(nppadded_testing)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab size: 15061\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 60, 200)           3012200   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 60, 200)           0         \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 58, 90)            54090     \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 29, 90)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 27, 90)            24390     \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 90)                0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 90)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 90)                8190      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 90)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 91        \n",
            "=================================================================\n",
            "Total params: 3,098,961\n",
            "Trainable params: 86,761\n",
            "Non-trainable params: 3,012,200\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEr4OzT-iHDe"
      },
      "source": [
        "#model.layers[2].get_weights()[0].shape\n",
        "#weights=np.random.rand(5,200,100)\n",
        "#bias=np.random.rand(100)\n",
        "#model.layers[2].set_weights([weights, bias])\n",
        "\n",
        "#model.layers[2].get_weights()[0]\n",
        "#https://androidkt.com/set-custom-weights-keras-using-numpy-array/"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UB7_3VPYesr9"
      },
      "source": [
        "F1-Score für jede Epoche https://aakashgoel12.medium.com/how-to-add-user-defined-function-get-f1-score-in-keras-metrics-3013f979ce0d\n",
        "\n",
        "Sehr gute Ressource für die verschiedenen Scores und Metriken https://neptune.ai/blog/evaluation-metrics-binary-classification#10  das und aakas verwendet\n",
        "\n",
        "hier: je eine Funktion für Recall, Precision, f1 https://neptune.ai/blog/keras-metrics \n",
        "\n",
        "https://keras.rstudio.com/reference/k_ones_like.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygyrbFJaMV9B"
      },
      "source": [
        "import keras.backend as K\n",
        "\n",
        "def metrics_recall(data_true, data_pred):\n",
        "    data_true = K.ones_like(data_true)\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(data_true,0,1)))\n",
        "\n",
        "    recall = true_positives / (possible_positives+K.epsilon())\n",
        "    return recall\n",
        "\n",
        "\n",
        "def metrics_precision(data_true, data_pred):\n",
        "    data_true = K.ones_like(data_true)\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "\n",
        "    positives_predicted = K.sum(K.round(K.clip(data_pred,0,1)))\n",
        "    precision = true_positives / (positives_predicted+K.epsilon())\n",
        "    return precision\n",
        "\n",
        "\n",
        "def metrics_f1(data_true, data_pred):\n",
        "    precision_data = metrics_precision(data_true, data_pred)\n",
        "    recall_data = metrics_recall(data_true, data_pred)\n",
        "    return 2*(precision_data*recall_data)/(precision_data+recall_data+K.epsilon())"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AfPD3_bWCm0"
      },
      "source": [
        "CNN16052106.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',metrics_recall,metrics_precision,metrics_f1])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpChKUY-QEWI"
      },
      "source": [
        "https://www.tensorflow.org/tensorboard/tensorboard_in_notebooks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJfMgUhHBoD1"
      },
      "source": [
        "#%reload_ext tensorboard\n",
        "#nur einmal pro Sitzung notwendig\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ISmMXLqP8Hc"
      },
      "source": [
        "\n",
        "logs_base_dir = \"./logs\"\n",
        "callbackForTB = tf.keras.callbacks.TensorBoard(logs_base_dir)\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2CHbXiP1LsF"
      },
      "source": [
        "training_epochs = 30\n",
        "batch_size = 40\n",
        "validation_split=0.2"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abV-QAxfW48r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4afd6244-40aa-4938-87e0-229fde6e9595"
      },
      "source": [
        "#Werte der Convolutional-Schichten variieren (Filter), Batch-Size variieren, kernel-size..\n",
        "CNN16052106.fit(nppadded_training, nptraining_labels, batch_size=batch_size, validation_split=validation_split, epochs=training_epochs, callbacks=[callbackForTB])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "91/91 [==============================] - 5s 43ms/step - loss: 0.6592 - accuracy: 0.6485 - metrics_recall: 0.0302 - metrics_precision: 0.1001 - metrics_f1: 0.0404 - val_loss: 0.6321 - val_accuracy: 0.6718 - val_metrics_recall: 0.0000e+00 - val_metrics_precision: 0.0000e+00 - val_metrics_f1: 0.0000e+00\n",
            "Epoch 2/30\n",
            "91/91 [==============================] - 3s 35ms/step - loss: 0.6331 - accuracy: 0.6645 - metrics_recall: 0.0011 - metrics_precision: 0.0178 - metrics_f1: 0.0019 - val_loss: 0.6143 - val_accuracy: 0.6729 - val_metrics_recall: 0.0076 - val_metrics_precision: 0.2609 - val_metrics_f1: 0.0147\n",
            "Epoch 3/30\n",
            "91/91 [==============================] - 3s 34ms/step - loss: 0.6007 - accuracy: 0.6682 - metrics_recall: 0.0624 - metrics_precision: 0.6891 - metrics_f1: 0.1067 - val_loss: 0.5819 - val_accuracy: 0.6918 - val_metrics_recall: 0.0722 - val_metrics_precision: 0.9130 - val_metrics_f1: 0.1309\n",
            "Epoch 4/30\n",
            "91/91 [==============================] - 3s 34ms/step - loss: 0.5681 - accuracy: 0.6930 - metrics_recall: 0.1363 - metrics_precision: 0.9886 - metrics_f1: 0.2233 - val_loss: 0.5818 - val_accuracy: 0.7018 - val_metrics_recall: 0.0703 - val_metrics_precision: 0.9565 - val_metrics_f1: 0.1288\n",
            "Epoch 5/30\n",
            "91/91 [==============================] - 3s 34ms/step - loss: 0.5566 - accuracy: 0.6906 - metrics_recall: 0.1765 - metrics_precision: 0.9725 - metrics_f1: 0.2901 - val_loss: 0.6094 - val_accuracy: 0.6242 - val_metrics_recall: 0.4922 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.6558\n",
            "Epoch 6/30\n",
            "91/91 [==============================] - 3s 34ms/step - loss: 0.5548 - accuracy: 0.7174 - metrics_recall: 0.2274 - metrics_precision: 0.9489 - metrics_f1: 0.3467 - val_loss: 0.5679 - val_accuracy: 0.6718 - val_metrics_recall: 0.4020 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.5694\n",
            "Epoch 7/30\n",
            "91/91 [==============================] - 3s 34ms/step - loss: 0.5213 - accuracy: 0.7431 - metrics_recall: 0.2640 - metrics_precision: 1.0000 - metrics_f1: 0.4058 - val_loss: 0.5410 - val_accuracy: 0.7284 - val_metrics_recall: 0.2330 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.3734\n",
            "Epoch 8/30\n",
            "91/91 [==============================] - 3s 34ms/step - loss: 0.4827 - accuracy: 0.7653 - metrics_recall: 0.2399 - metrics_precision: 1.0000 - metrics_f1: 0.3791 - val_loss: 0.5363 - val_accuracy: 0.7395 - val_metrics_recall: 0.2138 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.3480\n",
            "Epoch 9/30\n",
            "91/91 [==============================] - 3s 34ms/step - loss: 0.4740 - accuracy: 0.7619 - metrics_recall: 0.2672 - metrics_precision: 1.0000 - metrics_f1: 0.4171 - val_loss: 0.5423 - val_accuracy: 0.7062 - val_metrics_recall: 0.3552 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.5181\n",
            "Epoch 10/30\n",
            "91/91 [==============================] - 3s 34ms/step - loss: 0.4464 - accuracy: 0.7923 - metrics_recall: 0.2608 - metrics_precision: 1.0000 - metrics_f1: 0.4003 - val_loss: 0.5317 - val_accuracy: 0.7184 - val_metrics_recall: 0.2710 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.4222\n",
            "Epoch 11/30\n",
            "91/91 [==============================] - 3s 34ms/step - loss: 0.4245 - accuracy: 0.8110 - metrics_recall: 0.2875 - metrics_precision: 0.9998 - metrics_f1: 0.4389 - val_loss: 0.5653 - val_accuracy: 0.6840 - val_metrics_recall: 0.4192 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.5864\n",
            "Epoch 12/30\n",
            "91/91 [==============================] - 3s 34ms/step - loss: 0.4007 - accuracy: 0.8160 - metrics_recall: 0.3125 - metrics_precision: 1.0000 - metrics_f1: 0.4684 - val_loss: 0.5585 - val_accuracy: 0.7417 - val_metrics_recall: 0.1608 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.2707\n",
            "Epoch 13/30\n",
            "91/91 [==============================] - 3s 34ms/step - loss: 0.3769 - accuracy: 0.8303 - metrics_recall: 0.3078 - metrics_precision: 1.0000 - metrics_f1: 0.4616 - val_loss: 0.5440 - val_accuracy: 0.7084 - val_metrics_recall: 0.2721 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.4219\n",
            "Epoch 14/30\n",
            "91/91 [==============================] - 3s 34ms/step - loss: 0.3686 - accuracy: 0.8374 - metrics_recall: 0.2863 - metrics_precision: 1.0000 - metrics_f1: 0.4354 - val_loss: 0.6072 - val_accuracy: 0.6829 - val_metrics_recall: 0.4711 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.6366\n",
            "Epoch 15/30\n",
            "91/91 [==============================] - 3s 34ms/step - loss: 0.3769 - accuracy: 0.8320 - metrics_recall: 0.3319 - metrics_precision: 1.0000 - metrics_f1: 0.4845 - val_loss: 0.6472 - val_accuracy: 0.6707 - val_metrics_recall: 0.4788 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.6429\n",
            "Epoch 16/30\n",
            "91/91 [==============================] - 3s 34ms/step - loss: 0.3014 - accuracy: 0.8702 - metrics_recall: 0.3347 - metrics_precision: 1.0000 - metrics_f1: 0.4941 - val_loss: 0.5912 - val_accuracy: 0.7118 - val_metrics_recall: 0.2971 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.4532\n",
            "Epoch 17/30\n",
            "91/91 [==============================] - 3s 34ms/step - loss: 0.2842 - accuracy: 0.8773 - metrics_recall: 0.3288 - metrics_precision: 1.0000 - metrics_f1: 0.4889 - val_loss: 0.6079 - val_accuracy: 0.7228 - val_metrics_recall: 0.2480 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.3910\n",
            "Epoch 18/30\n",
            "91/91 [==============================] - 3s 34ms/step - loss: 0.2890 - accuracy: 0.8759 - metrics_recall: 0.3020 - metrics_precision: 1.0000 - metrics_f1: 0.4552 - val_loss: 0.6016 - val_accuracy: 0.7184 - val_metrics_recall: 0.3520 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.5164\n",
            "Epoch 19/30\n",
            "91/91 [==============================] - 3s 34ms/step - loss: 0.2678 - accuracy: 0.8779 - metrics_recall: 0.3011 - metrics_precision: 1.0000 - metrics_f1: 0.4558 - val_loss: 0.5986 - val_accuracy: 0.7184 - val_metrics_recall: 0.3359 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.4981\n",
            "Epoch 20/30\n",
            "91/91 [==============================] - 3s 34ms/step - loss: 0.2597 - accuracy: 0.8904 - metrics_recall: 0.3318 - metrics_precision: 1.0000 - metrics_f1: 0.4914 - val_loss: 0.6482 - val_accuracy: 0.7106 - val_metrics_recall: 0.2522 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.3955\n",
            "Epoch 21/30\n",
            "91/91 [==============================] - 3s 35ms/step - loss: 0.2416 - accuracy: 0.8973 - metrics_recall: 0.3098 - metrics_precision: 1.0000 - metrics_f1: 0.4667 - val_loss: 0.6057 - val_accuracy: 0.7140 - val_metrics_recall: 0.3002 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.4580\n",
            "Epoch 22/30\n",
            "91/91 [==============================] - 3s 34ms/step - loss: 0.2159 - accuracy: 0.9150 - metrics_recall: 0.3079 - metrics_precision: 1.0000 - metrics_f1: 0.4645 - val_loss: 0.6577 - val_accuracy: 0.7062 - val_metrics_recall: 0.3387 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.5006\n",
            "Epoch 23/30\n",
            "91/91 [==============================] - 3s 35ms/step - loss: 0.2290 - accuracy: 0.9043 - metrics_recall: 0.3147 - metrics_precision: 1.0000 - metrics_f1: 0.4734 - val_loss: 0.6803 - val_accuracy: 0.6996 - val_metrics_recall: 0.2987 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.4542\n",
            "Epoch 24/30\n",
            "91/91 [==============================] - 3s 36ms/step - loss: 0.2064 - accuracy: 0.9146 - metrics_recall: 0.3387 - metrics_precision: 1.0000 - metrics_f1: 0.5015 - val_loss: 0.6745 - val_accuracy: 0.7018 - val_metrics_recall: 0.3344 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.4959\n",
            "Epoch 25/30\n",
            "91/91 [==============================] - 3s 35ms/step - loss: 0.1910 - accuracy: 0.9254 - metrics_recall: 0.3234 - metrics_precision: 1.0000 - metrics_f1: 0.4827 - val_loss: 0.7638 - val_accuracy: 0.6885 - val_metrics_recall: 0.4427 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.6090\n",
            "Epoch 26/30\n",
            "91/91 [==============================] - 3s 35ms/step - loss: 0.1876 - accuracy: 0.9237 - metrics_recall: 0.3296 - metrics_precision: 1.0000 - metrics_f1: 0.4911 - val_loss: 0.7770 - val_accuracy: 0.6929 - val_metrics_recall: 0.2473 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.3912\n",
            "Epoch 27/30\n",
            "91/91 [==============================] - 3s 35ms/step - loss: 0.2343 - accuracy: 0.9030 - metrics_recall: 0.3138 - metrics_precision: 1.0000 - metrics_f1: 0.4686 - val_loss: 0.8169 - val_accuracy: 0.6630 - val_metrics_recall: 0.5142 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.6759\n",
            "Epoch 28/30\n",
            "91/91 [==============================] - 3s 36ms/step - loss: 0.2396 - accuracy: 0.9021 - metrics_recall: 0.3389 - metrics_precision: 1.0000 - metrics_f1: 0.4983 - val_loss: 0.7235 - val_accuracy: 0.6996 - val_metrics_recall: 0.3896 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.5551\n",
            "Epoch 29/30\n",
            "91/91 [==============================] - 3s 36ms/step - loss: 0.1706 - accuracy: 0.9357 - metrics_recall: 0.3421 - metrics_precision: 1.0000 - metrics_f1: 0.5056 - val_loss: 0.7318 - val_accuracy: 0.7051 - val_metrics_recall: 0.3259 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.4867\n",
            "Epoch 30/30\n",
            "91/91 [==============================] - 3s 35ms/step - loss: 0.1514 - accuracy: 0.9403 - metrics_recall: 0.3346 - metrics_precision: 1.0000 - metrics_f1: 0.4971 - val_loss: 0.7538 - val_accuracy: 0.6796 - val_metrics_recall: 0.3940 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.5614\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8103a17050>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJVL4SBLPB2P"
      },
      "source": [
        "#%tensorboard --logdir {logs_base_dir}"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_LnvWBcnoak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74ef273d-2d5f-47eb-f372-731421bab634"
      },
      "source": [
        "#results = model.evaluate(nppadded_testing, nptesting_labels, batch_size=batch_size)\n",
        "#print(\"test loss, test acc:\",results)\n",
        "\n",
        "(loss,accuracy, metrics_recall, metrics_precision,\n",
        "metrics_f1) = CNN16052106.evaluate(nppadded_testing, nptesting_labels, verbose=1)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "111/111 [==============================] - 1s 10ms/step - loss: 0.8195 - accuracy: 0.6560 - metrics_recall: 0.3455 - metrics_precision: 1.0000 - metrics_f1: 0.5071\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KgjIkhpKmHc"
      },
      "source": [
        "make some predictions of test data and save it to variable. verbose=0 -> do not generate output\n",
        "Gute Quelle: https://deeplizard.com/learn/video/2f-NjDUvZIE "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89GWuxryKlcM"
      },
      "source": [
        "CNN_predictions06 = CNN16052106.predict(x=nppadded_testing)\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3jPDaDJK_cN"
      },
      "source": [
        "#for p in CNN_predictions06:\n",
        " # print(p)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eC9efJy4Lp21"
      },
      "source": [
        "rounded predictions: give prediction value of most likely prediction (0 or 1). Printing the output of rounded prediction shows the prediction made by the model on the data (which output is most likely)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsG-TJuQLvtk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5859101b-0d06-4ca4-9c7d-728bd28d2817"
      },
      "source": [
        "prediction_rounded06 = np.round(CNN_predictions06)\n",
        "#np.argmax(CNN_predictions06,axis=-1)\n",
        "\n",
        "#for p in prediction_rounded06:\n",
        " # print(p)\n",
        "\n",
        "\n",
        "print(nptesting_labels[500:520])\n",
        "print(prediction_rounded06[500:520])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1]\n",
            "[[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egTtgpXgg8a2"
      },
      "source": [
        "https://deeplizard.com/learn/video/km7pxKy4UHU\n",
        "\n",
        "Quelle der def plot_confusion_matrix: https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSDXf7-_MITy"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0AMs1EzhBU1"
      },
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                        normalize=False,\n",
        "                        title='Confusion matrix',\n",
        "                        cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2JgEnlghCtl"
      },
      "source": [
        "cm = confusion_matrix(y_true=nptesting_labels, y_pred=prediction_rounded06)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckmF29whhFmX"
      },
      "source": [
        "plot_labels = ['no hatespeech','hatespeech']"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "2mpSE96rhK7K",
        "outputId": "d0555b77-c9ff-4a21-f724-bc9ca0800c4e"
      },
      "source": [
        "plot_confusion_matrix(cm=cm, classes=plot_labels, title='CNN Confusion 90Dense90')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix, without normalization\n",
            "[[1714  616]\n",
            " [ 599  603]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}