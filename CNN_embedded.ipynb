{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN embedded.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMwR0CwHdSCmo+B0j5KjDVr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BiancaStadl/ProjektarbeitML/blob/main/CNN_embedded.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXDOlIBymF0V"
      },
      "source": [
        "GloVe embeddings taken from:\n",
        "\n",
        "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. [pdf] [bib]\n",
        "\n",
        "hatespeechdata taken from (https://hatespeechdata.com/): Wiegand, M., Siegel, M. and Ruppenhofer, J., 2018. Overview of the GermEval 2018 Shared Task on the Identification of Offensive Language. In: Proceedings of GermEval 2018, 14th Conference on Natural Language Processing (KONVENS 2018). Vienna, Austria: Research Gate. available on: https://github.com/uds-lsv/GermEval-2018-Data (last checked: 09.05.2021)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlBmABDxfqII"
      },
      "source": [
        "wiki detox..https://colab.research.google.com/github/tensorflow/fairness-indicators/blob/master/g3doc/tutorials/Fairness_Indicators_TFCO_Wiki_Case_Study.ipynb#scrollTo=y6T5tlXcdW7J "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3xfitNdliBI"
      },
      "source": [
        "#import matplotlib.pyplot as plt -> f√ºr evtl Visualisierungen\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import string\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from keras import losses \n",
        "from keras import optimizers \n",
        "from keras import metrics \n",
        "\n",
        "#!pip install Tokenizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "#!pip install pad_sequences\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import preprocessing\n",
        "#from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTWJQ1iga_vS"
      },
      "source": [
        "Maximale Satzl√§nge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bq08Me5la_Cc"
      },
      "source": [
        "\n",
        "max_length = 60"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVYBMvYSotTH"
      },
      "source": [
        "url = \"https://github.com/uds-lsv/GermEval-2018-Data/archive/master.zip\"\n",
        "\n",
        "dataset = tf.keras.utils.get_file(\"GermEval-2018-Data-master.zip\", url, \n",
        "                                   extract=True, cache_dir='.',\n",
        "                                    cache_subdir='')\n",
        "\n",
        "dataset_dir = os.path.join(os.path.dirname(dataset), 'GermEval-2018-Data-master')\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cS14OUtfo34V"
      },
      "source": [
        "#os.listdir(dataset_dir)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2X429K6hpOVm"
      },
      "source": [
        "training_file = os.path.join(dataset_dir, 'germeval2018.training.txt')\n",
        "\n",
        "testing_file = os.path.join(dataset_dir, 'germeval2018.test.txt')\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uq8fG3LNtn_m"
      },
      "source": [
        "###Aufbereitung\n",
        "txt-Dateien lesen, und dabei jede Zeile splitten und teilen\n",
        "Twitter-Handler entfernen?\n",
        "Labels von S√§tzen trennen, Labels in eigenen Array packen.\n",
        "\n",
        "####Ressourcen\n",
        "* https://www.w3schools.com/python/gloss_python_if_statement.asp\n",
        "* https://stackabuse.com/using-regex-for-text-manipulation-in-python/\n",
        "* https://www.tutorialspoint.com/python/string_splitlines.htm \n",
        "* https://note.nkmk.me/en/python-split-rsplit-splitlines-re/ \n",
        "* https://www.w3schools.com/python/python_regex.asp \n",
        "\n",
        "g√§be bei keras tf.keras.preprocessing.text_dataset_from_directory, aber daf√ºr m√ºssten die Daten auf bestimmte Weise in Verzeichnis organisiert sein, hier nicht der Fall.\n",
        "\n",
        "\n",
        "Einteilung der Daten: Testdaten\n",
        "Trainingsdaten -> noch ca 500 f√ºr Validierungsdaten\n",
        "\n",
        "labels -> \"other\", also nicht-negative Aussagen bekommen \"0\", negative Aussagen bekommen \"1\"\n",
        "\n",
        " Regex f√ºr Emojis  ->\n",
        "\n",
        "(\\u00a9|\\u00ae|[\\u2000-\\u3300]|\\ud83c[\\ud000-\\udfff]|\\ud83d[\\ud000-\\udfff]|\\ud83e[\\ud000-\\udfff])\n",
        "\n",
        "genommen von https://www.regextester.com/106421 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Py_cwD4eZkXo"
      },
      "source": [
        "def remove_clutter(string):\n",
        "   string = re.sub(\"@[^\\s]+\",\" \",string)\n",
        "   string = re.sub(\"#[^\\s]+\",\" \", string)\n",
        "   string = re.sub(\"\\u00a9\",\" \", string)\n",
        "   string = re.sub(\"\\u00ae\",\" \", string)\n",
        "   string = re.sub(\"[\\u2000-\\u3300]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83c[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83d[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83e[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"üòú\", \" \",string)\n",
        "   string = re.sub(\"üç´\", \" \",string)\n",
        "   string = re.sub(\"üòÅ\", \" \",string)\n",
        "   string = re.sub(\"üêñ\", \" \",string)\n",
        "   string = re.sub(\"üò°\", \" \",string)\n",
        "   string = re.sub(\"üòá\", \" \",string)\n",
        "   string = re.sub(\"üò¨\", \" \",string)\n",
        "   string = re.sub(\"üòÉ\", \" \",string)\n",
        "   string = re.sub(\"üòÇ\", \" \",string)\n",
        "   string = re.sub(\"üíô\", \" \",string)  \n",
        "   string = re.sub(\"üòõ\", \" \",string)\n",
        "   string = re.sub(\"üôè\", \" \",string)\n",
        "   string = re.sub(\"üëç\", \" \",string)\n",
        "   string = re.sub(\"üñï\", \" \",string)\n",
        "   string = re.sub(\"üòâ\", \" \",string)\n",
        "   string = re.sub(\"üí©\", \" \",string)\n",
        "   string = re.sub(\"ü§¢\", \" \",string)\n",
        "   string = re.sub(\"üëè\", \" \",string)\n",
        "   string = re.sub(\"üò®\", \" \",string)\n",
        "   string = re.sub(\"ü§£\", \" \",string)\n",
        "   string = re.sub(\"ü§°\", \" \",string)\n",
        "   string = re.sub(\"üòà\", \" \",string)\n",
        "   string = re.sub(\"üíÉüèΩ\", \" \",string)\n",
        "   string = re.sub(\"üëπ\", \" \",string)\n",
        "   string = re.sub(\"ü§ò\", \" \",string)\n",
        "   string = re.sub(\"üò±\", \" \",string)\n",
        "   string = re.sub(\"ü§î\", \" \",string) \n",
        "   string = re.sub(\"üåà\", \" \",string) \n",
        "   string = re.sub(\"üíï\", \" \",string) \n",
        "   string = re.sub(\"üë©‚Äç‚ù§Ô∏è‚Äçüë©\", \" \",string) \n",
        "   string = re.sub(\"üòç\", \" \",string) \n",
        "   string = re.sub(\"üëÜ\", \" \",string) \n",
        "   string = re.sub(\"üòñ\", \" \",string) \n",
        "   string = re.sub(\"üëá\", \" \",string) \n",
        "   string = re.sub(\"üî•\", \" \",string) \n",
        "   string = re.sub(\"üòò\", \" \",string) \n",
        "   string = re.sub(\"üéâ\", \" \",string) \n",
        "   string = re.sub(\"ü§¨\", \" \",string) \n",
        "   string = re.sub(\"üëä\", \" \",string)\n",
        "   string = re.sub(\"üá©üá™\", \" \",string)  \n",
        "   string = re.sub(\"üíî\", \" \",string)\n",
        "   string = re.sub(\"üôà\", \" \",string)\n",
        "   string = re.sub(\"ü§Ø\", \" \",string)\n",
        "   string = re.sub(\"üêü\", \" \",string)\n",
        "   string = re.sub(\"üõ∂\", \" \",string)\n",
        "   string = re.sub(\"üòä\", \" \",string)\n",
        "   string = re.sub(\"üòì\", \" \",string)\n",
        "   string = re.sub(\"üò≥\", \" \",string)\n",
        "   string = re.sub(\"üöÄ\", \" \",string)\n",
        "   string = re.sub(\"üëé\", \" \",string)\n",
        "   string = re.sub(\"üòé\", \" \",string)\n",
        "   string = re.sub(\"üê∏\", \" \",string)\n",
        "   string = re.sub(\"üìà\", \" \",string)\n",
        "   string = re.sub(\"üôÇ\", \" \",string)\n",
        "   string = re.sub(\"üòÖ\", \" \",string)\n",
        "   string = re.sub(\"üòÜ\", \" \",string)\n",
        "   string = re.sub(\"üôéüèø\", \" \",string)\n",
        "   string = re.sub(\"üëéüèΩ\", \" \",string)\n",
        "   string = re.sub(\"ü§≠\", \" \",string)\n",
        "   string = re.sub(\"üò§\", \" \",string)\n",
        "   string = re.sub(\"üòö\", \" \",string)\n",
        "   string = re.sub(\"üòä\", \" \",string)\n",
        "   string = re.sub(\"üò≤\", \" \",string)\n",
        "   string = re.sub(\"ü§Æ\", \" \",string)\n",
        "   string = re.sub(\"üôÑ\", \" \",string)\n",
        "   string = re.sub(\"ü§ë\", \" \",string)\n",
        "   string = re.sub(\"üéÖ\", \" \",string)\n",
        "   string = re.sub(\"üëã\", \" \",string)\n",
        "   string = re.sub(\"üí™\", \" \",string)\n",
        "   string = re.sub(\"üòÑ\", \" \",string)\n",
        "   string = re.sub(\"üßê\", \" \",string)\n",
        "   string = re.sub(\"üò†\", \" \",string)\n",
        "   string = re.sub(\"üéà\", \" \",string)\n",
        "   string = re.sub(\"üöÇ\", \" \",string)\n",
        "   string = re.sub(\"üòä\", \" \",string)\n",
        "   string = re.sub(\"üöá\", \" \",string)\n",
        "   string = re.sub(\"üöä\", \" \",string)\n",
        "   string = re.sub(\"ü§∑\", \" \",string)\n",
        "   string = re.sub(\"üò•\", \" \",string)\n",
        "   string = re.sub(\"üôÉ\", \" \",string)\n",
        "   string = re.sub(\"üî©\", \" \",string)\n",
        "   string = re.sub(\"üîß\", \" \",string)\n",
        "   string = re.sub(\"üî®\", \" \",string)\n",
        "   string = re.sub(\"üõ†\", \" \",string)\n",
        "   string = re.sub(\"üíì\", \" \",string)\n",
        "   string = re.sub(\"üí°\", \" \",string)\n",
        "   string = re.sub(\"üç∏\", \" \",string)\n",
        "   string = re.sub(\"ü•É\", \" \",string)\n",
        "   string = re.sub(\"ü•Ç\", \" \",string)\n",
        "   string = re.sub(\"üò∑\", \" \",string)\n",
        "   string = re.sub(\"ü§ê\", \" \",string)\n",
        "   string = re.sub(\"üåé\", \" \",string)\n",
        "   string = re.sub(\"üëë\", \" \",string)\n",
        "   string = re.sub(\"ü§õ\", \" \",string)\n",
        "   string = re.sub(\"üòÄ\", \" \",string)\n",
        "   string = re.sub(\"üõ§\", \" \",string)\n",
        "   string = re.sub(\"üéÑ\", \" \",string)\n",
        "   string = re.sub(\"üì¥\", \" \",string)\n",
        "   string = re.sub(\"üå≠\", \" \",string)\n",
        "   string = re.sub(\"ü§ï\", \" \",string)\n",
        "   string = re.sub(\"üò≠\", \" \",string)\n",
        "   string = re.sub(\"üçæ\", \" \",string)\n",
        "   string = re.sub(\"üçû\", \" \",string)\n",
        "   string = re.sub(\"ü§¶\", \" \",string)\n",
        "   string = re.sub(\"ü§Ø\", \" \",string)\n",
        "   string = re.sub(\"üïØÔ∏è\", \" \",string)\n",
        "\n",
        "   string = re.sub(\"OTHER|OFFENSE|ABUSE|INSULT\",\" \",string)\n",
        "   return string"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5asMgo4LtnRg"
      },
      "source": [
        "statementsForTraining = []\n",
        "sentimentsForTraining = []\n",
        "\n",
        "\n",
        "fileToRead = open(training_file, 'r')\n",
        "\n",
        "while True:\n",
        "  #next line in file\n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  findSentiment = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "\n",
        "\n",
        "  statementsForTraining.append(line)\n",
        "   #sentimentsForTraining.append(findSentiment.group(0))\n",
        "\n",
        "  if findSentiment.group(0) == \"OTHER\":  \n",
        "    sentimentsForTraining.append(0)\n",
        "  else:\n",
        "    sentimentsForTraining.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        " #print(\"{}: {}\".format(count,line.strip()))\n",
        "  \n",
        " # print(sentiment.group(0))\n",
        " \n",
        "fileToRead.close()\n",
        "\n",
        "training_sentences = statementsForTraining\n",
        "training_labels = sentimentsForTraining\n",
        "\n",
        "#print(training_sentences[9])\n",
        "#print(training_labels[9])\n",
        "\n",
        "#print(len(training_sentences))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsqZPENb98gD"
      },
      "source": [
        "##do the same with testdata\n",
        "statementsForTesting = []\n",
        "sentimentsForTesting = []\n",
        "\n",
        "fileToRead = open(testing_file, 'r')\n",
        "\n",
        "while True:\n",
        "  #next line in file\n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  sent = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "\n",
        "    \n",
        "\n",
        "  statementsForTesting.append(line)\n",
        "  #print(len(line))\n",
        "  #sentimentsForTesting.append(sent.group(0))\n",
        "\n",
        "  if sent.group(0) == \"OTHER\": \n",
        "    sentimentsForTesting.append(0)\n",
        "  else:\n",
        "    sentimentsForTesting.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        "\n",
        "fileToRead.close()\n",
        "\n",
        "\n",
        "testing_sentences = statementsForTesting\n",
        "testing_labels = sentimentsForTesting\n",
        "#print(len(testing_sentences))\n",
        "#print(testing_sentences)   \n",
        "#print(testing_labels)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRUvDLD5bMbO"
      },
      "source": [
        "Padding -> im Prinzip die S√§tze alle auf die gleiche L√§nge bringen (in Theorieteil n√§her drauf eingehen) -> maxlen-Paramter ist f√ºr pad_sequences vorhanden, wenn nicht gesetzt -> alles wird auf die L√§nge des l√§ngsten Satzes aufgef√ºllt -> print(padded(shape)) gibt aus, wie viele Datens√§tze padded wurden und gibt an, wie viele Tokens der l√§ngste Datensatz hat\n",
        "print(padded[x]) gibt einen Satz aus (bereits tokenisiert)\n",
        "\n",
        "Padding -> sowohl f√ºr Trainigs- als auch f√ºr Testdaten\n",
        "\n",
        "Und: Daten als numpy-Arrays speichern (notwendig f√ºr tensorflow).\n",
        "\n",
        " -> Tokenizer https://towardsdatascience.com/text-classification-in-keras-part-2-how-to-use-the-keras-tokenizer-word-representations-fd571674df23 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3hFi7waTv5m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0ea5122-f7e5-4dab-d54b-225f9d5e823e"
      },
      "source": [
        "tokenizer = Tokenizer(oov_token=\"OOV\")\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "\n",
        "#creating a word index - nur die Trainigsdaten\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "validation_size = 500\n",
        "\n",
        "\n",
        "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "padded_training = pad_sequences(training_sequences, maxlen=max_length, padding='post')\n",
        "print(len(padded_training))\n",
        "\n",
        "validation_sequences = padded_training[0:validation_size]\n",
        "validation_labels = training_labels[0:validation_size]\n",
        "\n",
        "padded_training = padded_training[validation_size:]\n",
        "training_labels = training_labels[validation_size:]\n",
        "\n",
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
        "padded_testing = pad_sequences(testing_sequences, maxlen=max_length,  padding='post')\n",
        "\n",
        "#print(validation_sequences[499])\n",
        "print(padded_training[0])\n",
        "#print(len(validation_labels))\n",
        "#print(len(training_labels))\n",
        "\n",
        "\n",
        "nppadded_training = np.array(padded_training)\n",
        "nptraining_labels = np.array(training_labels)\n",
        "\n",
        "nppadded_validation = np.array(validation_sequences)\n",
        "npvalidation_labels = np.array(validation_labels)\n",
        "\n",
        "nppadded_testing = np.array(padded_testing)\n",
        "nptesting_labels = np.array(testing_labels)\n",
        "\n",
        "\n",
        "print(len(nppadded_training))\n",
        "print(len(nptraining_labels))\n",
        "print(len(word_index))\n",
        "\n",
        "#print(statementsForTraining[2])\n",
        "#print(nppadded_training[4])\n",
        "#print(nppadded_training.shape)\n",
        "#print(nptraining_labels[4])\n",
        "#print(nppadded_testing.shape)\n",
        "#print(word_index) \n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5009\n",
            "[  12 3982   11   41 6706 1040    4    5  202   39    3 2922   49 1360\n",
            "  810  495 3983    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0]\n",
            "4509\n",
            "4509\n",
            "15059\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tL3owrc8THkT"
      },
      "source": [
        "\n",
        "Dann: Embedding mit entweder word2vec oder glove\n",
        "Word2vec-Daten sind hier: http://vectors.nlpl.eu/repository/#\n",
        "Glove -> https://nlp.stanford.edu/projects/glove/ Da mal den Twitter-Vector runtergeladen\n",
        "Wenn Daten in GoogleDrive sind (w√§re auch via url m√∂glich..), muss Drive gemounted werden ( https://buomsoo-kim.github.io/colab/2020/05/09/Colab-mounting-google-drive.md/ ) aber auch hier https://enjoymachinelearning.com/posts/colab-with-google-drive/\n",
        "\n",
        "Die Word2vec vectors: http://vectors.nlpl.eu/repository/# \n",
        "\n",
        "glove-zitat:\n",
        "Citing GloVe\n",
        "\n",
        "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. [pdf] [bib]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zuO7T9ZTG57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f17d282-5ea0-4ba3-dc59-e44352c2b4bf"
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount(\"/content/drive\")\n",
        "os.listdir(\"/content/drive/MyDrive/Colab Notebooks\")\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['germeval_training.txt',\n",
              " 'glove.twitter.27B.50d.txt',\n",
              " 'glove.twitter.27B.200d.txt',\n",
              " 'glove.6B.200d.txt',\n",
              " 'glove.840B.300d.txt',\n",
              " 'tensorboard.gdoc',\n",
              " 'keras.gdoc',\n",
              " 'Vectorization CNN embedded_limited_vocab.ipynb',\n",
              " 'glove.42B.300d.txt',\n",
              " 'Embedding Glove Vergleich.ipynb',\n",
              " 'CNN embedded_limited_vocab.ipynb',\n",
              " 'LSTM_limited_vocab.ipynb',\n",
              " 'LSTM.ipynb',\n",
              " 'CNN embedded.ipynb']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7ToKO-sZLHK"
      },
      "source": [
        "\n",
        "Keras-Doc : https://keras.io/examples/nlp/pretrained_word_embeddings/#load-pretrained-word-embeddings \n",
        "embedding mit initializers.. weights m√ºsste auch funktionieren\n",
        "\n",
        "Diese erstellte Matrix mit Embedding dann in die Embedding-Schicht einbinden,  Trainable auf False, weil sich die Werte nicht durch Training anpassen sollen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AShIVfC7ZQAH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e73867b5-6a1a-43d4-b2ef-f44cfb00cb6a"
      },
      "source": [
        "#Gr√∂√üe Vokabel -> wordindex + 2 (weil padding + OOV) \n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "vocabulary_size = len(word_index)+2\n",
        "\n",
        "# dann erstell ich ein W√∂rterbuch mit Namen \"embedding_vector\", dort sind dann\n",
        "#die keys drinnen, die in glove-Datei drinnen sind mit dem entsprechenden Key\n",
        "\n",
        "embedding_index_glove = {}\n",
        "f = open('/content/drive/MyDrive/Colab Notebooks/glove.twitter.27B.200d.txt')\n",
        "for line in f:\n",
        "  value = line.split()\n",
        "  word = value[0]\n",
        "  coef = np.asarray(value[1:],dtype='float32')\n",
        "  embedding_index_glove[word] = coef\n",
        "\n",
        "print(\"%d gefunden: \"% len(embedding_index_glove))\n",
        "\n",
        "#Dann noch eine Embedding-Matrix erstellen\n",
        "#zweiter Wert = Embedding-Dimension der Datei, in dem Fall 200\n",
        "\n",
        "glove_matrix = np.zeros((vocabulary_size,200))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    embedding_value = embedding_index_glove.get(word)\n",
        "    if embedding_value is not None:\n",
        "      glove_matrix[index] = embedding_value\n",
        "      hits+=1\n",
        "    else:\n",
        "      misses+=1\n",
        "\n",
        "print(\"hits %d and %d misses\"%(hits,misses))\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1193514 gefunden: \n",
            "hits 6747 and 8312 misses\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZmvOfwhV4N5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e7e5d78-e17f-41c4-eda3-0c0c88a9b237"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "print(\"vocab size: %d\"%vocabulary_size)\n",
        "CNN16052102ES03 = tf.keras.Sequential()\n",
        "#Embedding -> hier dann auf das embedding verweisen, Input_dim -> die Anzahl der W√∂rter im word_index, output -> in dem Fall passend zum verwendeten Vektor\n",
        "#input-length -> auf 60  gepadded, trainable -> nein, weil nichts ver√§ndert werden soll\n",
        "#embeddings_initializer=keras.initializers.Constant(glove_matrix) vs weights = [glove_matrix]\n",
        "#Convolutional layers => filters = neurons.. mit 100? 265?\n",
        "#CNN16052102ES03.add(tf.keras.layers.Embedding(input_dim=vocabulary_size, output_dim=200, input_length=max_length))\n",
        "CNN16052102ES03.add(tf.keras.layers.Embedding(vocabulary_size, output_dim=200, input_length=60, embeddings_initializer = keras.initializers.Constant(glove_matrix), trainable= False))\n",
        "CNN16052102ES03.add(tf.keras.layers.Dropout(0.4))\n",
        "CNN16052102ES03.add(tf.keras.layers.Conv1D(filters=120, kernel_size=3, padding=\"valid\", activation=\"relu\"))\n",
        "CNN16052102ES03.add(tf.keras.layers.MaxPooling1D())\n",
        "CNN16052102ES03.add(tf.keras.layers.Conv1D(filters=120, kernel_size=3, padding=\"valid\", activation=\"relu\"))\n",
        "CNN16052102ES03.add(tf.keras.layers.GlobalAveragePooling1D())\n",
        "CNN16052102ES03.add(tf.keras.layers.Flatten())\n",
        "CNN16052102ES03.add(tf.keras.layers.Dense(260, activation=\"relu\"))\n",
        "CNN16052102ES03.add(tf.keras.layers.Dropout(0.4))\n",
        "CNN16052102ES03.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "CNN16052102ES03.summary()\n",
        "\n",
        "#nppadded_training = np.asmatrix(nppadded_training) not necessary\n",
        "#nppadded_testing = np.asmatrix(nppadded_testing)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab size: 15061\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 60, 200)           3012200   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 60, 200)           0         \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 58, 120)           72120     \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 29, 120)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 27, 120)           43320     \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 120)               0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 120)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 260)               31460     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 260)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 261       \n",
            "=================================================================\n",
            "Total params: 3,159,361\n",
            "Trainable params: 147,161\n",
            "Non-trainable params: 3,012,200\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEr4OzT-iHDe"
      },
      "source": [
        "#model.layers[2].get_weights()[0].shape\n",
        "#weights=np.random.rand(5,200,100)\n",
        "#bias=np.random.rand(100)\n",
        "#model.layers[2].set_weights([weights, bias])\n",
        "\n",
        "#model.layers[2].get_weights()[0]\n",
        "#https://androidkt.com/set-custom-weights-keras-using-numpy-array/"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UB7_3VPYesr9"
      },
      "source": [
        "F1-Score f√ºr jede Epoche https://aakashgoel12.medium.com/how-to-add-user-defined-function-get-f1-score-in-keras-metrics-3013f979ce0d\n",
        "\n",
        "Sehr gute Ressource f√ºr die verschiedenen Scores und Metriken https://neptune.ai/blog/evaluation-metrics-binary-classification#10  das und aakas verwendet\n",
        "\n",
        "hier: je eine Funktion f√ºr Recall, Precision, f1 https://neptune.ai/blog/keras-metrics \n",
        "\n",
        "https://keras.rstudio.com/reference/k_ones_like.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygyrbFJaMV9B"
      },
      "source": [
        "import keras.backend as K\n",
        "\n",
        "def metrics_recall(data_true, data_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(data_true,0,1)))\n",
        "\n",
        "    recall = true_positives / (possible_positives+K.epsilon())\n",
        "    return recall\n",
        "\n",
        "\n",
        "def metrics_precision(data_true, data_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "\n",
        "    positives_predicted = K.sum(K.round(K.clip(data_pred,0,1)))\n",
        "    precision = true_positives / (positives_predicted+K.epsilon())\n",
        "    return precision\n",
        "\n",
        "\n",
        "def metrics_f1(data_true, data_pred):\n",
        "    precision_data = metrics_precision(data_true, data_pred)\n",
        "    recall_data = metrics_recall(data_true, data_pred)\n",
        "    return 2*(precision_data*recall_data)/(precision_data+recall_data+K.epsilon())"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1ctlBrnuYJz"
      },
      "source": [
        "https://aakashgoel12.medium.com/how-to-add-user-defined-function-get-f1-score-in-keras-metrics-3013f979ce0d"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AfPD3_bWCm0"
      },
      "source": [
        "CNN16052102ES03.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',metrics_recall,metrics_precision,metrics_f1])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpChKUY-QEWI"
      },
      "source": [
        "https://www.tensorflow.org/tensorboard/tensorboard_in_notebooks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJfMgUhHBoD1"
      },
      "source": [
        "#%load_ext tensorboard\n",
        "#nur einmal pro Sitzung notwendig\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ISmMXLqP8Hc"
      },
      "source": [
        "\n",
        "logs_base_dir = \"./logs\"\n",
        "callbackForTB = tf.keras.callbacks.TensorBoard(logs_base_dir)\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ehh-EMXUQh8r"
      },
      "source": [
        "Early Stopping as defined in keras tensorflow documentation\n",
        "https://www.tensorflow.org/guide/keras/train_and_evaluate "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BY_t-PeQEjy"
      },
      "source": [
        "callbackEarlyStopping = [\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_loss\",\n",
        "        min_delta=0.0001,\n",
        "        patience=5,\n",
        "        verbose=1,\n",
        "    )\n",
        "]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2CHbXiP1LsF"
      },
      "source": [
        "training_epochs = 30\n",
        "batch_size = 40\n",
        "validation_split=0.2"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abV-QAxfW48r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "908aac3f-6f5f-4eda-ca3a-132a4baa354f"
      },
      "source": [
        "#Werte der Convolutional-Schichten variieren (Filter), Batch-Size variieren, kernel-size..\n",
        "CNN16052102ES03.fit(nppadded_training, nptraining_labels, batch_size=batch_size, validation_split=validation_split, epochs=training_epochs, callbacks=[callbackForTB,callbackEarlyStopping])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "91/91 [==============================] - 5s 45ms/step - loss: 0.6529 - accuracy: 0.6573 - metrics_recall: 0.0415 - metrics_precision: 0.0266 - metrics_f1: 0.0261 - val_loss: 0.6346 - val_accuracy: 0.6718 - val_metrics_recall: 0.0000e+00 - val_metrics_precision: 0.0000e+00 - val_metrics_f1: 0.0000e+00\n",
            "Epoch 2/30\n",
            "91/91 [==============================] - 3s 38ms/step - loss: 0.6339 - accuracy: 0.6629 - metrics_recall: 0.0061 - metrics_precision: 0.0187 - metrics_f1: 0.0080 - val_loss: 0.6179 - val_accuracy: 0.6818 - val_metrics_recall: 0.0803 - val_metrics_precision: 0.5254 - val_metrics_f1: 0.1359\n",
            "Epoch 3/30\n",
            "91/91 [==============================] - 4s 39ms/step - loss: 0.5996 - accuracy: 0.6690 - metrics_recall: 0.1234 - metrics_precision: 0.3746 - metrics_f1: 0.1665 - val_loss: 0.5893 - val_accuracy: 0.6951 - val_metrics_recall: 0.0922 - val_metrics_precision: 0.6957 - val_metrics_f1: 0.1589\n",
            "Epoch 4/30\n",
            "91/91 [==============================] - 4s 39ms/step - loss: 0.5731 - accuracy: 0.7006 - metrics_recall: 0.1942 - metrics_precision: 0.4872 - metrics_f1: 0.2502 - val_loss: 0.5693 - val_accuracy: 0.7084 - val_metrics_recall: 0.1554 - val_metrics_precision: 0.7688 - val_metrics_f1: 0.2494\n",
            "Epoch 5/30\n",
            "91/91 [==============================] - 4s 40ms/step - loss: 0.5666 - accuracy: 0.7032 - metrics_recall: 0.3369 - metrics_precision: 0.5939 - metrics_f1: 0.4005 - val_loss: 0.5473 - val_accuracy: 0.7317 - val_metrics_recall: 0.4503 - val_metrics_precision: 0.6534 - val_metrics_f1: 0.5069\n",
            "Epoch 6/30\n",
            "91/91 [==============================] - 4s 39ms/step - loss: 0.5248 - accuracy: 0.7331 - metrics_recall: 0.4932 - metrics_precision: 0.6807 - metrics_f1: 0.5342 - val_loss: 0.5387 - val_accuracy: 0.7306 - val_metrics_recall: 0.4752 - val_metrics_precision: 0.6182 - val_metrics_f1: 0.5201\n",
            "Epoch 7/30\n",
            "91/91 [==============================] - 4s 40ms/step - loss: 0.4991 - accuracy: 0.7481 - metrics_recall: 0.4821 - metrics_precision: 0.6826 - metrics_f1: 0.5369 - val_loss: 0.5294 - val_accuracy: 0.7350 - val_metrics_recall: 0.4092 - val_metrics_precision: 0.6653 - val_metrics_f1: 0.4880\n",
            "Epoch 8/30\n",
            "91/91 [==============================] - 4s 40ms/step - loss: 0.4747 - accuracy: 0.7664 - metrics_recall: 0.5487 - metrics_precision: 0.7254 - metrics_f1: 0.5866 - val_loss: 0.5486 - val_accuracy: 0.7018 - val_metrics_recall: 0.6176 - val_metrics_precision: 0.5417 - val_metrics_f1: 0.5627\n",
            "Epoch 9/30\n",
            "91/91 [==============================] - 4s 39ms/step - loss: 0.4416 - accuracy: 0.8038 - metrics_recall: 0.6409 - metrics_precision: 0.7772 - metrics_f1: 0.6810 - val_loss: 0.5404 - val_accuracy: 0.7140 - val_metrics_recall: 0.5261 - val_metrics_precision: 0.5687 - val_metrics_f1: 0.5339\n",
            "Epoch 10/30\n",
            "91/91 [==============================] - 4s 39ms/step - loss: 0.4116 - accuracy: 0.8163 - metrics_recall: 0.6783 - metrics_precision: 0.7868 - metrics_f1: 0.7068 - val_loss: 0.5281 - val_accuracy: 0.7173 - val_metrics_recall: 0.5203 - val_metrics_precision: 0.5751 - val_metrics_f1: 0.5351\n",
            "Epoch 11/30\n",
            "91/91 [==============================] - 4s 40ms/step - loss: 0.3650 - accuracy: 0.8436 - metrics_recall: 0.7076 - metrics_precision: 0.8151 - metrics_f1: 0.7372 - val_loss: 0.5434 - val_accuracy: 0.7306 - val_metrics_recall: 0.4344 - val_metrics_precision: 0.6237 - val_metrics_f1: 0.5008\n",
            "Epoch 12/30\n",
            "91/91 [==============================] - 4s 39ms/step - loss: 0.3540 - accuracy: 0.8482 - metrics_recall: 0.7250 - metrics_precision: 0.8253 - metrics_f1: 0.7505 - val_loss: 0.5601 - val_accuracy: 0.7228 - val_metrics_recall: 0.5213 - val_metrics_precision: 0.5880 - val_metrics_f1: 0.5429\n",
            "Epoch 13/30\n",
            "91/91 [==============================] - 4s 40ms/step - loss: 0.2925 - accuracy: 0.8695 - metrics_recall: 0.7764 - metrics_precision: 0.8370 - metrics_f1: 0.7939 - val_loss: 0.5657 - val_accuracy: 0.7262 - val_metrics_recall: 0.6123 - val_metrics_precision: 0.5768 - val_metrics_f1: 0.5846\n",
            "Epoch 14/30\n",
            "91/91 [==============================] - 4s 40ms/step - loss: 0.2823 - accuracy: 0.8805 - metrics_recall: 0.8064 - metrics_precision: 0.8428 - metrics_f1: 0.8181 - val_loss: 0.5704 - val_accuracy: 0.7162 - val_metrics_recall: 0.5524 - val_metrics_precision: 0.5685 - val_metrics_f1: 0.5501\n",
            "Epoch 15/30\n",
            "91/91 [==============================] - 4s 40ms/step - loss: 0.2568 - accuracy: 0.8913 - metrics_recall: 0.7956 - metrics_precision: 0.8733 - metrics_f1: 0.8226 - val_loss: 0.6000 - val_accuracy: 0.7084 - val_metrics_recall: 0.6208 - val_metrics_precision: 0.5493 - val_metrics_f1: 0.5714\n",
            "Epoch 00015: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff77c0c2450>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJVL4SBLPB2P"
      },
      "source": [
        "#%tensorboard --logdir {logs_base_dir}"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_LnvWBcnoak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69d7e5d7-e37a-4074-98d1-52017103b67c"
      },
      "source": [
        "#results = model.evaluate(nppadded_testing, nptesting_labels, batch_size=batch_size)\n",
        "#print(\"test loss, test acc:\",results)\n",
        "\n",
        "(loss,accuracy, metrics_recall,metrics_precision,\n",
        "metrics_f1) = CNN16052102ES03.evaluate(nppadded_testing, nptesting_labels, verbose=1)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "111/111 [==============================] - 1s 11ms/step - loss: 0.6804 - accuracy: 0.6512 - metrics_recall: 0.4542 - metrics_precision: 0.4911 - metrics_f1: 0.4576\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KgjIkhpKmHc"
      },
      "source": [
        "make some predictions of test data and save it to variable. verbose=0 -> do not generate output\n",
        "Gute Quelle: https://deeplizard.com/learn/video/2f-NjDUvZIE "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89GWuxryKlcM"
      },
      "source": [
        "CNN_predictions06 = CNN16052102ES03.predict(x=nppadded_testing)\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3jPDaDJK_cN"
      },
      "source": [
        "#for p in CNN_predictions06:\n",
        " # print(p)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eC9efJy4Lp21"
      },
      "source": [
        "rounded predictions: give prediction value of most likely prediction (0 or 1). Printing the output of rounded prediction shows the prediction made by the model on the data (which output is most likely)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsG-TJuQLvtk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37c54d04-7ee8-4032-bb7a-86f157f4bb47"
      },
      "source": [
        "prediction_rounded06 = np.round(CNN_predictions06)\n",
        "#np.argmax(CNN_predictions06,axis=-1)\n",
        "\n",
        "#for p in prediction_rounded06:\n",
        " # print(p)\n",
        "\n",
        "\n",
        "print(nptesting_labels[500:520])\n",
        "print(prediction_rounded06[500:520])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1]\n",
            "[[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egTtgpXgg8a2"
      },
      "source": [
        "https://deeplizard.com/learn/video/km7pxKy4UHU\n",
        "\n",
        "Quelle der def plot_confusion_matrix: https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSDXf7-_MITy"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0AMs1EzhBU1"
      },
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                        normalize=False,\n",
        "                        title='Confusion matrix',\n",
        "                        cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2JgEnlghCtl"
      },
      "source": [
        "cm = confusion_matrix(y_true=nptesting_labels, y_pred=prediction_rounded06)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckmF29whhFmX"
      },
      "source": [
        "plot_labels = ['no hatespeech','hatespeech']"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "2mpSE96rhK7K",
        "outputId": "ed3c15fd-8170-4bd7-bd99-24a8c2cd7f46"
      },
      "source": [
        "plot_confusion_matrix(cm=cm, classes=plot_labels, title='CNN Confusion 120 EarlyStopping 0.0001')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix, without normalization\n",
            "[[1759  571]\n",
            " [ 661  541]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}