{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN embedded.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM+XHLhJ8TpKZJ0Mz4WN1wO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BiancaStadl/ProjektarbeitML/blob/main/CNN_embedded.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXDOlIBymF0V"
      },
      "source": [
        "GloVe embeddings taken from:\n",
        "\n",
        "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. [pdf] [bib]\n",
        "\n",
        "hatespeechdata taken from (https://hatespeechdata.com/): Wiegand, M., Siegel, M. and Ruppenhofer, J., 2018. Overview of the GermEval 2018 Shared Task on the Identification of Offensive Language. In: Proceedings of GermEval 2018, 14th Conference on Natural Language Processing (KONVENS 2018). Vienna, Austria: Research Gate. available on: https://github.com/uds-lsv/GermEval-2018-Data (last checked: 09.05.2021)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlBmABDxfqII"
      },
      "source": [
        "wiki detox..https://colab.research.google.com/github/tensorflow/fairness-indicators/blob/master/g3doc/tutorials/Fairness_Indicators_TFCO_Wiki_Case_Study.ipynb#scrollTo=y6T5tlXcdW7J "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3xfitNdliBI"
      },
      "source": [
        "#import matplotlib.pyplot as plt -> für evtl Visualisierungen\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import string\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from keras import losses \n",
        "from keras import optimizers \n",
        "from keras import metrics \n",
        "\n",
        "#!pip install Tokenizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "#!pip install pad_sequences\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import preprocessing\n",
        "#from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTWJQ1iga_vS"
      },
      "source": [
        "Maximale Satzlänge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bq08Me5la_Cc"
      },
      "source": [
        "\n",
        "max_length = 60"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVYBMvYSotTH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64f382fa-33eb-407f-f514-e045c821dd65"
      },
      "source": [
        "url = \"https://github.com/uds-lsv/GermEval-2018-Data/archive/master.zip\"\n",
        "\n",
        "dataset = tf.keras.utils.get_file(\"GermEval-2018-Data-master.zip\", url, \n",
        "                                   extract=True, cache_dir='.',\n",
        "                                    cache_subdir='')\n",
        "\n",
        "dataset_dir = os.path.join(os.path.dirname(dataset), 'GermEval-2018-Data-master')\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/uds-lsv/GermEval-2018-Data/archive/master.zip\n",
            "15261696/Unknown - 1s 0us/step"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cS14OUtfo34V"
      },
      "source": [
        "#os.listdir(dataset_dir)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2X429K6hpOVm"
      },
      "source": [
        "training_file = os.path.join(dataset_dir, 'germeval2018.training.txt')\n",
        "\n",
        "testing_file = os.path.join(dataset_dir, 'germeval2018.test.txt')\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uq8fG3LNtn_m"
      },
      "source": [
        "###Aufbereitung\n",
        "txt-Dateien lesen, und dabei jede Zeile splitten und teilen\n",
        "Twitter-Handler entfernen?\n",
        "Labels von Sätzen trennen, Labels in eigenen Array packen.\n",
        "\n",
        "####Ressourcen\n",
        "* https://www.w3schools.com/python/gloss_python_if_statement.asp\n",
        "* https://stackabuse.com/using-regex-for-text-manipulation-in-python/\n",
        "* https://www.tutorialspoint.com/python/string_splitlines.htm \n",
        "* https://note.nkmk.me/en/python-split-rsplit-splitlines-re/ \n",
        "* https://www.w3schools.com/python/python_regex.asp \n",
        "\n",
        "gäbe bei keras tf.keras.preprocessing.text_dataset_from_directory, aber dafür müssten die Daten auf bestimmte Weise in Verzeichnis organisiert sein, hier nicht der Fall.\n",
        "\n",
        "\n",
        "Einteilung der Daten: Testdaten\n",
        "Trainingsdaten -> noch ca 500 für Validierungsdaten\n",
        "\n",
        "labels -> \"other\", also nicht-negative Aussagen bekommen \"0\", negative Aussagen bekommen \"1\"\n",
        "\n",
        " Regex für Emojis  ->\n",
        "\n",
        "(\\u00a9|\\u00ae|[\\u2000-\\u3300]|\\ud83c[\\ud000-\\udfff]|\\ud83d[\\ud000-\\udfff]|\\ud83e[\\ud000-\\udfff])\n",
        "\n",
        "genommen von https://www.regextester.com/106421 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Py_cwD4eZkXo"
      },
      "source": [
        "def remove_clutter(string):\n",
        "   string = re.sub(\"@[^\\s]+\",\" \",string)\n",
        "   string = re.sub(\"#[^\\s]+\",\" \", string)\n",
        "   string = re.sub(\"\\u00a9\",\" \", string)\n",
        "   string = re.sub(\"\\u00ae\",\" \", string)\n",
        "   string = re.sub(\"[\\u2000-\\u3300]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83c[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83d[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83e[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"😜\", \" \",string)\n",
        "   string = re.sub(\"🍫\", \" \",string)\n",
        "   string = re.sub(\"😁\", \" \",string)\n",
        "   string = re.sub(\"🐖\", \" \",string)\n",
        "   string = re.sub(\"😡\", \" \",string)\n",
        "   string = re.sub(\"😇\", \" \",string)\n",
        "   string = re.sub(\"😬\", \" \",string)\n",
        "   string = re.sub(\"😃\", \" \",string)\n",
        "   string = re.sub(\"😂\", \" \",string)\n",
        "   string = re.sub(\"💙\", \" \",string)  \n",
        "   string = re.sub(\"😛\", \" \",string)\n",
        "   string = re.sub(\"🙏\", \" \",string)\n",
        "   string = re.sub(\"👍\", \" \",string)\n",
        "   string = re.sub(\"🖕\", \" \",string)\n",
        "   string = re.sub(\"😉\", \" \",string)\n",
        "   string = re.sub(\"💩\", \" \",string)\n",
        "   string = re.sub(\"🤢\", \" \",string)\n",
        "   string = re.sub(\"👏\", \" \",string)\n",
        "   string = re.sub(\"😨\", \" \",string)\n",
        "   string = re.sub(\"🤣\", \" \",string)\n",
        "   string = re.sub(\"🤡\", \" \",string)\n",
        "   string = re.sub(\"😈\", \" \",string)\n",
        "   string = re.sub(\"💃🏽\", \" \",string)\n",
        "   string = re.sub(\"👹\", \" \",string)\n",
        "   string = re.sub(\"🤘\", \" \",string)\n",
        "   string = re.sub(\"😱\", \" \",string)\n",
        "   string = re.sub(\"🤔\", \" \",string) \n",
        "   string = re.sub(\"🌈\", \" \",string) \n",
        "   string = re.sub(\"💕\", \" \",string) \n",
        "   string = re.sub(\"👩‍❤️‍👩\", \" \",string) \n",
        "   string = re.sub(\"😍\", \" \",string) \n",
        "   string = re.sub(\"👆\", \" \",string) \n",
        "   string = re.sub(\"😖\", \" \",string) \n",
        "   string = re.sub(\"👇\", \" \",string) \n",
        "   string = re.sub(\"🔥\", \" \",string) \n",
        "   string = re.sub(\"😘\", \" \",string) \n",
        "   string = re.sub(\"🎉\", \" \",string) \n",
        "   string = re.sub(\"🤬\", \" \",string) \n",
        "   string = re.sub(\"👊\", \" \",string)\n",
        "   string = re.sub(\"🇩🇪\", \" \",string)  \n",
        "   string = re.sub(\"💔\", \" \",string)\n",
        "   string = re.sub(\"🙈\", \" \",string)\n",
        "   string = re.sub(\"🤯\", \" \",string)\n",
        "   string = re.sub(\"🐟\", \" \",string)\n",
        "   string = re.sub(\"🛶\", \" \",string)\n",
        "   string = re.sub(\"😊\", \" \",string)\n",
        "   string = re.sub(\"😓\", \" \",string)\n",
        "   string = re.sub(\"😳\", \" \",string)\n",
        "   string = re.sub(\"🚀\", \" \",string)\n",
        "   string = re.sub(\"👎\", \" \",string)\n",
        "   string = re.sub(\"😎\", \" \",string)\n",
        "   string = re.sub(\"🐸\", \" \",string)\n",
        "   string = re.sub(\"📈\", \" \",string)\n",
        "   string = re.sub(\"🙂\", \" \",string)\n",
        "   string = re.sub(\"😅\", \" \",string)\n",
        "   string = re.sub(\"😆\", \" \",string)\n",
        "   string = re.sub(\"🙎🏿\", \" \",string)\n",
        "   string = re.sub(\"👎🏽\", \" \",string)\n",
        "   string = re.sub(\"🤭\", \" \",string)\n",
        "   string = re.sub(\"😤\", \" \",string)\n",
        "   string = re.sub(\"😚\", \" \",string)\n",
        "   string = re.sub(\"😊\", \" \",string)\n",
        "   string = re.sub(\"😲\", \" \",string)\n",
        "   string = re.sub(\"🤮\", \" \",string)\n",
        "   string = re.sub(\"🙄\", \" \",string)\n",
        "   string = re.sub(\"🤑\", \" \",string)\n",
        "   string = re.sub(\"🎅\", \" \",string)\n",
        "   string = re.sub(\"👋\", \" \",string)\n",
        "   string = re.sub(\"💪\", \" \",string)\n",
        "   string = re.sub(\"😄\", \" \",string)\n",
        "   string = re.sub(\"🧐\", \" \",string)\n",
        "   string = re.sub(\"😠\", \" \",string)\n",
        "   string = re.sub(\"🎈\", \" \",string)\n",
        "   string = re.sub(\"🚂\", \" \",string)\n",
        "   string = re.sub(\"😊\", \" \",string)\n",
        "   string = re.sub(\"🚇\", \" \",string)\n",
        "   string = re.sub(\"🚊\", \" \",string)\n",
        "   string = re.sub(\"🤷\", \" \",string)\n",
        "   string = re.sub(\"😥\", \" \",string)\n",
        "   string = re.sub(\"🙃\", \" \",string)\n",
        "   string = re.sub(\"🔩\", \" \",string)\n",
        "   string = re.sub(\"🔧\", \" \",string)\n",
        "   string = re.sub(\"🔨\", \" \",string)\n",
        "   string = re.sub(\"🛠\", \" \",string)\n",
        "   string = re.sub(\"💓\", \" \",string)\n",
        "   string = re.sub(\"💡\", \" \",string)\n",
        "   string = re.sub(\"🍸\", \" \",string)\n",
        "   string = re.sub(\"🥃\", \" \",string)\n",
        "   string = re.sub(\"🥂\", \" \",string)\n",
        "   string = re.sub(\"😷\", \" \",string)\n",
        "   string = re.sub(\"🤐\", \" \",string)\n",
        "   string = re.sub(\"🌎\", \" \",string)\n",
        "   string = re.sub(\"👑\", \" \",string)\n",
        "   string = re.sub(\"🤛\", \" \",string)\n",
        "   string = re.sub(\"😀\", \" \",string)\n",
        "   string = re.sub(\"🛤\", \" \",string)\n",
        "   string = re.sub(\"🎄\", \" \",string)\n",
        "   string = re.sub(\"📴\", \" \",string)\n",
        "   string = re.sub(\"🌭\", \" \",string)\n",
        "   string = re.sub(\"🤕\", \" \",string)\n",
        "   string = re.sub(\"😭\", \" \",string)\n",
        "   string = re.sub(\"🍾\", \" \",string)\n",
        "   string = re.sub(\"🍞\", \" \",string)\n",
        "   string = re.sub(\"🤦\", \" \",string)\n",
        "   string = re.sub(\"🤯\", \" \",string)\n",
        "   string = re.sub(\"🕯️\", \" \",string)\n",
        "\n",
        "   string = re.sub(\"OTHER|OFFENSE|ABUSE|INSULT\",\" \",string)\n",
        "   return string"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5asMgo4LtnRg"
      },
      "source": [
        "statementsForTraining = []\n",
        "sentimentsForTraining = []\n",
        "\n",
        "\n",
        "fileToRead = open(training_file, 'r')\n",
        "\n",
        "while True:\n",
        "  #next line in file\n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  findSentiment = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "\n",
        "\n",
        "  statementsForTraining.append(line)\n",
        "   #sentimentsForTraining.append(findSentiment.group(0))\n",
        "\n",
        "  if findSentiment.group(0) == \"OTHER\":  \n",
        "    sentimentsForTraining.append(0)\n",
        "  else:\n",
        "    sentimentsForTraining.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        " #print(\"{}: {}\".format(count,line.strip()))\n",
        "  \n",
        " # print(sentiment.group(0))\n",
        " \n",
        "fileToRead.close()\n",
        "\n",
        "training_sentences = statementsForTraining\n",
        "training_labels = sentimentsForTraining\n",
        "\n",
        "#print(training_sentences[9])\n",
        "#print(training_labels[9])\n",
        "\n",
        "#print(len(training_sentences))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsqZPENb98gD"
      },
      "source": [
        "##do the same with testdata\n",
        "statementsForTesting = []\n",
        "sentimentsForTesting = []\n",
        "\n",
        "fileToRead = open(testing_file, 'r')\n",
        "\n",
        "while True:\n",
        "  #next line in file\n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  sent = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "\n",
        "    \n",
        "\n",
        "  statementsForTesting.append(line)\n",
        "  #print(len(line))\n",
        "  #sentimentsForTesting.append(sent.group(0))\n",
        "\n",
        "  if sent.group(0) == \"OTHER\": \n",
        "    sentimentsForTesting.append(0)\n",
        "  else:\n",
        "    sentimentsForTesting.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        "\n",
        "fileToRead.close()\n",
        "\n",
        "\n",
        "testing_sentences = statementsForTesting\n",
        "testing_labels = sentimentsForTesting\n",
        "#print(len(testing_sentences))\n",
        "#print(testing_sentences)   \n",
        "#print(testing_labels)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRUvDLD5bMbO"
      },
      "source": [
        "Padding -> im Prinzip die Sätze alle auf die gleiche Länge bringen (in Theorieteil näher drauf eingehen) -> maxlen-Paramter ist für pad_sequences vorhanden, wenn nicht gesetzt -> alles wird auf die Länge des längsten Satzes aufgefüllt -> print(padded(shape)) gibt aus, wie viele Datensätze padded wurden und gibt an, wie viele Tokens der längste Datensatz hat\n",
        "print(padded[x]) gibt einen Satz aus (bereits tokenisiert)\n",
        "\n",
        "Padding -> sowohl für Trainigs- als auch für Testdaten\n",
        "\n",
        "Und: Daten als numpy-Arrays speichern (notwendig für tensorflow).\n",
        "\n",
        " -> Tokenizer https://towardsdatascience.com/text-classification-in-keras-part-2-how-to-use-the-keras-tokenizer-word-representations-fd571674df23 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3hFi7waTv5m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a6450cc-7275-4d1b-b609-a9061ecde2a8"
      },
      "source": [
        "tokenizer = Tokenizer(oov_token=\"OOV\")\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "\n",
        "#creating a word index - nur die Trainigsdaten\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "validation_size = 500\n",
        "\n",
        "\n",
        "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "padded_training = pad_sequences(training_sequences, maxlen=max_length, padding='post')\n",
        "print(len(padded_training))\n",
        "\n",
        "validation_sequences = padded_training[0:validation_size]\n",
        "validation_labels = training_labels[0:validation_size]\n",
        "\n",
        "padded_training = padded_training[validation_size:]\n",
        "training_labels = training_labels[validation_size:]\n",
        "\n",
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
        "padded_testing = pad_sequences(testing_sequences, maxlen=max_length,  padding='post')\n",
        "\n",
        "#print(validation_sequences[499])\n",
        "print(padded_training[0])\n",
        "#print(len(validation_labels))\n",
        "#print(len(training_labels))\n",
        "\n",
        "\n",
        "nppadded_training = np.array(padded_training)\n",
        "nptraining_labels = np.array(training_labels)\n",
        "\n",
        "nppadded_validation = np.array(validation_sequences)\n",
        "npvalidation_labels = np.array(validation_labels)\n",
        "\n",
        "nppadded_testing = np.array(padded_testing)\n",
        "nptesting_labels = np.array(testing_labels)\n",
        "\n",
        "\n",
        "print(len(nppadded_training))\n",
        "print(len(nptraining_labels))\n",
        "print(len(word_index))\n",
        "\n",
        "#print(statementsForTraining[2])\n",
        "#print(nppadded_training[4])\n",
        "#print(nppadded_training.shape)\n",
        "#print(nptraining_labels[4])\n",
        "#print(nppadded_testing.shape)\n",
        "#print(word_index) \n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5009\n",
            "[  12 3982   11   41 6706 1040    4    5  202   39    3 2922   49 1360\n",
            "  810  495 3983    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0]\n",
            "4509\n",
            "4509\n",
            "15059\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tL3owrc8THkT"
      },
      "source": [
        "\n",
        "Dann: Embedding mit entweder word2vec oder glove\n",
        "Word2vec-Daten sind hier: http://vectors.nlpl.eu/repository/#\n",
        "Glove -> https://nlp.stanford.edu/projects/glove/ Da mal den Twitter-Vector runtergeladen\n",
        "Wenn Daten in GoogleDrive sind (wäre auch via url möglich..), muss Drive gemounted werden ( https://buomsoo-kim.github.io/colab/2020/05/09/Colab-mounting-google-drive.md/ ) aber auch hier https://enjoymachinelearning.com/posts/colab-with-google-drive/\n",
        "\n",
        "Die Word2vec vectors: http://vectors.nlpl.eu/repository/# \n",
        "\n",
        "glove-zitat:\n",
        "Citing GloVe\n",
        "\n",
        "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. [pdf] [bib]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zuO7T9ZTG57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b2030fc-8cae-4653-a9e4-7a86932f7f25"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "os.listdir(\"/content/drive/MyDrive/Colab Notebooks\")\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['germeval_training.txt',\n",
              " 'glove.twitter.27B.50d.txt',\n",
              " 'glove.twitter.27B.200d.txt',\n",
              " 'glove.6B.200d.txt',\n",
              " 'glove.840B.300d.txt',\n",
              " 'tensorboard.gdoc',\n",
              " 'keras.gdoc',\n",
              " 'Vectorization CNN embedded_limited_vocab.ipynb',\n",
              " 'glove.42B.300d.txt',\n",
              " 'Embedding Glove Vergleich.ipynb',\n",
              " 'CNN embedded_limited_vocab.ipynb',\n",
              " 'LSTM_limited_vocab.ipynb',\n",
              " 'LSTM.ipynb',\n",
              " 'CNN embedded.ipynb']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7ToKO-sZLHK"
      },
      "source": [
        "\n",
        "Keras-Doc : https://keras.io/examples/nlp/pretrained_word_embeddings/#load-pretrained-word-embeddings \n",
        "embedding mit initializers.. weights müsste auch funktionieren\n",
        "\n",
        "Diese erstellte Matrix mit Embedding dann in die Embedding-Schicht einbinden,  Trainable auf False, weil sich die Werte nicht durch Training anpassen sollen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AShIVfC7ZQAH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3c52162-7f81-4023-ee3e-6a0b731ad7e3"
      },
      "source": [
        "#Größe Vokabel -> wordindex + 2 (weil padding + OOV) \n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "vocabulary_size = len(word_index)+2\n",
        "\n",
        "# dann erstell ich ein Wörterbuch mit Namen \"embedding_vector\", dort sind dann\n",
        "#die keys drinnen, die in glove-Datei drinnen sind mit dem entsprechenden Key\n",
        "\n",
        "embedding_index_glove = {}\n",
        "f = open('/content/drive/MyDrive/Colab Notebooks/glove.twitter.27B.200d.txt')\n",
        "for line in f:\n",
        "  value = line.split()\n",
        "  word = value[0]\n",
        "  coef = np.asarray(value[1:],dtype='float32')\n",
        "  embedding_index_glove[word] = coef\n",
        "\n",
        "print(\"%d gefunden: \"% len(embedding_index_glove))\n",
        "\n",
        "#Dann noch eine Embedding-Matrix erstellen\n",
        "#zweiter Wert = Embedding-Dimension der Datei, in dem Fall 200\n",
        "\n",
        "glove_matrix = np.zeros((vocabulary_size,200))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    embedding_value = embedding_index_glove.get(word)\n",
        "    if embedding_value is not None:\n",
        "      glove_matrix[index] = embedding_value\n",
        "      hits+=1\n",
        "    else:\n",
        "      misses+=1\n",
        "\n",
        "print(\"hits %d and %d misses\"%(hits,misses))\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1193514 gefunden: \n",
            "hits 6747 and 8312 misses\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZmvOfwhV4N5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6276b4d8-dba8-4820-d744-4bae263b47b4"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "print(\"vocab size: %d\"%vocabulary_size)\n",
        "CNN16052102ES = tf.keras.Sequential()\n",
        "#Embedding -> hier dann auf das embedding verweisen, Input_dim -> die Anzahl der Wörter im word_index, output -> in dem Fall passend zum verwendeten Vektor\n",
        "#input-length -> auf 60  gepadded, trainable -> nein, weil nichts verändert werden soll\n",
        "#embeddings_initializer=keras.initializers.Constant(glove_matrix) vs weights = [glove_matrix]\n",
        "#Convolutional layers => filters = neurons.. mit 100? 265?\n",
        "#CNN16052102ES.add(tf.keras.layers.Embedding(input_dim=vocabulary_size, output_dim=200, input_length=max_length))\n",
        "CNN16052102ES.add(tf.keras.layers.Embedding(vocabulary_size, output_dim=200, input_length=60, embeddings_initializer = keras.initializers.Constant(glove_matrix), trainable= False))\n",
        "CNN16052102ES.add(tf.keras.layers.Dropout(0.4))\n",
        "CNN16052102ES.add(tf.keras.layers.Conv1D(filters=120, kernel_size=3, padding=\"valid\", activation=\"relu\"))\n",
        "CNN16052102ES.add(tf.keras.layers.MaxPooling1D())\n",
        "CNN16052102ES.add(tf.keras.layers.Conv1D(filters=120, kernel_size=3, padding=\"valid\", activation=\"relu\"))\n",
        "CNN16052102ES.add(tf.keras.layers.GlobalAveragePooling1D())\n",
        "CNN16052102ES.add(tf.keras.layers.Flatten())\n",
        "CNN16052102ES.add(tf.keras.layers.Dense(260, activation=\"relu\"))\n",
        "CNN16052102ES.add(tf.keras.layers.Dropout(0.4))\n",
        "CNN16052102ES.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "CNN16052102ES.summary()\n",
        "\n",
        "#nppadded_training = np.asmatrix(nppadded_training) not necessary\n",
        "#nppadded_testing = np.asmatrix(nppadded_testing)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab size: 15061\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 60, 200)           3012200   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 60, 200)           0         \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 58, 120)           72120     \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 29, 120)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 27, 120)           43320     \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 120)               0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 120)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 260)               31460     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 260)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 261       \n",
            "=================================================================\n",
            "Total params: 3,159,361\n",
            "Trainable params: 147,161\n",
            "Non-trainable params: 3,012,200\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEr4OzT-iHDe"
      },
      "source": [
        "#model.layers[2].get_weights()[0].shape\n",
        "#weights=np.random.rand(5,200,100)\n",
        "#bias=np.random.rand(100)\n",
        "#model.layers[2].set_weights([weights, bias])\n",
        "\n",
        "#model.layers[2].get_weights()[0]\n",
        "#https://androidkt.com/set-custom-weights-keras-using-numpy-array/"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UB7_3VPYesr9"
      },
      "source": [
        "F1-Score für jede Epoche https://aakashgoel12.medium.com/how-to-add-user-defined-function-get-f1-score-in-keras-metrics-3013f979ce0d\n",
        "\n",
        "Sehr gute Ressource für die verschiedenen Scores und Metriken https://neptune.ai/blog/evaluation-metrics-binary-classification#10  das und aakas verwendet\n",
        "\n",
        "hier: je eine Funktion für Recall, Precision, f1 https://neptune.ai/blog/keras-metrics \n",
        "\n",
        "https://keras.rstudio.com/reference/k_ones_like.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygyrbFJaMV9B"
      },
      "source": [
        "import keras.backend as K\n",
        "\n",
        "def metrics_recall(data_true, data_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(data_true,0,1)))\n",
        "\n",
        "    recall = true_positives / (possible_positives+K.epsilon())\n",
        "    return recall\n",
        "\n",
        "\n",
        "def metrics_precision(data_true, data_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "\n",
        "    positives_predicted = K.sum(K.round(K.clip(data_pred,0,1)))\n",
        "    precision = true_positives / (positives_predicted+K.epsilon())\n",
        "    return precision\n",
        "\n",
        "\n",
        "def metrics_f1(data_true, data_pred):\n",
        "    precision_data = metrics_precision(data_true, data_pred)\n",
        "    recall_data = metrics_recall(data_true, data_pred)\n",
        "    return 2*(precision_data*recall_data)/(precision_data+recall_data+K.epsilon())"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1ctlBrnuYJz"
      },
      "source": [
        "https://aakashgoel12.medium.com/how-to-add-user-defined-function-get-f1-score-in-keras-metrics-3013f979ce0d"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AfPD3_bWCm0"
      },
      "source": [
        "CNN16052102ES.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',metrics_recall,metrics_precision,metrics_f1])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpChKUY-QEWI"
      },
      "source": [
        "https://www.tensorflow.org/tensorboard/tensorboard_in_notebooks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJfMgUhHBoD1"
      },
      "source": [
        "%load_ext tensorboard\n",
        "#nur einmal pro Sitzung notwendig\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ISmMXLqP8Hc"
      },
      "source": [
        "\n",
        "logs_base_dir = \"./logs\"\n",
        "callbackForTB = tf.keras.callbacks.TensorBoard(logs_base_dir)\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ehh-EMXUQh8r"
      },
      "source": [
        "Early Stopping as defined in keras tensorflow documentation\n",
        "https://www.tensorflow.org/guide/keras/train_and_evaluate "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BY_t-PeQEjy"
      },
      "source": [
        "callbackEarlyStopping = [\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_loss\",\n",
        "        min_delta=1e-2,\n",
        "        patience=3,\n",
        "        verbose=1,\n",
        "    )\n",
        "]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2CHbXiP1LsF"
      },
      "source": [
        "training_epochs = 30\n",
        "batch_size = 40\n",
        "validation_split=0.2"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abV-QAxfW48r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "972dc386-8ba0-4046-f8de-a35097823190"
      },
      "source": [
        "#Werte der Convolutional-Schichten variieren (Filter), Batch-Size variieren, kernel-size..\n",
        "CNN16052102ES.fit(nppadded_training, nptraining_labels, batch_size=batch_size, validation_split=validation_split, epochs=training_epochs, callbacks=[callbackForTB,callbackEarlyStopping])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "91/91 [==============================] - 5s 44ms/step - loss: 0.6676 - accuracy: 0.6369 - metrics_recall: 0.0555 - metrics_precision: 0.0175 - metrics_f1: 0.0266 - val_loss: 0.6352 - val_accuracy: 0.6718 - val_metrics_recall: 0.0000e+00 - val_metrics_precision: 0.0000e+00 - val_metrics_f1: 0.0000e+00\n",
            "Epoch 2/30\n",
            "91/91 [==============================] - 3s 37ms/step - loss: 0.6358 - accuracy: 0.6645 - metrics_recall: 0.0051 - metrics_precision: 0.0180 - metrics_f1: 0.0064 - val_loss: 0.5974 - val_accuracy: 0.6707 - val_metrics_recall: 0.0112 - val_metrics_precision: 0.0870 - val_metrics_f1: 0.0197\n",
            "Epoch 3/30\n",
            "91/91 [==============================] - 3s 38ms/step - loss: 0.6112 - accuracy: 0.6584 - metrics_recall: 0.0718 - metrics_precision: 0.2713 - metrics_f1: 0.1019 - val_loss: 0.5795 - val_accuracy: 0.6929 - val_metrics_recall: 0.0965 - val_metrics_precision: 0.6565 - val_metrics_f1: 0.1633\n",
            "Epoch 4/30\n",
            "91/91 [==============================] - 3s 38ms/step - loss: 0.5943 - accuracy: 0.6828 - metrics_recall: 0.2504 - metrics_precision: 0.6042 - metrics_f1: 0.3249 - val_loss: 0.5655 - val_accuracy: 0.7151 - val_metrics_recall: 0.1916 - val_metrics_precision: 0.7953 - val_metrics_f1: 0.2954\n",
            "Epoch 5/30\n",
            "91/91 [==============================] - 3s 38ms/step - loss: 0.5590 - accuracy: 0.7080 - metrics_recall: 0.3584 - metrics_precision: 0.6572 - metrics_f1: 0.4245 - val_loss: 0.5974 - val_accuracy: 0.6541 - val_metrics_recall: 0.7039 - val_metrics_precision: 0.4828 - val_metrics_f1: 0.5616\n",
            "Epoch 6/30\n",
            "91/91 [==============================] - 3s 38ms/step - loss: 0.5313 - accuracy: 0.7216 - metrics_recall: 0.4909 - metrics_precision: 0.6642 - metrics_f1: 0.5038 - val_loss: 0.5509 - val_accuracy: 0.7228 - val_metrics_recall: 0.4215 - val_metrics_precision: 0.6330 - val_metrics_f1: 0.4809\n",
            "Epoch 7/30\n",
            "91/91 [==============================] - 3s 38ms/step - loss: 0.4923 - accuracy: 0.7560 - metrics_recall: 0.4663 - metrics_precision: 0.7027 - metrics_f1: 0.5369 - val_loss: 0.5304 - val_accuracy: 0.7195 - val_metrics_recall: 0.4980 - val_metrics_precision: 0.5920 - val_metrics_f1: 0.5179\n",
            "Epoch 8/30\n",
            "91/91 [==============================] - 3s 38ms/step - loss: 0.4536 - accuracy: 0.7780 - metrics_recall: 0.5890 - metrics_precision: 0.7294 - metrics_f1: 0.6314 - val_loss: 0.5334 - val_accuracy: 0.7062 - val_metrics_recall: 0.5355 - val_metrics_precision: 0.5589 - val_metrics_f1: 0.5338\n",
            "Epoch 9/30\n",
            "91/91 [==============================] - 3s 38ms/step - loss: 0.4202 - accuracy: 0.7998 - metrics_recall: 0.6374 - metrics_precision: 0.7488 - metrics_f1: 0.6702 - val_loss: 0.5391 - val_accuracy: 0.7073 - val_metrics_recall: 0.4901 - val_metrics_precision: 0.5517 - val_metrics_f1: 0.5054\n",
            "Epoch 10/30\n",
            "91/91 [==============================] - 3s 38ms/step - loss: 0.3761 - accuracy: 0.8424 - metrics_recall: 0.6881 - metrics_precision: 0.8280 - metrics_f1: 0.7360 - val_loss: 0.5515 - val_accuracy: 0.7029 - val_metrics_recall: 0.5080 - val_metrics_precision: 0.5524 - val_metrics_f1: 0.5135\n",
            "Epoch 00010: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f83f4635150>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJVL4SBLPB2P"
      },
      "source": [
        "#%tensorboard --logdir {logs_base_dir}"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_LnvWBcnoak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b625ea28-1ab8-4247-cb20-66454068a6b7"
      },
      "source": [
        "#results = model.evaluate(nppadded_testing, nptesting_labels, batch_size=batch_size)\n",
        "#print(\"test loss, test acc:\",results)\n",
        "\n",
        "(loss,accuracy, metrics_recall,metrics_precision,\n",
        "metrics_f1) = CNN16052102ES.evaluate(nppadded_testing, nptesting_labels, verbose=1)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "111/111 [==============================] - 1s 10ms/step - loss: 0.5972 - accuracy: 0.6753 - metrics_recall: 0.3773 - metrics_precision: 0.5333 - metrics_f1: 0.4264\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KgjIkhpKmHc"
      },
      "source": [
        "make some predictions of test data and save it to variable. verbose=0 -> do not generate output\n",
        "Gute Quelle: https://deeplizard.com/learn/video/2f-NjDUvZIE "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89GWuxryKlcM"
      },
      "source": [
        "CNN_predictions06 = CNN16052102ES.predict(x=nppadded_testing)\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3jPDaDJK_cN"
      },
      "source": [
        "#for p in CNN_predictions06:\n",
        " # print(p)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eC9efJy4Lp21"
      },
      "source": [
        "rounded predictions: give prediction value of most likely prediction (0 or 1). Printing the output of rounded prediction shows the prediction made by the model on the data (which output is most likely)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsG-TJuQLvtk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6701b7bc-2081-4c07-8bc8-8c907f554747"
      },
      "source": [
        "prediction_rounded06 = np.round(CNN_predictions06)\n",
        "#np.argmax(CNN_predictions06,axis=-1)\n",
        "\n",
        "#for p in prediction_rounded06:\n",
        " # print(p)\n",
        "\n",
        "\n",
        "print(nptesting_labels[500:520])\n",
        "print(prediction_rounded06[500:520])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1]\n",
            "[[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egTtgpXgg8a2"
      },
      "source": [
        "https://deeplizard.com/learn/video/km7pxKy4UHU\n",
        "\n",
        "Quelle der def plot_confusion_matrix: https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSDXf7-_MITy"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0AMs1EzhBU1"
      },
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                        normalize=False,\n",
        "                        title='Confusion matrix',\n",
        "                        cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2JgEnlghCtl"
      },
      "source": [
        "cm = confusion_matrix(y_true=nptesting_labels, y_pred=prediction_rounded06)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckmF29whhFmX"
      },
      "source": [
        "plot_labels = ['no hatespeech','hatespeech']"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "2mpSE96rhK7K",
        "outputId": "17a8cfbe-0392-4500-d5b7-c725884e2566"
      },
      "source": [
        "plot_confusion_matrix(cm=cm, classes=plot_labels, title='CNN Confusion 90Dense90')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix, without normalization\n",
            "[[1939  391]\n",
            " [ 756  446]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}