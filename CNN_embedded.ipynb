{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN embedded.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNnLde67Y5OU4ZptVY5v0MT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BiancaStadl/ProjektarbeitML/blob/main/CNN_embedded.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXDOlIBymF0V"
      },
      "source": [
        "GloVe embeddings taken from:\n",
        "\n",
        "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. [pdf] [bib]\n",
        "\n",
        "hatespeechdata taken from (https://hatespeechdata.com/): Wiegand, M., Siegel, M. and Ruppenhofer, J., 2018. Overview of the GermEval 2018 Shared Task on the Identification of Offensive Language. In: Proceedings of GermEval 2018, 14th Conference on Natural Language Processing (KONVENS 2018). Vienna, Austria: Research Gate. available on: https://github.com/uds-lsv/GermEval-2018-Data (last checked: 09.05.2021)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlBmABDxfqII"
      },
      "source": [
        "wiki detox..https://colab.research.google.com/github/tensorflow/fairness-indicators/blob/master/g3doc/tutorials/Fairness_Indicators_TFCO_Wiki_Case_Study.ipynb#scrollTo=y6T5tlXcdW7J "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3xfitNdliBI"
      },
      "source": [
        "#import matplotlib.pyplot as plt -> für evtl Visualisierungen\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import string\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from keras import losses \n",
        "from keras import optimizers \n",
        "from keras import metrics \n",
        "\n",
        "#!pip install Tokenizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "#!pip install pad_sequences\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import preprocessing\n",
        "#from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTWJQ1iga_vS"
      },
      "source": [
        "Maximale Satzlänge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bq08Me5la_Cc"
      },
      "source": [
        "\n",
        "max_length = 60"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVYBMvYSotTH"
      },
      "source": [
        "url = \"https://github.com/uds-lsv/GermEval-2018-Data/archive/master.zip\"\n",
        "\n",
        "dataset = tf.keras.utils.get_file(\"GermEval-2018-Data-master.zip\", url, \n",
        "                                   extract=True, cache_dir='.',\n",
        "                                    cache_subdir='')\n",
        "\n",
        "dataset_dir = os.path.join(os.path.dirname(dataset), 'GermEval-2018-Data-master')\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cS14OUtfo34V"
      },
      "source": [
        "#os.listdir(dataset_dir)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2X429K6hpOVm"
      },
      "source": [
        "training_file = os.path.join(dataset_dir, 'germeval2018.training.txt')\n",
        "\n",
        "testing_file = os.path.join(dataset_dir, 'germeval2018.test.txt')\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uq8fG3LNtn_m"
      },
      "source": [
        "###Aufbereitung\n",
        "txt-Dateien lesen, und dabei jede Zeile splitten und teilen\n",
        "Twitter-Handler entfernen?\n",
        "Labels von Sätzen trennen, Labels in eigenen Array packen.\n",
        "\n",
        "####Ressourcen\n",
        "* https://www.w3schools.com/python/gloss_python_if_statement.asp\n",
        "* https://stackabuse.com/using-regex-for-text-manipulation-in-python/\n",
        "* https://www.tutorialspoint.com/python/string_splitlines.htm \n",
        "* https://note.nkmk.me/en/python-split-rsplit-splitlines-re/ \n",
        "* https://www.w3schools.com/python/python_regex.asp \n",
        "\n",
        "gäbe bei keras tf.keras.preprocessing.text_dataset_from_directory, aber dafür müssten die Daten auf bestimmte Weise in Verzeichnis organisiert sein, hier nicht der Fall.\n",
        "\n",
        "\n",
        "Einteilung der Daten: Testdaten\n",
        "Trainingsdaten -> noch ca 500 für Validierungsdaten\n",
        "\n",
        "labels -> \"other\", also nicht-negative Aussagen bekommen \"0\", negative Aussagen bekommen \"1\"\n",
        "\n",
        " Regex für Emojis  ->\n",
        "\n",
        "(\\u00a9|\\u00ae|[\\u2000-\\u3300]|\\ud83c[\\ud000-\\udfff]|\\ud83d[\\ud000-\\udfff]|\\ud83e[\\ud000-\\udfff])\n",
        "\n",
        "genommen von https://www.regextester.com/106421 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Py_cwD4eZkXo"
      },
      "source": [
        "def remove_clutter(string):\n",
        "   string = re.sub(\"@[^\\s]+\",\" \",string)\n",
        "   string = re.sub(\"#[^\\s]+\",\" \", string)\n",
        "   string = re.sub(\"\\u00a9\",\" \", string)\n",
        "   string = re.sub(\"\\u00ae\",\" \", string)\n",
        "   string = re.sub(\"[\\u2000-\\u3300]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83c[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83d[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83e[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"😜\", \" \",string)\n",
        "   string = re.sub(\"🍫\", \" \",string)\n",
        "   string = re.sub(\"😁\", \" \",string)\n",
        "   string = re.sub(\"🐖\", \" \",string)\n",
        "   string = re.sub(\"😡\", \" \",string)\n",
        "   string = re.sub(\"😇\", \" \",string)\n",
        "   string = re.sub(\"😬\", \" \",string)\n",
        "   string = re.sub(\"😃\", \" \",string)\n",
        "   string = re.sub(\"😂\", \" \",string)\n",
        "   string = re.sub(\"💙\", \" \",string)  \n",
        "   string = re.sub(\"😛\", \" \",string)\n",
        "   string = re.sub(\"🙏\", \" \",string)\n",
        "   string = re.sub(\"👍\", \" \",string)\n",
        "   string = re.sub(\"🖕\", \" \",string)\n",
        "   string = re.sub(\"😉\", \" \",string)\n",
        "   string = re.sub(\"💩\", \" \",string)\n",
        "   string = re.sub(\"🤢\", \" \",string)\n",
        "   string = re.sub(\"👏\", \" \",string)\n",
        "   string = re.sub(\"😨\", \" \",string)\n",
        "   string = re.sub(\"🤣\", \" \",string)\n",
        "   string = re.sub(\"🤡\", \" \",string)\n",
        "   string = re.sub(\"😈\", \" \",string)\n",
        "   string = re.sub(\"💃🏽\", \" \",string)\n",
        "   string = re.sub(\"👹\", \" \",string)\n",
        "   string = re.sub(\"🤘\", \" \",string)\n",
        "   string = re.sub(\"😱\", \" \",string)\n",
        "   string = re.sub(\"🤔\", \" \",string) \n",
        "   string = re.sub(\"🌈\", \" \",string) \n",
        "   string = re.sub(\"💕\", \" \",string) \n",
        "   string = re.sub(\"👩‍❤️‍👩\", \" \",string) \n",
        "   string = re.sub(\"😍\", \" \",string) \n",
        "   string = re.sub(\"👆\", \" \",string) \n",
        "   string = re.sub(\"😖\", \" \",string) \n",
        "   string = re.sub(\"👇\", \" \",string) \n",
        "   string = re.sub(\"🔥\", \" \",string) \n",
        "   string = re.sub(\"😘\", \" \",string) \n",
        "   string = re.sub(\"🎉\", \" \",string) \n",
        "   string = re.sub(\"🤬\", \" \",string) \n",
        "   string = re.sub(\"👊\", \" \",string)\n",
        "   string = re.sub(\"🇩🇪\", \" \",string)  \n",
        "   string = re.sub(\"💔\", \" \",string)\n",
        "   string = re.sub(\"🙈\", \" \",string)\n",
        "   string = re.sub(\"🤯\", \" \",string)\n",
        "   string = re.sub(\"🐟\", \" \",string)\n",
        "   string = re.sub(\"🛶\", \" \",string)\n",
        "   string = re.sub(\"😊\", \" \",string)\n",
        "   string = re.sub(\"😓\", \" \",string)\n",
        "   string = re.sub(\"😳\", \" \",string)\n",
        "   string = re.sub(\"🚀\", \" \",string)\n",
        "   string = re.sub(\"👎\", \" \",string)\n",
        "   string = re.sub(\"😎\", \" \",string)\n",
        "   string = re.sub(\"🐸\", \" \",string)\n",
        "   string = re.sub(\"📈\", \" \",string)\n",
        "   string = re.sub(\"🙂\", \" \",string)\n",
        "   string = re.sub(\"😅\", \" \",string)\n",
        "   string = re.sub(\"😆\", \" \",string)\n",
        "   string = re.sub(\"🙎🏿\", \" \",string)\n",
        "   string = re.sub(\"👎🏽\", \" \",string)\n",
        "   string = re.sub(\"🤭\", \" \",string)\n",
        "   string = re.sub(\"😤\", \" \",string)\n",
        "   string = re.sub(\"😚\", \" \",string)\n",
        "   string = re.sub(\"😊\", \" \",string)\n",
        "   string = re.sub(\"😲\", \" \",string)\n",
        "   string = re.sub(\"🤮\", \" \",string)\n",
        "   string = re.sub(\"🙄\", \" \",string)\n",
        "   string = re.sub(\"🤑\", \" \",string)\n",
        "   string = re.sub(\"🎅\", \" \",string)\n",
        "   string = re.sub(\"👋\", \" \",string)\n",
        "   string = re.sub(\"💪\", \" \",string)\n",
        "   string = re.sub(\"😄\", \" \",string)\n",
        "   string = re.sub(\"🧐\", \" \",string)\n",
        "   string = re.sub(\"😠\", \" \",string)\n",
        "   string = re.sub(\"🎈\", \" \",string)\n",
        "   string = re.sub(\"🚂\", \" \",string)\n",
        "   string = re.sub(\"😊\", \" \",string)\n",
        "   string = re.sub(\"🚇\", \" \",string)\n",
        "   string = re.sub(\"🚊\", \" \",string)\n",
        "   string = re.sub(\"🤷\", \" \",string)\n",
        "   string = re.sub(\"😥\", \" \",string)\n",
        "   string = re.sub(\"🙃\", \" \",string)\n",
        "   string = re.sub(\"🔩\", \" \",string)\n",
        "   string = re.sub(\"🔧\", \" \",string)\n",
        "   string = re.sub(\"🔨\", \" \",string)\n",
        "   string = re.sub(\"🛠\", \" \",string)\n",
        "   string = re.sub(\"💓\", \" \",string)\n",
        "   string = re.sub(\"💡\", \" \",string)\n",
        "   string = re.sub(\"🍸\", \" \",string)\n",
        "   string = re.sub(\"🥃\", \" \",string)\n",
        "   string = re.sub(\"🥂\", \" \",string)\n",
        "   string = re.sub(\"😷\", \" \",string)\n",
        "   string = re.sub(\"🤐\", \" \",string)\n",
        "   string = re.sub(\"🌎\", \" \",string)\n",
        "   string = re.sub(\"👑\", \" \",string)\n",
        "   string = re.sub(\"🤛\", \" \",string)\n",
        "   string = re.sub(\"😀\", \" \",string)\n",
        "   string = re.sub(\"🛤\", \" \",string)\n",
        "   string = re.sub(\"🎄\", \" \",string)\n",
        "   string = re.sub(\"📴\", \" \",string)\n",
        "   string = re.sub(\"🌭\", \" \",string)\n",
        "   string = re.sub(\"🤕\", \" \",string)\n",
        "   string = re.sub(\"😭\", \" \",string)\n",
        "   string = re.sub(\"🍾\", \" \",string)\n",
        "   string = re.sub(\"🍞\", \" \",string)\n",
        "   string = re.sub(\"🤦\", \" \",string)\n",
        "   string = re.sub(\"🤯\", \" \",string)\n",
        "   string = re.sub(\"🕯️\", \" \",string)\n",
        "\n",
        "   string = re.sub(\"OTHER|OFFENSE|ABUSE|INSULT\",\" \",string)\n",
        "   return string"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5asMgo4LtnRg"
      },
      "source": [
        "statementsForTraining = []\n",
        "sentimentsForTraining = []\n",
        "\n",
        "\n",
        "fileToRead = open(training_file, 'r')\n",
        "\n",
        "while True:\n",
        "  #next line in file\n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  findSentiment = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "\n",
        "\n",
        "  statementsForTraining.append(line)\n",
        "   #sentimentsForTraining.append(findSentiment.group(0))\n",
        "\n",
        "  if findSentiment.group(0) == \"OTHER\":  \n",
        "    sentimentsForTraining.append(0)\n",
        "  else:\n",
        "    sentimentsForTraining.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        " #print(\"{}: {}\".format(count,line.strip()))\n",
        "  \n",
        " # print(sentiment.group(0))\n",
        " \n",
        "fileToRead.close()\n",
        "\n",
        "training_sentences = statementsForTraining\n",
        "training_labels = sentimentsForTraining\n",
        "\n",
        "#print(training_sentences[9])\n",
        "#print(training_labels[9])\n",
        "\n",
        "#print(len(training_sentences))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsqZPENb98gD"
      },
      "source": [
        "##do the same with testdata\n",
        "statementsForTesting = []\n",
        "sentimentsForTesting = []\n",
        "\n",
        "fileToRead = open(testing_file, 'r')\n",
        "\n",
        "while True:\n",
        "  #next line in file\n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  sent = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "\n",
        "    \n",
        "\n",
        "  statementsForTesting.append(line)\n",
        "  #print(len(line))\n",
        "  #sentimentsForTesting.append(sent.group(0))\n",
        "\n",
        "  if sent.group(0) == \"OTHER\": \n",
        "    sentimentsForTesting.append(0)\n",
        "  else:\n",
        "    sentimentsForTesting.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        "\n",
        "fileToRead.close()\n",
        "\n",
        "\n",
        "testing_sentences = statementsForTesting\n",
        "testing_labels = sentimentsForTesting\n",
        "#print(len(testing_sentences))\n",
        "#print(testing_sentences)   \n",
        "#print(testing_labels)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRUvDLD5bMbO"
      },
      "source": [
        "Padding -> im Prinzip die Sätze alle auf die gleiche Länge bringen (in Theorieteil näher drauf eingehen) -> maxlen-Paramter ist für pad_sequences vorhanden, wenn nicht gesetzt -> alles wird auf die Länge des längsten Satzes aufgefüllt -> print(padded(shape)) gibt aus, wie viele Datensätze padded wurden und gibt an, wie viele Tokens der längste Datensatz hat\n",
        "print(padded[x]) gibt einen Satz aus (bereits tokenisiert)\n",
        "\n",
        "Padding -> sowohl für Trainigs- als auch für Testdaten\n",
        "\n",
        "Und: Daten als numpy-Arrays speichern (notwendig für tensorflow).\n",
        "\n",
        " -> Tokenizer https://towardsdatascience.com/text-classification-in-keras-part-2-how-to-use-the-keras-tokenizer-word-representations-fd571674df23 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3hFi7waTv5m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6c6ef74-28ac-4712-b385-dc29b1ecb7a9"
      },
      "source": [
        "tokenizer = Tokenizer(oov_token=\"OOV\")\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "\n",
        "#creating a word index - nur die Trainigsdaten\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "validation_size = 500\n",
        "\n",
        "\n",
        "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "padded_training = pad_sequences(training_sequences, maxlen=max_length, padding='post')\n",
        "print(len(padded_training))\n",
        "\n",
        "validation_sequences = padded_training[0:validation_size]\n",
        "validation_labels = training_labels[0:validation_size]\n",
        "\n",
        "padded_training = padded_training[validation_size:]\n",
        "training_labels = training_labels[validation_size:]\n",
        "\n",
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
        "padded_testing = pad_sequences(testing_sequences, maxlen=max_length,  padding='post')\n",
        "\n",
        "#print(validation_sequences[499])\n",
        "print(padded_training[0])\n",
        "#print(len(validation_labels))\n",
        "#print(len(training_labels))\n",
        "\n",
        "\n",
        "nppadded_training = np.array(padded_training)\n",
        "nptraining_labels = np.array(training_labels)\n",
        "\n",
        "nppadded_validation = np.array(validation_sequences)\n",
        "npvalidation_labels = np.array(validation_labels)\n",
        "\n",
        "nppadded_testing = np.array(padded_testing)\n",
        "nptesting_labels = np.array(testing_labels)\n",
        "\n",
        "\n",
        "print(len(nppadded_training))\n",
        "print(len(nptraining_labels))\n",
        "print(len(word_index))\n",
        "\n",
        "#print(statementsForTraining[2])\n",
        "#print(nppadded_training[4])\n",
        "#print(nppadded_training.shape)\n",
        "#print(nptraining_labels[4])\n",
        "#print(nppadded_testing.shape)\n",
        "#print(word_index) \n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5009\n",
            "[  12 3982   11   41 6706 1040    4    5  202   39    3 2922   49 1360\n",
            "  810  495 3983    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0]\n",
            "4509\n",
            "4509\n",
            "15059\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tL3owrc8THkT"
      },
      "source": [
        "\n",
        "Dann: Embedding mit entweder word2vec oder glove\n",
        "Word2vec-Daten sind hier: http://vectors.nlpl.eu/repository/#\n",
        "Glove -> https://nlp.stanford.edu/projects/glove/ Da mal den Twitter-Vector runtergeladen\n",
        "Wenn Daten in GoogleDrive sind (wäre auch via url möglich..), muss Drive gemounted werden ( https://buomsoo-kim.github.io/colab/2020/05/09/Colab-mounting-google-drive.md/ ) aber auch hier https://enjoymachinelearning.com/posts/colab-with-google-drive/\n",
        "\n",
        "Die Word2vec vectors: http://vectors.nlpl.eu/repository/# \n",
        "\n",
        "glove-zitat:\n",
        "Citing GloVe\n",
        "\n",
        "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. [pdf] [bib]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zuO7T9ZTG57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e687079-600e-499c-9eae-ee790f6929fb"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "os.listdir(\"/content/drive/MyDrive/Colab Notebooks\")\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['germeval_training.txt',\n",
              " 'glove.twitter.27B.50d.txt',\n",
              " 'glove.twitter.27B.200d.txt',\n",
              " 'glove.6B.200d.txt',\n",
              " 'glove.840B.300d.txt',\n",
              " 'tensorboard.gdoc',\n",
              " 'keras.gdoc',\n",
              " 'Vectorization CNN embedded_limited_vocab.ipynb',\n",
              " 'glove.42B.300d.txt',\n",
              " 'Embedding Glove Vergleich.ipynb',\n",
              " 'CNN embedded_limited_vocab.ipynb',\n",
              " 'LSTM_limited_vocab.ipynb',\n",
              " 'LSTM.ipynb',\n",
              " 'CNN embedded.ipynb']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7ToKO-sZLHK"
      },
      "source": [
        "\n",
        "Keras-Doc : https://keras.io/examples/nlp/pretrained_word_embeddings/#load-pretrained-word-embeddings \n",
        "embedding mit initializers.. weights müsste auch funktionieren\n",
        "\n",
        "Diese erstellte Matrix mit Embedding dann in die Embedding-Schicht einbinden,  Trainable auf False, weil sich die Werte nicht durch Training anpassen sollen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AShIVfC7ZQAH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a59da314-db3d-4068-c779-e02dd05bbd48"
      },
      "source": [
        "#Größe Vokabel -> wordindex + 2 (weil padding + OOV) \n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "vocabulary_size = len(word_index)+2\n",
        "\n",
        "# dann erstell ich ein Wörterbuch mit Namen \"embedding_vector\", dort sind dann\n",
        "#die keys drinnen, die in glove-Datei drinnen sind mit dem entsprechenden Key\n",
        "\n",
        "embedding_index_glove = {}\n",
        "f = open('/content/drive/MyDrive/Colab Notebooks/glove.twitter.27B.200d.txt')\n",
        "for line in f:\n",
        "  value = line.split()\n",
        "  word = value[0]\n",
        "  coef = np.asarray(value[1:],dtype='float32')\n",
        "  embedding_index_glove[word] = coef\n",
        "\n",
        "print(\"%d gefunden: \"% len(embedding_index_glove))\n",
        "\n",
        "#Dann noch eine Embedding-Matrix erstellen\n",
        "#zweiter Wert = Embedding-Dimension der Datei, in dem Fall 200\n",
        "\n",
        "glove_matrix = np.zeros((vocabulary_size,200))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    embedding_value = embedding_index_glove.get(word)\n",
        "    if embedding_value is not None:\n",
        "      glove_matrix[index] = embedding_value\n",
        "      hits+=1\n",
        "    else:\n",
        "      misses+=1\n",
        "\n",
        "print(\"hits %d and %d misses\"%(hits,misses))\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1193514 gefunden: \n",
            "hits 6747 and 8312 misses\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZmvOfwhV4N5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de18056e-8e67-4cde-fba3-831e90de8faa"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "print(\"vocab size: %d\"%vocabulary_size)\n",
        "CNN16052105 = tf.keras.Sequential()\n",
        "#Embedding -> hier dann auf das embedding verweisen, Input_dim -> die Anzahl der Wörter im word_index, output -> in dem Fall passend zum verwendeten Vektor\n",
        "#input-length -> auf 60  gepadded, trainable -> nein, weil nichts verändert werden soll\n",
        "#embeddings_initializer=keras.initializers.Constant(glove_matrix) vs weights = [glove_matrix]\n",
        "#Convolutional layers => filters = neurons.. mit 100? 265?\n",
        "CNN16052105.add(tf.keras.layers.Embedding(vocabulary_size, output_dim=200, input_length=60, embeddings_initializer = keras.initializers.Constant(glove_matrix), trainable= False))\n",
        "CNN16052105.add(tf.keras.layers.Dropout(0.4))\n",
        "CNN16052105.add(tf.keras.layers.Conv1D(filters=260, kernel_size=3, padding=\"valid\", activation=\"relu\"))\n",
        "CNN16052105.add(tf.keras.layers.MaxPooling1D())\n",
        "CNN16052105.add(tf.keras.layers.Conv1D(filters=260, kernel_size=3, padding=\"valid\", activation=\"relu\"))\n",
        "CNN16052105.add(tf.keras.layers.GlobalAveragePooling1D())\n",
        "CNN16052105.add(tf.keras.layers.Flatten())\n",
        "CNN16052105.add(tf.keras.layers.Dense(260, activation=\"relu\"))\n",
        "CNN16052105.add(tf.keras.layers.Dropout(0.4))\n",
        "CNN16052105.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "CNN16052105.summary()\n",
        "\n",
        "#nppadded_training = np.asmatrix(nppadded_training) not necessary\n",
        "#nppadded_testing = np.asmatrix(nppadded_testing)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab size: 15061\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 60, 200)           3012200   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 60, 200)           0         \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 58, 260)           156260    \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 29, 260)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 27, 260)           203060    \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 260)               0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 260)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 260)               67860     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 260)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 261       \n",
            "=================================================================\n",
            "Total params: 3,439,641\n",
            "Trainable params: 427,441\n",
            "Non-trainable params: 3,012,200\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEr4OzT-iHDe"
      },
      "source": [
        "#model.layers[2].get_weights()[0].shape\n",
        "#weights=np.random.rand(5,200,100)\n",
        "#bias=np.random.rand(100)\n",
        "#model.layers[2].set_weights([weights, bias])\n",
        "\n",
        "#model.layers[2].get_weights()[0]\n",
        "#https://androidkt.com/set-custom-weights-keras-using-numpy-array/"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UB7_3VPYesr9"
      },
      "source": [
        "F1-Score für jede Epoche https://aakashgoel12.medium.com/how-to-add-user-defined-function-get-f1-score-in-keras-metrics-3013f979ce0d\n",
        "\n",
        "Sehr gute Ressource für die verschiedenen Scores und Metriken https://neptune.ai/blog/evaluation-metrics-binary-classification#10  das und aakas verwendet\n",
        "\n",
        "hier: je eine Funktion für Recall, Precision, f1 https://neptune.ai/blog/keras-metrics \n",
        "\n",
        "https://keras.rstudio.com/reference/k_ones_like.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygyrbFJaMV9B"
      },
      "source": [
        "import keras.backend as K\n",
        "\n",
        "def metrics_recall(data_true, data_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(data_true,0,1)))\n",
        "\n",
        "    recall = true_positives / (possible_positives+K.epsilon())\n",
        "    return recall\n",
        "\n",
        "\n",
        "def metrics_precision(data_true, data_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "\n",
        "    positives_predicted = K.sum(K.round(K.clip(data_pred,0,1)))\n",
        "    precision = true_positives / (positives_predicted+K.epsilon())\n",
        "    return precision\n",
        "\n",
        "\n",
        "def metrics_f1(data_true, data_pred):\n",
        "    precision_data = metrics_precision(data_true, data_pred)\n",
        "    recall_data = metrics_recall(data_true, data_pred)\n",
        "    return 2*(precision_data*recall_data)/(precision_data+recall_data+K.epsilon())"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1ctlBrnuYJz"
      },
      "source": [
        "https://aakashgoel12.medium.com/how-to-add-user-defined-function-get-f1-score-in-keras-metrics-3013f979ce0d"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AfPD3_bWCm0"
      },
      "source": [
        "CNN16052105.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',metrics_recall,metrics_precision,metrics_f1])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpChKUY-QEWI"
      },
      "source": [
        "https://www.tensorflow.org/tensorboard/tensorboard_in_notebooks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJfMgUhHBoD1"
      },
      "source": [
        "#%reload_ext tensorboard\n",
        "#nur einmal pro Sitzung notwendig\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ISmMXLqP8Hc"
      },
      "source": [
        "\n",
        "logs_base_dir = \"./logs\"\n",
        "callbackForTB = tf.keras.callbacks.TensorBoard(logs_base_dir)\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2CHbXiP1LsF"
      },
      "source": [
        "training_epochs = 30\n",
        "batch_size = 40\n",
        "validation_split=0.2"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abV-QAxfW48r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e6fdab0-b491-4fb8-e78a-7eba51866874"
      },
      "source": [
        "#Werte der Convolutional-Schichten variieren (Filter), Batch-Size variieren, kernel-size..\n",
        "CNN16052105.fit(nppadded_training, nptraining_labels, batch_size=batch_size, validation_split=validation_split, epochs=training_epochs, callbacks=[callbackForTB])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "91/91 [==============================] - 11s 102ms/step - loss: 0.6631 - accuracy: 0.6434 - metrics_recall: 0.0333 - metrics_precision: 0.0178 - metrics_f1: 0.0232 - val_loss: 0.6319 - val_accuracy: 0.6718 - val_metrics_recall: 0.0000e+00 - val_metrics_precision: 0.0000e+00 - val_metrics_f1: 0.0000e+00\n",
            "Epoch 2/30\n",
            "91/91 [==============================] - 9s 94ms/step - loss: 0.6327 - accuracy: 0.6682 - metrics_recall: 0.0108 - metrics_precision: 0.0345 - metrics_f1: 0.0156 - val_loss: 0.6193 - val_accuracy: 0.6752 - val_metrics_recall: 0.3624 - val_metrics_precision: 0.5161 - val_metrics_f1: 0.4141\n",
            "Epoch 3/30\n",
            "91/91 [==============================] - 9s 95ms/step - loss: 0.5846 - accuracy: 0.6907 - metrics_recall: 0.2677 - metrics_precision: 0.6283 - metrics_f1: 0.3422 - val_loss: 0.5996 - val_accuracy: 0.6652 - val_metrics_recall: 0.6259 - val_metrics_precision: 0.4957 - val_metrics_f1: 0.5396\n",
            "Epoch 4/30\n",
            "91/91 [==============================] - 9s 94ms/step - loss: 0.5599 - accuracy: 0.7066 - metrics_recall: 0.3967 - metrics_precision: 0.6454 - metrics_f1: 0.4251 - val_loss: 0.5679 - val_accuracy: 0.6918 - val_metrics_recall: 0.5309 - val_metrics_precision: 0.5328 - val_metrics_f1: 0.5199\n",
            "Epoch 5/30\n",
            "91/91 [==============================] - 9s 95ms/step - loss: 0.5188 - accuracy: 0.7372 - metrics_recall: 0.4652 - metrics_precision: 0.6681 - metrics_f1: 0.5242 - val_loss: 0.5378 - val_accuracy: 0.7295 - val_metrics_recall: 0.2876 - val_metrics_precision: 0.7126 - val_metrics_f1: 0.3898\n",
            "Epoch 6/30\n",
            "91/91 [==============================] - 9s 94ms/step - loss: 0.4766 - accuracy: 0.7791 - metrics_recall: 0.5413 - metrics_precision: 0.7495 - metrics_f1: 0.6059 - val_loss: 0.5564 - val_accuracy: 0.7228 - val_metrics_recall: 0.2255 - val_metrics_precision: 0.7118 - val_metrics_f1: 0.3285\n",
            "Epoch 7/30\n",
            "91/91 [==============================] - 9s 94ms/step - loss: 0.4698 - accuracy: 0.7710 - metrics_recall: 0.5519 - metrics_precision: 0.7746 - metrics_f1: 0.5971 - val_loss: 0.5658 - val_accuracy: 0.6863 - val_metrics_recall: 0.6475 - val_metrics_precision: 0.5212 - val_metrics_f1: 0.5648\n",
            "Epoch 8/30\n",
            "91/91 [==============================] - 9s 95ms/step - loss: 0.3841 - accuracy: 0.8409 - metrics_recall: 0.6943 - metrics_precision: 0.8117 - metrics_f1: 0.7353 - val_loss: 0.5719 - val_accuracy: 0.7184 - val_metrics_recall: 0.3786 - val_metrics_precision: 0.6027 - val_metrics_f1: 0.4470\n",
            "Epoch 9/30\n",
            "91/91 [==============================] - 9s 94ms/step - loss: 0.3697 - accuracy: 0.8372 - metrics_recall: 0.6808 - metrics_precision: 0.8278 - metrics_f1: 0.7198 - val_loss: 0.5480 - val_accuracy: 0.7195 - val_metrics_recall: 0.4785 - val_metrics_precision: 0.5809 - val_metrics_f1: 0.5099\n",
            "Epoch 10/30\n",
            "91/91 [==============================] - 9s 95ms/step - loss: 0.3853 - accuracy: 0.8203 - metrics_recall: 0.6654 - metrics_precision: 0.8237 - metrics_f1: 0.7015 - val_loss: 0.5884 - val_accuracy: 0.7206 - val_metrics_recall: 0.4921 - val_metrics_precision: 0.5778 - val_metrics_f1: 0.5182\n",
            "Epoch 11/30\n",
            "91/91 [==============================] - 9s 95ms/step - loss: 0.2775 - accuracy: 0.8797 - metrics_recall: 0.7625 - metrics_precision: 0.8394 - metrics_f1: 0.7899 - val_loss: 0.6349 - val_accuracy: 0.7106 - val_metrics_recall: 0.3548 - val_metrics_precision: 0.5956 - val_metrics_f1: 0.4299\n",
            "Epoch 12/30\n",
            "91/91 [==============================] - 9s 96ms/step - loss: 0.2787 - accuracy: 0.8795 - metrics_recall: 0.8022 - metrics_precision: 0.8494 - metrics_f1: 0.8157 - val_loss: 0.6928 - val_accuracy: 0.7162 - val_metrics_recall: 0.3521 - val_metrics_precision: 0.5964 - val_metrics_f1: 0.4289\n",
            "Epoch 13/30\n",
            "91/91 [==============================] - 9s 94ms/step - loss: 0.2468 - accuracy: 0.9011 - metrics_recall: 0.8121 - metrics_precision: 0.9016 - metrics_f1: 0.8431 - val_loss: 0.6497 - val_accuracy: 0.6940 - val_metrics_recall: 0.6114 - val_metrics_precision: 0.5235 - val_metrics_f1: 0.5525\n",
            "Epoch 14/30\n",
            "91/91 [==============================] - 9s 95ms/step - loss: 0.2057 - accuracy: 0.9209 - metrics_recall: 0.8494 - metrics_precision: 0.9089 - metrics_f1: 0.8712 - val_loss: 0.6766 - val_accuracy: 0.6951 - val_metrics_recall: 0.6031 - val_metrics_precision: 0.5304 - val_metrics_f1: 0.5482\n",
            "Epoch 15/30\n",
            "91/91 [==============================] - 9s 95ms/step - loss: 0.2033 - accuracy: 0.9182 - metrics_recall: 0.8683 - metrics_precision: 0.8925 - metrics_f1: 0.8745 - val_loss: 0.6862 - val_accuracy: 0.7095 - val_metrics_recall: 0.5525 - val_metrics_precision: 0.5527 - val_metrics_f1: 0.5410\n",
            "Epoch 16/30\n",
            "91/91 [==============================] - 9s 94ms/step - loss: 0.1882 - accuracy: 0.9271 - metrics_recall: 0.8793 - metrics_precision: 0.9192 - metrics_f1: 0.8888 - val_loss: 0.6719 - val_accuracy: 0.7095 - val_metrics_recall: 0.5268 - val_metrics_precision: 0.5548 - val_metrics_f1: 0.5277\n",
            "Epoch 17/30\n",
            "91/91 [==============================] - 9s 95ms/step - loss: 0.1612 - accuracy: 0.9368 - metrics_recall: 0.8894 - metrics_precision: 0.9334 - metrics_f1: 0.9038 - val_loss: 0.7385 - val_accuracy: 0.6940 - val_metrics_recall: 0.5501 - val_metrics_precision: 0.5314 - val_metrics_f1: 0.5292\n",
            "Epoch 18/30\n",
            "91/91 [==============================] - 9s 94ms/step - loss: 0.1341 - accuracy: 0.9457 - metrics_recall: 0.8999 - metrics_precision: 0.9408 - metrics_f1: 0.9156 - val_loss: 0.8012 - val_accuracy: 0.6940 - val_metrics_recall: 0.5907 - val_metrics_precision: 0.5254 - val_metrics_f1: 0.5472\n",
            "Epoch 19/30\n",
            "91/91 [==============================] - 9s 96ms/step - loss: 0.1351 - accuracy: 0.9476 - metrics_recall: 0.9133 - metrics_precision: 0.9244 - metrics_f1: 0.9144 - val_loss: 0.8974 - val_accuracy: 0.7228 - val_metrics_recall: 0.4468 - val_metrics_precision: 0.5916 - val_metrics_f1: 0.4967\n",
            "Epoch 20/30\n",
            "91/91 [==============================] - 9s 94ms/step - loss: 0.1392 - accuracy: 0.9423 - metrics_recall: 0.9041 - metrics_precision: 0.9220 - metrics_f1: 0.9080 - val_loss: 0.8516 - val_accuracy: 0.7062 - val_metrics_recall: 0.5060 - val_metrics_precision: 0.5588 - val_metrics_f1: 0.5197\n",
            "Epoch 21/30\n",
            "91/91 [==============================] - 9s 95ms/step - loss: 0.1151 - accuracy: 0.9536 - metrics_recall: 0.9197 - metrics_precision: 0.9460 - metrics_f1: 0.9288 - val_loss: 0.8054 - val_accuracy: 0.7217 - val_metrics_recall: 0.4680 - val_metrics_precision: 0.5867 - val_metrics_f1: 0.5085\n",
            "Epoch 22/30\n",
            "91/91 [==============================] - 9s 96ms/step - loss: 0.1145 - accuracy: 0.9636 - metrics_recall: 0.9308 - metrics_precision: 0.9602 - metrics_f1: 0.9421 - val_loss: 0.8656 - val_accuracy: 0.7029 - val_metrics_recall: 0.5091 - val_metrics_precision: 0.5416 - val_metrics_f1: 0.5126\n",
            "Epoch 23/30\n",
            "91/91 [==============================] - 9s 95ms/step - loss: 0.1081 - accuracy: 0.9605 - metrics_recall: 0.9473 - metrics_precision: 0.9429 - metrics_f1: 0.9421 - val_loss: 0.9072 - val_accuracy: 0.6774 - val_metrics_recall: 0.6121 - val_metrics_precision: 0.4996 - val_metrics_f1: 0.5409\n",
            "Epoch 24/30\n",
            "91/91 [==============================] - 9s 96ms/step - loss: 0.1179 - accuracy: 0.9533 - metrics_recall: 0.9280 - metrics_precision: 0.9321 - metrics_f1: 0.9256 - val_loss: 0.9136 - val_accuracy: 0.7007 - val_metrics_recall: 0.5860 - val_metrics_precision: 0.5315 - val_metrics_f1: 0.5466\n",
            "Epoch 25/30\n",
            "91/91 [==============================] - 9s 95ms/step - loss: 0.1060 - accuracy: 0.9554 - metrics_recall: 0.9184 - metrics_precision: 0.9390 - metrics_f1: 0.9219 - val_loss: 0.9764 - val_accuracy: 0.6973 - val_metrics_recall: 0.5985 - val_metrics_precision: 0.5334 - val_metrics_f1: 0.5489\n",
            "Epoch 26/30\n",
            "91/91 [==============================] - 9s 97ms/step - loss: 0.0967 - accuracy: 0.9645 - metrics_recall: 0.9480 - metrics_precision: 0.9475 - metrics_f1: 0.9447 - val_loss: 0.8688 - val_accuracy: 0.7007 - val_metrics_recall: 0.5014 - val_metrics_precision: 0.5415 - val_metrics_f1: 0.5052\n",
            "Epoch 27/30\n",
            "91/91 [==============================] - 9s 94ms/step - loss: 0.0863 - accuracy: 0.9673 - metrics_recall: 0.9455 - metrics_precision: 0.9522 - metrics_f1: 0.9471 - val_loss: 0.9667 - val_accuracy: 0.7118 - val_metrics_recall: 0.5094 - val_metrics_precision: 0.5605 - val_metrics_f1: 0.5226\n",
            "Epoch 28/30\n",
            "91/91 [==============================] - 9s 95ms/step - loss: 0.0705 - accuracy: 0.9768 - metrics_recall: 0.9558 - metrics_precision: 0.9741 - metrics_f1: 0.9632 - val_loss: 1.0859 - val_accuracy: 0.6996 - val_metrics_recall: 0.5249 - val_metrics_precision: 0.5409 - val_metrics_f1: 0.5194\n",
            "Epoch 29/30\n",
            "91/91 [==============================] - 9s 95ms/step - loss: 0.0811 - accuracy: 0.9661 - metrics_recall: 0.9425 - metrics_precision: 0.9621 - metrics_f1: 0.9494 - val_loss: 0.9580 - val_accuracy: 0.6818 - val_metrics_recall: 0.6283 - val_metrics_precision: 0.5106 - val_metrics_f1: 0.5517\n",
            "Epoch 30/30\n",
            "91/91 [==============================] - 9s 97ms/step - loss: 0.0794 - accuracy: 0.9717 - metrics_recall: 0.9527 - metrics_precision: 0.9614 - metrics_f1: 0.9554 - val_loss: 0.9031 - val_accuracy: 0.7029 - val_metrics_recall: 0.5490 - val_metrics_precision: 0.5386 - val_metrics_f1: 0.5342\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2c297509d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJVL4SBLPB2P"
      },
      "source": [
        "#%tensorboard --logdir {logs_base_dir}"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_LnvWBcnoak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "185aa46a-342d-4660-d42d-6541dffe72c6"
      },
      "source": [
        "#results = model.evaluate(nppadded_testing, nptesting_labels, batch_size=batch_size)\n",
        "#print(\"test loss, test acc:\",results)\n",
        "\n",
        "(loss,accuracy, metrics_recall,metrics_precision,\n",
        "metrics_f1) = CNN16052105.evaluate(nppadded_testing, nptesting_labels, verbose=1)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "111/111 [==============================] - 2s 20ms/step - loss: 0.9423 - accuracy: 0.6741 - metrics_recall: 0.4664 - metrics_precision: 0.5334 - metrics_f1: 0.4827\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KgjIkhpKmHc"
      },
      "source": [
        "make some predictions of test data and save it to variable. verbose=0 -> do not generate output\n",
        "Gute Quelle: https://deeplizard.com/learn/video/2f-NjDUvZIE "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89GWuxryKlcM"
      },
      "source": [
        "CNN_predictions05 = CNN16052105.predict(x=nppadded_testing)\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3jPDaDJK_cN"
      },
      "source": [
        "#for p in CNN_predictions05:\n",
        " # print(p)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eC9efJy4Lp21"
      },
      "source": [
        "rounded predictions: give prediction value of most likely prediction (0 or 1). Printing the output of rounded prediction shows the prediction made by the model on the data (which output is most likely)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsG-TJuQLvtk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2fc5625-693c-42c6-c6d6-55feb2d7909c"
      },
      "source": [
        "prediction_rounded05 = np.round(CNN_predictions05)\n",
        "#np.argmax(CNN_predictions05,axis=-1)\n",
        "\n",
        "#for p in prediction_rounded05:\n",
        " # print(p)\n",
        "\n",
        "\n",
        "print(nptesting_labels[500:520])\n",
        "print(prediction_rounded05[500:520])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1]\n",
            "[[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egTtgpXgg8a2"
      },
      "source": [
        "https://deeplizard.com/learn/video/km7pxKy4UHU\n",
        "\n",
        "Quelle der def plot_confusion_matrix: https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSDXf7-_MITy"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0AMs1EzhBU1"
      },
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                        normalize=False,\n",
        "                        title='Confusion matrix',\n",
        "                        cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2JgEnlghCtl"
      },
      "source": [
        "cm = confusion_matrix(y_true=nptesting_labels, y_pred=prediction_rounded05)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckmF29whhFmX"
      },
      "source": [
        "plot_labels = ['no hatespeech','hatespeech']"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "2mpSE96rhK7K",
        "outputId": "693c3b52-fecc-448d-8b31-f30a7a6c68aa"
      },
      "source": [
        "plot_confusion_matrix(cm=cm, classes=plot_labels, title='CNN Confusion 260')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix, without normalization\n",
            "[[1832  498]\n",
            " [ 653  549]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}