{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN embedded.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNW9mOMQTkTMgBJ77WViY8w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BiancaStadl/ProjektarbeitML/blob/main/CNN_embedded.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXDOlIBymF0V"
      },
      "source": [
        "GloVe embeddings taken from:\n",
        "\n",
        "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. [pdf] [bib]\n",
        "\n",
        "hatespeechdata taken from (https://hatespeechdata.com/): Wiegand, M., Siegel, M. and Ruppenhofer, J., 2018. Overview of the GermEval 2018 Shared Task on the Identification of Offensive Language. In: Proceedings of GermEval 2018, 14th Conference on Natural Language Processing (KONVENS 2018). Vienna, Austria: Research Gate. available on: https://github.com/uds-lsv/GermEval-2018-Data (last checked: 09.05.2021)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlBmABDxfqII"
      },
      "source": [
        "wiki detox..https://colab.research.google.com/github/tensorflow/fairness-indicators/blob/master/g3doc/tutorials/Fairness_Indicators_TFCO_Wiki_Case_Study.ipynb#scrollTo=y6T5tlXcdW7J "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3xfitNdliBI"
      },
      "source": [
        "#import matplotlib.pyplot as plt -> für evtl Visualisierungen\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import string\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from keras import losses \n",
        "from keras import optimizers \n",
        "from keras import metrics \n",
        "\n",
        "#!pip install Tokenizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "#!pip install pad_sequences\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import preprocessing\n",
        "#from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTWJQ1iga_vS"
      },
      "source": [
        "Maximale Satzlänge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bq08Me5la_Cc"
      },
      "source": [
        "\n",
        "max_length = 60"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVYBMvYSotTH"
      },
      "source": [
        "url = \"https://github.com/uds-lsv/GermEval-2018-Data/archive/master.zip\"\n",
        "\n",
        "dataset = tf.keras.utils.get_file(\"GermEval-2018-Data-master.zip\", url, \n",
        "                                   extract=True, cache_dir='.',\n",
        "                                    cache_subdir='')\n",
        "\n",
        "dataset_dir = os.path.join(os.path.dirname(dataset), 'GermEval-2018-Data-master')\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cS14OUtfo34V"
      },
      "source": [
        "#os.listdir(dataset_dir)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2X429K6hpOVm"
      },
      "source": [
        "training_file = os.path.join(dataset_dir, 'germeval2018.training.txt')\n",
        "\n",
        "testing_file = os.path.join(dataset_dir, 'germeval2018.test.txt')\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uq8fG3LNtn_m"
      },
      "source": [
        "###Aufbereitung\n",
        "txt-Dateien lesen, und dabei jede Zeile splitten und teilen\n",
        "Twitter-Handler entfernen?\n",
        "Labels von Sätzen trennen, Labels in eigenen Array packen.\n",
        "\n",
        "####Ressourcen\n",
        "* https://www.w3schools.com/python/gloss_python_if_statement.asp\n",
        "* https://stackabuse.com/using-regex-for-text-manipulation-in-python/\n",
        "* https://www.tutorialspoint.com/python/string_splitlines.htm \n",
        "* https://note.nkmk.me/en/python-split-rsplit-splitlines-re/ \n",
        "* https://www.w3schools.com/python/python_regex.asp \n",
        "\n",
        "gäbe bei keras tf.keras.preprocessing.text_dataset_from_directory, aber dafür müssten die Daten auf bestimmte Weise in Verzeichnis organisiert sein, hier nicht der Fall.\n",
        "\n",
        "\n",
        "Einteilung der Daten: Testdaten\n",
        "Trainingsdaten -> noch ca 500 für Validierungsdaten\n",
        "\n",
        "labels -> \"other\", also nicht-negative Aussagen bekommen \"0\", negative Aussagen bekommen \"1\"\n",
        "\n",
        " Regex für Emojis  ->\n",
        "\n",
        "(\\u00a9|\\u00ae|[\\u2000-\\u3300]|\\ud83c[\\ud000-\\udfff]|\\ud83d[\\ud000-\\udfff]|\\ud83e[\\ud000-\\udfff])\n",
        "\n",
        "genommen von https://www.regextester.com/106421 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Py_cwD4eZkXo"
      },
      "source": [
        "def remove_clutter(string):\n",
        "   string = re.sub(\"@[^\\s]+\",\" \",string)\n",
        "   string = re.sub(\"#[^\\s]+\",\" \", string)\n",
        "   string = re.sub(\"\\u00a9\",\" \", string)\n",
        "   string = re.sub(\"\\u00ae\",\" \", string)\n",
        "   string = re.sub(\"[\\u2000-\\u3300]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83c[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83d[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83e[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"😜\", \" \",string)\n",
        "   string = re.sub(\"🍫\", \" \",string)\n",
        "   string = re.sub(\"😁\", \" \",string)\n",
        "   string = re.sub(\"🐖\", \" \",string)\n",
        "   string = re.sub(\"😡\", \" \",string)\n",
        "   string = re.sub(\"😇\", \" \",string)\n",
        "   string = re.sub(\"😬\", \" \",string)\n",
        "   string = re.sub(\"😃\", \" \",string)\n",
        "   string = re.sub(\"😂\", \" \",string)\n",
        "   string = re.sub(\"💙\", \" \",string)  \n",
        "   string = re.sub(\"😛\", \" \",string)\n",
        "   string = re.sub(\"🙏\", \" \",string)\n",
        "   string = re.sub(\"👍\", \" \",string)\n",
        "   string = re.sub(\"🖕\", \" \",string)\n",
        "   string = re.sub(\"😉\", \" \",string)\n",
        "   string = re.sub(\"💩\", \" \",string)\n",
        "   string = re.sub(\"🤢\", \" \",string)\n",
        "   string = re.sub(\"👏\", \" \",string)\n",
        "   string = re.sub(\"😨\", \" \",string)\n",
        "   string = re.sub(\"🤣\", \" \",string)\n",
        "   string = re.sub(\"🤡\", \" \",string)\n",
        "   string = re.sub(\"😈\", \" \",string)\n",
        "   string = re.sub(\"💃🏽\", \" \",string)\n",
        "   string = re.sub(\"👹\", \" \",string)\n",
        "   string = re.sub(\"🤘\", \" \",string)\n",
        "   string = re.sub(\"😱\", \" \",string)\n",
        "   string = re.sub(\"🤔\", \" \",string) \n",
        "   string = re.sub(\"🌈\", \" \",string) \n",
        "   string = re.sub(\"💕\", \" \",string) \n",
        "   string = re.sub(\"👩‍❤️‍👩\", \" \",string) \n",
        "   string = re.sub(\"😍\", \" \",string) \n",
        "   string = re.sub(\"👆\", \" \",string) \n",
        "   string = re.sub(\"😖\", \" \",string) \n",
        "   string = re.sub(\"👇\", \" \",string) \n",
        "   string = re.sub(\"🔥\", \" \",string) \n",
        "   string = re.sub(\"😘\", \" \",string) \n",
        "   string = re.sub(\"🎉\", \" \",string) \n",
        "   string = re.sub(\"🤬\", \" \",string) \n",
        "   string = re.sub(\"👊\", \" \",string)\n",
        "   string = re.sub(\"🇩🇪\", \" \",string)  \n",
        "   string = re.sub(\"💔\", \" \",string)\n",
        "   string = re.sub(\"🙈\", \" \",string)\n",
        "   string = re.sub(\"🤯\", \" \",string)\n",
        "   string = re.sub(\"🐟\", \" \",string)\n",
        "   string = re.sub(\"🛶\", \" \",string)\n",
        "   string = re.sub(\"😊\", \" \",string)\n",
        "   string = re.sub(\"😓\", \" \",string)\n",
        "   string = re.sub(\"😳\", \" \",string)\n",
        "   string = re.sub(\"🚀\", \" \",string)\n",
        "   string = re.sub(\"👎\", \" \",string)\n",
        "   string = re.sub(\"😎\", \" \",string)\n",
        "   string = re.sub(\"🐸\", \" \",string)\n",
        "   string = re.sub(\"📈\", \" \",string)\n",
        "   string = re.sub(\"🙂\", \" \",string)\n",
        "   string = re.sub(\"😅\", \" \",string)\n",
        "   string = re.sub(\"😆\", \" \",string)\n",
        "   string = re.sub(\"🙎🏿\", \" \",string)\n",
        "   string = re.sub(\"👎🏽\", \" \",string)\n",
        "   string = re.sub(\"🤭\", \" \",string)\n",
        "   string = re.sub(\"😤\", \" \",string)\n",
        "   string = re.sub(\"😚\", \" \",string)\n",
        "   string = re.sub(\"😊\", \" \",string)\n",
        "   string = re.sub(\"😲\", \" \",string)\n",
        "   string = re.sub(\"🤮\", \" \",string)\n",
        "   string = re.sub(\"🙄\", \" \",string)\n",
        "   string = re.sub(\"🤑\", \" \",string)\n",
        "   string = re.sub(\"🎅\", \" \",string)\n",
        "   string = re.sub(\"👋\", \" \",string)\n",
        "   string = re.sub(\"💪\", \" \",string)\n",
        "   string = re.sub(\"😄\", \" \",string)\n",
        "   string = re.sub(\"🧐\", \" \",string)\n",
        "   string = re.sub(\"😠\", \" \",string)\n",
        "   string = re.sub(\"🎈\", \" \",string)\n",
        "   string = re.sub(\"🚂\", \" \",string)\n",
        "   string = re.sub(\"😊\", \" \",string)\n",
        "   string = re.sub(\"🚇\", \" \",string)\n",
        "   string = re.sub(\"🚊\", \" \",string)\n",
        "   string = re.sub(\"🤷\", \" \",string)\n",
        "   string = re.sub(\"😥\", \" \",string)\n",
        "   string = re.sub(\"🙃\", \" \",string)\n",
        "   string = re.sub(\"🔩\", \" \",string)\n",
        "   string = re.sub(\"🔧\", \" \",string)\n",
        "   string = re.sub(\"🔨\", \" \",string)\n",
        "   string = re.sub(\"🛠\", \" \",string)\n",
        "   string = re.sub(\"💓\", \" \",string)\n",
        "   string = re.sub(\"💡\", \" \",string)\n",
        "   string = re.sub(\"🍸\", \" \",string)\n",
        "   string = re.sub(\"🥃\", \" \",string)\n",
        "   string = re.sub(\"🥂\", \" \",string)\n",
        "   string = re.sub(\"😷\", \" \",string)\n",
        "   string = re.sub(\"🤐\", \" \",string)\n",
        "   string = re.sub(\"🌎\", \" \",string)\n",
        "   string = re.sub(\"👑\", \" \",string)\n",
        "   string = re.sub(\"🤛\", \" \",string)\n",
        "   string = re.sub(\"😀\", \" \",string)\n",
        "   string = re.sub(\"🛤\", \" \",string)\n",
        "   string = re.sub(\"🎄\", \" \",string)\n",
        "   string = re.sub(\"📴\", \" \",string)\n",
        "   string = re.sub(\"🌭\", \" \",string)\n",
        "   string = re.sub(\"🤕\", \" \",string)\n",
        "   string = re.sub(\"😭\", \" \",string)\n",
        "   string = re.sub(\"🍾\", \" \",string)\n",
        "   string = re.sub(\"🍞\", \" \",string)\n",
        "   string = re.sub(\"🤦\", \" \",string)\n",
        "   string = re.sub(\"🤯\", \" \",string)\n",
        "   string = re.sub(\"🕯️\", \" \",string)\n",
        "\n",
        "   string = re.sub(\"OTHER|OFFENSE|ABUSE|INSULT\",\" \",string)\n",
        "   return string"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5asMgo4LtnRg"
      },
      "source": [
        "statementsForTraining = []\n",
        "sentimentsForTraining = []\n",
        "\n",
        "\n",
        "fileToRead = open(training_file, 'r')\n",
        "\n",
        "while True:\n",
        "  #next line in file\n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  findSentiment = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "\n",
        "\n",
        "  statementsForTraining.append(line)\n",
        "   #sentimentsForTraining.append(findSentiment.group(0))\n",
        "\n",
        "  if findSentiment.group(0) == \"OTHER\":  \n",
        "    sentimentsForTraining.append(0)\n",
        "  else:\n",
        "    sentimentsForTraining.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        " #print(\"{}: {}\".format(count,line.strip()))\n",
        "  \n",
        " # print(sentiment.group(0))\n",
        " \n",
        "fileToRead.close()\n",
        "\n",
        "training_sentences = statementsForTraining\n",
        "training_labels = sentimentsForTraining\n",
        "\n",
        "#print(training_sentences[9])\n",
        "#print(training_labels[9])\n",
        "\n",
        "#print(len(training_sentences))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsqZPENb98gD"
      },
      "source": [
        "##do the same with testdata\n",
        "statementsForTesting = []\n",
        "sentimentsForTesting = []\n",
        "\n",
        "fileToRead = open(testing_file, 'r')\n",
        "\n",
        "while True:\n",
        "  #next line in file\n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  sent = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "\n",
        "    \n",
        "\n",
        "  statementsForTesting.append(line)\n",
        "  #print(len(line))\n",
        "  #sentimentsForTesting.append(sent.group(0))\n",
        "\n",
        "  if sent.group(0) == \"OTHER\": \n",
        "    sentimentsForTesting.append(0)\n",
        "  else:\n",
        "    sentimentsForTesting.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        "\n",
        "fileToRead.close()\n",
        "\n",
        "\n",
        "testing_sentences = statementsForTesting\n",
        "testing_labels = sentimentsForTesting\n",
        "#print(len(testing_sentences))\n",
        "#print(testing_sentences)   \n",
        "#print(testing_labels)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRUvDLD5bMbO"
      },
      "source": [
        "Padding -> im Prinzip die Sätze alle auf die gleiche Länge bringen (in Theorieteil näher drauf eingehen) -> maxlen-Paramter ist für pad_sequences vorhanden, wenn nicht gesetzt -> alles wird auf die Länge des längsten Satzes aufgefüllt -> print(padded(shape)) gibt aus, wie viele Datensätze padded wurden und gibt an, wie viele Tokens der längste Datensatz hat\n",
        "print(padded[x]) gibt einen Satz aus (bereits tokenisiert)\n",
        "\n",
        "Padding -> sowohl für Trainigs- als auch für Testdaten\n",
        "\n",
        "Und: Daten als numpy-Arrays speichern (notwendig für tensorflow).\n",
        "\n",
        " -> Tokenizer https://towardsdatascience.com/text-classification-in-keras-part-2-how-to-use-the-keras-tokenizer-word-representations-fd571674df23 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3hFi7waTv5m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05143eca-b1a9-43ca-9290-5984d27b93f2"
      },
      "source": [
        "tokenizer = Tokenizer(oov_token=\"OOV\")\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "\n",
        "#creating a word index - nur die Trainigsdaten\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "validation_size = 500\n",
        "\n",
        "\n",
        "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "padded_training = pad_sequences(training_sequences, maxlen=max_length, padding='post')\n",
        "print(len(padded_training))\n",
        "\n",
        "validation_sequences = padded_training[0:validation_size]\n",
        "validation_labels = training_labels[0:validation_size]\n",
        "\n",
        "padded_training = padded_training[validation_size:]\n",
        "training_labels = training_labels[validation_size:]\n",
        "\n",
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
        "padded_testing = pad_sequences(testing_sequences, maxlen=max_length,  padding='post')\n",
        "\n",
        "#print(validation_sequences[499])\n",
        "print(padded_training[0])\n",
        "#print(len(validation_labels))\n",
        "#print(len(training_labels))\n",
        "\n",
        "\n",
        "nppadded_training = np.array(padded_training)\n",
        "nptraining_labels = np.array(training_labels)\n",
        "\n",
        "nppadded_validation = np.array(validation_sequences)\n",
        "npvalidation_labels = np.array(validation_labels)\n",
        "\n",
        "nppadded_testing = np.array(padded_testing)\n",
        "nptesting_labels = np.array(testing_labels)\n",
        "\n",
        "\n",
        "print(len(nppadded_training))\n",
        "print(len(nptraining_labels))\n",
        "print(len(word_index))\n",
        "\n",
        "#print(statementsForTraining[2])\n",
        "#print(nppadded_training[4])\n",
        "#print(nppadded_training.shape)\n",
        "#print(nptraining_labels[4])\n",
        "#print(nppadded_testing.shape)\n",
        "#print(word_index) \n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5009\n",
            "[  12 3982   11   41 6706 1040    4    5  202   39    3 2922   49 1360\n",
            "  810  495 3983    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0]\n",
            "4509\n",
            "4509\n",
            "15059\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tL3owrc8THkT"
      },
      "source": [
        "\n",
        "Dann: Embedding mit entweder word2vec oder glove\n",
        "Word2vec-Daten sind hier: http://vectors.nlpl.eu/repository/#\n",
        "Glove -> https://nlp.stanford.edu/projects/glove/ Da mal den Twitter-Vector runtergeladen\n",
        "Wenn Daten in GoogleDrive sind (wäre auch via url möglich..), muss Drive gemounted werden ( https://buomsoo-kim.github.io/colab/2020/05/09/Colab-mounting-google-drive.md/ ) aber auch hier https://enjoymachinelearning.com/posts/colab-with-google-drive/\n",
        "\n",
        "Die Word2vec vectors: http://vectors.nlpl.eu/repository/# \n",
        "\n",
        "glove-zitat:\n",
        "Citing GloVe\n",
        "\n",
        "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. [pdf] [bib]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zuO7T9ZTG57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89220a51-220b-41e9-d90f-486e1f0a5214"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "os.listdir(\"/content/drive/MyDrive/Colab Notebooks\")\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['germeval_training.txt',\n",
              " 'glove.twitter.27B.50d.txt',\n",
              " 'glove.twitter.27B.200d.txt',\n",
              " 'glove.6B.200d.txt',\n",
              " 'glove.840B.300d.txt',\n",
              " 'tensorboard.gdoc',\n",
              " 'keras.gdoc',\n",
              " 'Vectorization CNN embedded_limited_vocab.ipynb',\n",
              " 'glove.42B.300d.txt',\n",
              " 'Embedding Glove Vergleich.ipynb',\n",
              " 'CNN embedded_limited_vocab.ipynb',\n",
              " 'LSTM_limited_vocab.ipynb',\n",
              " 'LSTM.ipynb',\n",
              " 'CNN embedded.ipynb']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7ToKO-sZLHK"
      },
      "source": [
        "\n",
        "Keras-Doc : https://keras.io/examples/nlp/pretrained_word_embeddings/#load-pretrained-word-embeddings \n",
        "embedding mit initializers.. weights müsste auch funktionieren\n",
        "\n",
        "Diese erstellte Matrix mit Embedding dann in die Embedding-Schicht einbinden,  Trainable auf False, weil sich die Werte nicht durch Training anpassen sollen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AShIVfC7ZQAH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6ef2aa2-4c2d-4a64-cb5f-cb224a56e803"
      },
      "source": [
        "#Größe Vokabel -> wordindex + 2 (weil padding + OOV) \n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "vocabulary_size = len(word_index)+2\n",
        "\n",
        "# dann erstell ich ein Wörterbuch mit Namen \"embedding_vector\", dort sind dann\n",
        "#die keys drinnen, die in glove-Datei drinnen sind mit dem entsprechenden Key\n",
        "\n",
        "embedding_index_glove = {}\n",
        "f = open('/content/drive/MyDrive/Colab Notebooks/glove.twitter.27B.200d.txt')\n",
        "for line in f:\n",
        "  value = line.split()\n",
        "  word = value[0]\n",
        "  coef = np.asarray(value[1:],dtype='float32')\n",
        "  embedding_index_glove[word] = coef\n",
        "\n",
        "print(\"%d gefunden: \"% len(embedding_index_glove))\n",
        "\n",
        "#Dann noch eine Embedding-Matrix erstellen\n",
        "#zweiter Wert = Embedding-Dimension der Datei, in dem Fall 200\n",
        "\n",
        "glove_matrix = np.zeros((vocabulary_size,200))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    embedding_value = embedding_index_glove.get(word)\n",
        "    if embedding_value is not None:\n",
        "      glove_matrix[index] = embedding_value\n",
        "      hits+=1\n",
        "    else:\n",
        "      misses+=1\n",
        "\n",
        "print(\"hits %d and %d misses\"%(hits,misses))\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1193514 gefunden: \n",
            "hits 6747 and 8312 misses\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZmvOfwhV4N5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dcc400d-640a-4525-c516-be4673490f36"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "print(\"vocab size: %d\"%vocabulary_size)\n",
        "CNN16052102 = tf.keras.Sequential()\n",
        "#Embedding -> hier dann auf das embedding verweisen, Input_dim -> die Anzahl der Wörter im word_index, output -> in dem Fall passend zum verwendeten Vektor\n",
        "#input-length -> auf 60  gepadded, trainable -> nein, weil nichts verändert werden soll\n",
        "#embeddings_initializer=keras.initializers.Constant(glove_matrix) vs weights = [glove_matrix]\n",
        "#Convolutional layers => filters = neurons.. mit 100? 265?\n",
        "CNN16052102.add(tf.keras.layers.Embedding(vocabulary_size, output_dim=200, input_length=60, embeddings_initializer = keras.initializers.Constant(glove_matrix), trainable= False))\n",
        "CNN16052102.add(tf.keras.layers.Dropout(0.4))\n",
        "CNN16052102.add(tf.keras.layers.Conv1D(filters=90, kernel_size=3, padding=\"valid\", activation=\"relu\"))\n",
        "CNN16052102.add(tf.keras.layers.MaxPooling1D())\n",
        "CNN16052102.add(tf.keras.layers.Conv1D(filters=90, kernel_size=3, padding=\"valid\", activation=\"relu\"))\n",
        "CNN16052102.add(tf.keras.layers.GlobalAveragePooling1D())\n",
        "CNN16052102.add(tf.keras.layers.Flatten())\n",
        "CNN16052102.add(tf.keras.layers.Dense(260, activation=\"relu\"))\n",
        "CNN16052102.add(tf.keras.layers.Dropout(0.4))\n",
        "CNN16052102.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "CNN16052102.summary()\n",
        "\n",
        "#nppadded_training = np.asmatrix(nppadded_training) not necessary\n",
        "#nppadded_testing = np.asmatrix(nppadded_testing)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab size: 15061\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 60, 200)           3012200   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 60, 200)           0         \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 58, 90)            54090     \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 29, 90)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 27, 90)            24390     \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 90)                0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 90)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 260)               23660     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 260)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 261       \n",
            "=================================================================\n",
            "Total params: 3,114,601\n",
            "Trainable params: 102,401\n",
            "Non-trainable params: 3,012,200\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEr4OzT-iHDe"
      },
      "source": [
        "#model.layers[2].get_weights()[0].shape\n",
        "#weights=np.random.rand(5,200,100)\n",
        "#bias=np.random.rand(100)\n",
        "#model.layers[2].set_weights([weights, bias])\n",
        "\n",
        "#model.layers[2].get_weights()[0]\n",
        "#https://androidkt.com/set-custom-weights-keras-using-numpy-array/"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UB7_3VPYesr9"
      },
      "source": [
        "F1-Score für jede Epoche https://aakashgoel12.medium.com/how-to-add-user-defined-function-get-f1-score-in-keras-metrics-3013f979ce0d\n",
        "\n",
        "Sehr gute Ressource für die verschiedenen Scores und Metriken https://neptune.ai/blog/evaluation-metrics-binary-classification#10  das und aakas verwendet\n",
        "\n",
        "hier: je eine Funktion für Recall, Precision, f1 https://neptune.ai/blog/keras-metrics \n",
        "\n",
        "https://keras.rstudio.com/reference/k_ones_like.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygyrbFJaMV9B"
      },
      "source": [
        "import keras.backend as K\n",
        "\n",
        "def metrics_recall(data_true, data_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(data_true,0,1)))\n",
        "\n",
        "    recall = true_positives / (possible_positives+K.epsilon())\n",
        "    return recall\n",
        "\n",
        "\n",
        "def metrics_precision(data_true, data_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "\n",
        "    positives_predicted = K.sum(K.round(K.clip(data_pred,0,1)))\n",
        "    precision = true_positives / (positives_predicted+K.epsilon())\n",
        "    return precision\n",
        "\n",
        "\n",
        "def metrics_f1(data_true, data_pred):\n",
        "    precision_data = metrics_precision(data_true, data_pred)\n",
        "    recall_data = metrics_recall(data_true, data_pred)\n",
        "    return 2*(precision_data*recall_data)/(precision_data+recall_data+K.epsilon())"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1ctlBrnuYJz"
      },
      "source": [
        "https://aakashgoel12.medium.com/how-to-add-user-defined-function-get-f1-score-in-keras-metrics-3013f979ce0d"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AfPD3_bWCm0"
      },
      "source": [
        "CNN16052102.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',metrics_recall,metrics_precision,metrics_f1])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpChKUY-QEWI"
      },
      "source": [
        "https://www.tensorflow.org/tensorboard/tensorboard_in_notebooks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJfMgUhHBoD1"
      },
      "source": [
        "#%reload_ext tensorboard\n",
        "#nur einmal pro Sitzung notwendig\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ISmMXLqP8Hc"
      },
      "source": [
        "\n",
        "logs_base_dir = \"./logs\"\n",
        "callbackForTB = tf.keras.callbacks.TensorBoard(logs_base_dir)\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2CHbXiP1LsF"
      },
      "source": [
        "training_epochs = 30\n",
        "batch_size = 40\n",
        "validation_split=0.2"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abV-QAxfW48r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5708178d-1b7e-4e88-b64d-1707638603b8"
      },
      "source": [
        "#Werte der Convolutional-Schichten variieren (Filter), Batch-Size variieren, kernel-size..\n",
        "CNN16052102.fit(nppadded_training, nptraining_labels, batch_size=batch_size, validation_split=validation_split, epochs=training_epochs, callbacks=[callbackForTB])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "91/91 [==============================] - 5s 41ms/step - loss: 0.6637 - accuracy: 0.6396 - metrics_recall: 0.0783 - metrics_precision: 0.0840 - metrics_f1: 0.0492 - val_loss: 0.6357 - val_accuracy: 0.6718 - val_metrics_recall: 0.0000e+00 - val_metrics_precision: 0.0000e+00 - val_metrics_f1: 0.0000e+00\n",
            "Epoch 2/30\n",
            "91/91 [==============================] - 3s 35ms/step - loss: 0.6323 - accuracy: 0.6702 - metrics_recall: 0.0016 - metrics_precision: 0.0044 - metrics_f1: 0.0022 - val_loss: 0.6112 - val_accuracy: 0.6718 - val_metrics_recall: 0.0000e+00 - val_metrics_precision: 0.0000e+00 - val_metrics_f1: 0.0000e+00\n",
            "Epoch 3/30\n",
            "91/91 [==============================] - 3s 34ms/step - loss: 0.6057 - accuracy: 0.6693 - metrics_recall: 0.0457 - metrics_precision: 0.1641 - metrics_f1: 0.0646 - val_loss: 0.5951 - val_accuracy: 0.6996 - val_metrics_recall: 0.2402 - val_metrics_precision: 0.6465 - val_metrics_f1: 0.3385\n",
            "Epoch 4/30\n",
            "91/91 [==============================] - 3s 36ms/step - loss: 0.5846 - accuracy: 0.6836 - metrics_recall: 0.2596 - metrics_precision: 0.6030 - metrics_f1: 0.3276 - val_loss: 0.5958 - val_accuracy: 0.6674 - val_metrics_recall: 0.5476 - val_metrics_precision: 0.4953 - val_metrics_f1: 0.5066\n",
            "Epoch 5/30\n",
            "91/91 [==============================] - 3s 36ms/step - loss: 0.5614 - accuracy: 0.6962 - metrics_recall: 0.3028 - metrics_precision: 0.6048 - metrics_f1: 0.3635 - val_loss: 0.5635 - val_accuracy: 0.7140 - val_metrics_recall: 0.2217 - val_metrics_precision: 0.7449 - val_metrics_f1: 0.3242\n",
            "Epoch 6/30\n",
            "91/91 [==============================] - 3s 36ms/step - loss: 0.5292 - accuracy: 0.7276 - metrics_recall: 0.4120 - metrics_precision: 0.6632 - metrics_f1: 0.4729 - val_loss: 0.5886 - val_accuracy: 0.6619 - val_metrics_recall: 0.6542 - val_metrics_precision: 0.4894 - val_metrics_f1: 0.5495\n",
            "Epoch 7/30\n",
            "91/91 [==============================] - 3s 35ms/step - loss: 0.5237 - accuracy: 0.7294 - metrics_recall: 0.5449 - metrics_precision: 0.6535 - metrics_f1: 0.5416 - val_loss: 0.5455 - val_accuracy: 0.7251 - val_metrics_recall: 0.4660 - val_metrics_precision: 0.6150 - val_metrics_f1: 0.5138\n",
            "Epoch 8/30\n",
            "91/91 [==============================] - 3s 36ms/step - loss: 0.5075 - accuracy: 0.7447 - metrics_recall: 0.5213 - metrics_precision: 0.6970 - metrics_f1: 0.5384 - val_loss: 0.5392 - val_accuracy: 0.7084 - val_metrics_recall: 0.4247 - val_metrics_precision: 0.5667 - val_metrics_f1: 0.4675\n",
            "Epoch 9/30\n",
            "91/91 [==============================] - 3s 36ms/step - loss: 0.4620 - accuracy: 0.7749 - metrics_recall: 0.5842 - metrics_precision: 0.7283 - metrics_f1: 0.6279 - val_loss: 0.5325 - val_accuracy: 0.7129 - val_metrics_recall: 0.4087 - val_metrics_precision: 0.5958 - val_metrics_f1: 0.4657\n",
            "Epoch 10/30\n",
            "91/91 [==============================] - 3s 36ms/step - loss: 0.4378 - accuracy: 0.7873 - metrics_recall: 0.5977 - metrics_precision: 0.7525 - metrics_f1: 0.6447 - val_loss: 0.5353 - val_accuracy: 0.7118 - val_metrics_recall: 0.3882 - val_metrics_precision: 0.5958 - val_metrics_f1: 0.4554\n",
            "Epoch 11/30\n",
            "91/91 [==============================] - 3s 36ms/step - loss: 0.4139 - accuracy: 0.8162 - metrics_recall: 0.6460 - metrics_precision: 0.7874 - metrics_f1: 0.6922 - val_loss: 0.6003 - val_accuracy: 0.6641 - val_metrics_recall: 0.7218 - val_metrics_precision: 0.4874 - val_metrics_f1: 0.5724\n",
            "Epoch 12/30\n",
            "91/91 [==============================] - 3s 36ms/step - loss: 0.3970 - accuracy: 0.8147 - metrics_recall: 0.7013 - metrics_precision: 0.7586 - metrics_f1: 0.7070 - val_loss: 0.6004 - val_accuracy: 0.6829 - val_metrics_recall: 0.6841 - val_metrics_precision: 0.5099 - val_metrics_f1: 0.5732\n",
            "Epoch 13/30\n",
            "91/91 [==============================] - 3s 36ms/step - loss: 0.3454 - accuracy: 0.8578 - metrics_recall: 0.7581 - metrics_precision: 0.8319 - metrics_f1: 0.7735 - val_loss: 0.6739 - val_accuracy: 0.7195 - val_metrics_recall: 0.2309 - val_metrics_precision: 0.6707 - val_metrics_f1: 0.3303\n",
            "Epoch 14/30\n",
            "91/91 [==============================] - 3s 36ms/step - loss: 0.3829 - accuracy: 0.8306 - metrics_recall: 0.6800 - metrics_precision: 0.8364 - metrics_f1: 0.7167 - val_loss: 0.5743 - val_accuracy: 0.6973 - val_metrics_recall: 0.4688 - val_metrics_precision: 0.5437 - val_metrics_f1: 0.4891\n",
            "Epoch 15/30\n",
            "91/91 [==============================] - 3s 36ms/step - loss: 0.3173 - accuracy: 0.8627 - metrics_recall: 0.7458 - metrics_precision: 0.8100 - metrics_f1: 0.7658 - val_loss: 0.5960 - val_accuracy: 0.7195 - val_metrics_recall: 0.4375 - val_metrics_precision: 0.5932 - val_metrics_f1: 0.4894\n",
            "Epoch 16/30\n",
            "91/91 [==============================] - 3s 36ms/step - loss: 0.3052 - accuracy: 0.8681 - metrics_recall: 0.7775 - metrics_precision: 0.8332 - metrics_f1: 0.7917 - val_loss: 0.6547 - val_accuracy: 0.6818 - val_metrics_recall: 0.6725 - val_metrics_precision: 0.5099 - val_metrics_f1: 0.5673\n",
            "Epoch 17/30\n",
            "91/91 [==============================] - 3s 36ms/step - loss: 0.3012 - accuracy: 0.8672 - metrics_recall: 0.7766 - metrics_precision: 0.8268 - metrics_f1: 0.7888 - val_loss: 0.6365 - val_accuracy: 0.6907 - val_metrics_recall: 0.5887 - val_metrics_precision: 0.5212 - val_metrics_f1: 0.5420\n",
            "Epoch 18/30\n",
            "91/91 [==============================] - 3s 36ms/step - loss: 0.2550 - accuracy: 0.8907 - metrics_recall: 0.8270 - metrics_precision: 0.8628 - metrics_f1: 0.8369 - val_loss: 0.6431 - val_accuracy: 0.7106 - val_metrics_recall: 0.4851 - val_metrics_precision: 0.5629 - val_metrics_f1: 0.5052\n",
            "Epoch 19/30\n",
            "91/91 [==============================] - 3s 37ms/step - loss: 0.2803 - accuracy: 0.8808 - metrics_recall: 0.8140 - metrics_precision: 0.8524 - metrics_f1: 0.8175 - val_loss: 0.6672 - val_accuracy: 0.6973 - val_metrics_recall: 0.5507 - val_metrics_precision: 0.5280 - val_metrics_f1: 0.5292\n",
            "Epoch 20/30\n",
            "91/91 [==============================] - 3s 36ms/step - loss: 0.2219 - accuracy: 0.9159 - metrics_recall: 0.8443 - metrics_precision: 0.8981 - metrics_f1: 0.8621 - val_loss: 0.7123 - val_accuracy: 0.7239 - val_metrics_recall: 0.4393 - val_metrics_precision: 0.6084 - val_metrics_f1: 0.4935\n",
            "Epoch 21/30\n",
            "91/91 [==============================] - 3s 37ms/step - loss: 0.2435 - accuracy: 0.8974 - metrics_recall: 0.8017 - metrics_precision: 0.8939 - metrics_f1: 0.8325 - val_loss: 0.7068 - val_accuracy: 0.6951 - val_metrics_recall: 0.5796 - val_metrics_precision: 0.5282 - val_metrics_f1: 0.5413\n",
            "Epoch 22/30\n",
            "91/91 [==============================] - 3s 37ms/step - loss: 0.1987 - accuracy: 0.9182 - metrics_recall: 0.8621 - metrics_precision: 0.8980 - metrics_f1: 0.8745 - val_loss: 0.7496 - val_accuracy: 0.6829 - val_metrics_recall: 0.6340 - val_metrics_precision: 0.5116 - val_metrics_f1: 0.5528\n",
            "Epoch 23/30\n",
            "91/91 [==============================] - 3s 37ms/step - loss: 0.1994 - accuracy: 0.9194 - metrics_recall: 0.8712 - metrics_precision: 0.9009 - metrics_f1: 0.8761 - val_loss: 0.7123 - val_accuracy: 0.6973 - val_metrics_recall: 0.4725 - val_metrics_precision: 0.5373 - val_metrics_f1: 0.4866\n",
            "Epoch 24/30\n",
            "91/91 [==============================] - 3s 38ms/step - loss: 0.1930 - accuracy: 0.9211 - metrics_recall: 0.8539 - metrics_precision: 0.9025 - metrics_f1: 0.8696 - val_loss: 0.7232 - val_accuracy: 0.6940 - val_metrics_recall: 0.6072 - val_metrics_precision: 0.5321 - val_metrics_f1: 0.5535\n",
            "Epoch 25/30\n",
            "91/91 [==============================] - 3s 38ms/step - loss: 0.1980 - accuracy: 0.9169 - metrics_recall: 0.8681 - metrics_precision: 0.8867 - metrics_f1: 0.8717 - val_loss: 0.7825 - val_accuracy: 0.7206 - val_metrics_recall: 0.4641 - val_metrics_precision: 0.5901 - val_metrics_f1: 0.5034\n",
            "Epoch 26/30\n",
            "91/91 [==============================] - 3s 37ms/step - loss: 0.1838 - accuracy: 0.9304 - metrics_recall: 0.8886 - metrics_precision: 0.9150 - metrics_f1: 0.8967 - val_loss: 0.8181 - val_accuracy: 0.7140 - val_metrics_recall: 0.4353 - val_metrics_precision: 0.5902 - val_metrics_f1: 0.4834\n",
            "Epoch 27/30\n",
            "91/91 [==============================] - 3s 38ms/step - loss: 0.1945 - accuracy: 0.9228 - metrics_recall: 0.8666 - metrics_precision: 0.9076 - metrics_f1: 0.8789 - val_loss: 0.7581 - val_accuracy: 0.6907 - val_metrics_recall: 0.6769 - val_metrics_precision: 0.5219 - val_metrics_f1: 0.5766\n",
            "Epoch 28/30\n",
            "91/91 [==============================] - 3s 37ms/step - loss: 0.1778 - accuracy: 0.9240 - metrics_recall: 0.8629 - metrics_precision: 0.9145 - metrics_f1: 0.8798 - val_loss: 0.7622 - val_accuracy: 0.7118 - val_metrics_recall: 0.4097 - val_metrics_precision: 0.5716 - val_metrics_f1: 0.4583\n",
            "Epoch 29/30\n",
            "91/91 [==============================] - 3s 38ms/step - loss: 0.1737 - accuracy: 0.9290 - metrics_recall: 0.8897 - metrics_precision: 0.9105 - metrics_f1: 0.8930 - val_loss: 0.8030 - val_accuracy: 0.7106 - val_metrics_recall: 0.5906 - val_metrics_precision: 0.5536 - val_metrics_f1: 0.5574\n",
            "Epoch 30/30\n",
            "91/91 [==============================] - 3s 38ms/step - loss: 0.1671 - accuracy: 0.9259 - metrics_recall: 0.8862 - metrics_precision: 0.8983 - metrics_f1: 0.8879 - val_loss: 0.7612 - val_accuracy: 0.6984 - val_metrics_recall: 0.5970 - val_metrics_precision: 0.5370 - val_metrics_f1: 0.5503\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd6a1dd0490>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJVL4SBLPB2P"
      },
      "source": [
        "#%tensorboard --logdir {logs_base_dir}"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_LnvWBcnoak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fc0969d-b3c8-4b73-ffe1-dee041006809"
      },
      "source": [
        "#results = model.evaluate(nppadded_testing, nptesting_labels, batch_size=batch_size)\n",
        "#print(\"test loss, test acc:\",results)\n",
        "\n",
        "(loss,accuracy, metrics_recall,metrics_precision,\n",
        "metrics_f1) = CNN16052102.evaluate(nppadded_testing, nptesting_labels, verbose=1)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "111/111 [==============================] - 1s 9ms/step - loss: 0.8088 - accuracy: 0.6676 - metrics_recall: 0.4779 - metrics_precision: 0.5171 - metrics_f1: 0.4824\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KgjIkhpKmHc"
      },
      "source": [
        "make some predictions of test data and save it to variable. verbose=0 -> do not generate output\n",
        "Gute Quelle: https://deeplizard.com/learn/video/2f-NjDUvZIE "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89GWuxryKlcM"
      },
      "source": [
        "CNN_predictions02 = CNN16052102.predict(x=nppadded_testing)\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3jPDaDJK_cN"
      },
      "source": [
        "#for p in CNN_predictions02:\n",
        " # print(p)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eC9efJy4Lp21"
      },
      "source": [
        "rounded predictions: give prediction value of most likely prediction (0 or 1). Printing the output of rounded prediction shows the prediction made by the model on the data (which output is most likely)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsG-TJuQLvtk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa8f1342-f305-482c-eb80-48d422a276f5"
      },
      "source": [
        "prediction_rounded02 = np.round(CNN_predictions02)\n",
        "#np.argmax(CNN_predictions02,axis=-1)\n",
        "\n",
        "#for p in prediction_rounded02:\n",
        " # print(p)\n",
        "\n",
        "\n",
        "print(nptesting_labels[500:520])\n",
        "print(prediction_rounded02[500:520])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1]\n",
            "[[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egTtgpXgg8a2"
      },
      "source": [
        "https://deeplizard.com/learn/video/km7pxKy4UHU\n",
        "\n",
        "Quelle der def plot_confusion_matrix: https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSDXf7-_MITy"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0AMs1EzhBU1"
      },
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                        normalize=False,\n",
        "                        title='Confusion matrix',\n",
        "                        cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2JgEnlghCtl"
      },
      "source": [
        "cm = confusion_matrix(y_true=nptesting_labels, y_pred=prediction_rounded02)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckmF29whhFmX"
      },
      "source": [
        "plot_labels = ['no hatespeech','hatespeech']"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "2mpSE96rhK7K",
        "outputId": "fad07823-07a7-43c0-90a5-db47b5ad14fe"
      },
      "source": [
        "plot_confusion_matrix(cm=cm, classes=plot_labels, title='CNN Confusion 90')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix, without normalization\n",
            "[[1791  539]\n",
            " [ 635  567]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}