{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN embedded.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNI90V8j4gk2el7ZJpZriic",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BiancaStadl/ProjektarbeitML/blob/main/CNN_embedded.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXDOlIBymF0V"
      },
      "source": [
        "GloVe embeddings taken from:\n",
        "\n",
        "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. [pdf] [bib]\n",
        "\n",
        "hatespeechdata taken from (https://hatespeechdata.com/): Wiegand, M., Siegel, M. and Ruppenhofer, J., 2018. Overview of the GermEval 2018 Shared Task on the Identification of Offensive Language. In: Proceedings of GermEval 2018, 14th Conference on Natural Language Processing (KONVENS 2018). Vienna, Austria: Research Gate. available on: https://github.com/uds-lsv/GermEval-2018-Data (last checked: 09.05.2021)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlBmABDxfqII"
      },
      "source": [
        "wiki detox..https://colab.research.google.com/github/tensorflow/fairness-indicators/blob/master/g3doc/tutorials/Fairness_Indicators_TFCO_Wiki_Case_Study.ipynb#scrollTo=y6T5tlXcdW7J "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3xfitNdliBI"
      },
      "source": [
        "#import matplotlib.pyplot as plt -> für evtl Visualisierungen\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import string\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from keras import losses \n",
        "from keras import optimizers \n",
        "from keras import metrics \n",
        "\n",
        "#!pip install Tokenizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "#!pip install pad_sequences\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import preprocessing\n",
        "#from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTWJQ1iga_vS"
      },
      "source": [
        "Maximale Satzlänge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bq08Me5la_Cc"
      },
      "source": [
        "\n",
        "max_length = 60"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVYBMvYSotTH"
      },
      "source": [
        "url = \"https://github.com/uds-lsv/GermEval-2018-Data/archive/master.zip\"\n",
        "\n",
        "dataset = tf.keras.utils.get_file(\"GermEval-2018-Data-master.zip\", url, \n",
        "                                   extract=True, cache_dir='.',\n",
        "                                    cache_subdir='')\n",
        "\n",
        "dataset_dir = os.path.join(os.path.dirname(dataset), 'GermEval-2018-Data-master')\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cS14OUtfo34V"
      },
      "source": [
        "#os.listdir(dataset_dir)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2X429K6hpOVm"
      },
      "source": [
        "training_file = os.path.join(dataset_dir, 'germeval2018.training.txt')\n",
        "\n",
        "testing_file = os.path.join(dataset_dir, 'germeval2018.test.txt')\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uq8fG3LNtn_m"
      },
      "source": [
        "###Aufbereitung\n",
        "txt-Dateien lesen, und dabei jede Zeile splitten und teilen\n",
        "Twitter-Handler entfernen?\n",
        "Labels von Sätzen trennen, Labels in eigenen Array packen.\n",
        "\n",
        "####Ressourcen\n",
        "* https://www.w3schools.com/python/gloss_python_if_statement.asp\n",
        "* https://stackabuse.com/using-regex-for-text-manipulation-in-python/\n",
        "* https://www.tutorialspoint.com/python/string_splitlines.htm \n",
        "* https://note.nkmk.me/en/python-split-rsplit-splitlines-re/ \n",
        "* https://www.w3schools.com/python/python_regex.asp \n",
        "\n",
        "gäbe bei keras tf.keras.preprocessing.text_dataset_from_directory, aber dafür müssten die Daten auf bestimmte Weise in Verzeichnis organisiert sein, hier nicht der Fall.\n",
        "\n",
        "\n",
        "Einteilung der Daten: Testdaten\n",
        "Trainingsdaten -> noch ca 500 für Validierungsdaten\n",
        "\n",
        "labels -> \"other\", also nicht-negative Aussagen bekommen \"0\", negative Aussagen bekommen \"1\"\n",
        "\n",
        " Regex für Emojis  ->\n",
        "\n",
        "(\\u00a9|\\u00ae|[\\u2000-\\u3300]|\\ud83c[\\ud000-\\udfff]|\\ud83d[\\ud000-\\udfff]|\\ud83e[\\ud000-\\udfff])\n",
        "\n",
        "genommen von https://www.regextester.com/106421 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Py_cwD4eZkXo"
      },
      "source": [
        "def remove_clutter(string):\n",
        "   string = re.sub(\"@[^\\s]+\",\" \",string)\n",
        "   string = re.sub(\"#[^\\s]+\",\" \", string)\n",
        "   string = re.sub(\"\\u00a9\",\" \", string)\n",
        "   string = re.sub(\"\\u00ae\",\" \", string)\n",
        "   string = re.sub(\"[\\u2000-\\u3300]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83c[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83d[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83e[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"😜\", \" \",string)\n",
        "   string = re.sub(\"🍫\", \" \",string)\n",
        "   string = re.sub(\"😁\", \" \",string)\n",
        "   string = re.sub(\"🐖\", \" \",string)\n",
        "   string = re.sub(\"😡\", \" \",string)\n",
        "   string = re.sub(\"😇\", \" \",string)\n",
        "   string = re.sub(\"😬\", \" \",string)\n",
        "   string = re.sub(\"😃\", \" \",string)\n",
        "   string = re.sub(\"😂\", \" \",string)\n",
        "   string = re.sub(\"💙\", \" \",string)  \n",
        "   string = re.sub(\"😛\", \" \",string)\n",
        "   string = re.sub(\"🙏\", \" \",string)\n",
        "   string = re.sub(\"👍\", \" \",string)\n",
        "   string = re.sub(\"🖕\", \" \",string)\n",
        "   string = re.sub(\"😉\", \" \",string)\n",
        "   string = re.sub(\"💩\", \" \",string)\n",
        "   string = re.sub(\"🤢\", \" \",string)\n",
        "   string = re.sub(\"👏\", \" \",string)\n",
        "   string = re.sub(\"😨\", \" \",string)\n",
        "   string = re.sub(\"🤣\", \" \",string)\n",
        "   string = re.sub(\"🤡\", \" \",string)\n",
        "   string = re.sub(\"😈\", \" \",string)\n",
        "   string = re.sub(\"💃🏽\", \" \",string)\n",
        "   string = re.sub(\"👹\", \" \",string)\n",
        "   string = re.sub(\"🤘\", \" \",string)\n",
        "   string = re.sub(\"😱\", \" \",string)\n",
        "   string = re.sub(\"🤔\", \" \",string) \n",
        "   string = re.sub(\"🌈\", \" \",string) \n",
        "   string = re.sub(\"💕\", \" \",string) \n",
        "   string = re.sub(\"👩‍❤️‍👩\", \" \",string) \n",
        "   string = re.sub(\"😍\", \" \",string) \n",
        "   string = re.sub(\"👆\", \" \",string) \n",
        "   string = re.sub(\"😖\", \" \",string) \n",
        "   string = re.sub(\"👇\", \" \",string) \n",
        "   string = re.sub(\"🔥\", \" \",string) \n",
        "   string = re.sub(\"😘\", \" \",string) \n",
        "   string = re.sub(\"🎉\", \" \",string) \n",
        "   string = re.sub(\"🤬\", \" \",string) \n",
        "   string = re.sub(\"👊\", \" \",string)\n",
        "   string = re.sub(\"🇩🇪\", \" \",string)  \n",
        "   string = re.sub(\"💔\", \" \",string)\n",
        "   string = re.sub(\"🙈\", \" \",string)\n",
        "   string = re.sub(\"🤯\", \" \",string)\n",
        "   string = re.sub(\"🐟\", \" \",string)\n",
        "   string = re.sub(\"🛶\", \" \",string)\n",
        "   string = re.sub(\"😊\", \" \",string)\n",
        "   string = re.sub(\"😓\", \" \",string)\n",
        "   string = re.sub(\"😳\", \" \",string)\n",
        "   string = re.sub(\"🚀\", \" \",string)\n",
        "   string = re.sub(\"👎\", \" \",string)\n",
        "   string = re.sub(\"😎\", \" \",string)\n",
        "   string = re.sub(\"🐸\", \" \",string)\n",
        "   string = re.sub(\"📈\", \" \",string)\n",
        "   string = re.sub(\"🙂\", \" \",string)\n",
        "   string = re.sub(\"😅\", \" \",string)\n",
        "   string = re.sub(\"😆\", \" \",string)\n",
        "   string = re.sub(\"🙎🏿\", \" \",string)\n",
        "   string = re.sub(\"👎🏽\", \" \",string)\n",
        "   string = re.sub(\"🤭\", \" \",string)\n",
        "   string = re.sub(\"😤\", \" \",string)\n",
        "   string = re.sub(\"😚\", \" \",string)\n",
        "   string = re.sub(\"😊\", \" \",string)\n",
        "   string = re.sub(\"😲\", \" \",string)\n",
        "   string = re.sub(\"🤮\", \" \",string)\n",
        "   string = re.sub(\"🙄\", \" \",string)\n",
        "   string = re.sub(\"🤑\", \" \",string)\n",
        "   string = re.sub(\"🎅\", \" \",string)\n",
        "   string = re.sub(\"👋\", \" \",string)\n",
        "   string = re.sub(\"💪\", \" \",string)\n",
        "   string = re.sub(\"😄\", \" \",string)\n",
        "   string = re.sub(\"🧐\", \" \",string)\n",
        "   string = re.sub(\"😠\", \" \",string)\n",
        "   string = re.sub(\"🎈\", \" \",string)\n",
        "   string = re.sub(\"🚂\", \" \",string)\n",
        "   string = re.sub(\"😊\", \" \",string)\n",
        "   string = re.sub(\"🚇\", \" \",string)\n",
        "   string = re.sub(\"🚊\", \" \",string)\n",
        "   string = re.sub(\"🤷\", \" \",string)\n",
        "   string = re.sub(\"😥\", \" \",string)\n",
        "   string = re.sub(\"🙃\", \" \",string)\n",
        "   string = re.sub(\"🔩\", \" \",string)\n",
        "   string = re.sub(\"🔧\", \" \",string)\n",
        "   string = re.sub(\"🔨\", \" \",string)\n",
        "   string = re.sub(\"🛠\", \" \",string)\n",
        "   string = re.sub(\"💓\", \" \",string)\n",
        "   string = re.sub(\"💡\", \" \",string)\n",
        "   string = re.sub(\"🍸\", \" \",string)\n",
        "   string = re.sub(\"🥃\", \" \",string)\n",
        "   string = re.sub(\"🥂\", \" \",string)\n",
        "   string = re.sub(\"😷\", \" \",string)\n",
        "   string = re.sub(\"🤐\", \" \",string)\n",
        "   string = re.sub(\"🌎\", \" \",string)\n",
        "   string = re.sub(\"👑\", \" \",string)\n",
        "   string = re.sub(\"🤛\", \" \",string)\n",
        "   string = re.sub(\"😀\", \" \",string)\n",
        "   string = re.sub(\"🛤\", \" \",string)\n",
        "   string = re.sub(\"🎄\", \" \",string)\n",
        "   string = re.sub(\"📴\", \" \",string)\n",
        "   string = re.sub(\"🌭\", \" \",string)\n",
        "   string = re.sub(\"🤕\", \" \",string)\n",
        "   string = re.sub(\"😭\", \" \",string)\n",
        "   string = re.sub(\"🍾\", \" \",string)\n",
        "   string = re.sub(\"🍞\", \" \",string)\n",
        "   string = re.sub(\"🤦\", \" \",string)\n",
        "   string = re.sub(\"🤯\", \" \",string)\n",
        "   string = re.sub(\"🕯️\", \" \",string)\n",
        "\n",
        "   string = re.sub(\"OTHER|OFFENSE|ABUSE|INSULT\",\" \",string)\n",
        "   return string"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5asMgo4LtnRg"
      },
      "source": [
        "statementsForTraining = []\n",
        "sentimentsForTraining = []\n",
        "\n",
        "\n",
        "fileToRead = open(training_file, 'r')\n",
        "\n",
        "while True:\n",
        "  #next line in file\n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  findSentiment = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "\n",
        "\n",
        "  statementsForTraining.append(line)\n",
        "   #sentimentsForTraining.append(findSentiment.group(0))\n",
        "\n",
        "  if findSentiment.group(0) == \"OTHER\":  \n",
        "    sentimentsForTraining.append(0)\n",
        "  else:\n",
        "    sentimentsForTraining.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        " #print(\"{}: {}\".format(count,line.strip()))\n",
        "  \n",
        " # print(sentiment.group(0))\n",
        " \n",
        "fileToRead.close()\n",
        "\n",
        "training_sentences = statementsForTraining\n",
        "training_labels = sentimentsForTraining\n",
        "\n",
        "#print(training_sentences[9])\n",
        "#print(training_labels[9])\n",
        "\n",
        "#print(len(training_sentences))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsqZPENb98gD"
      },
      "source": [
        "##do the same with testdata\n",
        "statementsForTesting = []\n",
        "sentimentsForTesting = []\n",
        "\n",
        "fileToRead = open(testing_file, 'r')\n",
        "\n",
        "while True:\n",
        "  #next line in file\n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  sent = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "\n",
        "    \n",
        "\n",
        "  statementsForTesting.append(line)\n",
        "  #print(len(line))\n",
        "  #sentimentsForTesting.append(sent.group(0))\n",
        "\n",
        "  if sent.group(0) == \"OTHER\": \n",
        "    sentimentsForTesting.append(0)\n",
        "  else:\n",
        "    sentimentsForTesting.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        "\n",
        "fileToRead.close()\n",
        "\n",
        "\n",
        "testing_sentences = statementsForTesting\n",
        "testing_labels = sentimentsForTesting\n",
        "#print(len(testing_sentences))\n",
        "#print(testing_sentences)   \n",
        "#print(testing_labels)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRUvDLD5bMbO"
      },
      "source": [
        "Padding -> im Prinzip die Sätze alle auf die gleiche Länge bringen (in Theorieteil näher drauf eingehen) -> maxlen-Paramter ist für pad_sequences vorhanden, wenn nicht gesetzt -> alles wird auf die Länge des längsten Satzes aufgefüllt -> print(padded(shape)) gibt aus, wie viele Datensätze padded wurden und gibt an, wie viele Tokens der längste Datensatz hat\n",
        "print(padded[x]) gibt einen Satz aus (bereits tokenisiert)\n",
        "\n",
        "Padding -> sowohl für Trainigs- als auch für Testdaten\n",
        "\n",
        "Und: Daten als numpy-Arrays speichern (notwendig für tensorflow).\n",
        "\n",
        " -> Tokenizer https://towardsdatascience.com/text-classification-in-keras-part-2-how-to-use-the-keras-tokenizer-word-representations-fd571674df23 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3hFi7waTv5m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "794fba8a-df81-4c7c-c1ba-d2d97a03f4c4"
      },
      "source": [
        "tokenizer = Tokenizer(oov_token=\"OOV\")\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "\n",
        "#creating a word index - nur die Trainigsdaten\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "validation_size = 500\n",
        "\n",
        "\n",
        "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "padded_training = pad_sequences(training_sequences, maxlen=max_length, padding='post')\n",
        "print(len(padded_training))\n",
        "\n",
        "validation_sequences = padded_training[0:validation_size]\n",
        "validation_labels = training_labels[0:validation_size]\n",
        "\n",
        "padded_training = padded_training[validation_size:]\n",
        "training_labels = training_labels[validation_size:]\n",
        "\n",
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
        "padded_testing = pad_sequences(testing_sequences, maxlen=max_length,  padding='post')\n",
        "\n",
        "#print(validation_sequences[499])\n",
        "print(padded_training[0])\n",
        "#print(len(validation_labels))\n",
        "#print(len(training_labels))\n",
        "\n",
        "\n",
        "nppadded_training = np.array(padded_training)\n",
        "nptraining_labels = np.array(training_labels)\n",
        "\n",
        "nppadded_validation = np.array(validation_sequences)\n",
        "npvalidation_labels = np.array(validation_labels)\n",
        "\n",
        "nppadded_testing = np.array(padded_testing)\n",
        "nptesting_labels = np.array(testing_labels)\n",
        "\n",
        "\n",
        "print(len(nppadded_training))\n",
        "print(len(nptraining_labels))\n",
        "print(len(word_index))\n",
        "\n",
        "#print(statementsForTraining[2])\n",
        "#print(nppadded_training[4])\n",
        "#print(nppadded_training.shape)\n",
        "#print(nptraining_labels[4])\n",
        "#print(nppadded_testing.shape)\n",
        "#print(word_index) \n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5009\n",
            "[  12 3982   11   41 6706 1040    4    5  202   39    3 2922   49 1360\n",
            "  810  495 3983    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0]\n",
            "4509\n",
            "4509\n",
            "15059\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tL3owrc8THkT"
      },
      "source": [
        "\n",
        "Dann: Embedding mit entweder word2vec oder glove\n",
        "Word2vec-Daten sind hier: http://vectors.nlpl.eu/repository/#\n",
        "Glove -> https://nlp.stanford.edu/projects/glove/ Da mal den Twitter-Vector runtergeladen\n",
        "Wenn Daten in GoogleDrive sind (wäre auch via url möglich..), muss Drive gemounted werden ( https://buomsoo-kim.github.io/colab/2020/05/09/Colab-mounting-google-drive.md/ ) aber auch hier https://enjoymachinelearning.com/posts/colab-with-google-drive/\n",
        "\n",
        "Die Word2vec vectors: http://vectors.nlpl.eu/repository/# \n",
        "\n",
        "glove-zitat:\n",
        "Citing GloVe\n",
        "\n",
        "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. [pdf] [bib]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zuO7T9ZTG57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f8d7f2d-08bf-48d6-e230-1067a76333ef"
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount(\"/content/drive\")\n",
        "os.listdir(\"/content/drive/MyDrive/Colab Notebooks\")\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['germeval_training.txt',\n",
              " 'glove.twitter.27B.50d.txt',\n",
              " 'glove.twitter.27B.200d.txt',\n",
              " 'glove.6B.200d.txt',\n",
              " 'glove.840B.300d.txt',\n",
              " 'tensorboard.gdoc',\n",
              " 'keras.gdoc',\n",
              " 'Vectorization CNN embedded_limited_vocab.ipynb',\n",
              " 'glove.42B.300d.txt',\n",
              " 'Embedding Glove Vergleich.ipynb',\n",
              " 'CNN embedded_limited_vocab.ipynb',\n",
              " 'LSTM_limited_vocab.ipynb',\n",
              " 'LSTM.ipynb',\n",
              " 'CNN embedded.ipynb']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7ToKO-sZLHK"
      },
      "source": [
        "\n",
        "Keras-Doc : https://keras.io/examples/nlp/pretrained_word_embeddings/#load-pretrained-word-embeddings \n",
        "embedding mit initializers.. weights müsste auch funktionieren\n",
        "\n",
        "Diese erstellte Matrix mit Embedding dann in die Embedding-Schicht einbinden,  Trainable auf False, weil sich die Werte nicht durch Training anpassen sollen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AShIVfC7ZQAH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78ccc1ad-cb3c-4b9b-8fa0-e88599f94840"
      },
      "source": [
        "#Größe Vokabel -> wordindex + 2 (weil padding + OOV) \n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "vocabulary_size = len(word_index)+2\n",
        "\n",
        "# dann erstell ich ein Wörterbuch mit Namen \"embedding_vector\", dort sind dann\n",
        "#die keys drinnen, die in glove-Datei drinnen sind mit dem entsprechenden Key\n",
        "\n",
        "embedding_index_glove = {}\n",
        "f = open('/content/drive/MyDrive/Colab Notebooks/glove.twitter.27B.50d.txt')\n",
        "for line in f:\n",
        "  value = line.split()\n",
        "  word = value[0]\n",
        "  coef = np.asarray(value[1:],dtype='float32')\n",
        "  embedding_index_glove[word] = coef\n",
        "\n",
        "print(\"%d gefunden: \"% len(embedding_index_glove))\n",
        "\n",
        "#Dann noch eine Embedding-Matrix erstellen\n",
        "#zweiter Wert = Embedding-Dimension der Datei, in dem Fall 50\n",
        "\n",
        "glove_matrix = np.zeros((vocabulary_size,50))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    embedding_value = embedding_index_glove.get(word)\n",
        "    if embedding_value is not None:\n",
        "      glove_matrix[index] = embedding_value\n",
        "      hits+=1\n",
        "    else:\n",
        "      misses+=1\n",
        "\n",
        "print(\"hits %d and %d misses\"%(hits,misses))\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1193514 gefunden: \n",
            "hits 6747 and 8312 misses\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZmvOfwhV4N5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d289ee9-fe5f-4634-f959-32ef376c7908"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "print(\"vocab size: %d\"%vocabulary_size)\n",
        "CNN1605210250d = tf.keras.Sequential()\n",
        "#Embedding -> hier dann auf das embedding verweisen, Input_dim -> die Anzahl der Wörter im word_index, output -> in dem Fall passend zum verwendeten Vektor\n",
        "#input-length -> auf 60  gepadded, trainable -> nein, weil nichts verändert werden soll\n",
        "#embeddings_initializer=keras.initializers.Constant(glove_matrix) vs weights = [glove_matrix]\n",
        "#Convolutional layers => filters = neurons.. mit 100? 265?\n",
        "#CNN1605210250d.add(tf.keras.layers.Embedding(input_dim=vocabulary_size, output_dim=200, input_length=max_length))\n",
        "CNN1605210250d.add(tf.keras.layers.Embedding(vocabulary_size, output_dim=50, input_length=60, embeddings_initializer = keras.initializers.Constant(glove_matrix), trainable= False))\n",
        "CNN1605210250d.add(tf.keras.layers.Dropout(0.4))\n",
        "CNN1605210250d.add(tf.keras.layers.Conv1D(filters=120, kernel_size=3, padding=\"valid\", activation=\"relu\"))\n",
        "CNN1605210250d.add(tf.keras.layers.MaxPooling1D())\n",
        "CNN1605210250d.add(tf.keras.layers.Conv1D(filters=120, kernel_size=3, padding=\"valid\", activation=\"relu\"))\n",
        "CNN1605210250d.add(tf.keras.layers.GlobalAveragePooling1D())\n",
        "CNN1605210250d.add(tf.keras.layers.Flatten())\n",
        "CNN1605210250d.add(tf.keras.layers.Dense(260, activation=\"relu\"))\n",
        "CNN1605210250d.add(tf.keras.layers.Dropout(0.4))\n",
        "CNN1605210250d.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "CNN1605210250d.summary()\n",
        "\n",
        "#nppadded_training = np.asmatrix(nppadded_training) not necessary\n",
        "#nppadded_testing = np.asmatrix(nppadded_testing)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab size: 15061\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 60, 50)            753050    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 60, 50)            0         \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 58, 120)           18120     \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 29, 120)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 27, 120)           43320     \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 120)               0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 120)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 260)               31460     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 260)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 261       \n",
            "=================================================================\n",
            "Total params: 846,211\n",
            "Trainable params: 93,161\n",
            "Non-trainable params: 753,050\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEr4OzT-iHDe"
      },
      "source": [
        "#model.layers[2].get_weights()[0].shape\n",
        "#weights=np.random.rand(5,200,100)\n",
        "#bias=np.random.rand(100)\n",
        "#model.layers[2].set_weights([weights, bias])\n",
        "\n",
        "#model.layers[2].get_weights()[0]\n",
        "#https://androidkt.com/set-custom-weights-keras-using-numpy-array/"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UB7_3VPYesr9"
      },
      "source": [
        "F1-Score für jede Epoche https://aakashgoel12.medium.com/how-to-add-user-defined-function-get-f1-score-in-keras-metrics-3013f979ce0d\n",
        "\n",
        "Sehr gute Ressource für die verschiedenen Scores und Metriken https://neptune.ai/blog/evaluation-metrics-binary-classification#10  das und aakas verwendet\n",
        "\n",
        "hier: je eine Funktion für Recall, Precision, f1 https://neptune.ai/blog/keras-metrics \n",
        "\n",
        "https://keras.rstudio.com/reference/k_ones_like.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygyrbFJaMV9B"
      },
      "source": [
        "import keras.backend as K\n",
        "\n",
        "def metrics_recall(data_true, data_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(data_true,0,1)))\n",
        "\n",
        "    recall = true_positives / (possible_positives+K.epsilon())\n",
        "    return recall\n",
        "\n",
        "\n",
        "def metrics_precision(data_true, data_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "\n",
        "    positives_predicted = K.sum(K.round(K.clip(data_pred,0,1)))\n",
        "    precision = true_positives / (positives_predicted+K.epsilon())\n",
        "    return precision\n",
        "\n",
        "\n",
        "def metrics_f1(data_true, data_pred):\n",
        "    precision_data = metrics_precision(data_true, data_pred)\n",
        "    recall_data = metrics_recall(data_true, data_pred)\n",
        "    return 2*(precision_data*recall_data)/(precision_data+recall_data+K.epsilon())"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1ctlBrnuYJz"
      },
      "source": [
        "https://aakashgoel12.medium.com/how-to-add-user-defined-function-get-f1-score-in-keras-metrics-3013f979ce0d"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AfPD3_bWCm0"
      },
      "source": [
        "CNN1605210250d.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',metrics_recall,metrics_precision,metrics_f1])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpChKUY-QEWI"
      },
      "source": [
        "https://www.tensorflow.org/tensorboard/tensorboard_in_notebooks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJfMgUhHBoD1"
      },
      "source": [
        "#%load_ext tensorboard\n",
        "#nur einmal pro Sitzung notwendig\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ISmMXLqP8Hc"
      },
      "source": [
        "\n",
        "logs_base_dir = \"./logs\"\n",
        "callbackForTB = tf.keras.callbacks.TensorBoard(logs_base_dir)\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ehh-EMXUQh8r"
      },
      "source": [
        "Early Stopping as defined in keras tensorflow documentation\n",
        "https://www.tensorflow.org/guide/keras/train_and_evaluate "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BY_t-PeQEjy"
      },
      "source": [
        "callbackEarlyStopping = [\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_loss\",\n",
        "        mode=\"min\",\n",
        "        patience=3,\n",
        "        verbose=1,\n",
        "    )\n",
        "]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2CHbXiP1LsF"
      },
      "source": [
        "training_epochs = 30\n",
        "batch_size = 40\n",
        "validation_split=0.2"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abV-QAxfW48r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2d0e9a4-b52a-4de5-96c6-b19e2e5b79b1"
      },
      "source": [
        "#Werte der Convolutional-Schichten variieren (Filter), Batch-Size variieren, kernel-size..\n",
        "CNN1605210250d.fit(nppadded_training, nptraining_labels, batch_size=batch_size, validation_split=validation_split, epochs=training_epochs, callbacks=[callbackForTB])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "91/91 [==============================] - 4s 29ms/step - loss: 0.6520 - accuracy: 0.6582 - metrics_recall: 0.0555 - metrics_precision: 0.0228 - metrics_f1: 0.0323 - val_loss: 0.6362 - val_accuracy: 0.6718 - val_metrics_recall: 0.0000e+00 - val_metrics_precision: 0.0000e+00 - val_metrics_f1: 0.0000e+00\n",
            "Epoch 2/30\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.6408 - accuracy: 0.6579 - metrics_recall: 0.0000e+00 - metrics_precision: 0.0000e+00 - metrics_f1: 0.0000e+00 - val_loss: 0.6201 - val_accuracy: 0.6707 - val_metrics_recall: 0.0000e+00 - val_metrics_precision: 0.0000e+00 - val_metrics_f1: 0.0000e+00\n",
            "Epoch 3/30\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.6333 - accuracy: 0.6561 - metrics_recall: 0.0139 - metrics_precision: 0.0774 - metrics_f1: 0.0224 - val_loss: 0.6052 - val_accuracy: 0.6752 - val_metrics_recall: 0.0196 - val_metrics_precision: 0.1739 - val_metrics_f1: 0.0350\n",
            "Epoch 4/30\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.5999 - accuracy: 0.6770 - metrics_recall: 0.0840 - metrics_precision: 0.2514 - metrics_f1: 0.1032 - val_loss: 0.6137 - val_accuracy: 0.6996 - val_metrics_recall: 0.3018 - val_metrics_precision: 0.5959 - val_metrics_f1: 0.3852\n",
            "Epoch 5/30\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.6109 - accuracy: 0.6746 - metrics_recall: 0.1077 - metrics_precision: 0.3838 - metrics_f1: 0.1482 - val_loss: 0.5977 - val_accuracy: 0.7029 - val_metrics_recall: 0.1636 - val_metrics_precision: 0.7630 - val_metrics_f1: 0.2612\n",
            "Epoch 6/30\n",
            "91/91 [==============================] - 2s 22ms/step - loss: 0.5910 - accuracy: 0.6871 - metrics_recall: 0.2341 - metrics_precision: 0.5833 - metrics_f1: 0.3053 - val_loss: 0.5843 - val_accuracy: 0.6996 - val_metrics_recall: 0.1211 - val_metrics_precision: 0.7435 - val_metrics_f1: 0.2036\n",
            "Epoch 7/30\n",
            "91/91 [==============================] - 2s 22ms/step - loss: 0.5784 - accuracy: 0.6973 - metrics_recall: 0.2290 - metrics_precision: 0.6230 - metrics_f1: 0.3089 - val_loss: 0.5980 - val_accuracy: 0.6774 - val_metrics_recall: 0.4598 - val_metrics_precision: 0.5129 - val_metrics_f1: 0.4713\n",
            "Epoch 8/30\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.5766 - accuracy: 0.6963 - metrics_recall: 0.2928 - metrics_precision: 0.6241 - metrics_f1: 0.3688 - val_loss: 0.5968 - val_accuracy: 0.6896 - val_metrics_recall: 0.0504 - val_metrics_precision: 0.5652 - val_metrics_f1: 0.0912\n",
            "Epoch 9/30\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.5664 - accuracy: 0.6984 - metrics_recall: 0.1514 - metrics_precision: 0.6641 - metrics_f1: 0.2271 - val_loss: 0.5821 - val_accuracy: 0.6951 - val_metrics_recall: 0.3752 - val_metrics_precision: 0.5510 - val_metrics_f1: 0.4357\n",
            "Epoch 10/30\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.5666 - accuracy: 0.6928 - metrics_recall: 0.3552 - metrics_precision: 0.6178 - metrics_f1: 0.4335 - val_loss: 0.5760 - val_accuracy: 0.6996 - val_metrics_recall: 0.2547 - val_metrics_precision: 0.6202 - val_metrics_f1: 0.3516\n",
            "Epoch 11/30\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.5553 - accuracy: 0.7127 - metrics_recall: 0.3692 - metrics_precision: 0.6495 - metrics_f1: 0.4405 - val_loss: 0.5741 - val_accuracy: 0.6929 - val_metrics_recall: 0.2586 - val_metrics_precision: 0.5894 - val_metrics_f1: 0.3477\n",
            "Epoch 12/30\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.5584 - accuracy: 0.7016 - metrics_recall: 0.2912 - metrics_precision: 0.5690 - metrics_f1: 0.3646 - val_loss: 0.5785 - val_accuracy: 0.6973 - val_metrics_recall: 0.4601 - val_metrics_precision: 0.5350 - val_metrics_f1: 0.4821\n",
            "Epoch 13/30\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.5362 - accuracy: 0.7319 - metrics_recall: 0.4523 - metrics_precision: 0.7009 - metrics_f1: 0.5281 - val_loss: 0.5753 - val_accuracy: 0.7118 - val_metrics_recall: 0.3001 - val_metrics_precision: 0.6443 - val_metrics_f1: 0.3949\n",
            "Epoch 14/30\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.5167 - accuracy: 0.7455 - metrics_recall: 0.4598 - metrics_precision: 0.6954 - metrics_f1: 0.5372 - val_loss: 0.5755 - val_accuracy: 0.6962 - val_metrics_recall: 0.4571 - val_metrics_precision: 0.5491 - val_metrics_f1: 0.4861\n",
            "Epoch 15/30\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.5287 - accuracy: 0.7257 - metrics_recall: 0.4588 - metrics_precision: 0.6607 - metrics_f1: 0.5135 - val_loss: 0.5652 - val_accuracy: 0.7073 - val_metrics_recall: 0.3944 - val_metrics_precision: 0.5706 - val_metrics_f1: 0.4531\n",
            "Epoch 16/30\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.5095 - accuracy: 0.7414 - metrics_recall: 0.5090 - metrics_precision: 0.6731 - metrics_f1: 0.5513 - val_loss: 0.5736 - val_accuracy: 0.7018 - val_metrics_recall: 0.4773 - val_metrics_precision: 0.5637 - val_metrics_f1: 0.5070\n",
            "Epoch 17/30\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.5081 - accuracy: 0.7423 - metrics_recall: 0.5001 - metrics_precision: 0.6683 - metrics_f1: 0.5475 - val_loss: 0.5884 - val_accuracy: 0.6807 - val_metrics_recall: 0.5750 - val_metrics_precision: 0.5071 - val_metrics_f1: 0.5270\n",
            "Epoch 18/30\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.4756 - accuracy: 0.7716 - metrics_recall: 0.5761 - metrics_precision: 0.6866 - metrics_f1: 0.6083 - val_loss: 0.5740 - val_accuracy: 0.6907 - val_metrics_recall: 0.4651 - val_metrics_precision: 0.5275 - val_metrics_f1: 0.4853\n",
            "Epoch 19/30\n",
            "91/91 [==============================] - 2s 22ms/step - loss: 0.4783 - accuracy: 0.7719 - metrics_recall: 0.5197 - metrics_precision: 0.7511 - metrics_f1: 0.5944 - val_loss: 0.5765 - val_accuracy: 0.6807 - val_metrics_recall: 0.5038 - val_metrics_precision: 0.5053 - val_metrics_f1: 0.4925\n",
            "Epoch 20/30\n",
            "91/91 [==============================] - 2s 22ms/step - loss: 0.4794 - accuracy: 0.7628 - metrics_recall: 0.5590 - metrics_precision: 0.7176 - metrics_f1: 0.6075 - val_loss: 0.5738 - val_accuracy: 0.7140 - val_metrics_recall: 0.4414 - val_metrics_precision: 0.5865 - val_metrics_f1: 0.4886\n",
            "Epoch 21/30\n",
            "91/91 [==============================] - 2s 22ms/step - loss: 0.4755 - accuracy: 0.7683 - metrics_recall: 0.5385 - metrics_precision: 0.7425 - metrics_f1: 0.5985 - val_loss: 0.5925 - val_accuracy: 0.7018 - val_metrics_recall: 0.4078 - val_metrics_precision: 0.5655 - val_metrics_f1: 0.4623\n",
            "Epoch 22/30\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.4680 - accuracy: 0.7942 - metrics_recall: 0.6166 - metrics_precision: 0.7524 - metrics_f1: 0.6444 - val_loss: 0.5786 - val_accuracy: 0.6962 - val_metrics_recall: 0.4604 - val_metrics_precision: 0.5370 - val_metrics_f1: 0.4851\n",
            "Epoch 23/30\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.4435 - accuracy: 0.7878 - metrics_recall: 0.5977 - metrics_precision: 0.7394 - metrics_f1: 0.6443 - val_loss: 0.5880 - val_accuracy: 0.6818 - val_metrics_recall: 0.4147 - val_metrics_precision: 0.5144 - val_metrics_f1: 0.4462\n",
            "Epoch 24/30\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.4484 - accuracy: 0.7885 - metrics_recall: 0.5852 - metrics_precision: 0.7259 - metrics_f1: 0.6343 - val_loss: 0.5997 - val_accuracy: 0.6674 - val_metrics_recall: 0.5462 - val_metrics_precision: 0.4985 - val_metrics_f1: 0.5084\n",
            "Epoch 25/30\n",
            "91/91 [==============================] - 2s 22ms/step - loss: 0.4509 - accuracy: 0.7861 - metrics_recall: 0.6254 - metrics_precision: 0.7531 - metrics_f1: 0.6462 - val_loss: 0.6074 - val_accuracy: 0.6718 - val_metrics_recall: 0.5088 - val_metrics_precision: 0.5048 - val_metrics_f1: 0.4946\n",
            "Epoch 26/30\n",
            "91/91 [==============================] - 2s 22ms/step - loss: 0.4330 - accuracy: 0.7979 - metrics_recall: 0.6709 - metrics_precision: 0.7213 - metrics_f1: 0.6744 - val_loss: 0.5902 - val_accuracy: 0.7018 - val_metrics_recall: 0.3413 - val_metrics_precision: 0.5869 - val_metrics_f1: 0.4212\n",
            "Epoch 27/30\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.4134 - accuracy: 0.8027 - metrics_recall: 0.6488 - metrics_precision: 0.7603 - metrics_f1: 0.6810 - val_loss: 0.5840 - val_accuracy: 0.6729 - val_metrics_recall: 0.4538 - val_metrics_precision: 0.5030 - val_metrics_f1: 0.4654\n",
            "Epoch 28/30\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.4203 - accuracy: 0.8026 - metrics_recall: 0.5850 - metrics_precision: 0.7629 - metrics_f1: 0.6424 - val_loss: 0.6280 - val_accuracy: 0.6552 - val_metrics_recall: 0.5516 - val_metrics_precision: 0.4776 - val_metrics_f1: 0.5034\n",
            "Epoch 29/30\n",
            "91/91 [==============================] - 2s 22ms/step - loss: 0.4079 - accuracy: 0.8081 - metrics_recall: 0.6530 - metrics_precision: 0.7410 - metrics_f1: 0.6737 - val_loss: 0.6136 - val_accuracy: 0.6685 - val_metrics_recall: 0.5550 - val_metrics_precision: 0.4945 - val_metrics_f1: 0.5142\n",
            "Epoch 30/30\n",
            "91/91 [==============================] - 2s 22ms/step - loss: 0.4023 - accuracy: 0.8108 - metrics_recall: 0.6782 - metrics_precision: 0.7752 - metrics_f1: 0.7018 - val_loss: 0.6769 - val_accuracy: 0.6319 - val_metrics_recall: 0.6509 - val_metrics_precision: 0.4572 - val_metrics_f1: 0.5274\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7feb9b613590>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJVL4SBLPB2P"
      },
      "source": [
        "#%tensorboard --logdir {logs_base_dir}"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_LnvWBcnoak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36ddee1d-e1f5-4f64-b357-3741c7066a4c"
      },
      "source": [
        "#results = model.evaluate(nppadded_testing, nptesting_labels, batch_size=batch_size)\n",
        "#print(\"test loss, test acc:\",results)\n",
        "\n",
        "(loss,accuracy, metrics_recall,metrics_precision,\n",
        "metrics_f1) = CNN1605210250d.evaluate(nppadded_testing, nptesting_labels, verbose=1)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "111/111 [==============================] - 1s 6ms/step - loss: 0.6899 - accuracy: 0.6045 - metrics_recall: 0.5243 - metrics_precision: 0.4369 - metrics_f1: 0.4661\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KgjIkhpKmHc"
      },
      "source": [
        "make some predictions of test data and save it to variable. verbose=0 -> do not generate output\n",
        "Gute Quelle: https://deeplizard.com/learn/video/2f-NjDUvZIE "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89GWuxryKlcM"
      },
      "source": [
        "CNN_predictions08 = CNN1605210250d.predict(x=nppadded_testing)\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3jPDaDJK_cN"
      },
      "source": [
        "#for p in CNN_predictions08:\n",
        " # print(p)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eC9efJy4Lp21"
      },
      "source": [
        "rounded predictions: give prediction value of most likely prediction (0 or 1). Printing the output of rounded prediction shows the prediction made by the model on the data (which output is most likely)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsG-TJuQLvtk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59bffb7f-c8b9-48e9-91b4-2d2f55e25755"
      },
      "source": [
        "prediction_rounded08 = np.round(CNN_predictions08)\n",
        "#np.argmax(CNN_predictions08,axis=-1)\n",
        "\n",
        "#for p in prediction_rounded08:\n",
        " # print(p)\n",
        "\n",
        "\n",
        "print(nptesting_labels[500:520])\n",
        "print(prediction_rounded08[500:520])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1]\n",
            "[[0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egTtgpXgg8a2"
      },
      "source": [
        "https://deeplizard.com/learn/video/km7pxKy4UHU\n",
        "\n",
        "Quelle der def plot_confusion_matrix: https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSDXf7-_MITy"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0AMs1EzhBU1"
      },
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                        normalize=False,\n",
        "                        title='Confusion matrix',\n",
        "                        cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2JgEnlghCtl"
      },
      "source": [
        "cm = confusion_matrix(y_true=nptesting_labels, y_pred=prediction_rounded08)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckmF29whhFmX"
      },
      "source": [
        "plot_labels = ['no hatespeech','hatespeech']"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "2mpSE96rhK7K",
        "outputId": "fa5fcdc3-7bc5-4ebc-9ddc-e92b077d6f93"
      },
      "source": [
        "plot_confusion_matrix(cm=cm, classes=plot_labels, title='CNN Confusion 120 embedding glove 50d')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix, without normalization\n",
            "[[1508  822]\n",
            " [ 575  627]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAAEmCAYAAACzoiEDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd5wV1fnH8c93WTpIkaKACCoWNIqAgpoY7CVGLCii/qwJmqiJKcaaYI1GTWyxxBY1KiJgFCsiagQiCoigWAmgIKD03hae3x/nXByWZffusruzd/d587ov7p05M3Pu3LvPPfPMmTMyM5xzzqUjL+0KOOdcTeZB2DnnUuRB2DnnUuRB2DnnUuRB2DnnUuRB2DnnUuRBuIaQVF/Si5KWSBq8Fes5Q9Lr5Vm3XCbpWklPltO6ekmaVcz8xyTdGJ//SNLn5bHd0pDUQZJJyq/sbZcXSTMkHZ52PTI8CG+BpNMljZe0XNIcSa9K+mGcd238Ip6aKJ8fp3WIrx+Lr/dPlNlFUrEds4vb7lbqA7QGtjWzU8q6EjN7ysyOLIf6bEJSHUlD4h+ISepVaP5lkj6WtEzSdEmXFZrfQdJbklZK+qwq/ZFVBDMbZWa7pV2PyhK/Eyvi38VySQ8n5knSXyQtiI+/SFKa9S0ND8JFkPRb4E7gz4TA1R64D+idKLYQuE5SrWJWtRC4sZy3W1Y7Al+YWUE5rKuijAbOBOYWMU/AWUAz4GjgYkmnJeYPBCYC2wJXA0MktazY6rpKto+ZNYqPnyWm9wdOAPYB9gZ+ClyQRgXLxMz8kXgATYDlwCnFlLkWeAqYBJwdp+UDBnSIrx8D/kYIKD+O03YJu7zM261LCNKz4+NOoG6c1wuYBfwO+A6YA5wb510HrAXWxW2cH9/Dk4l1d4j1z4+vzwGmAcuA6cAZiemjE8sdCIwDlsT/D0zMexu4ARgT1/M60CKLz2AW0KuEMncD98TnuwJrgMaJ+aOAC4vZj7cDXwPfAg8A9Qvtxz8k9uMJwLHAF4Qf1qsKfReGAIPie/yAECwy89sAQ4F5cT/+KjGvfvyeLAI+AS4DZiXm7xvXtyyu/xngxmQ9E2VnAL8HJsfPYhBQLzH/D/G9zAZ+Fj/rXbawfzoC78TtvgHcm/muFPE9aQMMi/tlKvDzxPRVQPNC72c+UDu+Pg/4NL7/4cCOxXzexdX3v0D/xOvzgbGJ1/8HfAUsIPxAzwAOTzPOJB/eEt7cAUA94N8llDPgj8AASbW3UGYloVV7Uzlt92qgJ9CF8Ku/P3BNYv52hGDelvBFvFdSMzMbEOsxyEIr4pHiKiKpISHIHWNmjQmB9sMiyjUHXo5ltyX86LwsadtEsdOBc4FWQB1CoNgq8VDzR8CUOGlPYJqZLUsUmxSnF+UWQuDuQvhhbAv8KTF/O8JnkZn+EKGF3i1u94+SOibK9wYGA82Bp4HnJdWWlAe8GOvSFjgMuFTSUXG5AcDO8XEUcHbiPdYBngf+Fdc7GDi5hF1zKuEooSOhRXhOXNfRwG+Bw+P77VXCep4G3id8ptcSgtiWPEP40WpDSHn9WdKhZjYbeLdQnU8HhpjZOkm9gauAk4CWhB/NgSXU6x1JcyU9l0n7RXsS9nHGxs9eUmfg/vge2sT31K6E7VQqD8Kb2xaYb1kctpvZMEIL52fFFPsH0F7SMeWw3TOA683sOzObR2jhJv9A1sX568zsFUKrt6x5ww3AXpLqm9kcM5tSRJmfAF+a2b/MrMDMBgKfEQ4HM/5pZl+Y2SrgWULg21rXEr67/4yvGxFaf0lLgMaFF4wBvD/wGzNbGAP3n4FkamMdcJOZrSMEmRbAXWa2LO6HTwg/ghkTzGxILP83QgDvCewHtDSz681srZlNIwT0zLZOjdtZaGYzCT9mGT2B2sCd8fMcQjjSKM7dZjbbzBYSgn9mX59K+BymmNlKwv4rkqT2sd5/inUeTWjpFlV2B+Ag4HIzW21mHwIPE9JGEIJ5v1hW8X0/HeddCNxsZp/G7/yfgS6SdtxC1X5MaIXvTmjNv5Q4OVj4818CNIrb7AO8ZGbvmNkaQsNpw5befxo8CG9uAdCiFGd/ryG0UOsVNTN+8DfEx9Zutw3hsCrjqzht4zoKBfGVhC9oqZjZCqAv4Q9ljqSXJe2eRX0ydWqbeJ3M75apPkmSLib8kf8k7lsIPzbbFCq6DeFwurCWQANggqTFkhYDr8XpGQvMbH18vir+/21i/io2fR8zM0/MbAPftwx3BNpkthO3dRUh308sMzOxnuS+bAN8Y/F4uoj5RdnSvi68neTzwtoAC2OwLql8pmxyPyc//6HAAZK2Bw4mBL9Rcd6OwF2J/bKQkPdPfnc2ikF0rZktBn5NaO3vEWcX/vy3AZbHfbfJe4/f7QVbevNp8CC8uXcJ+cUTsilsZiMIubBfFlPsn0BTwqHX1mx3NuHLm9E+TiuLFYRglLFdcqaZDTezI4DtCa3bh7KoT6ZO35SxTsWSdB5wBXCYmSW7ck0BdpKUbPnuw/fpiqT5hCC6p5k1jY8mZrY1Pw47JOqYRzjcnU3445+e2E5TM2tsZsfG4nOSyxL2HYl5bQud5U/OL405bHoIvsOWCsayzSUlvxtbKj87lk3u942fv5ktIpwH6EtIRTyT+FGZCVxQaN/UN7P/ZvmejBC0IXzOySOT5Ge/yT6O7yuZLkudB+FCzGwJIQ94r6QTJDWI+b1jJN26hcWuJpz42NI6Cwj5v8u3crsDgWsktZTUIpYvax/VD4GDJbWX1AS4MjNDUmtJvWNueA2hpVHUIdwrwK6xW12+pL5AZ+ClslRIUl1JmSOKOpLqZYKQpDMIh6xHxMP6jczsi/h+BsRlTiTkRIcW3kZsqT4E3CGpVVx320Setiy6STopHsVcSthnYwl51WWSLlfop11L0l6S9ovLPQtcKamZpHbAJYl1vgsUAL+K34OTCOcAyuJZ4FxJe8Qg9MctFTSzr4DxwLUK3QYPYNP0UrLsTMJJsZvjft+bcC4i+Z18mnDk0ofvUxEQToZeKSmTu20iqciuk5L2lNQl7r9GwF8Jgf7TWOQJ4Lfxc2xDODn9WJw3BDhO0g9jnv16qljcq1KVqSrM7K+EExnXEHK+M4GLCSdKiio/hvAHV5yBhF/lrdnujYQ/kMnAR4Qz51l3gSu0rRGEM+iTgQlsGjjzYj1mEw4Tfwz8ooh1LACOI3zpFxB+iI4zs/llqRPwOaGV2pZwtnwV37e0byS0YMbp+76iDySWPQ3oTjjTfgvQJ+bNi3I54ehlrKSlhB4AW9Pn9gVCa28RIUd/Uszjrifsny6EnhHzCTnTJnG56wiH79MJLcZ/ZVZoZmsJR07nED6DvsBzZamcmb1KyDe/RXzfcdaaLSxyBuFE8QLCfh9UTNl+hFztbMJJ5QFm9kZi/jCgEzDXzDaePDOzfwN/AZ6Jn8HHwJbOm7SOdVhK6LHTgfA9Wxfn/4OQA/8oruflOI2Yw7+I8AMwh/AZbfGCmDRo05STc666k7QHIVjVzeYEtKRBwGexl40rZ94Sdq4GkHRiTPc0I7RAX9xSAJa0n6SdJeXF7m292cJRoNt6HoSdqxkuIFx88j9gPUWklxK2I1xos5yQxviFmU2s6ArWVJ6OcM65FHlL2DnnUpSzw9FVd8qvb6qz2QVfroLsulObkgu5cjP3m5ksXrSgXEY6q7XNjmYFq4otY6vmDTezo8tje+XNg3AVpTqNqbvbqSUXdOXiwUHXp12FGqX/SYeW27qsYFWJfyurP7y3RbltsJx5EHbO5TYJ8oobUbZq8yDsnMt9yt3TWx6EnXM5zlvCzjmXrty5m9FmPAg753Kb8HSEc86lx9MRzjmXLk9HOOdcWuTpCOecS43wdIRzzqXHW8LOOZceAbW8Jeycc+nxE3POOZcWT0c451y6/MScc86lRPJ0hHPOpcpbws45l5bczgnnbs2dcy4jk5LY0qPExfWopO8kfVzEvN9JMkkt4mtJulvSVEmTJXVNlD1b0pfxcXY2Vfcg7JzLbRLk5Rf/KNljwGb3oJO0A3Ak8HVi8jFAp/joD9wfyzYHBgA9gP2BAZKalbRhD8LOudy3lS1hM3sHWFjErDuAPwCWmNYbeMKCsUBTSdsDRwEjzGyhmS0CRlBEYC/Mc8LOudxX8om5FpLGJ14/aGYPFreApN7AN2Y2SZsG8rbAzMTrWXHalqYXy4Owcy63KasTc/PNrHv2q1QD4CpCKqJCeTrCOZf7tjIdUYSdgY7AJEkzgHbAB5K2A74BdkiUbRenbWl6sTwIO+dymoC8vLxiH6VlZh+ZWSsz62BmHQipha5mNhcYBpwVe0n0BJaY2RxgOHCkpGbxhNyRcVqxPB3hnMttio+tWYU0EOhFyB3PAgaY2SNbKP4KcCwwFVgJnAtgZgsl3QCMi+WuN7OiTvZtwoOwcy7HCW3lZctm1q+E+R0Szw24aAvlHgUeLc22PQg753JeWVIOVYUHYedcztvalnCaPAg753KaJJTnQdg551LjLWHnnEuRB2HnnEuL8HSEc86lyVvCzjmXEiHvouacc6nK3YawB2HnXI6TpyOccy5Vno5w1dYDA87gmIP3Yt7CZXQ/5c8AXH3BsZx30oHMW7QcgAF/H8bw0Z8A8PvzjuSc3gewfsMGfnfrEN5491MALjnjEM458UDMjClTZ9N/wJOsWVuQzpvKIW2b1mW7JnUBWLFmPZ9/u4LdWjekUb18zIxlq9fz5bcrMKBV4zq0a14PAQUbjKnfrmTF2vWp1r8yqBzGjkhT7v58uErxrxfH0vuiezebfs+Tb9HztFvoedotGwPw7jttxylHdaVrn5s4/qL7uOvKU8nLE21aNuGX/X7MQWfcSvdT/kytvDxOOapbZb+VnFMnX7RtVo+JXy9lwldLkUKg/XbZWsbPWMKEr5aSJzYG6dXrNjB55jImfLWUrxesplPrhim/g0oSu6gV96jKPAi7Yo354H8sXLIyq7LH9dqbwcM/YO26Ar6avYD/zZzPfnt1ACC/Vi3q161NrVp51K9XhznzllRgrasPAXmxlZcnsbZgA4tWrNs4f9nqAurmhz/jpasLKNhg30+vXXP+vCUV+6jKas6n5MrVhacdzPuDruSBAWfQtHF9ANq2bMKsuYs2lvnmu0W0adWE2fOWcOcTI/ni1RuYPuImli5fxcixn6VV9ZyxtsCYuWg1PXZqSs+dmrJ+g7Fo5fcpHAGttqnLwpXrNlt2uyZ1WbhibSXWNl0ehMuZpMck9SlF+aaSflmRddoakmZIapF2PcrLQ4NH0fmn19LjtFuYO38pt/z2pGLLN21cn+N6/YA9jhvATkdeTcP6dTjt2P0qqba5Kz9PtGhUh/enL+a9aYvJyxOtGtfZOH+X1g1YsqqApas2za03qZ/PdtvUZfq8VZVd5dR4OiJ9TYEqG4Srm+8WLmPDBsPMePS5MXTfa0cAvpm3hHbbNdtYrm2rZsz+bgmH9tidGbMXMH/RcgoKNvD8m5PouU/HtKqfM5o2yGf1ug2sW28YMH/ZWrapH86lt29ej9q18pg2b9NUUcM6tdi1dUOmzF62MTVR3ZXUCq6RLWFJHSR9KukhSVMkvS6pfpzXRdJYSZMl/Tvei6koB0v6r6RpmVaxpEaSRkr6QNJH8ZbUALcAO0v6UNJtsexlksbF7VwXpzWU9LKkSZI+ltQ3Tp8h6da4zvcl7RKnt5Q0NK5nnKSDEut5NJadmKmHpFqSbo/rnizpksT7uSRR793Ld49Xru1abLPxee9D9+GT/80B4OW3J3PKUV2pUzufHdtsyy7tWzLu4xnMnLuQ/X/Qkfr1agNwyP678fn0b1Opey5ZU7CBxvVqkWnINWtQm5Vr17PdNnVp1rA2n81Zvkn5uvl5dG7TiM/nrmDVug0p1Dg9uRyEK7KLWiegn5n9XNKzwMnAk8ATwCVm9h9J1wMDgEuLWH574IfA7oQb6w0BVgMnmtnSeHg/VtIw4ApgLzPrAiDpyLj9/Qmps2GSDgZaArPN7CexXJPE9paY2Q8knQXcCRwH3AXcYWajJbUn3LRvD+Bq4E0zO09SU+B9SW8AZwEdgC5mViCpeWL9882sa0yb/B74WeE3LKk/0B+A2o2y2ccV7vGbz+FH3TrRomkjpr52Azc88AoHd+vE3ru1w8z4as5CLrlxIACfTpvL0NcnMnHo1RSs38CltzzLhg3GuI+/4t9vTOTdpy+nYP0GJn02i0eGjkn5nVV9y1avZ/7ydXTdsQlmxvI165mzZA0/3KUZq9dtoMsO4cdw/vK1fL1wNe23rUd+LbFLqwYAGDDx66UpvoPKU9VTDsVRuF1SOa9U6gCMMLNO8fXlQG3gHuAjM2sfp+8MDDazroWWfywu/1R8vczMGkuqDdwBHAxsAHYj3Ja6HvCSme0Vy98O9AEWx1U2Am4GRgGvA4Ni+VGx/AzgUDObFrcx18y2lfQdMDtRtZZxm2/HbWaScc2Bo4AbgQfMbESh9zMDOMjMvpHUA7jJzA4vbh/mNWhldXc7tbgirhwNH3R92lWoUfqfdCifffxhuUTOuq07Wdsz7iq2zPQ7fjLBzLqXx/bKW0W2hNcknq8H6m/F8pkP6wxCIOxmZuticKtXxLICbjazf2w2Q+pKuFPqjZJGmlnmry/5a5R5ngf0NLPVhdYh4GQz+7zQ9Gzez3r8Ihnnyo0EeTncEq7UE3NmtgRYJOlHcdL/Af8pxSqaAN/FAHwIsGOcvgxonCg3HDhPUiMASW0ltZLUBlhpZk8CtwHJFnjfxP/vxuevAxvzupK6JNZ/SQzGSNo3Th8BXCApP05PpiOccxUit0/MpdEiOxt4QFIDYBpwbimWfQp4UdJHwHjgMwAzWyBpjKSPgVfN7DJJewDvxg9gOXAmsAtwm6QNwDrgF4l1N5M0mdBizdz++lfAvXF6PvAOcCFwAyFvPFlSHjCdkEN+GNg1Tl8HPAT8vRTvzzlXBlU8zharQnLCuSamNbqb2fy065LhOeHK5TnhylWeOeF62+9qHc6+p9gyn//l6BqZE3bOuQoncjsn7EEYMLMOadfBOVd2HoSdcy4tyu2csAdh51xOE35nDeecS5E8HeGcc2nK5ZZwdRlFzTlXQ2WumCvuUfI69Kik7+K1Bplpt0n6LDHYWNPEvCslTZX0uaSjEtOPjtOmSroim/p7EHbO5Typ+EcWHgOOLjRtBGFgsL2BL4Arw7bUGTgN2DMuc18cQbEWcC9wDNAZ6BfLFsuDsHMu523tZctm9g6wsNC0180sM0jXWKBdfN4beMbM1pjZdGAqYcTG/YGpZjbNzNYCz8SyxfKcsHMut2U3gE8LSeMTrx80swdLsZXzCKMvArQlBOWMWXEawMxC03uUtGIPws65nBa6qJVYbH5ZL1uWdDVh2NqnyrJ8STwIO+dyXMWNlCbpHMLgXIfZ9wPtfAPskCjWLk6jmOlb5Dlh51zO29reEUWRdDTwB+B4M0vezG8YcJqkupI6Eu7i8z4wDugkqaOkOoSTd8NK2o63hJ1zua0cLluWNBDoRcgdzyLcdu1KoC4wIra0x5rZhWY2Jd6y7RNCmuIiM1sf13MxYbzxWsCjZjalpG17EHbO5bQwitrWHdSbWb8iJj9STPmbgJuKmP4K8Epptu1B2DmX83L4gjkPws653JfLly17EHbO5TTJB/BxzrlU5XBDeMtBWNI9bHob+E2Y2a8qpEbOOVdKtappS3h8MfOcc65KCIP0VMMgbGaPJ19LalCow7JzzlUJOdwQLvmKOUkHSPoE+Cy+3kfSfRVeM+ecy1JFXDFXWbLp4XwncBSwAMDMJgEHV2SlnHMuWwJUwr+qLKveEWY2s1DOZX3FVMc550pJqrYn5jJmSjoQMEm1gV8Dn1ZstZxzLns5fF4uqyB8IXAXYdDi2YTBKS6qyEo551y2BOTlcBQuMQib2XzgjEqoi3POlUlVP/lWnGx6R+wk6UVJ8+LdSF+QtFNlVM4550pS0k0+q3ojOZveEU8DzwLbA22AwcDAiqyUc86VRp5U7KMqyyYINzCzf5lZQXw8CdSr6Io551y2cjkIFzd2RPP49FVJVxBu32xAX0o5aLFzzlWUcGIu7VqUXXEn5iYQgm7m7V2QmGeEW38451y6qutQlmbWsTIr4pxzZVUtB/BJkrQX0JlELtjMnqioSjnnXLaqczoCAEkDCHch7UzIBR8DjAY8CDvnqoSqfvKtONn0jugDHAbMNbNzgX2AJhVaK+ecy5JUTXtHJKwysw2SCiRtA3wH7FDB9XLOuaxVyxNzCeMlNQUeIvSYWA68W6G1cs65Uqjijd1iZTN2xC/j0wckvQZsY2aTK7ZazjmXHVH1Uw7FKe5ija7FzTOzDyqmSg5g3z3aM+a9v6ddjRpjxeqCtKtQo9SrU6v8Vqbqm474azHzDDi0nOvinHNlkk0Pg6qquIs1DqnMijjnXFmI6nvLe+ecywk5HIM9CDvnclsYMzh3o7AHYedczquVw0nhbO6sIUlnSvpTfN1e0v4VXzXnnCtZ5h5zW3PFnKRH452DPk5May5phKQv4//N4nRJulvSVEmTkz3JJJ0dy38p6exs6p/N78d9wAFAv/h6GXBvNit3zrnKkFfCIwuPAUcXmnYFMNLMOgEj42sI4+d0io/+wP2wcQz2AUAPYH9gQCZwl1T3kvQws4uA1QBmtgiok8VyzjlX4SRRK6/4R0nM7B1gYaHJvYHH4/PHgRMS05+wYCzQVNL2wFHACDNbGOPkCDYP7JvJJie8TlItQt9gJLUENmSxnHPOVYosMg4tJI1PvH7QzB4sYZnWZjYnPp8LtI7P2wIzE+VmxWlbml6sbILw3cC/gVaSbiKMqnZNFss551yFE5Bfcmt3vpl1L+s2zMwkWVmXL042Y0c8JWkCYThLASeY2acVURnnnCuLCuqh9q2k7c1sTkw3fBenf8OmI0m2i9O+IYy9npz+dkkbyaZ3RHtgJfAiMAxYEac551z6FC7WKO5RRsOATA+Hs4EXEtPPir0kegJLYtpiOHCkpGbxhNyRcVqxsklHvMz3N/ysB3QEPgf2LMWbcc65CiGg1lY2hSUNJLRiW0iaRejlcAvwrKTzga+AU2PxV4BjgamEBuq5AGa2UNINwLhY7nozK3yybzPZpCN+UKiyXYFfbqG4c85Vuq29bNnM+m1h1mFFlDXgoi2s51Hg0dJsu9RXzJnZB5J6lHY555yrCNV+AB9Jv028zAO6ArMrrEbOOVcaquZ31gAaJ54XEHLEQyumOs45V3rV8s4aAPEijcZm9vtKqo9zzpVKSEekXYuyK+72RvlmViDpoMqskHPOlY7Io3q2hN8n5H8/lDQMGAysyMw0s+cquG7OOVciqZq2hBPqAQsI95TL9Bc2wIOwc65KqK454VaxZ8THfB98MyrkGmrnnCstUX17R9QCGkGRyRYPws65KqO69hOeY2bXV1pNnHOuDEQ1veU9RbeAnXOuaqnGN/rc7Jpp55yraspjAJ80bTEIZzP6j3POVQW5G4L9lvfOuZwn8qrpiTnnnKvyqvOJOeecywnV9cScc85Vfaq+V8w551yV5+kI55xLmbeEnXMuRTkcgz0IO+dyW0hH5G4U9iDsnMtx8nSEc86lKYdjsAdh51xuk6rp2BHOFWW3XTrQuFFjatWqRX5+PmPeG8+Zp/fly88/B2DxksU0bdKU9yZ8yFczZtDlB3uw6667AbB/j57cc98DaVY/5yxZvJhLL76ATz+ZgiTuvu9BXhr2PMNffZk6dWrToePO3HP/wzRp2pTBg57m3rv+unHZKR9/xJuj3+cHe3dJ8R1UjhyOwR6EXem99sZbtGjRYuPrJ58etPH55Zf9jiZNmmx8vdPOO/PehA8rtX7VyVV/+A2HHn4k/3xyEGvXrmXVypX0OnQ5f7zuJvLz87nuj1dy51//woAbbuaUvqdzSt/TAfhkykec1a9PjQjAAMrhE3O53MfZVTFmxtAhz3Jq335pV6VaWLpkCe/+dzRnnn0eAHXq1KFJ06YcctgR5OeH9lP3/Xowe/aszZZ9bvAgTjz51Eqtb1oyQ1kW96jKPAi7UpHET485kgP378YjDz24ybwxo0fRulVrdunUaeO0GdOn07P7vhxx6I8ZPXpUZVc3p3311XS2bdGCSy48n0MO6s6vL+rPihUrNinz1L8e47Ajjt5s2eefG8xJp/StrKqmTir+UZVV2SAsqYOkj0tR/gRJnSuyTmUl6RxJf0+7HuVh5NujeXfcBzz/0qv84/57GT3qnY3znn1mIKec9n0reLvtt+eLaV8zdvxE/nLb3zjn/05n6dKlaVQ7JxUUFDD5w4mc+7MLeGvMeBo2bMjdf7t14/y/3XYz+fn5G1MQGRPGvUf9+vXZo/NelV3l1KiEf1VZlQ3CZXACUCWDcHXStm1bAFq1asXxJ5zIuHHvAyFgvPD8c/RJtL7q1q3LtttuC0DXbt3Yaaed+fKLLyq/0jmqTdt2tGnbjm779QDgp71PZtKHEwEY+OTjvP7qyzzwyBObjSD23NBnOanPaZVe37SI4lMRno7YOrUkPSRpiqTXJdWX9HNJ4yRNkjRUUgNJBwLHA7dJ+lDSzvHxmqQJkkZJ2h1A0imSPo7LvxOnnSPpBUlvS/pS0oBMBSSdKen9uN5/SKoVpx8p6V1JH0gaLKlRnL6fpP/G9b8vqXFcVZtYny8l3UoOWrFiBcuWLdv4/I0Rr7PnnqG19ebIN9h1t91p167dxvLz5s1j/fr1AEyfNo2pU7+k4047VX7Fc1Tr1tvRtm07vvwi9Dx55z9vstvuezByxHDuufOvPDno3zRo0GCTZTZs2MALzw3hxD41Ix8MxHvMbX06QtJvYqz5WNJASfUkdZT0nqSpkgZJqhPL1o2vp8b5Hcpa/areO6IT0M/Mfi7pWeBk4DkzewhA0o3A+WZ2j6RhwEtmNiTOGwlcaGZfSuoB3AccCvwJOMrMvpHUNLGt/YG9gJXAOEkvAyuAvsBBZrZO0n3AGZJeAa4BDjezFZIuB34r6RZgENDXzMZJ2gZYFdffBdgXWAN8LukeM5tZMbutYnz37bf07XMiAAXrC+h72ukceVTIRw4e9FBuOM8AABTCSURBVMxmJ+RGj3qHG677E7Xza5OXl8c99z5A8+bNK73euezm2+/kwp+dxbq1a9mxw07cc//DHNHrANasWUOf3mHfd9uvB3+96z4A/jtmFG3btqNDx5rzY1ce95iT1Bb4FdDZzFbFeHMacCxwh5k9I+kB4Hzg/vj/IjPbRdJpwF8IsaLUqnoQnm5mmf5NE4AOwF4x+DYFGgHDCy8UW6UHAoMTh2p14/9jgMfiTn4usdgIM1sQl38O+CFQAHQjBGWA+sB3QE9C6mNMnF4HeBfYDZhjZuMAzGxpXB/ASDNbEl9/AuwIbBKEJfUH+gPs0L591jupsnTcaSfe/2BSkfMeevSxzaadeNLJnHjSyRVcq+rtB3t3YeQ7720ybdykz7ZY/oc/+jHD3xpT0dWqcsop4ZAP1Je0DmgAzCE03DJJ98eBawlBuHd8DjAE+LskmZmVZaNV2ZrE8/WEIPgYcIKZTZJ0DtCriOXygMVmtlknSTO7MLaMfwJMkNQtM6twUcJn+7iZXZmcIemnhKDdr9D0H5TivWy2783sQeBBgG7dupf6w3Suxio5CreQND7x+sH49wZAPDK+HfiacPT6OqHht9jMCmKxWUDb+LwtsRFlZgWSlgDbAvNLW/WqnhMuSmNgjqTawBmJ6cvivEwLdLqkUwAU7BOf72xm75nZn4B5wA5x+SMkNZdUn3CSbwwwEugjqVVctrmkHYGxwEGSdonTG0raFfgc2F7SfnF6Y0lV/YfOuZyXJxX7AOabWffEY5P+lZKaEVq3HYE2QENg875/FVH3ythIOfsj8B4hSCaPy54BLpM0UdLOhAB9vqRJwBTCDoZw8u4jhe5v/wUyx9fvA0OBycBQMxtvZp8Qcr+vS5oMjAC2N7N5wDnAwDj9XWB3M1tLyAvdE7c7AqhXIXvBObeRSnhk4XBC+nOema0jpCoPApomGlLtgG/i82+IDbg4vwmwoCx1r7KtNDObQThRlnl9e2L2/UWUH8PmXdQ2+yUzs5MKT4s521lmdkIR5QcRTrYVnv4msF8R08cRcsZJj8VHpsxxhZdzzpWNKJcbfX4N9JTUgJCOOAwYD7wF9CE08s4GXojlh8XX78b5b5YlHwxVOAg751xWyuGqODN7T9IQ4APCCfmJhPMzLwPPxM4AE4FH4iKPAP+SNBVYSOhJUSYehAEze4xES9U5l1vKo3eEmQ0ABhSaPI3QfbVw2dXAKeWwWQ/Czrlcp/JIR6TGg7BzLuflcAz2IOycy23hxFzatSg7D8LOuZxX1UdKK44HYedczvOWsHPOpSUHBm4vjgdh51zO83SEc86lREBe7sZgD8LOuWrAg7BzzqXH0xHOOZciT0c451yaPAg751w6wpjBuRuFPQg753KbPB3hnHPp8iDsnHNp2XgfuZzkQdg5l9NKcR+5KsmDsHMu9+VwFPYg7JzLeZ6OcM65FOVuCPYg7JzLdSqXW96nxoOwcy6n+e2NnHMuZTkcgz0IO+dyn5+Yc865NOVuDPYg7JzLbfKxI5xzLl0+ippzzqUpd2OwB2HnXO7zdIRzzqVGno5wzrm05PrFGnlpV8A557aWVPwju3WoqaQhkj6T9KmkAyQ1lzRC0pfx/2axrCTdLWmqpMmSupa17h6EnXM5TyX8y9JdwGtmtjuwD/ApcAUw0sw6ASPja4BjgE7x0R+4v6x19yDsnMtpmX7CxT1KXoeaAAcDjwCY2VozWwz0Bh6PxR4HTojPewNPWDAWaCpp+7LU34Owcy73qYQHtJA0PvHoX2gNHYF5wD8lTZT0sKSGQGszmxPLzAVax+dtgZmJ5WfFaaXmJ+acczkvi5TDfDPrXsz8fKArcImZvSfpLr5PPQBgZibJtq6mm/OWsHMu521tOoLQkp1lZu/F10MIQfnbTJoh/v9dnP8NsENi+XZxWunrXpaFnHOuSik5HVEsM5sLzJS0W5x0GPAJMAw4O047G3ghPh8GnBV7SfQEliTSFqXi6QjnXE4T5TaU5SXAU5LqANOAcwkN1WclnQ98BZway74CHAtMBVbGsmUis3JPcbhyIGke4UPPNS2A+WlXogbJ1f29o5m1LI8VSXqNsB+KM9/Mji6P7ZU3D8KuXEkaX8IJEFeOfH/nPs8JO+dcijwIO+dcijwIu/L2YNoVqGF8f+c4zwk751yKvCXsnHMp8iDsnHMp8iDsnHMp8iDsnHMp8iDsqixJteL/20mqn3Z9qhtJeYVe5/BNgnKXB2FX5UjqKOkgM1sv6afAKOBuSTelXbfqQFIDADPbIKmbpJMl1TPvKpUK76LmqhxJ/YB7CbeNOZQwctViwgArC8zs1ylWL6dJagoMAJ4H1hLuFjEbWAX8EfjQzArSq2HN4y1hV+WY2UDgYuAOoL6ZDQcmADcCzSX9I8365biGwBygL3AV0NvMegETgV8BXST56IqVyIOwqzIyOUlJnczsaeBS4FBJvWLr7AvgFsL9vDqnWNWcJElm9g3wJOEmlrsAPQDM7Crga8LdJMp852BXeh6EXZURbx9zPPCQpC5mNhS4FnhY0o/NbAMheJxnZp+kWddcEwOwSTqccBeIZ4CHgIMkHQNgZtcA/wPWpFfTmsdzwq7KiK3bfwH9zWxCYvpZwG1APzN7M6365boYbO8Afm1mwyXtQLhr8J7AK2b2YqoVrKE89+OqkibA15kALKm2ma0zsyckFQDeYiij2CPiUuAXZvZWbBnPlPQiUBc4UdJYwuDnvp8rkQdhl5rEIXJeTDXMBlZL2gP40szWSToY2NfM7kouk2a9c1QtoA5hH0MIvKuBRcA/gW3MbF5KdavRPCfsUpEIwMcBN0n6K6HL1HfARcCFknoTAsSUzHIegLOTOMm5o6S6ZrYMGA7cIqmZma2OP3CvAZjZjPRqW7N5S9ilIgbgQ4DrgdOAVwnphj8A5wE7A/sBF5vZG6lVNEfF/XsscDXwH0mtgLuBbYAxkv5JuHvwVWa2MMWq1nh+Ys6lRtK1wGhC8L0RON3Mpifm1zezVSlVL6fFk5xPA8cTjiy6Aieb2VJJfQlHHfPNbJSneNLlLWGXpjmEq+K2B840s+mSzgXam9l1eFepUksE1HqEILwL0As4Iwbg7sBzZrYus4wH4HR5TthVikSOsqekwyR1A14H9gYeBr6K034LvAdhbIO06ptrEoPvZBpWXwOnEy5LPtrMpsY+wlcCzVKootsCT0e4SiPpKEI/1duAR4DuQHvgfEKrtzVwm5kN80Pk7CVOch4BnAp8AEwFWhLSEW8DMwhXGw4wsxdSqqorgqcjXIWLrbTmwK+BE4AdCD0e5prZB5LeInShamxmX3kALp0YgA8F7iT0Bb6aMBbE7YQuaZcSWsbXmNlLvn+rFm8Ju0oj6U/AcqAPcI6ZfSHpdOAjM/so3drlrjju8sXA+0AB8A/geDObJamBma1MlPUAXMV4S9hViMQhcmtgWQwEzQmttJbxJFFX4DLg52nWNdfFcZcXEcaCWAMca2Zz41jMbSU9nBme0gNw1eNB2FWIxIUYtwITJRWY2dmSdgYelzSDcNb+WjMbn2JVc07iB25foCPhROZkYBwwIwbg/Qk54N/5+MBVm6cjXIWQtCchFzmQECAeABqY2bHxSrg8YI6ZjfVD5NKLJ+HuI4wqZ8B/CH1/dwIOAtYBt5rZsNQq6bLiQdiVO0nbApOAjwgXCKyM018CBpvZ42nWL9fFsTXuAi43s4nxR60bMM7MXpS0I7DKzL7zH7iqz/sJu3KR6AfcwcwWABcCnYAjEsXeAxqlUL2cl+gHDHAIYfjJgwFil7OVwFnx9Vdm9l187gG4ivOcsNtqiRzl8cDvJF0cu0LVA+6UtB8wnjBWwUWpVjYHJfbvYcACwpjLAPtLOjkOfv8f4ABJ25jZ0tQq60rNg7DbajFAHABcRxj/4VNJTcxsiKQ5wCBC3+Cfxnl+iFwKiR+4m4HLzOxDSUMJueA/xnk7A3/xAJx7PAi78tKC0NptE6+MO1bSekL3s/6ECwl2JJxIcqUgqQVwOXBi7Fu9N7At8BzhIpeDgEF+Z4zc5EHYlUniELkF4RD5C+BbwnCJtxKGqOwFdDKzVyQ1B26WNNrMlqdV7xxVizAA+9GSriDk1Q8Gfk8YG2ItcIikL83stfSq6crCe0e4MouHwecCswh9VF8C1pnZsnghxpPAz81sTCzfOA4u7oqR+IHbhxB85xF6P/wUeNnC/eFOBQ41swsltQcOA14zsznp1dyVhQdhVyZxSMSHgGOA+wERRu0yYB/CHTH+ELtM5ZnZBs8FZ0/hppy3Ao8RBro/wMymxXmHAH8nXIjxWpxWy8zWp1RdtxU8HeGyUkQAbU0YgrIzYTzgfma2MrbK5gGnmNnHcbkN4N2lshG7orUlXN59PGGkuTnA8jhve+AaQh/h1zKfiwfg3OUtYVei2NXsWDN7Lh4i7wL8j3DBQLM4b5akE4HjgEuSg8a44kmqDeSb2aq4r+sQRpybRhiY5+x4Qq43YQzm+ma20I8sqgdvCbtsrAPaS/o8Pj+ecDLuI2AJ0FlSB0IXtas9AGdPUj5wKLAiXun2Q0L64UjCLYmamdlaST2AK4DPzewz8COL6sJbwi4rcbCYF4B5ZtYtMe1HhCu41gFPmg/IXmpxLOCbgO2A35vZUEnbEe6O/C6h58n/EQY78gHZqxkPwm6LksE0HjK3I1yO3IOQ850naQczm5kZt9YDcPYK7d/HCPv3DmCimc2W1Jhwu6f5wKdm9qbv3+rHg7ArUqKb1E+AA4D1ZjZAUh7wN8IJoz8TLkO+wMxmpVjdnJPYv+2Ab4C6hFTEecArZvakpJZAbTObnWZdXcXyAXxckWKAOJYQaIcCZ0saAjQxs0sJYxVcDtznAbj0Ej9wgwn7+GLgHcK4EMdIug34jHC5t6vGvCXsiiSpPqEf8O1AG+Aqwq2J6hIun10sqWn83w+RS0nSDwnjAZ9ISDn0BEYRftg6A/sCX5nZyNQq6SqFB2G3UeaiisTrJkArQuvskNiFajHwMqHblN+xoRSSF1TE7mZfAB2AG4EBhDE2vgauM7N5ieX8R64a8y5qLtPqLTCzdZIOIlwQMN3MJkhqSrhYYAdJDQmDxjzqATh7mcu1LdwL7hBC4J1C2K8XAOeZ2SRJfYCmhB++jUHYA3D15kG4hlO4C8ZlwLAYjB8n5CkflnRmHBd4KnADYbSu88xstLfOsiOpAfCypLsJdxu5F/iEcBJuCuGk5zeS6gB7AOeb2ZS06usqn6cjarjY9exWwkhdecC/zWxkvPrtceA4M3tHUmfCPeL8ppylFPflFcBC4IrY6j2d0CJuQ+hr/T9goJkNTq2iLhUehGuwxMA6tQnjERxC6AnxYMz/ngQMAU4wv2HkVlG4MeezwJ/N7LZ4pVxfYDfCSGkP+KXINZN3UavBYgDOM7N1hJNDIwjjQuwnqY6ZPQecCqxJs57VgZmNIAz7eY6kfjGn/gzwOeHoY2Es5wG4hvGWcA1V6GqtfDMriHnJPwGNgWHAKDNbW7i8K7vY9/oG4G7zu047vCVc48ThECHx2ccAXDsG3OsJd2o4mcSdkT0Alw8ze4Uw0NHlktrEKxBdDeYt4Rokcans4YQBYaYB/zOzJ+P82rGbWh2gg5l9kWZ9qzNJLZN9gV3N5b/CNUgMwD8G7gHeJoxZcJGk38X562KOeK0H4IrlAdhleD/hmqcd8JCZ/RNA0nvAbZJeM7MpySvmnHMVz1vC1VwiB5xRHzgz8XoK4S7JnpdyLgUehKu5TApC0i8ldTazh4H3JI1UuA19d2BvoHa6NXWuZvITc9VU4iRcD+BRwqWyK4HRwFOEq+Q6ANsCN/vFGM6lw4NwNSZpf0KXsz+Y2WRJ/QhDJk42s0di96imfqWWc+nxdET11hQ4HDgivh4MjAF6Svo1IGAReD9g59LivSOqMTN7PY7/cLOk2WY2MN4doxYwKTO2rXMuPR6EqzkLdz8uAG6I40E8DgxMu17OucBzwjWEpOOBWwjpibneH9i5qsGDcA3il8o6V/V4EHbOuRR57wjnnEuRB2HnnEuRB2HnnEuRB2HnnEuRB2GXCknrJX0o6WNJg+Ot4cu6rsck9YnPH453ht5S2V6SDizDNmZIapHt9EJllpdyW9dK+n1p6+hykwdhl5ZVZtbFzPYi3E7pwuTMeDfiUjOzn5nZJ8UU6QWUOgg7V1E8CLuqYBSwS2yljpI0DPhEUi1Jt0kaJ2mypAsgjBAn6e+SPpf0BtAqsyJJb0vqHp8fLekDSZPi0J0dCMH+N7EV/iNJLSUNjdsYJ+mguOy2kl6XNEXSw4RxNool6XlJE+Iy/QvNuyNOHympZZy2s6TX4jKjJO1eHjvT5Ra/bNmlKrZ4jwFei5O6AnuZ2fQYyJaY2X6S6gJjJL0O7AvsBnQGWhOG6Xy00HpbAg8BB8d1NY+jxT0ALDez22O5p4E7zGy0pPbAcGAPYAAw2syul/QT4Pws3s55cRv1gXGShprZAqAhMN7MfiPpT3HdFwMPAhea2ZdxyNH7gEPLsBtdDvMg7NJSX9KH8fko4BFCmuB9M5sepx8J7J3J9wJNgE7AwcDAOADRbElvFrH+nsA7mXWZ2cIt1ONwoHPiBiTbSGoUt3FSXPZlSYuyeE+/knRifL5DrOsCYAMwKE5/EngubuNAYHBi23Wz2IarZjwIu7SsMrMuyQkxGK1ITgIuMbPhhcodW471yAN6mtnqIuqSNUm9CAH9ADNbKeltoN4Wilvc7uLC+8DVPJ4TdlXZcOAXkmoDSNpVUkPgHaBvzBlvDxxSxLJjgYMldYzLNo/TlwGNE+VeBy7JvJCUCYrvAKfHaccAzUqoaxNgUQzAuxNa4hl5QKY1fzohzbEUmC7plLgNSdqnhG24asiDsKvKHibkez+Q9DHwD8LR27+BL+O8J4B3Cy8YByrqTzj0n8T36YAXgRMzJ+aAXwHd44m/T/i+l8Z1hCA+hZCW+LqEur4G5Ev6lDBa3djEvBXA/vE9HEq42wnAGcD5sX5TgN5Z7BNXzfgAPs45lyJvCTvnXIo8CDvnXIo8CDvnXIo8CDvnXIo8CDvnXIo8CDvnXIo8CDvnXIr+H/H1OCY83GOcAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}