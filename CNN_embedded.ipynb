{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN embedded.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPRierPbBGsBqohxLczCI30",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BiancaStadl/ProjektarbeitML/blob/main/CNN_embedded.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXDOlIBymF0V"
      },
      "source": [
        "GloVe embeddings taken from:\n",
        "\n",
        "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. [pdf] [bib]\n",
        "\n",
        "hatespeechdata taken from (https://hatespeechdata.com/): Wiegand, M., Siegel, M. and Ruppenhofer, J., 2018. Overview of the GermEval 2018 Shared Task on the Identification of Offensive Language. In: Proceedings of GermEval 2018, 14th Conference on Natural Language Processing (KONVENS 2018). Vienna, Austria: Research Gate. available on: https://github.com/uds-lsv/GermEval-2018-Data (last checked: 09.05.2021)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlBmABDxfqII"
      },
      "source": [
        "wiki detox..https://colab.research.google.com/github/tensorflow/fairness-indicators/blob/master/g3doc/tutorials/Fairness_Indicators_TFCO_Wiki_Case_Study.ipynb#scrollTo=y6T5tlXcdW7J "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3xfitNdliBI"
      },
      "source": [
        "#import matplotlib.pyplot as plt -> f√ºr evtl Visualisierungen\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import string\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from keras import losses \n",
        "from keras import optimizers \n",
        "from keras import metrics \n",
        "\n",
        "#!pip install Tokenizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "#!pip install pad_sequences\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import preprocessing\n",
        "#from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTWJQ1iga_vS"
      },
      "source": [
        "Maximale Satzl√§nge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bq08Me5la_Cc"
      },
      "source": [
        "\n",
        "max_length = 60"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVYBMvYSotTH"
      },
      "source": [
        "url = \"https://github.com/uds-lsv/GermEval-2018-Data/archive/master.zip\"\n",
        "\n",
        "dataset = tf.keras.utils.get_file(\"GermEval-2018-Data-master.zip\", url, \n",
        "                                   extract=True, cache_dir='.',\n",
        "                                    cache_subdir='')\n",
        "\n",
        "dataset_dir = os.path.join(os.path.dirname(dataset), 'GermEval-2018-Data-master')\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cS14OUtfo34V"
      },
      "source": [
        "#os.listdir(dataset_dir)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2X429K6hpOVm"
      },
      "source": [
        "training_file = os.path.join(dataset_dir, 'germeval2018.training.txt')\n",
        "\n",
        "testing_file = os.path.join(dataset_dir, 'germeval2018.test.txt')\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uq8fG3LNtn_m"
      },
      "source": [
        "###Aufbereitung\n",
        "txt-Dateien lesen, und dabei jede Zeile splitten und teilen\n",
        "Twitter-Handler entfernen?\n",
        "Labels von S√§tzen trennen, Labels in eigenen Array packen.\n",
        "\n",
        "####Ressourcen\n",
        "* https://www.w3schools.com/python/gloss_python_if_statement.asp\n",
        "* https://stackabuse.com/using-regex-for-text-manipulation-in-python/\n",
        "* https://www.tutorialspoint.com/python/string_splitlines.htm \n",
        "* https://note.nkmk.me/en/python-split-rsplit-splitlines-re/ \n",
        "* https://www.w3schools.com/python/python_regex.asp \n",
        "\n",
        "g√§be bei keras tf.keras.preprocessing.text_dataset_from_directory, aber daf√ºr m√ºssten die Daten auf bestimmte Weise in Verzeichnis organisiert sein, hier nicht der Fall.\n",
        "\n",
        "\n",
        "Einteilung der Daten: Testdaten\n",
        "Trainingsdaten -> noch ca 500 f√ºr Validierungsdaten\n",
        "\n",
        "labels -> \"other\", also nicht-negative Aussagen bekommen \"0\", negative Aussagen bekommen \"1\"\n",
        "\n",
        " Regex f√ºr Emojis  ->\n",
        "\n",
        "(\\u00a9|\\u00ae|[\\u2000-\\u3300]|\\ud83c[\\ud000-\\udfff]|\\ud83d[\\ud000-\\udfff]|\\ud83e[\\ud000-\\udfff])\n",
        "\n",
        "genommen von https://www.regextester.com/106421 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Py_cwD4eZkXo"
      },
      "source": [
        "def remove_clutter(string):\n",
        "   string = re.sub(\"@[^\\s]+\",\" \",string)\n",
        "   string = re.sub(\"#[^\\s]+\",\" \", string)\n",
        "   string = re.sub(\"\\u00a9\",\" \", string)\n",
        "   string = re.sub(\"\\u00ae\",\" \", string)\n",
        "   string = re.sub(\"[\\u2000-\\u3300]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83c[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83d[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83e[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"üòú\", \" \",string)\n",
        "   string = re.sub(\"üç´\", \" \",string)\n",
        "   string = re.sub(\"üòÅ\", \" \",string)\n",
        "   string = re.sub(\"üêñ\", \" \",string)\n",
        "   string = re.sub(\"üò°\", \" \",string)\n",
        "   string = re.sub(\"üòá\", \" \",string)\n",
        "   string = re.sub(\"üò¨\", \" \",string)\n",
        "   string = re.sub(\"üòÉ\", \" \",string)\n",
        "   string = re.sub(\"üòÇ\", \" \",string)\n",
        "   string = re.sub(\"üíô\", \" \",string)  \n",
        "   string = re.sub(\"üòõ\", \" \",string)\n",
        "   string = re.sub(\"üôè\", \" \",string)\n",
        "   string = re.sub(\"üëç\", \" \",string)\n",
        "   string = re.sub(\"üñï\", \" \",string)\n",
        "   string = re.sub(\"üòâ\", \" \",string)\n",
        "   string = re.sub(\"üí©\", \" \",string)\n",
        "   string = re.sub(\"ü§¢\", \" \",string)\n",
        "   string = re.sub(\"üëè\", \" \",string)\n",
        "   string = re.sub(\"üò®\", \" \",string)\n",
        "   string = re.sub(\"ü§£\", \" \",string)\n",
        "   string = re.sub(\"ü§°\", \" \",string)\n",
        "   string = re.sub(\"üòà\", \" \",string)\n",
        "   string = re.sub(\"üíÉüèΩ\", \" \",string)\n",
        "   string = re.sub(\"üëπ\", \" \",string)\n",
        "   string = re.sub(\"ü§ò\", \" \",string)\n",
        "   string = re.sub(\"üò±\", \" \",string)\n",
        "   string = re.sub(\"ü§î\", \" \",string) \n",
        "   string = re.sub(\"üåà\", \" \",string) \n",
        "   string = re.sub(\"üíï\", \" \",string) \n",
        "   string = re.sub(\"üë©‚Äç‚ù§Ô∏è‚Äçüë©\", \" \",string) \n",
        "   string = re.sub(\"üòç\", \" \",string) \n",
        "   string = re.sub(\"üëÜ\", \" \",string) \n",
        "   string = re.sub(\"üòñ\", \" \",string) \n",
        "   string = re.sub(\"üëá\", \" \",string) \n",
        "   string = re.sub(\"üî•\", \" \",string) \n",
        "   string = re.sub(\"üòò\", \" \",string) \n",
        "   string = re.sub(\"üéâ\", \" \",string) \n",
        "   string = re.sub(\"ü§¨\", \" \",string) \n",
        "   string = re.sub(\"üëä\", \" \",string)\n",
        "   string = re.sub(\"üá©üá™\", \" \",string)  \n",
        "   string = re.sub(\"üíî\", \" \",string)\n",
        "   string = re.sub(\"üôà\", \" \",string)\n",
        "   string = re.sub(\"ü§Ø\", \" \",string)\n",
        "   string = re.sub(\"üêü\", \" \",string)\n",
        "   string = re.sub(\"üõ∂\", \" \",string)\n",
        "   string = re.sub(\"üòä\", \" \",string)\n",
        "   string = re.sub(\"üòì\", \" \",string)\n",
        "   string = re.sub(\"üò≥\", \" \",string)\n",
        "   string = re.sub(\"üöÄ\", \" \",string)\n",
        "   string = re.sub(\"üëé\", \" \",string)\n",
        "   string = re.sub(\"üòé\", \" \",string)\n",
        "   string = re.sub(\"üê∏\", \" \",string)\n",
        "   string = re.sub(\"üìà\", \" \",string)\n",
        "   string = re.sub(\"üôÇ\", \" \",string)\n",
        "   string = re.sub(\"üòÖ\", \" \",string)\n",
        "   string = re.sub(\"üòÜ\", \" \",string)\n",
        "   string = re.sub(\"üôéüèø\", \" \",string)\n",
        "   string = re.sub(\"üëéüèΩ\", \" \",string)\n",
        "   string = re.sub(\"ü§≠\", \" \",string)\n",
        "   string = re.sub(\"üò§\", \" \",string)\n",
        "   string = re.sub(\"üòö\", \" \",string)\n",
        "   string = re.sub(\"üòä\", \" \",string)\n",
        "   string = re.sub(\"üò≤\", \" \",string)\n",
        "   string = re.sub(\"ü§Æ\", \" \",string)\n",
        "   string = re.sub(\"üôÑ\", \" \",string)\n",
        "   string = re.sub(\"ü§ë\", \" \",string)\n",
        "   string = re.sub(\"üéÖ\", \" \",string)\n",
        "   string = re.sub(\"üëã\", \" \",string)\n",
        "   string = re.sub(\"üí™\", \" \",string)\n",
        "   string = re.sub(\"üòÑ\", \" \",string)\n",
        "   string = re.sub(\"üßê\", \" \",string)\n",
        "   string = re.sub(\"üò†\", \" \",string)\n",
        "   string = re.sub(\"üéà\", \" \",string)\n",
        "   string = re.sub(\"üöÇ\", \" \",string)\n",
        "   string = re.sub(\"üòä\", \" \",string)\n",
        "   string = re.sub(\"üöá\", \" \",string)\n",
        "   string = re.sub(\"üöä\", \" \",string)\n",
        "   string = re.sub(\"ü§∑\", \" \",string)\n",
        "   string = re.sub(\"üò•\", \" \",string)\n",
        "   string = re.sub(\"üôÉ\", \" \",string)\n",
        "   string = re.sub(\"üî©\", \" \",string)\n",
        "   string = re.sub(\"üîß\", \" \",string)\n",
        "   string = re.sub(\"üî®\", \" \",string)\n",
        "   string = re.sub(\"üõ†\", \" \",string)\n",
        "   string = re.sub(\"üíì\", \" \",string)\n",
        "   string = re.sub(\"üí°\", \" \",string)\n",
        "   string = re.sub(\"üç∏\", \" \",string)\n",
        "   string = re.sub(\"ü•É\", \" \",string)\n",
        "   string = re.sub(\"ü•Ç\", \" \",string)\n",
        "   string = re.sub(\"üò∑\", \" \",string)\n",
        "   string = re.sub(\"ü§ê\", \" \",string)\n",
        "   string = re.sub(\"üåé\", \" \",string)\n",
        "   string = re.sub(\"üëë\", \" \",string)\n",
        "   string = re.sub(\"ü§õ\", \" \",string)\n",
        "   string = re.sub(\"üòÄ\", \" \",string)\n",
        "   string = re.sub(\"üõ§\", \" \",string)\n",
        "   string = re.sub(\"üéÑ\", \" \",string)\n",
        "   string = re.sub(\"üì¥\", \" \",string)\n",
        "   string = re.sub(\"üå≠\", \" \",string)\n",
        "   string = re.sub(\"ü§ï\", \" \",string)\n",
        "   string = re.sub(\"üò≠\", \" \",string)\n",
        "   string = re.sub(\"üçæ\", \" \",string)\n",
        "   string = re.sub(\"üçû\", \" \",string)\n",
        "   string = re.sub(\"ü§¶\", \" \",string)\n",
        "   string = re.sub(\"ü§Ø\", \" \",string)\n",
        "   string = re.sub(\"üïØÔ∏è\", \" \",string)\n",
        "\n",
        "   string = re.sub(\"OTHER|OFFENSE|ABUSE|INSULT\",\" \",string)\n",
        "   return string"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5asMgo4LtnRg"
      },
      "source": [
        "statementsForTraining = []\n",
        "sentimentsForTraining = []\n",
        "\n",
        "\n",
        "fileToRead = open(training_file, 'r')\n",
        "\n",
        "while True:\n",
        "  #next line in file\n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  findSentiment = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "\n",
        "\n",
        "  statementsForTraining.append(line)\n",
        "   #sentimentsForTraining.append(findSentiment.group(0))\n",
        "\n",
        "  if findSentiment.group(0) == \"OTHER\":  \n",
        "    sentimentsForTraining.append(0)\n",
        "  else:\n",
        "    sentimentsForTraining.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        " #print(\"{}: {}\".format(count,line.strip()))\n",
        "  \n",
        " # print(sentiment.group(0))\n",
        " \n",
        "fileToRead.close()\n",
        "\n",
        "training_sentences = statementsForTraining\n",
        "training_labels = sentimentsForTraining\n",
        "\n",
        "#print(training_sentences[9])\n",
        "#print(training_labels[9])\n",
        "\n",
        "#print(len(training_sentences))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsqZPENb98gD"
      },
      "source": [
        "##do the same with testdata\n",
        "statementsForTesting = []\n",
        "sentimentsForTesting = []\n",
        "\n",
        "fileToRead = open(testing_file, 'r')\n",
        "\n",
        "while True:\n",
        "  #next line in file\n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  sent = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "\n",
        "    \n",
        "\n",
        "  statementsForTesting.append(line)\n",
        "  #print(len(line))\n",
        "  #sentimentsForTesting.append(sent.group(0))\n",
        "\n",
        "  if sent.group(0) == \"OTHER\": \n",
        "    sentimentsForTesting.append(0)\n",
        "  else:\n",
        "    sentimentsForTesting.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        "\n",
        "fileToRead.close()\n",
        "\n",
        "\n",
        "testing_sentences = statementsForTesting\n",
        "testing_labels = sentimentsForTesting\n",
        "#print(len(testing_sentences))\n",
        "#print(testing_sentences)   \n",
        "#print(testing_labels)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRUvDLD5bMbO"
      },
      "source": [
        "Padding -> im Prinzip die S√§tze alle auf die gleiche L√§nge bringen (in Theorieteil n√§her drauf eingehen) -> maxlen-Paramter ist f√ºr pad_sequences vorhanden, wenn nicht gesetzt -> alles wird auf die L√§nge des l√§ngsten Satzes aufgef√ºllt -> print(padded(shape)) gibt aus, wie viele Datens√§tze padded wurden und gibt an, wie viele Tokens der l√§ngste Datensatz hat\n",
        "print(padded[x]) gibt einen Satz aus (bereits tokenisiert)\n",
        "\n",
        "Padding -> sowohl f√ºr Trainigs- als auch f√ºr Testdaten\n",
        "\n",
        "Und: Daten als numpy-Arrays speichern (notwendig f√ºr tensorflow).\n",
        "\n",
        " -> Tokenizer https://towardsdatascience.com/text-classification-in-keras-part-2-how-to-use-the-keras-tokenizer-word-representations-fd571674df23 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3hFi7waTv5m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "948f7650-2a0f-43c8-d873-248900d1342c"
      },
      "source": [
        "tokenizer = Tokenizer(oov_token=\"OOV\")\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "\n",
        "#creating a word index - nur die Trainigsdaten\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "validation_size = 500\n",
        "\n",
        "\n",
        "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "padded_training = pad_sequences(training_sequences, maxlen=max_length, padding='post')\n",
        "print(len(padded_training))\n",
        "\n",
        "validation_sequences = padded_training[0:validation_size]\n",
        "validation_labels = training_labels[0:validation_size]\n",
        "\n",
        "padded_training = padded_training[validation_size:]\n",
        "training_labels = training_labels[validation_size:]\n",
        "\n",
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
        "padded_testing = pad_sequences(testing_sequences, maxlen=max_length,  padding='post')\n",
        "\n",
        "#print(validation_sequences[499])\n",
        "print(padded_training[0])\n",
        "#print(len(validation_labels))\n",
        "#print(len(training_labels))\n",
        "\n",
        "\n",
        "nppadded_training = np.array(padded_training)\n",
        "nptraining_labels = np.array(training_labels)\n",
        "\n",
        "nppadded_validation = np.array(validation_sequences)\n",
        "npvalidation_labels = np.array(validation_labels)\n",
        "\n",
        "nppadded_testing = np.array(padded_testing)\n",
        "nptesting_labels = np.array(testing_labels)\n",
        "\n",
        "\n",
        "print(len(nppadded_training))\n",
        "print(len(nptraining_labels))\n",
        "print(len(word_index))\n",
        "\n",
        "#print(statementsForTraining[2])\n",
        "#print(nppadded_training[4])\n",
        "#print(nppadded_training.shape)\n",
        "#print(nptraining_labels[4])\n",
        "#print(nppadded_testing.shape)\n",
        "#print(word_index) \n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5009\n",
            "[  12 3982   11   41 6706 1040    4    5  202   39    3 2922   49 1360\n",
            "  810  495 3983    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0]\n",
            "4509\n",
            "4509\n",
            "15059\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tL3owrc8THkT"
      },
      "source": [
        "\n",
        "Dann: Embedding mit entweder word2vec oder glove\n",
        "Word2vec-Daten sind hier: http://vectors.nlpl.eu/repository/#\n",
        "Glove -> https://nlp.stanford.edu/projects/glove/ Da mal den Twitter-Vector runtergeladen\n",
        "Wenn Daten in GoogleDrive sind (w√§re auch via url m√∂glich..), muss Drive gemounted werden ( https://buomsoo-kim.github.io/colab/2020/05/09/Colab-mounting-google-drive.md/ ) aber auch hier https://enjoymachinelearning.com/posts/colab-with-google-drive/\n",
        "\n",
        "Die Word2vec vectors: http://vectors.nlpl.eu/repository/# \n",
        "\n",
        "glove-zitat:\n",
        "Citing GloVe\n",
        "\n",
        "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. [pdf] [bib]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zuO7T9ZTG57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75428e67-ac4a-41be-f2e4-81a558d3c9ab"
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount(\"/content/drive\")\n",
        "os.listdir(\"/content/drive/MyDrive/Colab Notebooks\")\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['germeval_training.txt',\n",
              " 'glove.twitter.27B.50d.txt',\n",
              " 'glove.twitter.27B.200d.txt',\n",
              " 'glove.6B.200d.txt',\n",
              " 'glove.840B.300d.txt',\n",
              " 'tensorboard.gdoc',\n",
              " 'keras.gdoc',\n",
              " 'Vectorization CNN embedded_limited_vocab.ipynb',\n",
              " 'glove.42B.300d.txt',\n",
              " 'Embedding Glove Vergleich.ipynb',\n",
              " 'CNN embedded_limited_vocab.ipynb',\n",
              " 'LSTM_limited_vocab.ipynb',\n",
              " 'LSTM.ipynb',\n",
              " 'CNN embedded.ipynb']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7ToKO-sZLHK"
      },
      "source": [
        "\n",
        "Keras-Doc : https://keras.io/examples/nlp/pretrained_word_embeddings/#load-pretrained-word-embeddings \n",
        "embedding mit initializers.. weights m√ºsste auch funktionieren\n",
        "\n",
        "Diese erstellte Matrix mit Embedding dann in die Embedding-Schicht einbinden,  Trainable auf False, weil sich die Werte nicht durch Training anpassen sollen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AShIVfC7ZQAH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f408dc01-1d7d-478a-bce5-2439dc631eef"
      },
      "source": [
        "#Gr√∂√üe Vokabel -> wordindex + 2 (weil padding + OOV) \n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "vocabulary_size = len(word_index)+2\n",
        "\n",
        "# dann erstell ich ein W√∂rterbuch mit Namen \"embedding_vector\", dort sind dann\n",
        "#die keys drinnen, die in glove-Datei drinnen sind mit dem entsprechenden Key\n",
        "\n",
        "embedding_index_glove = {}\n",
        "f = open('/content/drive/MyDrive/Colab Notebooks/glove.twitter.27B.200d.txt')\n",
        "for line in f:\n",
        "  value = line.split()\n",
        "  word = value[0]\n",
        "  coef = np.asarray(value[1:],dtype='float32')\n",
        "  embedding_index_glove[word] = coef\n",
        "\n",
        "print(\"%d gefunden: \"% len(embedding_index_glove))\n",
        "\n",
        "#Dann noch eine Embedding-Matrix erstellen\n",
        "#zweiter Wert = Embedding-Dimension der Datei, in dem Fall 200\n",
        "\n",
        "glove_matrix = np.zeros((vocabulary_size,200))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    embedding_value = embedding_index_glove.get(word)\n",
        "    if embedding_value is not None:\n",
        "      glove_matrix[index] = embedding_value\n",
        "      hits+=1\n",
        "    else:\n",
        "      misses+=1\n",
        "\n",
        "print(\"hits %d and %d misses\"%(hits,misses))\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1193514 gefunden: \n",
            "hits 6747 and 8312 misses\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZmvOfwhV4N5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdd0265e-fcbc-44ab-d00d-94ccb4b3349d"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "print(\"vocab size: %d\"%vocabulary_size)\n",
        "CNN16052102ES08 = tf.keras.Sequential()\n",
        "#Embedding -> hier dann auf das embedding verweisen, Input_dim -> die Anzahl der W√∂rter im word_index, output -> in dem Fall passend zum verwendeten Vektor\n",
        "#input-length -> auf 60  gepadded, trainable -> nein, weil nichts ver√§ndert werden soll\n",
        "#embeddings_initializer=keras.initializers.Constant(glove_matrix) vs weights = [glove_matrix]\n",
        "#Convolutional layers => filters = neurons.. mit 100? 265?\n",
        "#CNN16052102ES08.add(tf.keras.layers.Embedding(input_dim=vocabulary_size, output_dim=200, input_length=max_length))\n",
        "CNN16052102ES08.add(tf.keras.layers.Embedding(vocabulary_size, output_dim=200, input_length=60, embeddings_initializer = keras.initializers.Constant(glove_matrix), trainable= False))\n",
        "CNN16052102ES08.add(tf.keras.layers.Dropout(0.4))\n",
        "CNN16052102ES08.add(tf.keras.layers.Conv1D(filters=50, kernel_size=3, padding=\"valid\", activation=\"relu\"))\n",
        "CNN16052102ES08.add(tf.keras.layers.MaxPooling1D())\n",
        "CNN16052102ES08.add(tf.keras.layers.Conv1D(filters=50, kernel_size=3, padding=\"valid\", activation=\"relu\"))\n",
        "CNN16052102ES08.add(tf.keras.layers.GlobalAveragePooling1D())\n",
        "CNN16052102ES08.add(tf.keras.layers.Flatten())\n",
        "CNN16052102ES08.add(tf.keras.layers.Dense(260, activation=\"relu\"))\n",
        "CNN16052102ES08.add(tf.keras.layers.Dropout(0.4))\n",
        "CNN16052102ES08.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "CNN16052102ES08.summary()\n",
        "\n",
        "#nppadded_training = np.asmatrix(nppadded_training) not necessary\n",
        "#nppadded_testing = np.asmatrix(nppadded_testing)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab size: 15061\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 60, 200)           3012200   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 60, 200)           0         \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 58, 50)            30050     \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 29, 50)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 27, 50)            7550      \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 260)               13260     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 260)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 261       \n",
            "=================================================================\n",
            "Total params: 3,063,321\n",
            "Trainable params: 51,121\n",
            "Non-trainable params: 3,012,200\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEr4OzT-iHDe"
      },
      "source": [
        "#model.layers[2].get_weights()[0].shape\n",
        "#weights=np.random.rand(5,200,100)\n",
        "#bias=np.random.rand(100)\n",
        "#model.layers[2].set_weights([weights, bias])\n",
        "\n",
        "#model.layers[2].get_weights()[0]\n",
        "#https://androidkt.com/set-custom-weights-keras-using-numpy-array/"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UB7_3VPYesr9"
      },
      "source": [
        "F1-Score f√ºr jede Epoche https://aakashgoel12.medium.com/how-to-add-user-defined-function-get-f1-score-in-keras-metrics-3013f979ce0d\n",
        "\n",
        "Sehr gute Ressource f√ºr die verschiedenen Scores und Metriken https://neptune.ai/blog/evaluation-metrics-binary-classification#10  das und aakas verwendet\n",
        "\n",
        "hier: je eine Funktion f√ºr Recall, Precision, f1 https://neptune.ai/blog/keras-metrics \n",
        "\n",
        "https://keras.rstudio.com/reference/k_ones_like.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygyrbFJaMV9B"
      },
      "source": [
        "import keras.backend as K\n",
        "\n",
        "def metrics_recall(data_true, data_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(data_true,0,1)))\n",
        "\n",
        "    recall = true_positives / (possible_positives+K.epsilon())\n",
        "    return recall\n",
        "\n",
        "\n",
        "def metrics_precision(data_true, data_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "\n",
        "    positives_predicted = K.sum(K.round(K.clip(data_pred,0,1)))\n",
        "    precision = true_positives / (positives_predicted+K.epsilon())\n",
        "    return precision\n",
        "\n",
        "\n",
        "def metrics_f1(data_true, data_pred):\n",
        "    precision_data = metrics_precision(data_true, data_pred)\n",
        "    recall_data = metrics_recall(data_true, data_pred)\n",
        "    return 2*(precision_data*recall_data)/(precision_data+recall_data+K.epsilon())"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1ctlBrnuYJz"
      },
      "source": [
        "https://aakashgoel12.medium.com/how-to-add-user-defined-function-get-f1-score-in-keras-metrics-3013f979ce0d"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AfPD3_bWCm0"
      },
      "source": [
        "CNN16052102ES08.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',metrics_recall,metrics_precision,metrics_f1])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpChKUY-QEWI"
      },
      "source": [
        "https://www.tensorflow.org/tensorboard/tensorboard_in_notebooks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJfMgUhHBoD1"
      },
      "source": [
        "#%load_ext tensorboard\n",
        "#nur einmal pro Sitzung notwendig\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ISmMXLqP8Hc"
      },
      "source": [
        "\n",
        "logs_base_dir = \"./logs\"\n",
        "callbackForTB = tf.keras.callbacks.TensorBoard(logs_base_dir)\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ehh-EMXUQh8r"
      },
      "source": [
        "Early Stopping as defined in keras tensorflow documentation\n",
        "https://www.tensorflow.org/guide/keras/train_and_evaluate "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BY_t-PeQEjy"
      },
      "source": [
        "callbackEarlyStopping = [\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_accuracy\",\n",
        "        mode=\"max\",\n",
        "        patience=3,\n",
        "        verbose=1,\n",
        "    )\n",
        "]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2CHbXiP1LsF"
      },
      "source": [
        "training_epochs = 30\n",
        "batch_size = 40\n",
        "validation_split=0.2"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abV-QAxfW48r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bbcb534-569a-4d58-91bc-944d1157e07d"
      },
      "source": [
        "#Werte der Convolutional-Schichten variieren (Filter), Batch-Size variieren, kernel-size..\n",
        "CNN16052102ES08.fit(nppadded_training, nptraining_labels, batch_size=batch_size, validation_split=validation_split, epochs=training_epochs, callbacks=[callbackForTB,callbackEarlyStopping])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "91/91 [==============================] - 4s 30ms/step - loss: 0.6508 - accuracy: 0.6528 - metrics_recall: 0.0454 - metrics_precision: 0.0185 - metrics_f1: 0.0263 - val_loss: 0.6395 - val_accuracy: 0.6718 - val_metrics_recall: 0.0000e+00 - val_metrics_precision: 0.0000e+00 - val_metrics_f1: 0.0000e+00\n",
            "Epoch 2/30\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.6279 - accuracy: 0.6785 - metrics_recall: 0.0036 - metrics_precision: 0.0245 - metrics_f1: 0.0060 - val_loss: 0.6080 - val_accuracy: 0.6907 - val_metrics_recall: 0.2511 - val_metrics_precision: 0.6140 - val_metrics_f1: 0.3430\n",
            "Epoch 3/30\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.5992 - accuracy: 0.6862 - metrics_recall: 0.1850 - metrics_precision: 0.5045 - metrics_f1: 0.2289 - val_loss: 0.5789 - val_accuracy: 0.7095 - val_metrics_recall: 0.2438 - val_metrics_precision: 0.6608 - val_metrics_f1: 0.3467\n",
            "Epoch 4/30\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.5792 - accuracy: 0.7038 - metrics_recall: 0.2140 - metrics_precision: 0.5800 - metrics_f1: 0.2769 - val_loss: 0.5589 - val_accuracy: 0.7095 - val_metrics_recall: 0.3575 - val_metrics_precision: 0.6162 - val_metrics_f1: 0.4348\n",
            "Epoch 5/30\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.5664 - accuracy: 0.7082 - metrics_recall: 0.3636 - metrics_precision: 0.6449 - metrics_f1: 0.4372 - val_loss: 0.5504 - val_accuracy: 0.7228 - val_metrics_recall: 0.2325 - val_metrics_precision: 0.7493 - val_metrics_f1: 0.3404\n",
            "Epoch 6/30\n",
            "91/91 [==============================] - 2s 25ms/step - loss: 0.5468 - accuracy: 0.7155 - metrics_recall: 0.3933 - metrics_precision: 0.6713 - metrics_f1: 0.4559 - val_loss: 0.5475 - val_accuracy: 0.7295 - val_metrics_recall: 0.2365 - val_metrics_precision: 0.8223 - val_metrics_f1: 0.3479\n",
            "Epoch 7/30\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.5322 - accuracy: 0.7363 - metrics_recall: 0.4022 - metrics_precision: 0.6976 - metrics_f1: 0.4789 - val_loss: 0.5457 - val_accuracy: 0.7273 - val_metrics_recall: 0.2663 - val_metrics_precision: 0.7514 - val_metrics_f1: 0.3762\n",
            "Epoch 8/30\n",
            "91/91 [==============================] - 2s 25ms/step - loss: 0.5033 - accuracy: 0.7439 - metrics_recall: 0.4218 - metrics_precision: 0.6705 - metrics_f1: 0.4824 - val_loss: 0.5363 - val_accuracy: 0.7284 - val_metrics_recall: 0.3999 - val_metrics_precision: 0.6309 - val_metrics_f1: 0.4687\n",
            "Epoch 9/30\n",
            "91/91 [==============================] - 2s 25ms/step - loss: 0.4843 - accuracy: 0.7538 - metrics_recall: 0.4779 - metrics_precision: 0.6912 - metrics_f1: 0.5476 - val_loss: 0.5325 - val_accuracy: 0.7262 - val_metrics_recall: 0.3763 - val_metrics_precision: 0.6486 - val_metrics_f1: 0.4593\n",
            "Epoch 00009: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f209939de50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJVL4SBLPB2P"
      },
      "source": [
        "#%tensorboard --logdir {logs_base_dir}"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_LnvWBcnoak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24b5a497-6b36-40cb-de30-7a6bea7adf5d"
      },
      "source": [
        "#results = model.evaluate(nppadded_testing, nptesting_labels, batch_size=batch_size)\n",
        "#print(\"test loss, test acc:\",results)\n",
        "\n",
        "(loss,accuracy, metrics_recall,metrics_precision,\n",
        "metrics_f1) = CNN16052102ES08.evaluate(nppadded_testing, nptesting_labels, verbose=1)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5712 - accuracy: 0.6985 - metrics_recall: 0.2741 - metrics_precision: 0.6100 - metrics_f1: 0.3657\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KgjIkhpKmHc"
      },
      "source": [
        "make some predictions of test data and save it to variable. verbose=0 -> do not generate output\n",
        "Gute Quelle: https://deeplizard.com/learn/video/2f-NjDUvZIE "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89GWuxryKlcM"
      },
      "source": [
        "CNN_predictions06 = CNN16052102ES08.predict(x=nppadded_testing)\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3jPDaDJK_cN"
      },
      "source": [
        "#for p in CNN_predictions06:\n",
        " # print(p)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eC9efJy4Lp21"
      },
      "source": [
        "rounded predictions: give prediction value of most likely prediction (0 or 1). Printing the output of rounded prediction shows the prediction made by the model on the data (which output is most likely)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsG-TJuQLvtk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b081291-6d26-48e9-bebd-e05ebb00ce1f"
      },
      "source": [
        "prediction_rounded06 = np.round(CNN_predictions06)\n",
        "#np.argmax(CNN_predictions06,axis=-1)\n",
        "\n",
        "#for p in prediction_rounded06:\n",
        " # print(p)\n",
        "\n",
        "\n",
        "print(nptesting_labels[500:520])\n",
        "print(prediction_rounded06[500:520])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1]\n",
            "[[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egTtgpXgg8a2"
      },
      "source": [
        "https://deeplizard.com/learn/video/km7pxKy4UHU\n",
        "\n",
        "Quelle der def plot_confusion_matrix: https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSDXf7-_MITy"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0AMs1EzhBU1"
      },
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                        normalize=False,\n",
        "                        title='Confusion matrix',\n",
        "                        cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2JgEnlghCtl"
      },
      "source": [
        "cm = confusion_matrix(y_true=nptesting_labels, y_pred=prediction_rounded06)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckmF29whhFmX"
      },
      "source": [
        "plot_labels = ['no hatespeech','hatespeech']"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "2mpSE96rhK7K",
        "outputId": "8f8afb3a-4d78-49b4-edd7-1cb537cf2938"
      },
      "source": [
        "plot_confusion_matrix(cm=cm, classes=plot_labels, title='CNN Confusion 50 EarlyStopping max acc')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix, without normalization\n",
            "[[2142  188]\n",
            " [ 877  325]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}