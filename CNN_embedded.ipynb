{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN embedded.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPkeXNKPbl4T/DHqROqy1Gd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BiancaStadl/ProjektarbeitML/blob/main/CNN_embedded.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXDOlIBymF0V"
      },
      "source": [
        "GloVe embeddings taken from:\n",
        "\n",
        "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. [pdf] [bib]\n",
        "\n",
        "hatespeechdata taken from (https://hatespeechdata.com/): Wiegand, M., Siegel, M. and Ruppenhofer, J., 2018. Overview of the GermEval 2018 Shared Task on the Identification of Offensive Language. In: Proceedings of GermEval 2018, 14th Conference on Natural Language Processing (KONVENS 2018). Vienna, Austria: Research Gate. available on: https://github.com/uds-lsv/GermEval-2018-Data (last checked: 09.05.2021)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlBmABDxfqII"
      },
      "source": [
        "wiki detox..https://colab.research.google.com/github/tensorflow/fairness-indicators/blob/master/g3doc/tutorials/Fairness_Indicators_TFCO_Wiki_Case_Study.ipynb#scrollTo=y6T5tlXcdW7J "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3xfitNdliBI"
      },
      "source": [
        "#import matplotlib.pyplot as plt -> für evtl Visualisierungen\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import string\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from keras import losses \n",
        "from keras import optimizers \n",
        "from keras import metrics \n",
        "\n",
        "#!pip install Tokenizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "#!pip install pad_sequences\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import preprocessing\n",
        "#from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTWJQ1iga_vS"
      },
      "source": [
        "Maximale Satzlänge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bq08Me5la_Cc"
      },
      "source": [
        "\n",
        "max_length = 60"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVYBMvYSotTH"
      },
      "source": [
        "url = \"https://github.com/uds-lsv/GermEval-2018-Data/archive/master.zip\"\n",
        "\n",
        "dataset = tf.keras.utils.get_file(\"GermEval-2018-Data-master.zip\", url, \n",
        "                                   extract=True, cache_dir='.',\n",
        "                                    cache_subdir='')\n",
        "\n",
        "dataset_dir = os.path.join(os.path.dirname(dataset), 'GermEval-2018-Data-master')\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cS14OUtfo34V"
      },
      "source": [
        "#os.listdir(dataset_dir)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2X429K6hpOVm"
      },
      "source": [
        "training_file = os.path.join(dataset_dir, 'germeval2018.training.txt')\n",
        "\n",
        "testing_file = os.path.join(dataset_dir, 'germeval2018.test.txt')\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uq8fG3LNtn_m"
      },
      "source": [
        "###Aufbereitung\n",
        "txt-Dateien lesen, und dabei jede Zeile splitten und teilen\n",
        "Twitter-Handler entfernen?\n",
        "Labels von Sätzen trennen, Labels in eigenen Array packen.\n",
        "\n",
        "####Ressourcen\n",
        "* https://www.w3schools.com/python/gloss_python_if_statement.asp\n",
        "* https://stackabuse.com/using-regex-for-text-manipulation-in-python/\n",
        "* https://www.tutorialspoint.com/python/string_splitlines.htm \n",
        "* https://note.nkmk.me/en/python-split-rsplit-splitlines-re/ \n",
        "* https://www.w3schools.com/python/python_regex.asp \n",
        "\n",
        "gäbe bei keras tf.keras.preprocessing.text_dataset_from_directory, aber dafür müssten die Daten auf bestimmte Weise in Verzeichnis organisiert sein, hier nicht der Fall.\n",
        "\n",
        "\n",
        "Einteilung der Daten: Testdaten\n",
        "Trainingsdaten -> noch ca 500 für Validierungsdaten\n",
        "\n",
        "labels -> \"other\", also nicht-negative Aussagen bekommen \"0\", negative Aussagen bekommen \"1\"\n",
        "\n",
        " Regex für Emojis  ->\n",
        "\n",
        "(\\u00a9|\\u00ae|[\\u2000-\\u3300]|\\ud83c[\\ud000-\\udfff]|\\ud83d[\\ud000-\\udfff]|\\ud83e[\\ud000-\\udfff])\n",
        "\n",
        "genommen von https://www.regextester.com/106421 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Py_cwD4eZkXo"
      },
      "source": [
        "def remove_clutter(string):\n",
        "   string = re.sub(\"@[^\\s]+\",\" \",string)\n",
        "   string = re.sub(\"#[^\\s]+\",\" \", string)\n",
        "   string = re.sub(\"\\u00a9\",\" \", string)\n",
        "   string = re.sub(\"\\u00ae\",\" \", string)\n",
        "   string = re.sub(\"[\\u2000-\\u3300]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83c[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83d[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83e[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"😜\", \" \",string)\n",
        "   string = re.sub(\"🍫\", \" \",string)\n",
        "   string = re.sub(\"😁\", \" \",string)\n",
        "   string = re.sub(\"🐖\", \" \",string)\n",
        "   string = re.sub(\"😡\", \" \",string)\n",
        "   string = re.sub(\"😇\", \" \",string)\n",
        "   string = re.sub(\"😬\", \" \",string)\n",
        "   string = re.sub(\"😃\", \" \",string)\n",
        "   string = re.sub(\"😂\", \" \",string)\n",
        "   string = re.sub(\"💙\", \" \",string)  \n",
        "   string = re.sub(\"😛\", \" \",string)\n",
        "   string = re.sub(\"🙏\", \" \",string)\n",
        "   string = re.sub(\"👍\", \" \",string)\n",
        "   string = re.sub(\"🖕\", \" \",string)\n",
        "   string = re.sub(\"😉\", \" \",string)\n",
        "   string = re.sub(\"💩\", \" \",string)\n",
        "   string = re.sub(\"🤢\", \" \",string)\n",
        "   string = re.sub(\"👏\", \" \",string)\n",
        "   string = re.sub(\"😨\", \" \",string)\n",
        "   string = re.sub(\"🤣\", \" \",string)\n",
        "   string = re.sub(\"🤡\", \" \",string)\n",
        "   string = re.sub(\"😈\", \" \",string)\n",
        "   string = re.sub(\"💃🏽\", \" \",string)\n",
        "   string = re.sub(\"👹\", \" \",string)\n",
        "   string = re.sub(\"🤘\", \" \",string)\n",
        "   string = re.sub(\"😱\", \" \",string)\n",
        "   string = re.sub(\"🤔\", \" \",string) \n",
        "   string = re.sub(\"🌈\", \" \",string) \n",
        "   string = re.sub(\"💕\", \" \",string) \n",
        "   string = re.sub(\"👩‍❤️‍👩\", \" \",string) \n",
        "   string = re.sub(\"😍\", \" \",string) \n",
        "   string = re.sub(\"👆\", \" \",string) \n",
        "   string = re.sub(\"😖\", \" \",string) \n",
        "   string = re.sub(\"👇\", \" \",string) \n",
        "   string = re.sub(\"🔥\", \" \",string) \n",
        "   string = re.sub(\"😘\", \" \",string) \n",
        "   string = re.sub(\"🎉\", \" \",string) \n",
        "   string = re.sub(\"🤬\", \" \",string) \n",
        "   string = re.sub(\"👊\", \" \",string)\n",
        "   string = re.sub(\"🇩🇪\", \" \",string)  \n",
        "   string = re.sub(\"💔\", \" \",string)\n",
        "   string = re.sub(\"🙈\", \" \",string)\n",
        "   string = re.sub(\"🤯\", \" \",string)\n",
        "   string = re.sub(\"🐟\", \" \",string)\n",
        "   string = re.sub(\"🛶\", \" \",string)\n",
        "   string = re.sub(\"😊\", \" \",string)\n",
        "   string = re.sub(\"😓\", \" \",string)\n",
        "   string = re.sub(\"😳\", \" \",string)\n",
        "   string = re.sub(\"🚀\", \" \",string)\n",
        "   string = re.sub(\"👎\", \" \",string)\n",
        "   string = re.sub(\"😎\", \" \",string)\n",
        "   string = re.sub(\"🐸\", \" \",string)\n",
        "   string = re.sub(\"📈\", \" \",string)\n",
        "   string = re.sub(\"🙂\", \" \",string)\n",
        "   string = re.sub(\"😅\", \" \",string)\n",
        "   string = re.sub(\"😆\", \" \",string)\n",
        "   string = re.sub(\"🙎🏿\", \" \",string)\n",
        "   string = re.sub(\"👎🏽\", \" \",string)\n",
        "   string = re.sub(\"🤭\", \" \",string)\n",
        "   string = re.sub(\"😤\", \" \",string)\n",
        "   string = re.sub(\"😚\", \" \",string)\n",
        "   string = re.sub(\"😊\", \" \",string)\n",
        "   string = re.sub(\"😲\", \" \",string)\n",
        "   string = re.sub(\"🤮\", \" \",string)\n",
        "   string = re.sub(\"🙄\", \" \",string)\n",
        "   string = re.sub(\"🤑\", \" \",string)\n",
        "   string = re.sub(\"🎅\", \" \",string)\n",
        "   string = re.sub(\"👋\", \" \",string)\n",
        "   string = re.sub(\"💪\", \" \",string)\n",
        "   string = re.sub(\"😄\", \" \",string)\n",
        "   string = re.sub(\"🧐\", \" \",string)\n",
        "   string = re.sub(\"😠\", \" \",string)\n",
        "   string = re.sub(\"🎈\", \" \",string)\n",
        "   string = re.sub(\"🚂\", \" \",string)\n",
        "   string = re.sub(\"😊\", \" \",string)\n",
        "   string = re.sub(\"🚇\", \" \",string)\n",
        "   string = re.sub(\"🚊\", \" \",string)\n",
        "   string = re.sub(\"🤷\", \" \",string)\n",
        "   string = re.sub(\"😥\", \" \",string)\n",
        "   string = re.sub(\"🙃\", \" \",string)\n",
        "   string = re.sub(\"🔩\", \" \",string)\n",
        "   string = re.sub(\"🔧\", \" \",string)\n",
        "   string = re.sub(\"🔨\", \" \",string)\n",
        "   string = re.sub(\"🛠\", \" \",string)\n",
        "   string = re.sub(\"💓\", \" \",string)\n",
        "   string = re.sub(\"💡\", \" \",string)\n",
        "   string = re.sub(\"🍸\", \" \",string)\n",
        "   string = re.sub(\"🥃\", \" \",string)\n",
        "   string = re.sub(\"🥂\", \" \",string)\n",
        "   string = re.sub(\"😷\", \" \",string)\n",
        "   string = re.sub(\"🤐\", \" \",string)\n",
        "   string = re.sub(\"🌎\", \" \",string)\n",
        "   string = re.sub(\"👑\", \" \",string)\n",
        "   string = re.sub(\"🤛\", \" \",string)\n",
        "   string = re.sub(\"😀\", \" \",string)\n",
        "   string = re.sub(\"🛤\", \" \",string)\n",
        "   string = re.sub(\"🎄\", \" \",string)\n",
        "   string = re.sub(\"📴\", \" \",string)\n",
        "   string = re.sub(\"🌭\", \" \",string)\n",
        "   string = re.sub(\"🤕\", \" \",string)\n",
        "   string = re.sub(\"😭\", \" \",string)\n",
        "   string = re.sub(\"🍾\", \" \",string)\n",
        "   string = re.sub(\"🍞\", \" \",string)\n",
        "   string = re.sub(\"🤦\", \" \",string)\n",
        "   string = re.sub(\"🤯\", \" \",string)\n",
        "   string = re.sub(\"🕯️\", \" \",string)\n",
        "\n",
        "   string = re.sub(\"OTHER|OFFENSE|ABUSE|INSULT\",\" \",string)\n",
        "   return string"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5asMgo4LtnRg"
      },
      "source": [
        "statementsForTraining = []\n",
        "sentimentsForTraining = []\n",
        "\n",
        "\n",
        "fileToRead = open(training_file, 'r')\n",
        "\n",
        "while True:\n",
        "  #next line in file\n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  findSentiment = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "\n",
        "\n",
        "  statementsForTraining.append(line)\n",
        "   #sentimentsForTraining.append(findSentiment.group(0))\n",
        "\n",
        "  if findSentiment.group(0) == \"OTHER\":  \n",
        "    sentimentsForTraining.append(0)\n",
        "  else:\n",
        "    sentimentsForTraining.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        " #print(\"{}: {}\".format(count,line.strip()))\n",
        "  \n",
        " # print(sentiment.group(0))\n",
        " \n",
        "fileToRead.close()\n",
        "\n",
        "training_sentences = statementsForTraining\n",
        "training_labels = sentimentsForTraining\n",
        "\n",
        "#print(training_sentences[9])\n",
        "#print(training_labels[9])\n",
        "\n",
        "#print(len(training_sentences))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsqZPENb98gD"
      },
      "source": [
        "##do the same with testdata\n",
        "statementsForTesting = []\n",
        "sentimentsForTesting = []\n",
        "\n",
        "fileToRead = open(testing_file, 'r')\n",
        "\n",
        "while True:\n",
        "  #next line in file\n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  sent = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "\n",
        "    \n",
        "\n",
        "  statementsForTesting.append(line)\n",
        "  #print(len(line))\n",
        "  #sentimentsForTesting.append(sent.group(0))\n",
        "\n",
        "  if sent.group(0) == \"OTHER\": \n",
        "    sentimentsForTesting.append(0)\n",
        "  else:\n",
        "    sentimentsForTesting.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        "\n",
        "fileToRead.close()\n",
        "\n",
        "\n",
        "testing_sentences = statementsForTesting\n",
        "testing_labels = sentimentsForTesting\n",
        "#print(len(testing_sentences))\n",
        "#print(testing_sentences)   \n",
        "#print(testing_labels)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRUvDLD5bMbO"
      },
      "source": [
        "Padding -> im Prinzip die Sätze alle auf die gleiche Länge bringen (in Theorieteil näher drauf eingehen) -> maxlen-Paramter ist für pad_sequences vorhanden, wenn nicht gesetzt -> alles wird auf die Länge des längsten Satzes aufgefüllt -> print(padded(shape)) gibt aus, wie viele Datensätze padded wurden und gibt an, wie viele Tokens der längste Datensatz hat\n",
        "print(padded[x]) gibt einen Satz aus (bereits tokenisiert)\n",
        "\n",
        "Padding -> sowohl für Trainigs- als auch für Testdaten\n",
        "\n",
        "Und: Daten als numpy-Arrays speichern (notwendig für tensorflow).\n",
        "\n",
        " -> Tokenizer https://towardsdatascience.com/text-classification-in-keras-part-2-how-to-use-the-keras-tokenizer-word-representations-fd571674df23 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3hFi7waTv5m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05fdecc0-e004-4433-805c-768c4dfa4e06"
      },
      "source": [
        "tokenizer = Tokenizer(oov_token=\"OOV\")\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "\n",
        "#creating a word index - nur die Trainigsdaten\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "validation_size = 500\n",
        "\n",
        "\n",
        "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "padded_training = pad_sequences(training_sequences, maxlen=max_length, padding='post')\n",
        "print(len(padded_training))\n",
        "\n",
        "validation_sequences = padded_training[0:validation_size]\n",
        "validation_labels = training_labels[0:validation_size]\n",
        "\n",
        "padded_training = padded_training[validation_size:]\n",
        "training_labels = training_labels[validation_size:]\n",
        "\n",
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
        "padded_testing = pad_sequences(testing_sequences, maxlen=max_length,  padding='post')\n",
        "\n",
        "#print(validation_sequences[499])\n",
        "print(padded_training[0])\n",
        "#print(len(validation_labels))\n",
        "#print(len(training_labels))\n",
        "\n",
        "\n",
        "nppadded_training = np.array(padded_training)\n",
        "nptraining_labels = np.array(training_labels)\n",
        "\n",
        "nppadded_validation = np.array(validation_sequences)\n",
        "npvalidation_labels = np.array(validation_labels)\n",
        "\n",
        "nppadded_testing = np.array(padded_testing)\n",
        "nptesting_labels = np.array(testing_labels)\n",
        "\n",
        "\n",
        "print(len(nppadded_training))\n",
        "print(len(nptraining_labels))\n",
        "print(len(word_index))\n",
        "\n",
        "#print(statementsForTraining[2])\n",
        "#print(nppadded_training[4])\n",
        "#print(nppadded_training.shape)\n",
        "#print(nptraining_labels[4])\n",
        "#print(nppadded_testing.shape)\n",
        "#print(word_index) \n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5009\n",
            "[  12 3982   11   41 6706 1040    4    5  202   39    3 2922   49 1360\n",
            "  810  495 3983    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0]\n",
            "4509\n",
            "4509\n",
            "15059\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tL3owrc8THkT"
      },
      "source": [
        "\n",
        "Dann: Embedding mit entweder word2vec oder glove\n",
        "Word2vec-Daten sind hier: http://vectors.nlpl.eu/repository/#\n",
        "Glove -> https://nlp.stanford.edu/projects/glove/ Da mal den Twitter-Vector runtergeladen\n",
        "Wenn Daten in GoogleDrive sind (wäre auch via url möglich..), muss Drive gemounted werden ( https://buomsoo-kim.github.io/colab/2020/05/09/Colab-mounting-google-drive.md/ ) aber auch hier https://enjoymachinelearning.com/posts/colab-with-google-drive/\n",
        "\n",
        "Die Word2vec vectors: http://vectors.nlpl.eu/repository/# \n",
        "\n",
        "glove-zitat:\n",
        "Citing GloVe\n",
        "\n",
        "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. [pdf] [bib]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zuO7T9ZTG57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f73a9e22-c343-4bd3-9e9b-d64bcc1ae4d6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "os.listdir(\"/content/drive/MyDrive/Colab Notebooks\")\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['germeval_training.txt',\n",
              " 'glove.twitter.27B.50d.txt',\n",
              " 'glove.twitter.27B.200d.txt',\n",
              " 'glove.6B.200d.txt',\n",
              " 'glove.840B.300d.txt',\n",
              " 'tensorboard.gdoc',\n",
              " 'keras.gdoc',\n",
              " 'Vectorization CNN embedded_limited_vocab.ipynb',\n",
              " 'glove.42B.300d.txt',\n",
              " 'Embedding Glove Vergleich.ipynb',\n",
              " 'LSTM.ipynb',\n",
              " 'CNN embedded_limited_vocab.ipynb',\n",
              " 'LSTM_limited_vocab.ipynb',\n",
              " 'CNN embedded.ipynb']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7ToKO-sZLHK"
      },
      "source": [
        "\n",
        "Keras-Doc : https://keras.io/examples/nlp/pretrained_word_embeddings/#load-pretrained-word-embeddings \n",
        "embedding mit initializers.. weights müsste auch funktionieren\n",
        "\n",
        "Diese erstellte Matrix mit Embedding dann in die Embedding-Schicht einbinden,  Trainable auf False, weil sich die Werte nicht durch Training anpassen sollen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AShIVfC7ZQAH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5df64219-4931-4328-e98f-2d83e1d9599d"
      },
      "source": [
        "#Größe Vokabel -> wordindex + 2 (weil padding + OOV) \n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "vocabulary_size = len(word_index)+2\n",
        "\n",
        "# dann erstell ich ein Wörterbuch mit Namen \"embedding_vector\", dort sind dann\n",
        "#die keys drinnen, die in glove-Datei drinnen sind mit dem entsprechenden Key\n",
        "\n",
        "embedding_index_glove = {}\n",
        "f = open('/content/drive/MyDrive/Colab Notebooks/glove.twitter.27B.200d.txt')\n",
        "for line in f:\n",
        "  value = line.split()\n",
        "  word = value[0]\n",
        "  coef = np.asarray(value[1:],dtype='float32')\n",
        "  embedding_index_glove[word] = coef\n",
        "\n",
        "print(\"%d gefunden: \"% len(embedding_index_glove))\n",
        "\n",
        "#Dann noch eine Embedding-Matrix erstellen\n",
        "#zweiter Wert = Embedding-Dimension der Datei, in dem Fall 200\n",
        "\n",
        "glove_matrix = np.zeros((vocabulary_size,200))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    embedding_value = embedding_index_glove.get(word)\n",
        "    if embedding_value is not None:\n",
        "      glove_matrix[index] = embedding_value\n",
        "      hits+=1\n",
        "    else:\n",
        "      misses+=1\n",
        "\n",
        "print(\"hits %d and %d misses\"%(hits,misses))\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1193514 gefunden: \n",
            "hits 6747 and 8312 misses\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZmvOfwhV4N5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e871e1c-bad6-435e-a92f-388ecac7b5de"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "print(\"vocab size: %d\"%vocabulary_size)\n",
        "CNN16052105 = tf.keras.Sequential()\n",
        "#Embedding -> hier dann auf das embedding verweisen, Input_dim -> die Anzahl der Wörter im word_index, output -> in dem Fall passend zum verwendeten Vektor\n",
        "#input-length -> auf 60  gepadded, trainable -> nein, weil nichts verändert werden soll\n",
        "#embeddings_initializer=keras.initializers.Constant(glove_matrix) vs weights = [glove_matrix]\n",
        "#Convolutional layers => filters = neurons.. mit 100? 265?\n",
        "CNN16052105.add(tf.keras.layers.Embedding(vocabulary_size, output_dim=200, input_length=60, embeddings_initializer = keras.initializers.Constant(glove_matrix), trainable= False))\n",
        "CNN16052105.add(tf.keras.layers.Dropout(0.4))\n",
        "CNN16052105.add(tf.keras.layers.Conv1D(filters=260, kernel_size=3, padding=\"valid\", activation=\"relu\"))\n",
        "CNN16052105.add(tf.keras.layers.MaxPooling1D())\n",
        "CNN16052105.add(tf.keras.layers.Conv1D(filters=260, kernel_size=3, padding=\"valid\", activation=\"relu\"))\n",
        "CNN16052105.add(tf.keras.layers.GlobalAveragePooling1D())\n",
        "CNN16052105.add(tf.keras.layers.Flatten())\n",
        "CNN16052105.add(tf.keras.layers.Dense(260, activation=\"relu\"))\n",
        "CNN16052105.add(tf.keras.layers.Dropout(0.4))\n",
        "CNN16052105.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "CNN16052105.summary()\n",
        "\n",
        "#nppadded_training = np.asmatrix(nppadded_training) not necessary\n",
        "#nppadded_testing = np.asmatrix(nppadded_testing)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab size: 15061\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 60, 200)           3012200   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 60, 200)           0         \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 58, 260)           156260    \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 29, 260)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 27, 260)           203060    \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 260)               0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 260)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 260)               67860     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 260)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 261       \n",
            "=================================================================\n",
            "Total params: 3,439,641\n",
            "Trainable params: 427,441\n",
            "Non-trainable params: 3,012,200\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEr4OzT-iHDe"
      },
      "source": [
        "#model.layers[2].get_weights()[0].shape\n",
        "#weights=np.random.rand(5,200,100)\n",
        "#bias=np.random.rand(100)\n",
        "#model.layers[2].set_weights([weights, bias])\n",
        "\n",
        "#model.layers[2].get_weights()[0]\n",
        "#https://androidkt.com/set-custom-weights-keras-using-numpy-array/"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UB7_3VPYesr9"
      },
      "source": [
        "F1-Score für jede Epoche https://aakashgoel12.medium.com/how-to-add-user-defined-function-get-f1-score-in-keras-metrics-3013f979ce0d\n",
        "\n",
        "Sehr gute Ressource für die verschiedenen Scores und Metriken https://neptune.ai/blog/evaluation-metrics-binary-classification#10  das und aakas verwendet\n",
        "\n",
        "hier: je eine Funktion für Recall, Precision, f1 https://neptune.ai/blog/keras-metrics \n",
        "\n",
        "https://keras.rstudio.com/reference/k_ones_like.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygyrbFJaMV9B"
      },
      "source": [
        "import keras.backend as K\n",
        "\n",
        "def metrics_recall(data_true, data_pred):\n",
        "    data_true = K.ones_like(data_true)\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(data_true,0,1)))\n",
        "\n",
        "    recall = true_positives / (possible_positives+K.epsilon())\n",
        "    return recall\n",
        "\n",
        "\n",
        "def metrics_precision(data_true, data_pred):\n",
        "    data_true = K.ones_like(data_true)\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "\n",
        "    positives_predicted = K.sum(K.round(K.clip(data_pred,0,1)))\n",
        "    precision = true_positives / (positives_predicted+K.epsilon())\n",
        "    return precision\n",
        "\n",
        "\n",
        "def metrics_f1(data_true, data_pred):\n",
        "    precision_data = metrics_precision(data_true, data_pred)\n",
        "    recall_data = metrics_recall(data_true, data_pred)\n",
        "    return 2*(precision_data*recall_data)/(precision_data+recall_data+K.epsilon())"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AfPD3_bWCm0"
      },
      "source": [
        "CNN16052105.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',metrics_recall,metrics_precision,metrics_f1])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpChKUY-QEWI"
      },
      "source": [
        "https://www.tensorflow.org/tensorboard/tensorboard_in_notebooks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJfMgUhHBoD1"
      },
      "source": [
        "#%reload_ext tensorboard\n",
        "#nur einmal pro Sitzung notwendig\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ISmMXLqP8Hc"
      },
      "source": [
        "\n",
        "logs_base_dir = \"./logs\"\n",
        "callbackForTB = tf.keras.callbacks.TensorBoard(logs_base_dir)\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2CHbXiP1LsF"
      },
      "source": [
        "training_epochs = 30\n",
        "batch_size = 40\n",
        "validation_split=0.2"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abV-QAxfW48r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bef25bf5-63fd-4dc1-9efc-cca84591e5bf"
      },
      "source": [
        "#Werte der Convolutional-Schichten variieren (Filter), Batch-Size variieren, kernel-size..\n",
        "CNN16052105.fit(nppadded_training, nptraining_labels, batch_size=batch_size, validation_split=validation_split, epochs=training_epochs, callbacks=[callbackForTB])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "91/91 [==============================] - 9s 92ms/step - loss: 0.6661 - accuracy: 0.6500 - metrics_recall: 0.0462 - metrics_precision: 0.1942 - metrics_f1: 0.0686 - val_loss: 0.6339 - val_accuracy: 0.6718 - val_metrics_recall: 0.0000e+00 - val_metrics_precision: 0.0000e+00 - val_metrics_f1: 0.0000e+00\n",
            "Epoch 2/30\n",
            "91/91 [==============================] - 8s 85ms/step - loss: 0.6410 - accuracy: 0.6542 - metrics_recall: 0.0033 - metrics_precision: 0.0745 - metrics_f1: 0.0062 - val_loss: 0.6069 - val_accuracy: 0.6718 - val_metrics_recall: 0.0000e+00 - val_metrics_precision: 0.0000e+00 - val_metrics_f1: 0.0000e+00\n",
            "Epoch 3/30\n",
            "91/91 [==============================] - 8s 86ms/step - loss: 0.6109 - accuracy: 0.6639 - metrics_recall: 0.0554 - metrics_precision: 0.4917 - metrics_f1: 0.0914 - val_loss: 0.5973 - val_accuracy: 0.7018 - val_metrics_recall: 0.0715 - val_metrics_precision: 0.9565 - val_metrics_f1: 0.1308\n",
            "Epoch 4/30\n",
            "91/91 [==============================] - 8s 86ms/step - loss: 0.5640 - accuracy: 0.6937 - metrics_recall: 0.1144 - metrics_precision: 0.8797 - metrics_f1: 0.1924 - val_loss: 0.5483 - val_accuracy: 0.7317 - val_metrics_recall: 0.1135 - val_metrics_precision: 0.9565 - val_metrics_f1: 0.1990\n",
            "Epoch 5/30\n",
            "91/91 [==============================] - 8s 87ms/step - loss: 0.5354 - accuracy: 0.7291 - metrics_recall: 0.2035 - metrics_precision: 1.0000 - metrics_f1: 0.3266 - val_loss: 0.5669 - val_accuracy: 0.6840 - val_metrics_recall: 0.3817 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.5485\n",
            "Epoch 6/30\n",
            "91/91 [==============================] - 8s 86ms/step - loss: 0.4869 - accuracy: 0.7606 - metrics_recall: 0.2614 - metrics_precision: 0.9998 - metrics_f1: 0.4022 - val_loss: 0.5434 - val_accuracy: 0.7251 - val_metrics_recall: 0.1436 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.2464\n",
            "Epoch 7/30\n",
            "91/91 [==============================] - 8s 87ms/step - loss: 0.4492 - accuracy: 0.7805 - metrics_recall: 0.2824 - metrics_precision: 0.9998 - metrics_f1: 0.4312 - val_loss: 0.5537 - val_accuracy: 0.6940 - val_metrics_recall: 0.3476 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.5111\n",
            "Epoch 8/30\n",
            "91/91 [==============================] - 8s 88ms/step - loss: 0.3979 - accuracy: 0.8187 - metrics_recall: 0.2882 - metrics_precision: 1.0000 - metrics_f1: 0.4403 - val_loss: 0.5600 - val_accuracy: 0.7162 - val_metrics_recall: 0.1945 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.3199\n",
            "Epoch 9/30\n",
            "91/91 [==============================] - 8s 87ms/step - loss: 0.3585 - accuracy: 0.8341 - metrics_recall: 0.3044 - metrics_precision: 1.0000 - metrics_f1: 0.4569 - val_loss: 0.5638 - val_accuracy: 0.6962 - val_metrics_recall: 0.3076 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.4645\n",
            "Epoch 10/30\n",
            "91/91 [==============================] - 8s 86ms/step - loss: 0.2988 - accuracy: 0.8595 - metrics_recall: 0.3097 - metrics_precision: 1.0000 - metrics_f1: 0.4664 - val_loss: 0.5788 - val_accuracy: 0.6929 - val_metrics_recall: 0.3565 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.5205\n",
            "Epoch 11/30\n",
            "91/91 [==============================] - 8s 86ms/step - loss: 0.2897 - accuracy: 0.8792 - metrics_recall: 0.3127 - metrics_precision: 1.0000 - metrics_f1: 0.4701 - val_loss: 0.6470 - val_accuracy: 0.7084 - val_metrics_recall: 0.3726 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.5372\n",
            "Epoch 12/30\n",
            "91/91 [==============================] - 8s 86ms/step - loss: 0.2523 - accuracy: 0.8923 - metrics_recall: 0.3305 - metrics_precision: 1.0000 - metrics_f1: 0.4898 - val_loss: 0.6034 - val_accuracy: 0.7206 - val_metrics_recall: 0.3054 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.4631\n",
            "Epoch 13/30\n",
            "91/91 [==============================] - 8s 87ms/step - loss: 0.2193 - accuracy: 0.9099 - metrics_recall: 0.3194 - metrics_precision: 1.0000 - metrics_f1: 0.4776 - val_loss: 0.6569 - val_accuracy: 0.7151 - val_metrics_recall: 0.3335 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.4922\n",
            "Epoch 14/30\n",
            "91/91 [==============================] - 8s 86ms/step - loss: 0.1983 - accuracy: 0.9171 - metrics_recall: 0.3195 - metrics_precision: 1.0000 - metrics_f1: 0.4778 - val_loss: 0.7995 - val_accuracy: 0.6585 - val_metrics_recall: 0.5025 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.6657\n",
            "Epoch 15/30\n",
            "91/91 [==============================] - 8s 86ms/step - loss: 0.2027 - accuracy: 0.9103 - metrics_recall: 0.3291 - metrics_precision: 1.0000 - metrics_f1: 0.4897 - val_loss: 0.7285 - val_accuracy: 0.7118 - val_metrics_recall: 0.2967 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.4530\n",
            "Epoch 16/30\n",
            "91/91 [==============================] - 8s 89ms/step - loss: 0.1819 - accuracy: 0.9267 - metrics_recall: 0.3368 - metrics_precision: 1.0000 - metrics_f1: 0.4980 - val_loss: 0.8739 - val_accuracy: 0.6497 - val_metrics_recall: 0.4943 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.6559\n",
            "Epoch 17/30\n",
            "91/91 [==============================] - 8s 89ms/step - loss: 0.1588 - accuracy: 0.9400 - metrics_recall: 0.3374 - metrics_precision: 1.0000 - metrics_f1: 0.4996 - val_loss: 0.7860 - val_accuracy: 0.7029 - val_metrics_recall: 0.3459 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.5060\n",
            "Epoch 18/30\n",
            "91/91 [==============================] - 8s 88ms/step - loss: 0.1489 - accuracy: 0.9407 - metrics_recall: 0.3335 - metrics_precision: 1.0000 - metrics_f1: 0.4937 - val_loss: 0.8092 - val_accuracy: 0.6996 - val_metrics_recall: 0.3304 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.4918\n",
            "Epoch 19/30\n",
            "91/91 [==============================] - 8s 88ms/step - loss: 0.1270 - accuracy: 0.9511 - metrics_recall: 0.3244 - metrics_precision: 1.0000 - metrics_f1: 0.4852 - val_loss: 0.8705 - val_accuracy: 0.6896 - val_metrics_recall: 0.3755 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.5382\n",
            "Epoch 20/30\n",
            "91/91 [==============================] - 8s 87ms/step - loss: 0.1186 - accuracy: 0.9461 - metrics_recall: 0.3339 - metrics_precision: 0.9998 - metrics_f1: 0.4945 - val_loss: 0.8827 - val_accuracy: 0.6851 - val_metrics_recall: 0.3442 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.5054\n",
            "Epoch 21/30\n",
            "91/91 [==============================] - 8s 88ms/step - loss: 0.1275 - accuracy: 0.9499 - metrics_recall: 0.3342 - metrics_precision: 0.9998 - metrics_f1: 0.4960 - val_loss: 0.8327 - val_accuracy: 0.6996 - val_metrics_recall: 0.3013 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.4576\n",
            "Epoch 22/30\n",
            "91/91 [==============================] - 8s 88ms/step - loss: 0.1054 - accuracy: 0.9567 - metrics_recall: 0.3306 - metrics_precision: 1.0000 - metrics_f1: 0.4913 - val_loss: 0.8865 - val_accuracy: 0.6918 - val_metrics_recall: 0.3737 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.5394\n",
            "Epoch 23/30\n",
            "91/91 [==============================] - 8s 88ms/step - loss: 0.1059 - accuracy: 0.9552 - metrics_recall: 0.3434 - metrics_precision: 1.0000 - metrics_f1: 0.5070 - val_loss: 0.8745 - val_accuracy: 0.7106 - val_metrics_recall: 0.2730 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.4227\n",
            "Epoch 24/30\n",
            "91/91 [==============================] - 8s 88ms/step - loss: 0.0909 - accuracy: 0.9679 - metrics_recall: 0.3411 - metrics_precision: 1.0000 - metrics_f1: 0.5026 - val_loss: 1.0678 - val_accuracy: 0.7206 - val_metrics_recall: 0.2393 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.3804\n",
            "Epoch 25/30\n",
            "91/91 [==============================] - 8s 89ms/step - loss: 0.0974 - accuracy: 0.9621 - metrics_recall: 0.3239 - metrics_precision: 1.0000 - metrics_f1: 0.4824 - val_loss: 0.9559 - val_accuracy: 0.6818 - val_metrics_recall: 0.3878 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.5529\n",
            "Epoch 26/30\n",
            "91/91 [==============================] - 8s 89ms/step - loss: 0.1009 - accuracy: 0.9591 - metrics_recall: 0.3166 - metrics_precision: 1.0000 - metrics_f1: 0.4755 - val_loss: 0.9234 - val_accuracy: 0.7251 - val_metrics_recall: 0.2911 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.4455\n",
            "Epoch 27/30\n",
            "91/91 [==============================] - 8s 89ms/step - loss: 0.0708 - accuracy: 0.9651 - metrics_recall: 0.3183 - metrics_precision: 1.0000 - metrics_f1: 0.4772 - val_loss: 1.2221 - val_accuracy: 0.7173 - val_metrics_recall: 0.1886 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.3120\n",
            "Epoch 28/30\n",
            "91/91 [==============================] - 8s 89ms/step - loss: 0.1084 - accuracy: 0.9623 - metrics_recall: 0.3426 - metrics_precision: 1.0000 - metrics_f1: 0.5066 - val_loss: 1.0335 - val_accuracy: 0.7073 - val_metrics_recall: 0.3042 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.4599\n",
            "Epoch 29/30\n",
            "91/91 [==============================] - 8s 89ms/step - loss: 0.0820 - accuracy: 0.9707 - metrics_recall: 0.3361 - metrics_precision: 1.0000 - metrics_f1: 0.4985 - val_loss: 1.0215 - val_accuracy: 0.6984 - val_metrics_recall: 0.3637 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.5269\n",
            "Epoch 30/30\n",
            "91/91 [==============================] - 8s 90ms/step - loss: 0.0637 - accuracy: 0.9768 - metrics_recall: 0.3333 - metrics_precision: 1.0000 - metrics_f1: 0.4965 - val_loss: 1.0418 - val_accuracy: 0.7118 - val_metrics_recall: 0.2676 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.4156\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc519021d10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJVL4SBLPB2P"
      },
      "source": [
        "#%tensorboard --logdir {logs_base_dir}"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_LnvWBcnoak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84a250a6-0798-4b3c-d402-d2b9d9b21eee"
      },
      "source": [
        "#results = model.evaluate(nppadded_testing, nptesting_labels, batch_size=batch_size)\n",
        "#print(\"test loss, test acc:\",results)\n",
        "\n",
        "(loss,accuracy, metrics_recall, metrics_precision,\n",
        "metrics_f1) = CNN16052105.evaluate(nppadded_testing, nptesting_labels, verbose=1)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "111/111 [==============================] - 2s 19ms/step - loss: 1.0472 - accuracy: 0.6863 - metrics_recall: 0.2459 - metrics_precision: 1.0000 - metrics_f1: 0.3882\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KgjIkhpKmHc"
      },
      "source": [
        "make some predictions of test data and save it to variable. verbose=0 -> do not generate output\n",
        "Gute Quelle: https://deeplizard.com/learn/video/2f-NjDUvZIE "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89GWuxryKlcM"
      },
      "source": [
        "CNN_predictions05 = CNN16052105.predict(x=nppadded_testing)\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3jPDaDJK_cN"
      },
      "source": [
        "#for p in CNN_predictions05:\n",
        " # print(p)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eC9efJy4Lp21"
      },
      "source": [
        "rounded predictions: give prediction value of most likely prediction (0 or 1). Printing the output of rounded prediction shows the prediction made by the model on the data (which output is most likely)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsG-TJuQLvtk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd00d88f-48d3-44c1-ea0f-af7b95171561"
      },
      "source": [
        "prediction_rounded05 = np.round(CNN_predictions05)\n",
        "#np.argmax(CNN_predictions05,axis=-1)\n",
        "\n",
        "#for p in prediction_rounded05:\n",
        " # print(p)\n",
        "\n",
        "\n",
        "print(nptesting_labels[500:520])\n",
        "print(prediction_rounded05[500:520])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1]\n",
            "[[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egTtgpXgg8a2"
      },
      "source": [
        "https://deeplizard.com/learn/video/km7pxKy4UHU\n",
        "\n",
        "Quelle der def plot_confusion_matrix: https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSDXf7-_MITy"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0AMs1EzhBU1"
      },
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                        normalize=False,\n",
        "                        title='Confusion matrix',\n",
        "                        cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2JgEnlghCtl"
      },
      "source": [
        "cm = confusion_matrix(y_true=nptesting_labels, y_pred=prediction_rounded05)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckmF29whhFmX"
      },
      "source": [
        "plot_labels = ['no hatespeech','hatespeech']"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "2mpSE96rhK7K",
        "outputId": "b0d8d5aa-c38c-4159-85e6-8eefc5d91787"
      },
      "source": [
        "plot_confusion_matrix(cm=cm, classes=plot_labels, title='CNN Confusion 260')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix, without normalization\n",
            "[[1942  388]\n",
            " [ 720  482]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}