{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN embedded.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOXpOysUWURNssIHChnAVnr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BiancaStadl/ProjektarbeitML/blob/main/CNN_embedded.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXDOlIBymF0V"
      },
      "source": [
        "GloVe embeddings taken from:\n",
        "\n",
        "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. [pdf] [bib]\n",
        "\n",
        "hatespeechdata taken from (https://hatespeechdata.com/): Wiegand, M., Siegel, M. and Ruppenhofer, J., 2018. Overview of the GermEval 2018 Shared Task on the Identification of Offensive Language. In: Proceedings of GermEval 2018, 14th Conference on Natural Language Processing (KONVENS 2018). Vienna, Austria: Research Gate. available on: https://github.com/uds-lsv/GermEval-2018-Data (last checked: 09.05.2021)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlBmABDxfqII"
      },
      "source": [
        "wiki detox..https://colab.research.google.com/github/tensorflow/fairness-indicators/blob/master/g3doc/tutorials/Fairness_Indicators_TFCO_Wiki_Case_Study.ipynb#scrollTo=y6T5tlXcdW7J "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3xfitNdliBI"
      },
      "source": [
        "#import matplotlib.pyplot as plt -> für evtl Visualisierungen\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import string\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from keras import losses \n",
        "from keras import optimizers \n",
        "from keras import metrics \n",
        "\n",
        "#!pip install Tokenizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "#!pip install pad_sequences\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import preprocessing\n",
        "#from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTWJQ1iga_vS"
      },
      "source": [
        "Maximale Satzlänge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bq08Me5la_Cc"
      },
      "source": [
        "\n",
        "max_length = 60"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVYBMvYSotTH"
      },
      "source": [
        "url = \"https://github.com/uds-lsv/GermEval-2018-Data/archive/master.zip\"\n",
        "\n",
        "dataset = tf.keras.utils.get_file(\"GermEval-2018-Data-master.zip\", url, \n",
        "                                   extract=True, cache_dir='.',\n",
        "                                    cache_subdir='')\n",
        "\n",
        "dataset_dir = os.path.join(os.path.dirname(dataset), 'GermEval-2018-Data-master')\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cS14OUtfo34V"
      },
      "source": [
        "#os.listdir(dataset_dir)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2X429K6hpOVm"
      },
      "source": [
        "training_file = os.path.join(dataset_dir, 'germeval2018.training.txt')\n",
        "\n",
        "testing_file = os.path.join(dataset_dir, 'germeval2018.test.txt')\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uq8fG3LNtn_m"
      },
      "source": [
        "###Aufbereitung\n",
        "txt-Dateien lesen, und dabei jede Zeile splitten und teilen\n",
        "Twitter-Handler entfernen?\n",
        "Labels von Sätzen trennen, Labels in eigenen Array packen.\n",
        "\n",
        "####Ressourcen\n",
        "* https://www.w3schools.com/python/gloss_python_if_statement.asp\n",
        "* https://stackabuse.com/using-regex-for-text-manipulation-in-python/\n",
        "* https://www.tutorialspoint.com/python/string_splitlines.htm \n",
        "* https://note.nkmk.me/en/python-split-rsplit-splitlines-re/ \n",
        "* https://www.w3schools.com/python/python_regex.asp \n",
        "\n",
        "gäbe bei keras tf.keras.preprocessing.text_dataset_from_directory, aber dafür müssten die Daten auf bestimmte Weise in Verzeichnis organisiert sein, hier nicht der Fall.\n",
        "\n",
        "\n",
        "Einteilung der Daten: Testdaten\n",
        "Trainingsdaten -> noch ca 500 für Validierungsdaten\n",
        "\n",
        "labels -> \"other\", also nicht-negative Aussagen bekommen \"0\", negative Aussagen bekommen \"1\"\n",
        "\n",
        " Regex für Emojis  ->\n",
        "\n",
        "(\\u00a9|\\u00ae|[\\u2000-\\u3300]|\\ud83c[\\ud000-\\udfff]|\\ud83d[\\ud000-\\udfff]|\\ud83e[\\ud000-\\udfff])\n",
        "\n",
        "genommen von https://www.regextester.com/106421 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Py_cwD4eZkXo"
      },
      "source": [
        "def remove_clutter(string):\n",
        "   string = re.sub(\"@[^\\s]+\",\" \",string)\n",
        "   string = re.sub(\"#[^\\s]+\",\" \", string)\n",
        "   string = re.sub(\"\\u00a9\",\" \", string)\n",
        "   string = re.sub(\"\\u00ae\",\" \", string)\n",
        "   string = re.sub(\"[\\u2000-\\u3300]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83c[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83d[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83e[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"😜\", \" \",string)\n",
        "   string = re.sub(\"🍫\", \" \",string)\n",
        "   string = re.sub(\"😁\", \" \",string)\n",
        "   string = re.sub(\"🐖\", \" \",string)\n",
        "   string = re.sub(\"😡\", \" \",string)\n",
        "   string = re.sub(\"😇\", \" \",string)\n",
        "   string = re.sub(\"😬\", \" \",string)\n",
        "   string = re.sub(\"😃\", \" \",string)\n",
        "   string = re.sub(\"😂\", \" \",string)\n",
        "   string = re.sub(\"💙\", \" \",string)  \n",
        "   string = re.sub(\"😛\", \" \",string)\n",
        "   string = re.sub(\"🙏\", \" \",string)\n",
        "   string = re.sub(\"👍\", \" \",string)\n",
        "   string = re.sub(\"🖕\", \" \",string)\n",
        "   string = re.sub(\"😉\", \" \",string)\n",
        "   string = re.sub(\"💩\", \" \",string)\n",
        "   string = re.sub(\"🤢\", \" \",string)\n",
        "   string = re.sub(\"👏\", \" \",string)\n",
        "   string = re.sub(\"😨\", \" \",string)\n",
        "   string = re.sub(\"🤣\", \" \",string)\n",
        "   string = re.sub(\"🤡\", \" \",string)\n",
        "   string = re.sub(\"😈\", \" \",string)\n",
        "   string = re.sub(\"💃🏽\", \" \",string)\n",
        "   string = re.sub(\"👹\", \" \",string)\n",
        "   string = re.sub(\"🤘\", \" \",string)\n",
        "   string = re.sub(\"😱\", \" \",string)\n",
        "   string = re.sub(\"🤔\", \" \",string) \n",
        "   string = re.sub(\"🌈\", \" \",string) \n",
        "   string = re.sub(\"💕\", \" \",string) \n",
        "   string = re.sub(\"👩‍❤️‍👩\", \" \",string) \n",
        "   string = re.sub(\"😍\", \" \",string) \n",
        "   string = re.sub(\"👆\", \" \",string) \n",
        "   string = re.sub(\"😖\", \" \",string) \n",
        "   string = re.sub(\"👇\", \" \",string) \n",
        "   string = re.sub(\"🔥\", \" \",string) \n",
        "   string = re.sub(\"😘\", \" \",string) \n",
        "   string = re.sub(\"🎉\", \" \",string) \n",
        "   string = re.sub(\"🤬\", \" \",string) \n",
        "   string = re.sub(\"👊\", \" \",string)\n",
        "   string = re.sub(\"🇩🇪\", \" \",string)  \n",
        "   string = re.sub(\"💔\", \" \",string)\n",
        "   string = re.sub(\"🙈\", \" \",string)\n",
        "   string = re.sub(\"🤯\", \" \",string)\n",
        "   string = re.sub(\"🐟\", \" \",string)\n",
        "   string = re.sub(\"🛶\", \" \",string)\n",
        "   string = re.sub(\"😊\", \" \",string)\n",
        "   string = re.sub(\"😓\", \" \",string)\n",
        "   string = re.sub(\"😳\", \" \",string)\n",
        "   string = re.sub(\"🚀\", \" \",string)\n",
        "   string = re.sub(\"👎\", \" \",string)\n",
        "   string = re.sub(\"😎\", \" \",string)\n",
        "   string = re.sub(\"🐸\", \" \",string)\n",
        "   string = re.sub(\"📈\", \" \",string)\n",
        "   string = re.sub(\"🙂\", \" \",string)\n",
        "   string = re.sub(\"😅\", \" \",string)\n",
        "   string = re.sub(\"😆\", \" \",string)\n",
        "   string = re.sub(\"🙎🏿\", \" \",string)\n",
        "   string = re.sub(\"👎🏽\", \" \",string)\n",
        "   string = re.sub(\"🤭\", \" \",string)\n",
        "   string = re.sub(\"😤\", \" \",string)\n",
        "   string = re.sub(\"😚\", \" \",string)\n",
        "   string = re.sub(\"😊\", \" \",string)\n",
        "   string = re.sub(\"😲\", \" \",string)\n",
        "   string = re.sub(\"🤮\", \" \",string)\n",
        "   string = re.sub(\"🙄\", \" \",string)\n",
        "   string = re.sub(\"🤑\", \" \",string)\n",
        "   string = re.sub(\"🎅\", \" \",string)\n",
        "   string = re.sub(\"👋\", \" \",string)\n",
        "   string = re.sub(\"💪\", \" \",string)\n",
        "   string = re.sub(\"😄\", \" \",string)\n",
        "   string = re.sub(\"🧐\", \" \",string)\n",
        "   string = re.sub(\"😠\", \" \",string)\n",
        "   string = re.sub(\"🎈\", \" \",string)\n",
        "   string = re.sub(\"🚂\", \" \",string)\n",
        "   string = re.sub(\"😊\", \" \",string)\n",
        "   string = re.sub(\"🚇\", \" \",string)\n",
        "   string = re.sub(\"🚊\", \" \",string)\n",
        "   string = re.sub(\"🤷\", \" \",string)\n",
        "   string = re.sub(\"😥\", \" \",string)\n",
        "   string = re.sub(\"🙃\", \" \",string)\n",
        "   string = re.sub(\"🔩\", \" \",string)\n",
        "   string = re.sub(\"🔧\", \" \",string)\n",
        "   string = re.sub(\"🔨\", \" \",string)\n",
        "   string = re.sub(\"🛠\", \" \",string)\n",
        "   string = re.sub(\"💓\", \" \",string)\n",
        "   string = re.sub(\"💡\", \" \",string)\n",
        "   string = re.sub(\"🍸\", \" \",string)\n",
        "   string = re.sub(\"🥃\", \" \",string)\n",
        "   string = re.sub(\"🥂\", \" \",string)\n",
        "   string = re.sub(\"😷\", \" \",string)\n",
        "   string = re.sub(\"🤐\", \" \",string)\n",
        "   string = re.sub(\"🌎\", \" \",string)\n",
        "   string = re.sub(\"👑\", \" \",string)\n",
        "   string = re.sub(\"🤛\", \" \",string)\n",
        "   string = re.sub(\"😀\", \" \",string)\n",
        "   string = re.sub(\"🛤\", \" \",string)\n",
        "   string = re.sub(\"🎄\", \" \",string)\n",
        "   string = re.sub(\"📴\", \" \",string)\n",
        "   string = re.sub(\"🌭\", \" \",string)\n",
        "   string = re.sub(\"🤕\", \" \",string)\n",
        "   string = re.sub(\"😭\", \" \",string)\n",
        "   string = re.sub(\"🍾\", \" \",string)\n",
        "   string = re.sub(\"🍞\", \" \",string)\n",
        "   string = re.sub(\"🤦\", \" \",string)\n",
        "   string = re.sub(\"🤯\", \" \",string)\n",
        "   string = re.sub(\"🕯️\", \" \",string)\n",
        "\n",
        "   string = re.sub(\"OTHER|OFFENSE|ABUSE|INSULT\",\" \",string)\n",
        "   return string"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5asMgo4LtnRg"
      },
      "source": [
        "statementsForTraining = []\n",
        "sentimentsForTraining = []\n",
        "\n",
        "\n",
        "fileToRead = open(training_file, 'r')\n",
        "\n",
        "while True:\n",
        "  #next line in file\n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  findSentiment = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "\n",
        "\n",
        "  statementsForTraining.append(line)\n",
        "   #sentimentsForTraining.append(findSentiment.group(0))\n",
        "\n",
        "  if findSentiment.group(0) == \"OTHER\":  \n",
        "    sentimentsForTraining.append(0)\n",
        "  else:\n",
        "    sentimentsForTraining.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        " #print(\"{}: {}\".format(count,line.strip()))\n",
        "  \n",
        " # print(sentiment.group(0))\n",
        " \n",
        "fileToRead.close()\n",
        "\n",
        "training_sentences = statementsForTraining\n",
        "training_labels = sentimentsForTraining\n",
        "\n",
        "#print(training_sentences[9])\n",
        "#print(training_labels[9])\n",
        "\n",
        "#print(len(training_sentences))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsqZPENb98gD"
      },
      "source": [
        "##do the same with testdata\n",
        "statementsForTesting = []\n",
        "sentimentsForTesting = []\n",
        "\n",
        "fileToRead = open(testing_file, 'r')\n",
        "\n",
        "while True:\n",
        "  #next line in file\n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  sent = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "\n",
        "    \n",
        "\n",
        "  statementsForTesting.append(line)\n",
        "  #print(len(line))\n",
        "  #sentimentsForTesting.append(sent.group(0))\n",
        "\n",
        "  if sent.group(0) == \"OTHER\": \n",
        "    sentimentsForTesting.append(0)\n",
        "  else:\n",
        "    sentimentsForTesting.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        "\n",
        "fileToRead.close()\n",
        "\n",
        "\n",
        "testing_sentences = statementsForTesting\n",
        "testing_labels = sentimentsForTesting\n",
        "#print(len(testing_sentences))\n",
        "#print(testing_sentences)   \n",
        "#print(testing_labels)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRUvDLD5bMbO"
      },
      "source": [
        "Padding -> im Prinzip die Sätze alle auf die gleiche Länge bringen (in Theorieteil näher drauf eingehen) -> maxlen-Paramter ist für pad_sequences vorhanden, wenn nicht gesetzt -> alles wird auf die Länge des längsten Satzes aufgefüllt -> print(padded(shape)) gibt aus, wie viele Datensätze padded wurden und gibt an, wie viele Tokens der längste Datensatz hat\n",
        "print(padded[x]) gibt einen Satz aus (bereits tokenisiert)\n",
        "\n",
        "Padding -> sowohl für Trainigs- als auch für Testdaten\n",
        "\n",
        "Und: Daten als numpy-Arrays speichern (notwendig für tensorflow).\n",
        "\n",
        " -> Tokenizer https://towardsdatascience.com/text-classification-in-keras-part-2-how-to-use-the-keras-tokenizer-word-representations-fd571674df23 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3hFi7waTv5m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0795de46-dcf5-42bf-db3d-80f952f5e653"
      },
      "source": [
        "tokenizer = Tokenizer(oov_token=\"OOV\")\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "\n",
        "#creating a word index - nur die Trainigsdaten\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "validation_size = 500\n",
        "\n",
        "\n",
        "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "padded_training = pad_sequences(training_sequences, maxlen=max_length, padding='post')\n",
        "print(len(padded_training))\n",
        "\n",
        "validation_sequences = padded_training[0:validation_size]\n",
        "validation_labels = training_labels[0:validation_size]\n",
        "\n",
        "padded_training = padded_training[validation_size:]\n",
        "training_labels = training_labels[validation_size:]\n",
        "\n",
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
        "padded_testing = pad_sequences(testing_sequences, maxlen=max_length,  padding='post')\n",
        "\n",
        "#print(validation_sequences[499])\n",
        "print(padded_training[0])\n",
        "#print(len(validation_labels))\n",
        "#print(len(training_labels))\n",
        "\n",
        "\n",
        "nppadded_training = np.array(padded_training)\n",
        "nptraining_labels = np.array(training_labels)\n",
        "\n",
        "nppadded_validation = np.array(validation_sequences)\n",
        "npvalidation_labels = np.array(validation_labels)\n",
        "\n",
        "nppadded_testing = np.array(padded_testing)\n",
        "nptesting_labels = np.array(testing_labels)\n",
        "\n",
        "\n",
        "print(len(nppadded_training))\n",
        "print(len(nptraining_labels))\n",
        "print(len(word_index))\n",
        "\n",
        "#print(statementsForTraining[2])\n",
        "#print(nppadded_training[4])\n",
        "#print(nppadded_training.shape)\n",
        "#print(nptraining_labels[4])\n",
        "#print(nppadded_testing.shape)\n",
        "#print(word_index) \n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5009\n",
            "[  12 3982   11   41 6706 1040    4    5  202   39    3 2922   49 1360\n",
            "  810  495 3983    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0]\n",
            "4509\n",
            "4509\n",
            "15059\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tL3owrc8THkT"
      },
      "source": [
        "\n",
        "Dann: Embedding mit entweder word2vec oder glove\n",
        "Word2vec-Daten sind hier: http://vectors.nlpl.eu/repository/#\n",
        "Glove -> https://nlp.stanford.edu/projects/glove/ Da mal den Twitter-Vector runtergeladen\n",
        "Wenn Daten in GoogleDrive sind (wäre auch via url möglich..), muss Drive gemounted werden ( https://buomsoo-kim.github.io/colab/2020/05/09/Colab-mounting-google-drive.md/ ) aber auch hier https://enjoymachinelearning.com/posts/colab-with-google-drive/\n",
        "\n",
        "Die Word2vec vectors: http://vectors.nlpl.eu/repository/# \n",
        "\n",
        "glove-zitat:\n",
        "Citing GloVe\n",
        "\n",
        "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. [pdf] [bib]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zuO7T9ZTG57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a59e7454-3850-4a2b-bea9-52541940e13a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "os.listdir(\"/content/drive/MyDrive/Colab Notebooks\")\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['germeval_training.txt',\n",
              " 'glove.twitter.27B.50d.txt',\n",
              " 'glove.twitter.27B.200d.txt',\n",
              " 'glove.6B.200d.txt',\n",
              " 'glove.840B.300d.txt',\n",
              " 'tensorboard.gdoc',\n",
              " 'keras.gdoc',\n",
              " 'Vectorization CNN embedded_limited_vocab.ipynb',\n",
              " 'glove.42B.300d.txt',\n",
              " 'Embedding Glove Vergleich.ipynb',\n",
              " 'CNN embedded_limited_vocab.ipynb',\n",
              " 'LSTM_limited_vocab.ipynb',\n",
              " 'LSTM.ipynb',\n",
              " 'CNN embedded.ipynb']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7ToKO-sZLHK"
      },
      "source": [
        "\n",
        "Keras-Doc : https://keras.io/examples/nlp/pretrained_word_embeddings/#load-pretrained-word-embeddings \n",
        "embedding mit initializers.. weights müsste auch funktionieren\n",
        "\n",
        "Diese erstellte Matrix mit Embedding dann in die Embedding-Schicht einbinden,  Trainable auf False, weil sich die Werte nicht durch Training anpassen sollen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AShIVfC7ZQAH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3240459b-c849-49fe-ab4c-cceda9d1d305"
      },
      "source": [
        "#Größe Vokabel -> wordindex + 2 (weil padding + OOV) \n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "vocabulary_size = len(word_index)+2\n",
        "\n",
        "# dann erstell ich ein Wörterbuch mit Namen \"embedding_vector\", dort sind dann\n",
        "#die keys drinnen, die in glove-Datei drinnen sind mit dem entsprechenden Key\n",
        "\n",
        "embedding_index_glove = {}\n",
        "f = open('/content/drive/MyDrive/Colab Notebooks/glove.twitter.27B.200d.txt')\n",
        "for line in f:\n",
        "  value = line.split()\n",
        "  word = value[0]\n",
        "  coef = np.asarray(value[1:],dtype='float32')\n",
        "  embedding_index_glove[word] = coef\n",
        "\n",
        "print(\"%d gefunden: \"% len(embedding_index_glove))\n",
        "\n",
        "#Dann noch eine Embedding-Matrix erstellen\n",
        "#zweiter Wert = Embedding-Dimension der Datei, in dem Fall 200\n",
        "\n",
        "glove_matrix = np.zeros((vocabulary_size,200))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    embedding_value = embedding_index_glove.get(word)\n",
        "    if embedding_value is not None:\n",
        "      glove_matrix[index] = embedding_value\n",
        "      hits+=1\n",
        "    else:\n",
        "      misses+=1\n",
        "\n",
        "print(\"hits %d and %d misses\"%(hits,misses))\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1193514 gefunden: \n",
            "hits 6747 and 8312 misses\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZmvOfwhV4N5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0eb8e3c-4750-4fc8-bc4c-50d7a9c453bd"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "print(\"vocab size: %d\"%vocabulary_size)\n",
        "CNN16052104 = tf.keras.Sequential()\n",
        "#Embedding -> hier dann auf das embedding verweisen, Input_dim -> die Anzahl der Wörter im word_index, output -> in dem Fall passend zum verwendeten Vektor\n",
        "#input-length -> auf 60  gepadded, trainable -> nein, weil nichts verändert werden soll\n",
        "#embeddings_initializer=keras.initializers.Constant(glove_matrix) vs weights = [glove_matrix]\n",
        "#Convolutional layers => filters = neurons.. mit 100? 265?\n",
        "CNN16052104.add(tf.keras.layers.Embedding(vocabulary_size, output_dim=200, input_length=60, embeddings_initializer = keras.initializers.Constant(glove_matrix), trainable= False))\n",
        "CNN16052104.add(tf.keras.layers.Dropout(0.4))\n",
        "CNN16052104.add(tf.keras.layers.Conv1D(filters=120, kernel_size=3, padding=\"valid\", activation=\"relu\"))\n",
        "CNN16052104.add(tf.keras.layers.MaxPooling1D())\n",
        "CNN16052104.add(tf.keras.layers.Conv1D(filters=120, kernel_size=3, padding=\"valid\", activation=\"relu\"))\n",
        "CNN16052104.add(tf.keras.layers.GlobalAveragePooling1D())\n",
        "CNN16052104.add(tf.keras.layers.Flatten())\n",
        "CNN16052104.add(tf.keras.layers.Dense(260, activation=\"relu\"))\n",
        "CNN16052104.add(tf.keras.layers.Dropout(0.4))\n",
        "CNN16052104.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "CNN16052104.summary()\n",
        "\n",
        "#nppadded_training = np.asmatrix(nppadded_training) not necessary\n",
        "#nppadded_testing = np.asmatrix(nppadded_testing)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab size: 15061\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 60, 200)           3012200   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 60, 200)           0         \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 58, 120)           72120     \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 29, 120)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 27, 120)           43320     \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 120)               0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 120)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 260)               31460     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 260)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 261       \n",
            "=================================================================\n",
            "Total params: 3,159,361\n",
            "Trainable params: 147,161\n",
            "Non-trainable params: 3,012,200\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEr4OzT-iHDe"
      },
      "source": [
        "#model.layers[2].get_weights()[0].shape\n",
        "#weights=np.random.rand(5,200,100)\n",
        "#bias=np.random.rand(100)\n",
        "#model.layers[2].set_weights([weights, bias])\n",
        "\n",
        "#model.layers[2].get_weights()[0]\n",
        "#https://androidkt.com/set-custom-weights-keras-using-numpy-array/"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UB7_3VPYesr9"
      },
      "source": [
        "F1-Score für jede Epoche https://aakashgoel12.medium.com/how-to-add-user-defined-function-get-f1-score-in-keras-metrics-3013f979ce0d\n",
        "\n",
        "Sehr gute Ressource für die verschiedenen Scores und Metriken https://neptune.ai/blog/evaluation-metrics-binary-classification#10  das und aakas verwendet\n",
        "\n",
        "hier: je eine Funktion für Recall, Precision, f1 https://neptune.ai/blog/keras-metrics \n",
        "\n",
        "https://keras.rstudio.com/reference/k_ones_like.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygyrbFJaMV9B"
      },
      "source": [
        "import keras.backend as K\n",
        "\n",
        "def metrics_recall(data_true, data_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(data_true,0,1)))\n",
        "\n",
        "    recall = true_positives / (possible_positives+K.epsilon())\n",
        "    return recall\n",
        "\n",
        "\n",
        "def metrics_precision(data_true, data_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "\n",
        "    positives_predicted = K.sum(K.round(K.clip(data_pred,0,1)))\n",
        "    precision = true_positives / (positives_predicted+K.epsilon())\n",
        "    return precision\n",
        "\n",
        "\n",
        "def metrics_f1(data_true, data_pred):\n",
        "    precision_data = metrics_precision(data_true, data_pred)\n",
        "    recall_data = metrics_recall(data_true, data_pred)\n",
        "    return 2*(precision_data*recall_data)/(precision_data+recall_data+K.epsilon())"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1ctlBrnuYJz"
      },
      "source": [
        "https://aakashgoel12.medium.com/how-to-add-user-defined-function-get-f1-score-in-keras-metrics-3013f979ce0d"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AfPD3_bWCm0"
      },
      "source": [
        "CNN16052104.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',metrics_recall,metrics_precision,metrics_f1])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpChKUY-QEWI"
      },
      "source": [
        "https://www.tensorflow.org/tensorboard/tensorboard_in_notebooks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJfMgUhHBoD1"
      },
      "source": [
        "#%reload_ext tensorboard\n",
        "#nur einmal pro Sitzung notwendig\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ISmMXLqP8Hc"
      },
      "source": [
        "\n",
        "logs_base_dir = \"./logs\"\n",
        "callbackForTB = tf.keras.callbacks.TensorBoard(logs_base_dir)\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2CHbXiP1LsF"
      },
      "source": [
        "training_epochs = 30\n",
        "batch_size = 40\n",
        "validation_split=0.2"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abV-QAxfW48r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35587960-be61-42ff-c33d-ef891d95d272"
      },
      "source": [
        "#Werte der Convolutional-Schichten variieren (Filter), Batch-Size variieren, kernel-size..\n",
        "CNN16052104.fit(nppadded_training, nptraining_labels, batch_size=batch_size, validation_split=validation_split, epochs=training_epochs, callbacks=[callbackForTB])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "91/91 [==============================] - 5s 45ms/step - loss: 0.6649 - accuracy: 0.6499 - metrics_recall: 0.0000e+00 - metrics_precision: 0.0000e+00 - metrics_f1: 0.0000e+00 - val_loss: 0.6403 - val_accuracy: 0.6718 - val_metrics_recall: 0.0000e+00 - val_metrics_precision: 0.0000e+00 - val_metrics_f1: 0.0000e+00\n",
            "Epoch 2/30\n",
            "91/91 [==============================] - 4s 39ms/step - loss: 0.6349 - accuracy: 0.6712 - metrics_recall: 0.0000e+00 - metrics_precision: 0.0000e+00 - metrics_f1: 0.0000e+00 - val_loss: 0.6160 - val_accuracy: 0.6718 - val_metrics_recall: 0.0048 - val_metrics_precision: 0.0870 - val_metrics_f1: 0.0092\n",
            "Epoch 3/30\n",
            "91/91 [==============================] - 4s 40ms/step - loss: 0.6182 - accuracy: 0.6662 - metrics_recall: 0.0287 - metrics_precision: 0.1474 - metrics_f1: 0.0444 - val_loss: 0.5730 - val_accuracy: 0.7151 - val_metrics_recall: 0.2920 - val_metrics_precision: 0.6808 - val_metrics_f1: 0.3964\n",
            "Epoch 4/30\n",
            "91/91 [==============================] - 4s 41ms/step - loss: 0.5909 - accuracy: 0.6835 - metrics_recall: 0.3108 - metrics_precision: 0.5948 - metrics_f1: 0.3659 - val_loss: 0.5633 - val_accuracy: 0.7051 - val_metrics_recall: 0.1942 - val_metrics_precision: 0.7219 - val_metrics_f1: 0.2943\n",
            "Epoch 5/30\n",
            "91/91 [==============================] - 4s 41ms/step - loss: 0.5493 - accuracy: 0.7091 - metrics_recall: 0.3514 - metrics_precision: 0.6835 - metrics_f1: 0.4150 - val_loss: 0.5470 - val_accuracy: 0.7239 - val_metrics_recall: 0.3743 - val_metrics_precision: 0.6369 - val_metrics_f1: 0.4548\n",
            "Epoch 6/30\n",
            "91/91 [==============================] - 4s 39ms/step - loss: 0.5217 - accuracy: 0.7315 - metrics_recall: 0.4119 - metrics_precision: 0.6519 - metrics_f1: 0.4883 - val_loss: 0.5425 - val_accuracy: 0.7062 - val_metrics_recall: 0.4483 - val_metrics_precision: 0.5648 - val_metrics_f1: 0.4819\n",
            "Epoch 7/30\n",
            "91/91 [==============================] - 4s 41ms/step - loss: 0.5013 - accuracy: 0.7533 - metrics_recall: 0.5259 - metrics_precision: 0.6885 - metrics_f1: 0.5749 - val_loss: 0.5436 - val_accuracy: 0.7084 - val_metrics_recall: 0.5931 - val_metrics_precision: 0.5466 - val_metrics_f1: 0.5554\n",
            "Epoch 8/30\n",
            "91/91 [==============================] - 4s 41ms/step - loss: 0.4743 - accuracy: 0.7807 - metrics_recall: 0.5612 - metrics_precision: 0.7424 - metrics_f1: 0.6050 - val_loss: 0.5573 - val_accuracy: 0.6951 - val_metrics_recall: 0.6675 - val_metrics_precision: 0.5277 - val_metrics_f1: 0.5757\n",
            "Epoch 9/30\n",
            "91/91 [==============================] - 4s 41ms/step - loss: 0.4478 - accuracy: 0.7849 - metrics_recall: 0.5843 - metrics_precision: 0.7191 - metrics_f1: 0.6289 - val_loss: 0.5309 - val_accuracy: 0.7273 - val_metrics_recall: 0.5088 - val_metrics_precision: 0.5853 - val_metrics_f1: 0.5283\n",
            "Epoch 10/30\n",
            "91/91 [==============================] - 4s 41ms/step - loss: 0.4229 - accuracy: 0.7958 - metrics_recall: 0.6392 - metrics_precision: 0.7316 - metrics_f1: 0.6564 - val_loss: 0.5457 - val_accuracy: 0.7251 - val_metrics_recall: 0.3811 - val_metrics_precision: 0.6356 - val_metrics_f1: 0.4579\n",
            "Epoch 11/30\n",
            "91/91 [==============================] - 4s 40ms/step - loss: 0.3872 - accuracy: 0.8227 - metrics_recall: 0.6547 - metrics_precision: 0.8067 - metrics_f1: 0.7060 - val_loss: 0.5531 - val_accuracy: 0.7140 - val_metrics_recall: 0.5288 - val_metrics_precision: 0.5739 - val_metrics_f1: 0.5334\n",
            "Epoch 12/30\n",
            "91/91 [==============================] - 4s 41ms/step - loss: 0.3554 - accuracy: 0.8478 - metrics_recall: 0.7039 - metrics_precision: 0.8070 - metrics_f1: 0.7369 - val_loss: 0.5453 - val_accuracy: 0.7095 - val_metrics_recall: 0.5553 - val_metrics_precision: 0.5638 - val_metrics_f1: 0.5412\n",
            "Epoch 13/30\n",
            "91/91 [==============================] - 4s 42ms/step - loss: 0.3122 - accuracy: 0.8648 - metrics_recall: 0.7587 - metrics_precision: 0.8457 - metrics_f1: 0.7884 - val_loss: 0.6149 - val_accuracy: 0.6641 - val_metrics_recall: 0.7009 - val_metrics_precision: 0.4894 - val_metrics_f1: 0.5616\n",
            "Epoch 14/30\n",
            "91/91 [==============================] - 4s 41ms/step - loss: 0.3281 - accuracy: 0.8652 - metrics_recall: 0.7660 - metrics_precision: 0.8505 - metrics_f1: 0.7846 - val_loss: 0.6162 - val_accuracy: 0.6885 - val_metrics_recall: 0.6664 - val_metrics_precision: 0.5173 - val_metrics_f1: 0.5673\n",
            "Epoch 15/30\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.2930 - accuracy: 0.8729 - metrics_recall: 0.7934 - metrics_precision: 0.8369 - metrics_f1: 0.8032 - val_loss: 0.6354 - val_accuracy: 0.6962 - val_metrics_recall: 0.6250 - val_metrics_precision: 0.5294 - val_metrics_f1: 0.5590\n",
            "Epoch 16/30\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.2497 - accuracy: 0.8943 - metrics_recall: 0.8126 - metrics_precision: 0.8569 - metrics_f1: 0.8267 - val_loss: 0.6292 - val_accuracy: 0.7118 - val_metrics_recall: 0.6636 - val_metrics_precision: 0.5520 - val_metrics_f1: 0.5886\n",
            "Epoch 17/30\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.2301 - accuracy: 0.9044 - metrics_recall: 0.8379 - metrics_precision: 0.8776 - metrics_f1: 0.8471 - val_loss: 0.6759 - val_accuracy: 0.6918 - val_metrics_recall: 0.5942 - val_metrics_precision: 0.5231 - val_metrics_f1: 0.5418\n",
            "Epoch 18/30\n",
            "91/91 [==============================] - 4s 42ms/step - loss: 0.2458 - accuracy: 0.8977 - metrics_recall: 0.8437 - metrics_precision: 0.8598 - metrics_f1: 0.8434 - val_loss: 0.7043 - val_accuracy: 0.6729 - val_metrics_recall: 0.6755 - val_metrics_precision: 0.4985 - val_metrics_f1: 0.5604\n",
            "Epoch 19/30\n",
            "91/91 [==============================] - 4s 42ms/step - loss: 0.2552 - accuracy: 0.8906 - metrics_recall: 0.8553 - metrics_precision: 0.8506 - metrics_f1: 0.8396 - val_loss: 0.6671 - val_accuracy: 0.6973 - val_metrics_recall: 0.5689 - val_metrics_precision: 0.5370 - val_metrics_f1: 0.5369\n",
            "Epoch 20/30\n",
            "91/91 [==============================] - 4s 42ms/step - loss: 0.2124 - accuracy: 0.9109 - metrics_recall: 0.8481 - metrics_precision: 0.8953 - metrics_f1: 0.8641 - val_loss: 0.6999 - val_accuracy: 0.7173 - val_metrics_recall: 0.4860 - val_metrics_precision: 0.5677 - val_metrics_f1: 0.5119\n",
            "Epoch 21/30\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.2122 - accuracy: 0.9132 - metrics_recall: 0.8618 - metrics_precision: 0.8867 - metrics_f1: 0.8665 - val_loss: 0.7859 - val_accuracy: 0.6707 - val_metrics_recall: 0.7149 - val_metrics_precision: 0.4981 - val_metrics_f1: 0.5749\n",
            "Epoch 22/30\n",
            "91/91 [==============================] - 4s 42ms/step - loss: 0.2058 - accuracy: 0.9174 - metrics_recall: 0.8777 - metrics_precision: 0.8971 - metrics_f1: 0.8786 - val_loss: 0.7361 - val_accuracy: 0.6984 - val_metrics_recall: 0.5783 - val_metrics_precision: 0.5334 - val_metrics_f1: 0.5416\n",
            "Epoch 23/30\n",
            "91/91 [==============================] - 4s 42ms/step - loss: 0.1943 - accuracy: 0.9204 - metrics_recall: 0.8851 - metrics_precision: 0.8961 - metrics_f1: 0.8832 - val_loss: 0.7095 - val_accuracy: 0.6973 - val_metrics_recall: 0.5331 - val_metrics_precision: 0.5385 - val_metrics_f1: 0.5209\n",
            "Epoch 24/30\n",
            "91/91 [==============================] - 4s 42ms/step - loss: 0.1790 - accuracy: 0.9360 - metrics_recall: 0.9004 - metrics_precision: 0.9229 - metrics_f1: 0.9061 - val_loss: 0.7397 - val_accuracy: 0.7062 - val_metrics_recall: 0.5315 - val_metrics_precision: 0.5514 - val_metrics_f1: 0.5278\n",
            "Epoch 25/30\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.1599 - accuracy: 0.9340 - metrics_recall: 0.8886 - metrics_precision: 0.9196 - metrics_f1: 0.8992 - val_loss: 0.7988 - val_accuracy: 0.7173 - val_metrics_recall: 0.4397 - val_metrics_precision: 0.5935 - val_metrics_f1: 0.4903\n",
            "Epoch 26/30\n",
            "91/91 [==============================] - 4s 42ms/step - loss: 0.1823 - accuracy: 0.9318 - metrics_recall: 0.8900 - metrics_precision: 0.9088 - metrics_f1: 0.8916 - val_loss: 0.7590 - val_accuracy: 0.7206 - val_metrics_recall: 0.4544 - val_metrics_precision: 0.5909 - val_metrics_f1: 0.5023\n",
            "Epoch 27/30\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.1460 - accuracy: 0.9410 - metrics_recall: 0.8907 - metrics_precision: 0.9401 - metrics_f1: 0.9099 - val_loss: 0.8622 - val_accuracy: 0.7184 - val_metrics_recall: 0.5185 - val_metrics_precision: 0.5772 - val_metrics_f1: 0.5328\n",
            "Epoch 28/30\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.1597 - accuracy: 0.9317 - metrics_recall: 0.8927 - metrics_precision: 0.9087 - metrics_f1: 0.8965 - val_loss: 0.7794 - val_accuracy: 0.7129 - val_metrics_recall: 0.5230 - val_metrics_precision: 0.5588 - val_metrics_f1: 0.5266\n",
            "Epoch 29/30\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.1350 - accuracy: 0.9456 - metrics_recall: 0.9049 - metrics_precision: 0.9332 - metrics_f1: 0.9144 - val_loss: 0.9835 - val_accuracy: 0.6574 - val_metrics_recall: 0.7458 - val_metrics_precision: 0.4842 - val_metrics_f1: 0.5763\n",
            "Epoch 30/30\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.1513 - accuracy: 0.9435 - metrics_recall: 0.9157 - metrics_precision: 0.9215 - metrics_f1: 0.9138 - val_loss: 0.8779 - val_accuracy: 0.6996 - val_metrics_recall: 0.6476 - val_metrics_precision: 0.5374 - val_metrics_f1: 0.5723\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4f30782990>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJVL4SBLPB2P"
      },
      "source": [
        "#%tensorboard --logdir {logs_base_dir}"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_LnvWBcnoak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e419526b-4fae-4c88-9652-e8cd7037ad4f"
      },
      "source": [
        "#results = model.evaluate(nppadded_testing, nptesting_labels, batch_size=batch_size)\n",
        "#print(\"test loss, test acc:\",results)\n",
        "\n",
        "(loss,accuracy, metrics_recall,metrics_precision,\n",
        "metrics_f1) = CNN16052104.evaluate(nppadded_testing, nptesting_labels, verbose=1)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "111/111 [==============================] - 1s 11ms/step - loss: 0.8972 - accuracy: 0.6583 - metrics_recall: 0.5385 - metrics_precision: 0.5036 - metrics_f1: 0.5072\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KgjIkhpKmHc"
      },
      "source": [
        "make some predictions of test data and save it to variable. verbose=0 -> do not generate output\n",
        "Gute Quelle: https://deeplizard.com/learn/video/2f-NjDUvZIE "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89GWuxryKlcM"
      },
      "source": [
        "CNN_predictions04 = CNN16052104.predict(x=nppadded_testing)\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3jPDaDJK_cN"
      },
      "source": [
        "#for p in CNN_predictions04:\n",
        " # print(p)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eC9efJy4Lp21"
      },
      "source": [
        "rounded predictions: give prediction value of most likely prediction (0 or 1). Printing the output of rounded prediction shows the prediction made by the model on the data (which output is most likely)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsG-TJuQLvtk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e386a31e-7dda-4b38-9626-0a46780a52fd"
      },
      "source": [
        "prediction_rounded04 = np.round(CNN_predictions04)\n",
        "#np.argmax(CNN_predictions04,axis=-1)\n",
        "\n",
        "#for p in prediction_rounded04:\n",
        " # print(p)\n",
        "\n",
        "\n",
        "print(nptesting_labels[500:520])\n",
        "print(prediction_rounded04[500:520])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1]\n",
            "[[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egTtgpXgg8a2"
      },
      "source": [
        "https://deeplizard.com/learn/video/km7pxKy4UHU\n",
        "\n",
        "Quelle der def plot_confusion_matrix: https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSDXf7-_MITy"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0AMs1EzhBU1"
      },
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                        normalize=False,\n",
        "                        title='Confusion matrix',\n",
        "                        cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2JgEnlghCtl"
      },
      "source": [
        "cm = confusion_matrix(y_true=nptesting_labels, y_pred=prediction_rounded04)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckmF29whhFmX"
      },
      "source": [
        "plot_labels = ['no hatespeech','hatespeech']"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "2mpSE96rhK7K",
        "outputId": "b68665ed-47b2-47e1-fe30-2b340f8ed5f6"
      },
      "source": [
        "plot_confusion_matrix(cm=cm, classes=plot_labels, title='CNN Confusion 120')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix, without normalization\n",
            "[[1686  644]\n",
            " [ 563  639]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}