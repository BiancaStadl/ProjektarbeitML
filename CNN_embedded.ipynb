{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN embedded.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPX9KvxSMiCA5t7/s6EeJ/R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BiancaStadl/ProjektarbeitML/blob/main/CNN_embedded.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXDOlIBymF0V"
      },
      "source": [
        "GloVe embeddings taken from:\n",
        "\n",
        "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. [pdf] [bib]\n",
        "\n",
        "hatespeechdata taken from (https://hatespeechdata.com/): Wiegand, M., Siegel, M. and Ruppenhofer, J., 2018. Overview of the GermEval 2018 Shared Task on the Identification of Offensive Language. In: Proceedings of GermEval 2018, 14th Conference on Natural Language Processing (KONVENS 2018). Vienna, Austria: Research Gate. available on: https://github.com/uds-lsv/GermEval-2018-Data (last checked: 09.05.2021)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlBmABDxfqII"
      },
      "source": [
        "wiki detox..https://colab.research.google.com/github/tensorflow/fairness-indicators/blob/master/g3doc/tutorials/Fairness_Indicators_TFCO_Wiki_Case_Study.ipynb#scrollTo=y6T5tlXcdW7J "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3xfitNdliBI"
      },
      "source": [
        "#import matplotlib.pyplot as plt -> für evtl Visualisierungen\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import string\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from keras import losses \n",
        "from keras import optimizers \n",
        "from keras import metrics \n",
        "\n",
        "#!pip install Tokenizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "#!pip install pad_sequences\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import preprocessing\n",
        "#from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTWJQ1iga_vS"
      },
      "source": [
        "Maximale Satzlänge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bq08Me5la_Cc"
      },
      "source": [
        "\n",
        "max_length = 60"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVYBMvYSotTH"
      },
      "source": [
        "url = \"https://github.com/uds-lsv/GermEval-2018-Data/archive/master.zip\"\n",
        "\n",
        "dataset = tf.keras.utils.get_file(\"GermEval-2018-Data-master.zip\", url, \n",
        "                                   extract=True, cache_dir='.',\n",
        "                                    cache_subdir='')\n",
        "\n",
        "dataset_dir = os.path.join(os.path.dirname(dataset), 'GermEval-2018-Data-master')\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cS14OUtfo34V"
      },
      "source": [
        "#os.listdir(dataset_dir)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2X429K6hpOVm"
      },
      "source": [
        "training_file = os.path.join(dataset_dir, 'germeval2018.training.txt')\n",
        "\n",
        "testing_file = os.path.join(dataset_dir, 'germeval2018.test.txt')\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uq8fG3LNtn_m"
      },
      "source": [
        "###Aufbereitung\n",
        "txt-Dateien lesen, und dabei jede Zeile splitten und teilen\n",
        "Twitter-Handler entfernen?\n",
        "Labels von Sätzen trennen, Labels in eigenen Array packen.\n",
        "\n",
        "####Ressourcen\n",
        "* https://www.w3schools.com/python/gloss_python_if_statement.asp\n",
        "* https://stackabuse.com/using-regex-for-text-manipulation-in-python/\n",
        "* https://www.tutorialspoint.com/python/string_splitlines.htm \n",
        "* https://note.nkmk.me/en/python-split-rsplit-splitlines-re/ \n",
        "* https://www.w3schools.com/python/python_regex.asp \n",
        "\n",
        "gäbe bei keras tf.keras.preprocessing.text_dataset_from_directory, aber dafür müssten die Daten auf bestimmte Weise in Verzeichnis organisiert sein, hier nicht der Fall.\n",
        "\n",
        "\n",
        "Einteilung der Daten: Testdaten\n",
        "Trainingsdaten -> noch ca 500 für Validierungsdaten\n",
        "\n",
        "labels -> \"other\", also nicht-negative Aussagen bekommen \"0\", negative Aussagen bekommen \"1\"\n",
        "\n",
        " Regex für Emojis  ->\n",
        "\n",
        "(\\u00a9|\\u00ae|[\\u2000-\\u3300]|\\ud83c[\\ud000-\\udfff]|\\ud83d[\\ud000-\\udfff]|\\ud83e[\\ud000-\\udfff])\n",
        "\n",
        "genommen von https://www.regextester.com/106421 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Py_cwD4eZkXo"
      },
      "source": [
        "def remove_clutter(string):\n",
        "   string = re.sub(\"@[^\\s]+\",\" \",string)\n",
        "   string = re.sub(\"#[^\\s]+\",\" \", string)\n",
        "   string = re.sub(\"\\u00a9\",\" \", string)\n",
        "   string = re.sub(\"\\u00ae\",\" \", string)\n",
        "   string = re.sub(\"[\\u2000-\\u3300]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83c[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83d[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83e[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"😜\", \" \",string)\n",
        "   string = re.sub(\"🍫\", \" \",string)\n",
        "   string = re.sub(\"😁\", \" \",string)\n",
        "   string = re.sub(\"🐖\", \" \",string)\n",
        "   string = re.sub(\"😡\", \" \",string)\n",
        "   string = re.sub(\"😇\", \" \",string)\n",
        "   string = re.sub(\"😬\", \" \",string)\n",
        "   string = re.sub(\"😃\", \" \",string)\n",
        "   string = re.sub(\"😂\", \" \",string)\n",
        "   string = re.sub(\"💙\", \" \",string)  \n",
        "   string = re.sub(\"😛\", \" \",string)\n",
        "   string = re.sub(\"🙏\", \" \",string)\n",
        "   string = re.sub(\"👍\", \" \",string)\n",
        "   string = re.sub(\"🖕\", \" \",string)\n",
        "   string = re.sub(\"😉\", \" \",string)\n",
        "   string = re.sub(\"💩\", \" \",string)\n",
        "   string = re.sub(\"🤢\", \" \",string)\n",
        "   string = re.sub(\"👏\", \" \",string)\n",
        "   string = re.sub(\"😨\", \" \",string)\n",
        "   string = re.sub(\"🤣\", \" \",string)\n",
        "   string = re.sub(\"🤡\", \" \",string)\n",
        "   string = re.sub(\"😈\", \" \",string)\n",
        "   string = re.sub(\"💃🏽\", \" \",string)\n",
        "   string = re.sub(\"👹\", \" \",string)\n",
        "   string = re.sub(\"🤘\", \" \",string)\n",
        "   string = re.sub(\"😱\", \" \",string)\n",
        "   string = re.sub(\"🤔\", \" \",string) \n",
        "   string = re.sub(\"🌈\", \" \",string) \n",
        "   string = re.sub(\"💕\", \" \",string) \n",
        "   string = re.sub(\"👩‍❤️‍👩\", \" \",string) \n",
        "   string = re.sub(\"😍\", \" \",string) \n",
        "   string = re.sub(\"👆\", \" \",string) \n",
        "   string = re.sub(\"😖\", \" \",string) \n",
        "   string = re.sub(\"👇\", \" \",string) \n",
        "   string = re.sub(\"🔥\", \" \",string) \n",
        "   string = re.sub(\"😘\", \" \",string) \n",
        "   string = re.sub(\"🎉\", \" \",string) \n",
        "   string = re.sub(\"🤬\", \" \",string) \n",
        "   string = re.sub(\"👊\", \" \",string)\n",
        "   string = re.sub(\"🇩🇪\", \" \",string)  \n",
        "   string = re.sub(\"💔\", \" \",string)\n",
        "   string = re.sub(\"🙈\", \" \",string)\n",
        "   string = re.sub(\"🤯\", \" \",string)\n",
        "   string = re.sub(\"🐟\", \" \",string)\n",
        "   string = re.sub(\"🛶\", \" \",string)\n",
        "   string = re.sub(\"😊\", \" \",string)\n",
        "   string = re.sub(\"😓\", \" \",string)\n",
        "   string = re.sub(\"😳\", \" \",string)\n",
        "   string = re.sub(\"🚀\", \" \",string)\n",
        "   string = re.sub(\"👎\", \" \",string)\n",
        "   string = re.sub(\"😎\", \" \",string)\n",
        "   string = re.sub(\"🐸\", \" \",string)\n",
        "   string = re.sub(\"📈\", \" \",string)\n",
        "   string = re.sub(\"🙂\", \" \",string)\n",
        "   string = re.sub(\"😅\", \" \",string)\n",
        "   string = re.sub(\"😆\", \" \",string)\n",
        "   string = re.sub(\"🙎🏿\", \" \",string)\n",
        "   string = re.sub(\"👎🏽\", \" \",string)\n",
        "   string = re.sub(\"🤭\", \" \",string)\n",
        "   string = re.sub(\"😤\", \" \",string)\n",
        "   string = re.sub(\"😚\", \" \",string)\n",
        "   string = re.sub(\"😊\", \" \",string)\n",
        "   string = re.sub(\"😲\", \" \",string)\n",
        "   string = re.sub(\"🤮\", \" \",string)\n",
        "   string = re.sub(\"🙄\", \" \",string)\n",
        "   string = re.sub(\"🤑\", \" \",string)\n",
        "   string = re.sub(\"🎅\", \" \",string)\n",
        "   string = re.sub(\"👋\", \" \",string)\n",
        "   string = re.sub(\"💪\", \" \",string)\n",
        "   string = re.sub(\"😄\", \" \",string)\n",
        "   string = re.sub(\"🧐\", \" \",string)\n",
        "   string = re.sub(\"😠\", \" \",string)\n",
        "   string = re.sub(\"🎈\", \" \",string)\n",
        "   string = re.sub(\"🚂\", \" \",string)\n",
        "   string = re.sub(\"😊\", \" \",string)\n",
        "   string = re.sub(\"🚇\", \" \",string)\n",
        "   string = re.sub(\"🚊\", \" \",string)\n",
        "   string = re.sub(\"🤷\", \" \",string)\n",
        "   string = re.sub(\"😥\", \" \",string)\n",
        "   string = re.sub(\"🙃\", \" \",string)\n",
        "   string = re.sub(\"🔩\", \" \",string)\n",
        "   string = re.sub(\"🔧\", \" \",string)\n",
        "   string = re.sub(\"🔨\", \" \",string)\n",
        "   string = re.sub(\"🛠\", \" \",string)\n",
        "   string = re.sub(\"💓\", \" \",string)\n",
        "   string = re.sub(\"💡\", \" \",string)\n",
        "   string = re.sub(\"🍸\", \" \",string)\n",
        "   string = re.sub(\"🥃\", \" \",string)\n",
        "   string = re.sub(\"🥂\", \" \",string)\n",
        "   string = re.sub(\"😷\", \" \",string)\n",
        "   string = re.sub(\"🤐\", \" \",string)\n",
        "   string = re.sub(\"🌎\", \" \",string)\n",
        "   string = re.sub(\"👑\", \" \",string)\n",
        "   string = re.sub(\"🤛\", \" \",string)\n",
        "   string = re.sub(\"😀\", \" \",string)\n",
        "   string = re.sub(\"🛤\", \" \",string)\n",
        "   string = re.sub(\"🎄\", \" \",string)\n",
        "   string = re.sub(\"📴\", \" \",string)\n",
        "   string = re.sub(\"🌭\", \" \",string)\n",
        "   string = re.sub(\"🤕\", \" \",string)\n",
        "   string = re.sub(\"😭\", \" \",string)\n",
        "   string = re.sub(\"🍾\", \" \",string)\n",
        "   string = re.sub(\"🍞\", \" \",string)\n",
        "   string = re.sub(\"🤦\", \" \",string)\n",
        "   string = re.sub(\"🤯\", \" \",string)\n",
        "   string = re.sub(\"🕯️\", \" \",string)\n",
        "\n",
        "   string = re.sub(\"OTHER|OFFENSE|ABUSE|INSULT\",\" \",string)\n",
        "   return string"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5asMgo4LtnRg"
      },
      "source": [
        "statementsForTraining = []\n",
        "sentimentsForTraining = []\n",
        "\n",
        "\n",
        "fileToRead = open(training_file, 'r')\n",
        "\n",
        "while True:\n",
        "  #next line in file\n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  findSentiment = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "\n",
        "\n",
        "  statementsForTraining.append(line)\n",
        "   #sentimentsForTraining.append(findSentiment.group(0))\n",
        "\n",
        "  if findSentiment.group(0) == \"OTHER\":  \n",
        "    sentimentsForTraining.append(0)\n",
        "  else:\n",
        "    sentimentsForTraining.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        " #print(\"{}: {}\".format(count,line.strip()))\n",
        "  \n",
        " # print(sentiment.group(0))\n",
        " \n",
        "fileToRead.close()\n",
        "\n",
        "training_sentences = statementsForTraining\n",
        "training_labels = sentimentsForTraining\n",
        "\n",
        "#print(training_sentences[9])\n",
        "#print(training_labels[9])\n",
        "\n",
        "#print(len(training_sentences))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsqZPENb98gD"
      },
      "source": [
        "##do the same with testdata\n",
        "statementsForTesting = []\n",
        "sentimentsForTesting = []\n",
        "\n",
        "fileToRead = open(testing_file, 'r')\n",
        "\n",
        "while True:\n",
        "  #next line in file\n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  sent = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "\n",
        "    \n",
        "\n",
        "  statementsForTesting.append(line)\n",
        "  #print(len(line))\n",
        "  #sentimentsForTesting.append(sent.group(0))\n",
        "\n",
        "  if sent.group(0) == \"OTHER\": \n",
        "    sentimentsForTesting.append(0)\n",
        "  else:\n",
        "    sentimentsForTesting.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        "\n",
        "fileToRead.close()\n",
        "\n",
        "\n",
        "testing_sentences = statementsForTesting\n",
        "testing_labels = sentimentsForTesting\n",
        "#print(len(testing_sentences))\n",
        "#print(testing_sentences)   \n",
        "#print(testing_labels)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRUvDLD5bMbO"
      },
      "source": [
        "Padding -> im Prinzip die Sätze alle auf die gleiche Länge bringen (in Theorieteil näher drauf eingehen) -> maxlen-Paramter ist für pad_sequences vorhanden, wenn nicht gesetzt -> alles wird auf die Länge des längsten Satzes aufgefüllt -> print(padded(shape)) gibt aus, wie viele Datensätze padded wurden und gibt an, wie viele Tokens der längste Datensatz hat\n",
        "print(padded[x]) gibt einen Satz aus (bereits tokenisiert)\n",
        "\n",
        "Padding -> sowohl für Trainigs- als auch für Testdaten\n",
        "\n",
        "Und: Daten als numpy-Arrays speichern (notwendig für tensorflow).\n",
        "\n",
        " -> Tokenizer https://towardsdatascience.com/text-classification-in-keras-part-2-how-to-use-the-keras-tokenizer-word-representations-fd571674df23 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3hFi7waTv5m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "307b63bf-6a46-4445-8eca-35075b6b54ff"
      },
      "source": [
        "tokenizer = Tokenizer(oov_token=\"OOV\")\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "\n",
        "#creating a word index - nur die Trainigsdaten\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "validation_size = 500\n",
        "\n",
        "\n",
        "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "padded_training = pad_sequences(training_sequences, maxlen=max_length, padding='post')\n",
        "print(len(padded_training))\n",
        "\n",
        "validation_sequences = padded_training[0:validation_size]\n",
        "validation_labels = training_labels[0:validation_size]\n",
        "\n",
        "padded_training = padded_training[validation_size:]\n",
        "training_labels = training_labels[validation_size:]\n",
        "\n",
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
        "padded_testing = pad_sequences(testing_sequences, maxlen=max_length,  padding='post')\n",
        "\n",
        "#print(validation_sequences[499])\n",
        "print(padded_training[0])\n",
        "#print(len(validation_labels))\n",
        "#print(len(training_labels))\n",
        "\n",
        "\n",
        "nppadded_training = np.array(padded_training)\n",
        "nptraining_labels = np.array(training_labels)\n",
        "\n",
        "nppadded_validation = np.array(validation_sequences)\n",
        "npvalidation_labels = np.array(validation_labels)\n",
        "\n",
        "nppadded_testing = np.array(padded_testing)\n",
        "nptesting_labels = np.array(testing_labels)\n",
        "\n",
        "\n",
        "print(len(nppadded_training))\n",
        "print(len(nptraining_labels))\n",
        "print(len(word_index))\n",
        "\n",
        "#print(statementsForTraining[2])\n",
        "#print(nppadded_training[4])\n",
        "#print(nppadded_training.shape)\n",
        "#print(nptraining_labels[4])\n",
        "#print(nppadded_testing.shape)\n",
        "#print(word_index) \n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5009\n",
            "[  12 3982   11   41 6706 1040    4    5  202   39    3 2922   49 1360\n",
            "  810  495 3983    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0]\n",
            "4509\n",
            "4509\n",
            "15059\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tL3owrc8THkT"
      },
      "source": [
        "\n",
        "Dann: Embedding mit entweder word2vec oder glove\n",
        "Word2vec-Daten sind hier: http://vectors.nlpl.eu/repository/#\n",
        "Glove -> https://nlp.stanford.edu/projects/glove/ Da mal den Twitter-Vector runtergeladen\n",
        "Wenn Daten in GoogleDrive sind (wäre auch via url möglich..), muss Drive gemounted werden ( https://buomsoo-kim.github.io/colab/2020/05/09/Colab-mounting-google-drive.md/ ) aber auch hier https://enjoymachinelearning.com/posts/colab-with-google-drive/\n",
        "\n",
        "Die Word2vec vectors: http://vectors.nlpl.eu/repository/# \n",
        "\n",
        "glove-zitat:\n",
        "Citing GloVe\n",
        "\n",
        "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. [pdf] [bib]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zuO7T9ZTG57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "557da71e-1b93-4e2c-a672-c7a096af3dc8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "os.listdir(\"/content/drive/MyDrive/Colab Notebooks\")\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['germeval_training.txt',\n",
              " 'glove.twitter.27B.50d.txt',\n",
              " 'glove.twitter.27B.200d.txt',\n",
              " 'glove.6B.200d.txt',\n",
              " 'glove.840B.300d.txt',\n",
              " 'tensorboard.gdoc',\n",
              " 'keras.gdoc',\n",
              " 'Vectorization CNN embedded_limited_vocab.ipynb',\n",
              " 'glove.42B.300d.txt',\n",
              " 'Embedding Glove Vergleich.ipynb',\n",
              " 'LSTM.ipynb',\n",
              " 'CNN embedded_limited_vocab.ipynb',\n",
              " 'LSTM_limited_vocab.ipynb',\n",
              " 'CNN embedded.ipynb']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7ToKO-sZLHK"
      },
      "source": [
        "\n",
        "Keras-Doc : https://keras.io/examples/nlp/pretrained_word_embeddings/#load-pretrained-word-embeddings \n",
        "embedding mit initializers.. weights müsste auch funktionieren\n",
        "\n",
        "Diese erstellte Matrix mit Embedding dann in die Embedding-Schicht einbinden,  Trainable auf False, weil sich die Werte nicht durch Training anpassen sollen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AShIVfC7ZQAH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f24acf72-cd58-4523-b9bd-3d928d126d39"
      },
      "source": [
        "#Größe Vokabel -> wordindex + 2 (weil padding + OOV) \n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "vocabulary_size = len(word_index)+2\n",
        "\n",
        "# dann erstell ich ein Wörterbuch mit Namen \"embedding_vector\", dort sind dann\n",
        "#die keys drinnen, die in glove-Datei drinnen sind mit dem entsprechenden Key\n",
        "\n",
        "embedding_index_glove = {}\n",
        "f = open('/content/drive/MyDrive/Colab Notebooks/glove.twitter.27B.200d.txt')\n",
        "for line in f:\n",
        "  value = line.split()\n",
        "  word = value[0]\n",
        "  coef = np.asarray(value[1:],dtype='float32')\n",
        "  embedding_index_glove[word] = coef\n",
        "\n",
        "print(\"%d gefunden: \"% len(embedding_index_glove))\n",
        "\n",
        "#Dann noch eine Embedding-Matrix erstellen\n",
        "#zweiter Wert = Embedding-Dimension der Datei, in dem Fall 200\n",
        "\n",
        "glove_matrix = np.zeros((vocabulary_size,200))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    embedding_value = embedding_index_glove.get(word)\n",
        "    if embedding_value is not None:\n",
        "      glove_matrix[index] = embedding_value\n",
        "      hits+=1\n",
        "    else:\n",
        "      misses+=1\n",
        "\n",
        "print(\"hits %d and %d misses\"%(hits,misses))\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1193514 gefunden: \n",
            "hits 6747 and 8312 misses\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZmvOfwhV4N5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "985e20c0-b4ab-4d28-f5c4-f3e03c5705e1"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "print(\"vocab size: %d\"%vocabulary_size)\n",
        "CNN16052103 = tf.keras.Sequential()\n",
        "#Embedding -> hier dann auf das embedding verweisen, Input_dim -> die Anzahl der Wörter im word_index, output -> in dem Fall passend zum verwendeten Vektor\n",
        "#input-length -> auf 60  gepadded, trainable -> nein, weil nichts verändert werden soll\n",
        "#embeddings_initializer=keras.initializers.Constant(glove_matrix) vs weights = [glove_matrix]\n",
        "#Convolutional layers => filters = neurons.. mit 100? 265?\n",
        "CNN16052103.add(tf.keras.layers.Embedding(vocabulary_size, output_dim=200, input_length=60, embeddings_initializer = keras.initializers.Constant(glove_matrix), trainable= False))\n",
        "CNN16052103.add(tf.keras.layers.Dropout(0.4))\n",
        "CNN16052103.add(tf.keras.layers.Conv1D(filters=50, kernel_size=3, padding=\"valid\", activation=\"relu\"))\n",
        "CNN16052103.add(tf.keras.layers.MaxPooling1D())\n",
        "CNN16052103.add(tf.keras.layers.Conv1D(filters=50, kernel_size=3, padding=\"valid\", activation=\"relu\"))\n",
        "CNN16052103.add(tf.keras.layers.GlobalAveragePooling1D())\n",
        "CNN16052103.add(tf.keras.layers.Flatten())\n",
        "CNN16052103.add(tf.keras.layers.Dense(260, activation=\"relu\"))\n",
        "CNN16052103.add(tf.keras.layers.Dropout(0.4))\n",
        "CNN16052103.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "CNN16052103.summary()\n",
        "\n",
        "#nppadded_training = np.asmatrix(nppadded_training) not necessary\n",
        "#nppadded_testing = np.asmatrix(nppadded_testing)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab size: 15061\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 60, 200)           3012200   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 60, 200)           0         \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 58, 50)            30050     \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 29, 50)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 27, 50)            7550      \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 260)               13260     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 260)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 261       \n",
            "=================================================================\n",
            "Total params: 3,063,321\n",
            "Trainable params: 51,121\n",
            "Non-trainable params: 3,012,200\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEr4OzT-iHDe"
      },
      "source": [
        "#model.layers[2].get_weights()[0].shape\n",
        "#weights=np.random.rand(5,200,100)\n",
        "#bias=np.random.rand(100)\n",
        "#model.layers[2].set_weights([weights, bias])\n",
        "\n",
        "#model.layers[2].get_weights()[0]\n",
        "#https://androidkt.com/set-custom-weights-keras-using-numpy-array/"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UB7_3VPYesr9"
      },
      "source": [
        "F1-Score für jede Epoche https://aakashgoel12.medium.com/how-to-add-user-defined-function-get-f1-score-in-keras-metrics-3013f979ce0d\n",
        "\n",
        "Sehr gute Ressource für die verschiedenen Scores und Metriken https://neptune.ai/blog/evaluation-metrics-binary-classification#10  das und aakas verwendet\n",
        "\n",
        "hier: je eine Funktion für Recall, Precision, f1 https://neptune.ai/blog/keras-metrics \n",
        "\n",
        "https://keras.rstudio.com/reference/k_ones_like.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygyrbFJaMV9B"
      },
      "source": [
        "import keras.backend as K\n",
        "\n",
        "def metrics_recall(data_true, data_pred):\n",
        "    data_true = K.ones_like(data_true)\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(data_true,0,1)))\n",
        "\n",
        "    recall = true_positives / (possible_positives+K.epsilon())\n",
        "    return recall\n",
        "\n",
        "\n",
        "def metrics_precision(data_true, data_pred):\n",
        "    data_true = K.ones_like(data_true)\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "\n",
        "    positives_predicted = K.sum(K.round(K.clip(data_pred,0,1)))\n",
        "    precision = true_positives / (positives_predicted+K.epsilon())\n",
        "    return precision\n",
        "\n",
        "\n",
        "def metrics_f1(data_true, data_pred):\n",
        "    precision_data = metrics_precision(data_true, data_pred)\n",
        "    recall_data = metrics_recall(data_true, data_pred)\n",
        "    return 2*(precision_data*recall_data)/(precision_data+recall_data+K.epsilon())"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AfPD3_bWCm0"
      },
      "source": [
        "CNN16052103.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',metrics_recall,metrics_precision,metrics_f1])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpChKUY-QEWI"
      },
      "source": [
        "https://www.tensorflow.org/tensorboard/tensorboard_in_notebooks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJfMgUhHBoD1"
      },
      "source": [
        "#%reload_ext tensorboard\n",
        "#nur einmal pro Sitzung notwendig\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ISmMXLqP8Hc"
      },
      "source": [
        "\n",
        "logs_base_dir = \"./logs\"\n",
        "callbackForTB = tf.keras.callbacks.TensorBoard(logs_base_dir)\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2CHbXiP1LsF"
      },
      "source": [
        "training_epochs = 30\n",
        "batch_size = 40\n",
        "validation_split=0.2"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abV-QAxfW48r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb839383-d4e7-4db0-ed6b-32ed3353500f"
      },
      "source": [
        "#Werte der Convolutional-Schichten variieren (Filter), Batch-Size variieren, kernel-size..\n",
        "CNN16052103.fit(nppadded_training, nptraining_labels, batch_size=batch_size, validation_split=validation_split, epochs=training_epochs, callbacks=[callbackForTB])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "91/91 [==============================] - 4s 30ms/step - loss: 0.6579 - accuracy: 0.6488 - metrics_recall: 0.0411 - metrics_precision: 0.1393 - metrics_f1: 0.0545 - val_loss: 0.6391 - val_accuracy: 0.6718 - val_metrics_recall: 0.0000e+00 - val_metrics_precision: 0.0000e+00 - val_metrics_f1: 0.0000e+00\n",
            "Epoch 2/30\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.6370 - accuracy: 0.6601 - metrics_recall: 0.0017 - metrics_precision: 0.0323 - metrics_f1: 0.0032 - val_loss: 0.6050 - val_accuracy: 0.6707 - val_metrics_recall: 0.0011 - val_metrics_precision: 0.0435 - val_metrics_f1: 0.0021\n",
            "Epoch 3/30\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.6126 - accuracy: 0.6688 - metrics_recall: 0.0392 - metrics_precision: 0.6126 - metrics_f1: 0.0716 - val_loss: 0.5981 - val_accuracy: 0.6885 - val_metrics_recall: 0.1090 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.1938\n",
            "Epoch 4/30\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.6007 - accuracy: 0.6740 - metrics_recall: 0.1081 - metrics_precision: 0.8320 - metrics_f1: 0.1742 - val_loss: 0.5842 - val_accuracy: 0.6929 - val_metrics_recall: 0.0411 - val_metrics_precision: 0.9130 - val_metrics_f1: 0.0779\n",
            "Epoch 5/30\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.5856 - accuracy: 0.6804 - metrics_recall: 0.1666 - metrics_precision: 0.8444 - metrics_f1: 0.2651 - val_loss: 0.5648 - val_accuracy: 0.7151 - val_metrics_recall: 0.1534 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.2623\n",
            "Epoch 6/30\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.5601 - accuracy: 0.7062 - metrics_recall: 0.2051 - metrics_precision: 0.9936 - metrics_f1: 0.3316 - val_loss: 0.5765 - val_accuracy: 0.6885 - val_metrics_recall: 0.3491 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.5119\n",
            "Epoch 7/30\n",
            "91/91 [==============================] - 2s 25ms/step - loss: 0.5516 - accuracy: 0.7136 - metrics_recall: 0.2341 - metrics_precision: 0.9991 - metrics_f1: 0.3697 - val_loss: 0.5433 - val_accuracy: 0.7273 - val_metrics_recall: 0.1544 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.2638\n",
            "Epoch 8/30\n",
            "91/91 [==============================] - 2s 26ms/step - loss: 0.5245 - accuracy: 0.7432 - metrics_recall: 0.2359 - metrics_precision: 1.0000 - metrics_f1: 0.3713 - val_loss: 0.5409 - val_accuracy: 0.7228 - val_metrics_recall: 0.2189 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.3538\n",
            "Epoch 9/30\n",
            "91/91 [==============================] - 2s 26ms/step - loss: 0.5023 - accuracy: 0.7549 - metrics_recall: 0.2488 - metrics_precision: 1.0000 - metrics_f1: 0.3876 - val_loss: 0.5370 - val_accuracy: 0.7262 - val_metrics_recall: 0.2395 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.3817\n",
            "Epoch 10/30\n",
            "91/91 [==============================] - 2s 25ms/step - loss: 0.4734 - accuracy: 0.7620 - metrics_recall: 0.2736 - metrics_precision: 1.0000 - metrics_f1: 0.4199 - val_loss: 0.5941 - val_accuracy: 0.6674 - val_metrics_recall: 0.4594 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.6257\n",
            "Epoch 11/30\n",
            "91/91 [==============================] - 2s 26ms/step - loss: 0.4856 - accuracy: 0.7598 - metrics_recall: 0.2595 - metrics_precision: 1.0000 - metrics_f1: 0.3983 - val_loss: 0.5496 - val_accuracy: 0.6962 - val_metrics_recall: 0.3172 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.4758\n",
            "Epoch 12/30\n",
            "91/91 [==============================] - 2s 26ms/step - loss: 0.4429 - accuracy: 0.7931 - metrics_recall: 0.2721 - metrics_precision: 1.0000 - metrics_f1: 0.4194 - val_loss: 0.5552 - val_accuracy: 0.6984 - val_metrics_recall: 0.2946 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.4487\n",
            "Epoch 13/30\n",
            "91/91 [==============================] - 2s 26ms/step - loss: 0.4143 - accuracy: 0.8014 - metrics_recall: 0.2911 - metrics_precision: 1.0000 - metrics_f1: 0.4427 - val_loss: 0.5500 - val_accuracy: 0.6996 - val_metrics_recall: 0.3370 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.4996\n",
            "Epoch 14/30\n",
            "91/91 [==============================] - 2s 26ms/step - loss: 0.4213 - accuracy: 0.8101 - metrics_recall: 0.2882 - metrics_precision: 1.0000 - metrics_f1: 0.4396 - val_loss: 0.5429 - val_accuracy: 0.7084 - val_metrics_recall: 0.2944 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.4480\n",
            "Epoch 15/30\n",
            "91/91 [==============================] - 2s 26ms/step - loss: 0.3834 - accuracy: 0.8218 - metrics_recall: 0.2978 - metrics_precision: 1.0000 - metrics_f1: 0.4516 - val_loss: 0.5566 - val_accuracy: 0.6962 - val_metrics_recall: 0.3572 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.5184\n",
            "Epoch 16/30\n",
            "91/91 [==============================] - 2s 26ms/step - loss: 0.3863 - accuracy: 0.8266 - metrics_recall: 0.2972 - metrics_precision: 1.0000 - metrics_f1: 0.4482 - val_loss: 0.5808 - val_accuracy: 0.6874 - val_metrics_recall: 0.3864 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.5515\n",
            "Epoch 17/30\n",
            "91/91 [==============================] - 2s 26ms/step - loss: 0.3550 - accuracy: 0.8393 - metrics_recall: 0.2981 - metrics_precision: 1.0000 - metrics_f1: 0.4547 - val_loss: 0.5793 - val_accuracy: 0.6996 - val_metrics_recall: 0.3270 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.4882\n",
            "Epoch 18/30\n",
            "91/91 [==============================] - 3s 28ms/step - loss: 0.3491 - accuracy: 0.8455 - metrics_recall: 0.3232 - metrics_precision: 0.9998 - metrics_f1: 0.4813 - val_loss: 0.5731 - val_accuracy: 0.7106 - val_metrics_recall: 0.2866 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.4372\n",
            "Epoch 19/30\n",
            "91/91 [==============================] - 3s 28ms/step - loss: 0.3263 - accuracy: 0.8611 - metrics_recall: 0.3128 - metrics_precision: 1.0000 - metrics_f1: 0.4719 - val_loss: 0.5846 - val_accuracy: 0.7084 - val_metrics_recall: 0.3031 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.4575\n",
            "Epoch 20/30\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.3090 - accuracy: 0.8651 - metrics_recall: 0.3004 - metrics_precision: 1.0000 - metrics_f1: 0.4554 - val_loss: 0.5923 - val_accuracy: 0.7018 - val_metrics_recall: 0.3284 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.4837\n",
            "Epoch 21/30\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.3019 - accuracy: 0.8734 - metrics_recall: 0.2995 - metrics_precision: 1.0000 - metrics_f1: 0.4560 - val_loss: 0.6114 - val_accuracy: 0.7162 - val_metrics_recall: 0.3054 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.4600\n",
            "Epoch 22/30\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.3144 - accuracy: 0.8556 - metrics_recall: 0.3206 - metrics_precision: 1.0000 - metrics_f1: 0.4791 - val_loss: 0.5925 - val_accuracy: 0.7184 - val_metrics_recall: 0.3281 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.4869\n",
            "Epoch 23/30\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.2873 - accuracy: 0.8800 - metrics_recall: 0.3284 - metrics_precision: 1.0000 - metrics_f1: 0.4874 - val_loss: 0.6276 - val_accuracy: 0.7195 - val_metrics_recall: 0.2909 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.4415\n",
            "Epoch 24/30\n",
            "91/91 [==============================] - 3s 28ms/step - loss: 0.2978 - accuracy: 0.8698 - metrics_recall: 0.3113 - metrics_precision: 1.0000 - metrics_f1: 0.4659 - val_loss: 0.6759 - val_accuracy: 0.6652 - val_metrics_recall: 0.4825 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.6450\n",
            "Epoch 25/30\n",
            "91/91 [==============================] - 3s 28ms/step - loss: 0.2667 - accuracy: 0.8844 - metrics_recall: 0.3136 - metrics_precision: 1.0000 - metrics_f1: 0.4693 - val_loss: 0.6801 - val_accuracy: 0.6785 - val_metrics_recall: 0.4364 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.6025\n",
            "Epoch 26/30\n",
            "91/91 [==============================] - 3s 28ms/step - loss: 0.2607 - accuracy: 0.8929 - metrics_recall: 0.3269 - metrics_precision: 1.0000 - metrics_f1: 0.4855 - val_loss: 0.6418 - val_accuracy: 0.7206 - val_metrics_recall: 0.3098 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.4661\n",
            "Epoch 27/30\n",
            "91/91 [==============================] - 3s 28ms/step - loss: 0.2275 - accuracy: 0.9036 - metrics_recall: 0.3104 - metrics_precision: 1.0000 - metrics_f1: 0.4687 - val_loss: 0.7101 - val_accuracy: 0.6696 - val_metrics_recall: 0.4581 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.6229\n",
            "Epoch 28/30\n",
            "91/91 [==============================] - 3s 28ms/step - loss: 0.2363 - accuracy: 0.9018 - metrics_recall: 0.3287 - metrics_precision: 1.0000 - metrics_f1: 0.4867 - val_loss: 0.6436 - val_accuracy: 0.7018 - val_metrics_recall: 0.3087 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.4657\n",
            "Epoch 29/30\n",
            "91/91 [==============================] - 3s 28ms/step - loss: 0.2365 - accuracy: 0.9010 - metrics_recall: 0.3304 - metrics_precision: 0.9998 - metrics_f1: 0.4921 - val_loss: 0.7198 - val_accuracy: 0.6907 - val_metrics_recall: 0.3835 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.5480\n",
            "Epoch 30/30\n",
            "91/91 [==============================] - 3s 28ms/step - loss: 0.2902 - accuracy: 0.8743 - metrics_recall: 0.3319 - metrics_precision: 1.0000 - metrics_f1: 0.4876 - val_loss: 0.6512 - val_accuracy: 0.6951 - val_metrics_recall: 0.3618 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.5246\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2fab165210>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJVL4SBLPB2P"
      },
      "source": [
        "#%tensorboard --logdir {logs_base_dir}"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_LnvWBcnoak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94a4304e-ccc0-481c-dd43-334350ff98ad"
      },
      "source": [
        "#results = model.evaluate(nppadded_testing, nptesting_labels, batch_size=batch_size)\n",
        "#print(\"test loss, test acc:\",results)\n",
        "\n",
        "(loss,accuracy, metrics_recall, metrics_precision,\n",
        "metrics_f1) = CNN16052103.evaluate(nppadded_testing, nptesting_labels, verbose=1)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "111/111 [==============================] - 1s 6ms/step - loss: 0.6679 - accuracy: 0.6854 - metrics_recall: 0.3388 - metrics_precision: 1.0000 - metrics_f1: 0.5007\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KgjIkhpKmHc"
      },
      "source": [
        "make some predictions of test data and save it to variable. verbose=0 -> do not generate output\n",
        "Gute Quelle: https://deeplizard.com/learn/video/2f-NjDUvZIE "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89GWuxryKlcM"
      },
      "source": [
        "CNN_predictions03 = CNN16052103.predict(x=nppadded_testing)\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3jPDaDJK_cN"
      },
      "source": [
        "#for p in CNN_predictions03:\n",
        " # print(p)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eC9efJy4Lp21"
      },
      "source": [
        "rounded predictions: give prediction value of most likely prediction (0 or 1). Printing the output of rounded prediction shows the prediction made by the model on the data (which output is most likely)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsG-TJuQLvtk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f6f2531-ca07-4d2f-ff3e-85cd844b6739"
      },
      "source": [
        "prediction_rounded03 = np.round(CNN_predictions03)\n",
        "#np.argmax(CNN_predictions03,axis=-1)\n",
        "\n",
        "#for p in prediction_rounded03:\n",
        " # print(p)\n",
        "\n",
        "\n",
        "print(nptesting_labels[500:520])\n",
        "print(prediction_rounded03[500:520])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1]\n",
            "[[0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egTtgpXgg8a2"
      },
      "source": [
        "https://deeplizard.com/learn/video/km7pxKy4UHU\n",
        "\n",
        "Quelle der def plot_confusion_matrix: https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSDXf7-_MITy"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0AMs1EzhBU1"
      },
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                        normalize=False,\n",
        "                        title='Confusion matrix',\n",
        "                        cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2JgEnlghCtl"
      },
      "source": [
        "cm = confusion_matrix(y_true=nptesting_labels, y_pred=prediction_rounded03)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckmF29whhFmX"
      },
      "source": [
        "plot_labels = ['no hatespeech','hatespeech']"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "2mpSE96rhK7K",
        "outputId": "c6b62632-1fed-4cd0-ea0a-5875503987f8"
      },
      "source": [
        "plot_confusion_matrix(cm=cm, classes=plot_labels, title='CNN Confusion 50')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix, without normalization\n",
            "[[1778  552]\n",
            " [ 559  643]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}