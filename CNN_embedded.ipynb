{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN embedded.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM9nSuJpuyEtw8U6kKQMYcU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BiancaStadl/ProjektarbeitML/blob/main/CNN_embedded.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXDOlIBymF0V"
      },
      "source": [
        "GloVe embeddings taken from:\n",
        "\n",
        "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. [pdf] [bib]\n",
        "\n",
        "hatespeechdata taken from (https://hatespeechdata.com/): Wiegand, M., Siegel, M. and Ruppenhofer, J., 2018. Overview of the GermEval 2018 Shared Task on the Identification of Offensive Language. In: Proceedings of GermEval 2018, 14th Conference on Natural Language Processing (KONVENS 2018). Vienna, Austria: Research Gate. available on: https://github.com/uds-lsv/GermEval-2018-Data (last checked: 09.05.2021)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlBmABDxfqII"
      },
      "source": [
        "wiki detox..https://colab.research.google.com/github/tensorflow/fairness-indicators/blob/master/g3doc/tutorials/Fairness_Indicators_TFCO_Wiki_Case_Study.ipynb#scrollTo=y6T5tlXcdW7J "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3xfitNdliBI"
      },
      "source": [
        "#import matplotlib.pyplot as plt -> f√ºr evtl Visualisierungen\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import string\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from keras import losses \n",
        "from keras import optimizers \n",
        "from keras import metrics \n",
        "\n",
        "#!pip install Tokenizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "#!pip install pad_sequences\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import preprocessing\n",
        "#from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTWJQ1iga_vS"
      },
      "source": [
        "Maximale Satzl√§nge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bq08Me5la_Cc"
      },
      "source": [
        "\n",
        "max_length = 60"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVYBMvYSotTH"
      },
      "source": [
        "url = \"https://github.com/uds-lsv/GermEval-2018-Data/archive/master.zip\"\n",
        "\n",
        "dataset = tf.keras.utils.get_file(\"GermEval-2018-Data-master.zip\", url, \n",
        "                                   extract=True, cache_dir='.',\n",
        "                                    cache_subdir='')\n",
        "\n",
        "dataset_dir = os.path.join(os.path.dirname(dataset), 'GermEval-2018-Data-master')\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cS14OUtfo34V"
      },
      "source": [
        "#os.listdir(dataset_dir)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2X429K6hpOVm"
      },
      "source": [
        "training_file = os.path.join(dataset_dir, 'germeval2018.training.txt')\n",
        "\n",
        "testing_file = os.path.join(dataset_dir, 'germeval2018.test.txt')\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uq8fG3LNtn_m"
      },
      "source": [
        "###Aufbereitung\n",
        "txt-Dateien lesen, und dabei jede Zeile splitten und teilen\n",
        "Twitter-Handler entfernen?\n",
        "Labels von S√§tzen trennen, Labels in eigenen Array packen.\n",
        "\n",
        "####Ressourcen\n",
        "* https://www.w3schools.com/python/gloss_python_if_statement.asp\n",
        "* https://stackabuse.com/using-regex-for-text-manipulation-in-python/\n",
        "* https://www.tutorialspoint.com/python/string_splitlines.htm \n",
        "* https://note.nkmk.me/en/python-split-rsplit-splitlines-re/ \n",
        "* https://www.w3schools.com/python/python_regex.asp \n",
        "\n",
        "g√§be bei keras tf.keras.preprocessing.text_dataset_from_directory, aber daf√ºr m√ºssten die Daten auf bestimmte Weise in Verzeichnis organisiert sein, hier nicht der Fall.\n",
        "\n",
        "\n",
        "Einteilung der Daten: Testdaten\n",
        "Trainingsdaten -> noch ca 500 f√ºr Validierungsdaten\n",
        "\n",
        "labels -> \"other\", also nicht-negative Aussagen bekommen \"0\", negative Aussagen bekommen \"1\"\n",
        "\n",
        " Regex f√ºr Emojis  ->\n",
        "\n",
        "(\\u00a9|\\u00ae|[\\u2000-\\u3300]|\\ud83c[\\ud000-\\udfff]|\\ud83d[\\ud000-\\udfff]|\\ud83e[\\ud000-\\udfff])\n",
        "\n",
        "genommen von https://www.regextester.com/106421 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Py_cwD4eZkXo"
      },
      "source": [
        "def remove_clutter(string):\n",
        "   string = re.sub(\"@[^\\s]+\",\" \",string)\n",
        "   string = re.sub(\"#[^\\s]+\",\" \", string)\n",
        "   string = re.sub(\"\\u00a9\",\" \", string)\n",
        "   string = re.sub(\"\\u00ae\",\" \", string)\n",
        "   string = re.sub(\"[\\u2000-\\u3300]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83c[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83d[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83e[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"üòú\", \" \",string)\n",
        "   string = re.sub(\"üç´\", \" \",string)\n",
        "   string = re.sub(\"üòÅ\", \" \",string)\n",
        "   string = re.sub(\"üêñ\", \" \",string)\n",
        "   string = re.sub(\"üò°\", \" \",string)\n",
        "   string = re.sub(\"üòá\", \" \",string)\n",
        "   string = re.sub(\"üò¨\", \" \",string)\n",
        "   string = re.sub(\"üòÉ\", \" \",string)\n",
        "   string = re.sub(\"üòÇ\", \" \",string)\n",
        "   string = re.sub(\"üíô\", \" \",string)  \n",
        "   string = re.sub(\"üòõ\", \" \",string)\n",
        "   string = re.sub(\"üôè\", \" \",string)\n",
        "   string = re.sub(\"üëç\", \" \",string)\n",
        "   string = re.sub(\"üñï\", \" \",string)\n",
        "   string = re.sub(\"üòâ\", \" \",string)\n",
        "   string = re.sub(\"üí©\", \" \",string)\n",
        "   string = re.sub(\"ü§¢\", \" \",string)\n",
        "   string = re.sub(\"üëè\", \" \",string)\n",
        "   string = re.sub(\"üò®\", \" \",string)\n",
        "   string = re.sub(\"ü§£\", \" \",string)\n",
        "   string = re.sub(\"ü§°\", \" \",string)\n",
        "   string = re.sub(\"üòà\", \" \",string)\n",
        "   string = re.sub(\"üíÉüèΩ\", \" \",string)\n",
        "   string = re.sub(\"üëπ\", \" \",string)\n",
        "   string = re.sub(\"ü§ò\", \" \",string)\n",
        "   string = re.sub(\"üò±\", \" \",string)\n",
        "   string = re.sub(\"ü§î\", \" \",string) \n",
        "   string = re.sub(\"üåà\", \" \",string) \n",
        "   string = re.sub(\"üíï\", \" \",string) \n",
        "   string = re.sub(\"üë©‚Äç‚ù§Ô∏è‚Äçüë©\", \" \",string) \n",
        "   string = re.sub(\"üòç\", \" \",string) \n",
        "   string = re.sub(\"üëÜ\", \" \",string) \n",
        "   string = re.sub(\"üòñ\", \" \",string) \n",
        "   string = re.sub(\"üëá\", \" \",string) \n",
        "   string = re.sub(\"üî•\", \" \",string) \n",
        "   string = re.sub(\"üòò\", \" \",string) \n",
        "   string = re.sub(\"üéâ\", \" \",string) \n",
        "   string = re.sub(\"ü§¨\", \" \",string) \n",
        "   string = re.sub(\"üëä\", \" \",string)\n",
        "   string = re.sub(\"üá©üá™\", \" \",string)  \n",
        "   string = re.sub(\"üíî\", \" \",string)\n",
        "   string = re.sub(\"üôà\", \" \",string)\n",
        "   string = re.sub(\"ü§Ø\", \" \",string)\n",
        "   string = re.sub(\"üêü\", \" \",string)\n",
        "   string = re.sub(\"üõ∂\", \" \",string)\n",
        "   string = re.sub(\"üòä\", \" \",string)\n",
        "   string = re.sub(\"üòì\", \" \",string)\n",
        "   string = re.sub(\"üò≥\", \" \",string)\n",
        "   string = re.sub(\"üöÄ\", \" \",string)\n",
        "   string = re.sub(\"üëé\", \" \",string)\n",
        "   string = re.sub(\"üòé\", \" \",string)\n",
        "   string = re.sub(\"üê∏\", \" \",string)\n",
        "   string = re.sub(\"üìà\", \" \",string)\n",
        "   string = re.sub(\"üôÇ\", \" \",string)\n",
        "   string = re.sub(\"üòÖ\", \" \",string)\n",
        "   string = re.sub(\"üòÜ\", \" \",string)\n",
        "   string = re.sub(\"üôéüèø\", \" \",string)\n",
        "   string = re.sub(\"üëéüèΩ\", \" \",string)\n",
        "   string = re.sub(\"ü§≠\", \" \",string)\n",
        "   string = re.sub(\"üò§\", \" \",string)\n",
        "   string = re.sub(\"üòö\", \" \",string)\n",
        "   string = re.sub(\"üòä\", \" \",string)\n",
        "   string = re.sub(\"üò≤\", \" \",string)\n",
        "   string = re.sub(\"ü§Æ\", \" \",string)\n",
        "   string = re.sub(\"üôÑ\", \" \",string)\n",
        "   string = re.sub(\"ü§ë\", \" \",string)\n",
        "   string = re.sub(\"üéÖ\", \" \",string)\n",
        "   string = re.sub(\"üëã\", \" \",string)\n",
        "   string = re.sub(\"üí™\", \" \",string)\n",
        "   string = re.sub(\"üòÑ\", \" \",string)\n",
        "   string = re.sub(\"üßê\", \" \",string)\n",
        "   string = re.sub(\"üò†\", \" \",string)\n",
        "   string = re.sub(\"üéà\", \" \",string)\n",
        "   string = re.sub(\"üöÇ\", \" \",string)\n",
        "   string = re.sub(\"üòä\", \" \",string)\n",
        "   string = re.sub(\"üöá\", \" \",string)\n",
        "   string = re.sub(\"üöä\", \" \",string)\n",
        "   string = re.sub(\"ü§∑\", \" \",string)\n",
        "   string = re.sub(\"üò•\", \" \",string)\n",
        "   string = re.sub(\"üôÉ\", \" \",string)\n",
        "   string = re.sub(\"üî©\", \" \",string)\n",
        "   string = re.sub(\"üîß\", \" \",string)\n",
        "   string = re.sub(\"üî®\", \" \",string)\n",
        "   string = re.sub(\"üõ†\", \" \",string)\n",
        "   string = re.sub(\"üíì\", \" \",string)\n",
        "   string = re.sub(\"üí°\", \" \",string)\n",
        "   string = re.sub(\"üç∏\", \" \",string)\n",
        "   string = re.sub(\"ü•É\", \" \",string)\n",
        "   string = re.sub(\"ü•Ç\", \" \",string)\n",
        "   string = re.sub(\"üò∑\", \" \",string)\n",
        "   string = re.sub(\"ü§ê\", \" \",string)\n",
        "   string = re.sub(\"üåé\", \" \",string)\n",
        "   string = re.sub(\"üëë\", \" \",string)\n",
        "   string = re.sub(\"ü§õ\", \" \",string)\n",
        "   string = re.sub(\"üòÄ\", \" \",string)\n",
        "   string = re.sub(\"üõ§\", \" \",string)\n",
        "   string = re.sub(\"üéÑ\", \" \",string)\n",
        "   string = re.sub(\"üì¥\", \" \",string)\n",
        "   string = re.sub(\"üå≠\", \" \",string)\n",
        "   string = re.sub(\"ü§ï\", \" \",string)\n",
        "   string = re.sub(\"üò≠\", \" \",string)\n",
        "   string = re.sub(\"üçæ\", \" \",string)\n",
        "   string = re.sub(\"üçû\", \" \",string)\n",
        "   string = re.sub(\"ü§¶\", \" \",string)\n",
        "   string = re.sub(\"ü§Ø\", \" \",string)\n",
        "   string = re.sub(\"üïØÔ∏è\", \" \",string)\n",
        "\n",
        "   string = re.sub(\"OTHER|OFFENSE|ABUSE|INSULT\",\" \",string)\n",
        "   return string"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5asMgo4LtnRg"
      },
      "source": [
        "statementsForTraining = []\n",
        "sentimentsForTraining = []\n",
        "\n",
        "\n",
        "fileToRead = open(training_file, 'r')\n",
        "\n",
        "while True:\n",
        "  #next line in file\n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  findSentiment = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "\n",
        "\n",
        "  statementsForTraining.append(line)\n",
        "   #sentimentsForTraining.append(findSentiment.group(0))\n",
        "\n",
        "  if findSentiment.group(0) == \"OTHER\":  \n",
        "    sentimentsForTraining.append(0)\n",
        "  else:\n",
        "    sentimentsForTraining.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        " #print(\"{}: {}\".format(count,line.strip()))\n",
        "  \n",
        " # print(sentiment.group(0))\n",
        " \n",
        "fileToRead.close()\n",
        "\n",
        "training_sentences = statementsForTraining\n",
        "training_labels = sentimentsForTraining\n",
        "\n",
        "#print(training_sentences[9])\n",
        "#print(training_labels[9])\n",
        "\n",
        "#print(len(training_sentences))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsqZPENb98gD"
      },
      "source": [
        "##do the same with testdata\n",
        "statementsForTesting = []\n",
        "sentimentsForTesting = []\n",
        "\n",
        "fileToRead = open(testing_file, 'r')\n",
        "\n",
        "while True:\n",
        "  #next line in file\n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  sent = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "\n",
        "    \n",
        "\n",
        "  statementsForTesting.append(line)\n",
        "  #print(len(line))\n",
        "  #sentimentsForTesting.append(sent.group(0))\n",
        "\n",
        "  if sent.group(0) == \"OTHER\": \n",
        "    sentimentsForTesting.append(0)\n",
        "  else:\n",
        "    sentimentsForTesting.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        "\n",
        "fileToRead.close()\n",
        "\n",
        "\n",
        "testing_sentences = statementsForTesting\n",
        "testing_labels = sentimentsForTesting\n",
        "#print(len(testing_sentences))\n",
        "#print(testing_sentences)   \n",
        "#print(testing_labels)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRUvDLD5bMbO"
      },
      "source": [
        "Padding -> im Prinzip die S√§tze alle auf die gleiche L√§nge bringen (in Theorieteil n√§her drauf eingehen) -> maxlen-Paramter ist f√ºr pad_sequences vorhanden, wenn nicht gesetzt -> alles wird auf die L√§nge des l√§ngsten Satzes aufgef√ºllt -> print(padded(shape)) gibt aus, wie viele Datens√§tze padded wurden und gibt an, wie viele Tokens der l√§ngste Datensatz hat\n",
        "print(padded[x]) gibt einen Satz aus (bereits tokenisiert)\n",
        "\n",
        "Padding -> sowohl f√ºr Trainigs- als auch f√ºr Testdaten\n",
        "\n",
        "Und: Daten als numpy-Arrays speichern (notwendig f√ºr tensorflow).\n",
        "\n",
        " -> Tokenizer https://towardsdatascience.com/text-classification-in-keras-part-2-how-to-use-the-keras-tokenizer-word-representations-fd571674df23 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3hFi7waTv5m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ecc972b-1ef1-4804-d5f3-35c73b0dfdb6"
      },
      "source": [
        "tokenizer = Tokenizer(oov_token=\"OOV\")\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "\n",
        "#creating a word index - nur die Trainigsdaten\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "validation_size = 500\n",
        "\n",
        "\n",
        "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "padded_training = pad_sequences(training_sequences, maxlen=max_length, padding='post')\n",
        "print(len(padded_training))\n",
        "\n",
        "validation_sequences = padded_training[0:validation_size]\n",
        "validation_labels = training_labels[0:validation_size]\n",
        "\n",
        "padded_training = padded_training[validation_size:]\n",
        "training_labels = training_labels[validation_size:]\n",
        "\n",
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
        "padded_testing = pad_sequences(testing_sequences, maxlen=max_length,  padding='post')\n",
        "\n",
        "#print(validation_sequences[499])\n",
        "print(padded_training[0])\n",
        "#print(len(validation_labels))\n",
        "#print(len(training_labels))\n",
        "\n",
        "\n",
        "nppadded_training = np.array(padded_training)\n",
        "nptraining_labels = np.array(training_labels)\n",
        "\n",
        "nppadded_validation = np.array(validation_sequences)\n",
        "npvalidation_labels = np.array(validation_labels)\n",
        "\n",
        "nppadded_testing = np.array(padded_testing)\n",
        "nptesting_labels = np.array(testing_labels)\n",
        "\n",
        "\n",
        "print(len(nppadded_training))\n",
        "print(len(nptraining_labels))\n",
        "print(len(word_index))\n",
        "\n",
        "#print(statementsForTraining[2])\n",
        "#print(nppadded_training[4])\n",
        "#print(nppadded_training.shape)\n",
        "#print(nptraining_labels[4])\n",
        "#print(nppadded_testing.shape)\n",
        "#print(word_index) \n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5009\n",
            "[  12 3982   11   41 6706 1040    4    5  202   39    3 2922   49 1360\n",
            "  810  495 3983    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0]\n",
            "4509\n",
            "4509\n",
            "15059\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tL3owrc8THkT"
      },
      "source": [
        "\n",
        "Dann: Embedding mit entweder word2vec oder glove\n",
        "Word2vec-Daten sind hier: http://vectors.nlpl.eu/repository/#\n",
        "Glove -> https://nlp.stanford.edu/projects/glove/ Da mal den Twitter-Vector runtergeladen\n",
        "Wenn Daten in GoogleDrive sind (w√§re auch via url m√∂glich..), muss Drive gemounted werden ( https://buomsoo-kim.github.io/colab/2020/05/09/Colab-mounting-google-drive.md/ ) aber auch hier https://enjoymachinelearning.com/posts/colab-with-google-drive/\n",
        "\n",
        "Die Word2vec vectors: http://vectors.nlpl.eu/repository/# \n",
        "\n",
        "glove-zitat:\n",
        "Citing GloVe\n",
        "\n",
        "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. [pdf] [bib]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zuO7T9ZTG57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dd575fe-20c0-4b6a-e521-8a52b0ebf391"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "os.listdir(\"/content/drive/MyDrive/Colab Notebooks\")\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['germeval_training.txt',\n",
              " 'glove.twitter.27B.50d.txt',\n",
              " 'glove.twitter.27B.200d.txt',\n",
              " 'glove.6B.200d.txt',\n",
              " 'glove.840B.300d.txt',\n",
              " 'tensorboard.gdoc',\n",
              " 'keras.gdoc',\n",
              " 'Vectorization CNN embedded_limited_vocab.ipynb',\n",
              " 'glove.42B.300d.txt',\n",
              " 'Embedding Glove Vergleich.ipynb',\n",
              " 'CNN embedded_limited_vocab.ipynb',\n",
              " 'LSTM_limited_vocab.ipynb',\n",
              " 'LSTM.ipynb',\n",
              " 'CNN embedded.ipynb']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7ToKO-sZLHK"
      },
      "source": [
        "\n",
        "Keras-Doc : https://keras.io/examples/nlp/pretrained_word_embeddings/#load-pretrained-word-embeddings \n",
        "embedding mit initializers.. weights m√ºsste auch funktionieren\n",
        "\n",
        "Diese erstellte Matrix mit Embedding dann in die Embedding-Schicht einbinden,  Trainable auf False, weil sich die Werte nicht durch Training anpassen sollen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AShIVfC7ZQAH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5245277e-ff24-4a74-d6f7-3c1f56f3968c"
      },
      "source": [
        "#Gr√∂√üe Vokabel -> wordindex + 2 (weil padding + OOV) \n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "vocabulary_size = len(word_index)+2\n",
        "\n",
        "# dann erstell ich ein W√∂rterbuch mit Namen \"embedding_vector\", dort sind dann\n",
        "#die keys drinnen, die in glove-Datei drinnen sind mit dem entsprechenden Key\n",
        "\n",
        "embedding_index_glove = {}\n",
        "f = open('/content/drive/MyDrive/Colab Notebooks/glove.twitter.27B.200d.txt')\n",
        "for line in f:\n",
        "  value = line.split()\n",
        "  word = value[0]\n",
        "  coef = np.asarray(value[1:],dtype='float32')\n",
        "  embedding_index_glove[word] = coef\n",
        "\n",
        "print(\"%d gefunden: \"% len(embedding_index_glove))\n",
        "\n",
        "#Dann noch eine Embedding-Matrix erstellen\n",
        "#zweiter Wert = Embedding-Dimension der Datei, in dem Fall 200\n",
        "\n",
        "glove_matrix = np.zeros((vocabulary_size,200))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    embedding_value = embedding_index_glove.get(word)\n",
        "    if embedding_value is not None:\n",
        "      glove_matrix[index] = embedding_value\n",
        "      hits+=1\n",
        "    else:\n",
        "      misses+=1\n",
        "\n",
        "print(\"hits %d and %d misses\"%(hits,misses))\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1193514 gefunden: \n",
            "hits 6747 and 8312 misses\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZmvOfwhV4N5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbd9991d-6101-447e-a191-8c86a1b264e2"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "print(\"vocab size: %d\"%vocabulary_size)\n",
        "CNN16052101 = tf.keras.Sequential()\n",
        "#Embedding -> hier dann auf das embedding verweisen, Input_dim -> die Anzahl der W√∂rter im word_index, output -> in dem Fall passend zum verwendeten Vektor\n",
        "#input-length -> auf 60  gepadded, trainable -> nein, weil nichts ver√§ndert werden soll\n",
        "#embeddings_initializer=keras.initializers.Constant(glove_matrix) vs weights = [glove_matrix]\n",
        "#Convolutional layers => filters = neurons.. mit 100? 265?\n",
        "CNN16052101.add(tf.keras.layers.Embedding(vocabulary_size, output_dim=200, input_length=60, embeddings_initializer = keras.initializers.Constant(glove_matrix), trainable= False))\n",
        "CNN16052101.add(tf.keras.layers.Dropout(0.4))\n",
        "CNN16052101.add(tf.keras.layers.Conv1D(filters=30, kernel_size=3, padding=\"valid\", activation=\"relu\"))\n",
        "CNN16052101.add(tf.keras.layers.MaxPooling1D())\n",
        "CNN16052101.add(tf.keras.layers.Conv1D(filters=30, kernel_size=3, padding=\"valid\", activation=\"relu\"))\n",
        "CNN16052101.add(tf.keras.layers.GlobalAveragePooling1D())\n",
        "CNN16052101.add(tf.keras.layers.Flatten())\n",
        "CNN16052101.add(tf.keras.layers.Dense(260, activation=\"relu\"))\n",
        "CNN16052101.add(tf.keras.layers.Dropout(0.4))\n",
        "CNN16052101.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "CNN16052101.summary()\n",
        "\n",
        "#nppadded_training = np.asmatrix(nppadded_training) not necessary\n",
        "#nppadded_testing = np.asmatrix(nppadded_testing)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab size: 15061\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 60, 200)           3012200   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 60, 200)           0         \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 58, 30)            18030     \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 29, 30)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 27, 30)            2730      \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 30)                0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 30)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 260)               8060      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 260)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 261       \n",
            "=================================================================\n",
            "Total params: 3,041,281\n",
            "Trainable params: 29,081\n",
            "Non-trainable params: 3,012,200\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEr4OzT-iHDe"
      },
      "source": [
        "#model.layers[2].get_weights()[0].shape\n",
        "#weights=np.random.rand(5,200,100)\n",
        "#bias=np.random.rand(100)\n",
        "#model.layers[2].set_weights([weights, bias])\n",
        "\n",
        "#model.layers[2].get_weights()[0]\n",
        "#https://androidkt.com/set-custom-weights-keras-using-numpy-array/"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UB7_3VPYesr9"
      },
      "source": [
        "F1-Score f√ºr jede Epoche https://aakashgoel12.medium.com/how-to-add-user-defined-function-get-f1-score-in-keras-metrics-3013f979ce0d\n",
        "\n",
        "Sehr gute Ressource f√ºr die verschiedenen Scores und Metriken https://neptune.ai/blog/evaluation-metrics-binary-classification#10  das und aakas verwendet\n",
        "\n",
        "hier: je eine Funktion f√ºr Recall, Precision, f1 https://neptune.ai/blog/keras-metrics \n",
        "\n",
        "https://keras.rstudio.com/reference/k_ones_like.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygyrbFJaMV9B"
      },
      "source": [
        "import keras.backend as K\n",
        "\n",
        "def metrics_recall(data_true, data_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(data_true,0,1)))\n",
        "\n",
        "    recall = true_positives / (possible_positives+K.epsilon())\n",
        "    return recall\n",
        "\n",
        "\n",
        "def metrics_precision(data_true, data_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "\n",
        "    positives_predicted = K.sum(K.round(K.clip(data_pred,0,1)))\n",
        "    precision = true_positives / (positives_predicted+K.epsilon())\n",
        "    return precision\n",
        "\n",
        "\n",
        "def metrics_f1(data_true, data_pred):\n",
        "    precision_data = metrics_precision(data_true, data_pred)\n",
        "    recall_data = metrics_recall(data_true, data_pred)\n",
        "    return 2*(precision_data*recall_data)/(precision_data+recall_data+K.epsilon())"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1ctlBrnuYJz"
      },
      "source": [
        "https://aakashgoel12.medium.com/how-to-add-user-defined-function-get-f1-score-in-keras-metrics-3013f979ce0d"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AfPD3_bWCm0"
      },
      "source": [
        "CNN16052101.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',metrics_recall,metrics_precision,metrics_f1])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpChKUY-QEWI"
      },
      "source": [
        "https://www.tensorflow.org/tensorboard/tensorboard_in_notebooks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJfMgUhHBoD1"
      },
      "source": [
        "#%reload_ext tensorboard\n",
        "#nur einmal pro Sitzung notwendig\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ISmMXLqP8Hc"
      },
      "source": [
        "\n",
        "logs_base_dir = \"./logs\"\n",
        "callbackForTB = tf.keras.callbacks.TensorBoard(logs_base_dir)\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2CHbXiP1LsF"
      },
      "source": [
        "training_epochs = 30\n",
        "batch_size = 40\n",
        "validation_split=0.2"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abV-QAxfW48r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11fea101-7c45-4ca4-bc82-668d672aba6f"
      },
      "source": [
        "#Werte der Convolutional-Schichten variieren (Filter), Batch-Size variieren, kernel-size..\n",
        "CNN16052101.fit(nppadded_training, nptraining_labels, batch_size=batch_size, validation_split=validation_split, epochs=training_epochs, callbacks=[callbackForTB])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "91/91 [==============================] - 4s 29ms/step - loss: 0.6554 - accuracy: 0.6663 - metrics_recall: 0.0148 - metrics_precision: 0.0202 - metrics_f1: 0.0171 - val_loss: 0.6378 - val_accuracy: 0.6718 - val_metrics_recall: 0.0000e+00 - val_metrics_precision: 0.0000e+00 - val_metrics_f1: 0.0000e+00\n",
            "Epoch 2/30\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.6440 - accuracy: 0.6543 - metrics_recall: 0.0000e+00 - metrics_precision: 0.0000e+00 - metrics_f1: 0.0000e+00 - val_loss: 0.6149 - val_accuracy: 0.6718 - val_metrics_recall: 0.0000e+00 - val_metrics_precision: 0.0000e+00 - val_metrics_f1: 0.0000e+00\n",
            "Epoch 3/30\n",
            "91/91 [==============================] - 2s 25ms/step - loss: 0.6153 - accuracy: 0.6691 - metrics_recall: 0.0131 - metrics_precision: 0.0740 - metrics_f1: 0.0202 - val_loss: 0.6121 - val_accuracy: 0.6763 - val_metrics_recall: 0.4301 - val_metrics_precision: 0.5183 - val_metrics_f1: 0.4558\n",
            "Epoch 4/30\n",
            "91/91 [==============================] - 2s 26ms/step - loss: 0.5957 - accuracy: 0.6690 - metrics_recall: 0.1833 - metrics_precision: 0.5343 - metrics_f1: 0.2358 - val_loss: 0.6049 - val_accuracy: 0.6840 - val_metrics_recall: 0.3815 - val_metrics_precision: 0.5332 - val_metrics_f1: 0.4321\n",
            "Epoch 5/30\n",
            "91/91 [==============================] - 2s 25ms/step - loss: 0.5794 - accuracy: 0.6959 - metrics_recall: 0.2832 - metrics_precision: 0.6072 - metrics_f1: 0.3554 - val_loss: 0.5598 - val_accuracy: 0.7129 - val_metrics_recall: 0.2568 - val_metrics_precision: 0.7096 - val_metrics_f1: 0.3569\n",
            "Epoch 6/30\n",
            "91/91 [==============================] - 2s 25ms/step - loss: 0.5573 - accuracy: 0.7075 - metrics_recall: 0.3960 - metrics_precision: 0.6422 - metrics_f1: 0.4670 - val_loss: 0.5654 - val_accuracy: 0.7051 - val_metrics_recall: 0.1513 - val_metrics_precision: 0.6957 - val_metrics_f1: 0.2396\n",
            "Epoch 7/30\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.5633 - accuracy: 0.7013 - metrics_recall: 0.3621 - metrics_precision: 0.6777 - metrics_f1: 0.4302 - val_loss: 0.5551 - val_accuracy: 0.7262 - val_metrics_recall: 0.4983 - val_metrics_precision: 0.6054 - val_metrics_f1: 0.5371\n",
            "Epoch 8/30\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.5300 - accuracy: 0.7286 - metrics_recall: 0.4249 - metrics_precision: 0.6654 - metrics_f1: 0.4911 - val_loss: 0.5474 - val_accuracy: 0.7206 - val_metrics_recall: 0.5122 - val_metrics_precision: 0.5947 - val_metrics_f1: 0.5372\n",
            "Epoch 9/30\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.5124 - accuracy: 0.7469 - metrics_recall: 0.4863 - metrics_precision: 0.6886 - metrics_f1: 0.5468 - val_loss: 0.5423 - val_accuracy: 0.7251 - val_metrics_recall: 0.3169 - val_metrics_precision: 0.6934 - val_metrics_f1: 0.4158\n",
            "Epoch 10/30\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.5191 - accuracy: 0.7592 - metrics_recall: 0.5087 - metrics_precision: 0.7572 - metrics_f1: 0.5777 - val_loss: 0.5361 - val_accuracy: 0.7328 - val_metrics_recall: 0.5439 - val_metrics_precision: 0.5887 - val_metrics_f1: 0.5549\n",
            "Epoch 11/30\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.4668 - accuracy: 0.7709 - metrics_recall: 0.5742 - metrics_precision: 0.7207 - metrics_f1: 0.6199 - val_loss: 0.5486 - val_accuracy: 0.7206 - val_metrics_recall: 0.5728 - val_metrics_precision: 0.5678 - val_metrics_f1: 0.5607\n",
            "Epoch 12/30\n",
            "91/91 [==============================] - 2s 25ms/step - loss: 0.4632 - accuracy: 0.7754 - metrics_recall: 0.5610 - metrics_precision: 0.7217 - metrics_f1: 0.6158 - val_loss: 0.5477 - val_accuracy: 0.7140 - val_metrics_recall: 0.5988 - val_metrics_precision: 0.5518 - val_metrics_f1: 0.5632\n",
            "Epoch 13/30\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.4463 - accuracy: 0.7870 - metrics_recall: 0.6002 - metrics_precision: 0.7430 - metrics_f1: 0.6476 - val_loss: 0.5347 - val_accuracy: 0.7151 - val_metrics_recall: 0.3510 - val_metrics_precision: 0.6178 - val_metrics_f1: 0.4304\n",
            "Epoch 14/30\n",
            "91/91 [==============================] - 2s 25ms/step - loss: 0.4261 - accuracy: 0.7927 - metrics_recall: 0.5766 - metrics_precision: 0.7297 - metrics_f1: 0.6281 - val_loss: 0.5692 - val_accuracy: 0.6918 - val_metrics_recall: 0.6614 - val_metrics_precision: 0.5239 - val_metrics_f1: 0.5713\n",
            "Epoch 15/30\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.4322 - accuracy: 0.7997 - metrics_recall: 0.6565 - metrics_precision: 0.7397 - metrics_f1: 0.6807 - val_loss: 0.5431 - val_accuracy: 0.7151 - val_metrics_recall: 0.4594 - val_metrics_precision: 0.5735 - val_metrics_f1: 0.4926\n",
            "Epoch 16/30\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.4010 - accuracy: 0.8141 - metrics_recall: 0.6674 - metrics_precision: 0.7699 - metrics_f1: 0.7049 - val_loss: 0.5451 - val_accuracy: 0.7239 - val_metrics_recall: 0.4088 - val_metrics_precision: 0.6169 - val_metrics_f1: 0.4757\n",
            "Epoch 17/30\n",
            "91/91 [==============================] - 2s 25ms/step - loss: 0.4043 - accuracy: 0.8093 - metrics_recall: 0.6346 - metrics_precision: 0.7610 - metrics_f1: 0.6796 - val_loss: 0.5591 - val_accuracy: 0.7273 - val_metrics_recall: 0.4561 - val_metrics_precision: 0.6072 - val_metrics_f1: 0.5030\n",
            "Epoch 18/30\n",
            "91/91 [==============================] - 2s 25ms/step - loss: 0.3963 - accuracy: 0.8124 - metrics_recall: 0.6588 - metrics_precision: 0.7891 - metrics_f1: 0.6987 - val_loss: 0.5554 - val_accuracy: 0.7262 - val_metrics_recall: 0.4416 - val_metrics_precision: 0.6121 - val_metrics_f1: 0.4961\n",
            "Epoch 19/30\n",
            "91/91 [==============================] - 2s 25ms/step - loss: 0.3837 - accuracy: 0.8169 - metrics_recall: 0.6688 - metrics_precision: 0.7714 - metrics_f1: 0.6952 - val_loss: 0.5624 - val_accuracy: 0.7018 - val_metrics_recall: 0.5462 - val_metrics_precision: 0.5483 - val_metrics_f1: 0.5315\n",
            "Epoch 20/30\n",
            "91/91 [==============================] - 2s 25ms/step - loss: 0.3665 - accuracy: 0.8389 - metrics_recall: 0.7016 - metrics_precision: 0.8045 - metrics_f1: 0.7350 - val_loss: 0.5877 - val_accuracy: 0.7317 - val_metrics_recall: 0.4082 - val_metrics_precision: 0.6424 - val_metrics_f1: 0.4830\n",
            "Epoch 21/30\n",
            "91/91 [==============================] - 2s 25ms/step - loss: 0.3572 - accuracy: 0.8414 - metrics_recall: 0.7177 - metrics_precision: 0.8096 - metrics_f1: 0.7435 - val_loss: 0.5702 - val_accuracy: 0.7106 - val_metrics_recall: 0.5039 - val_metrics_precision: 0.5688 - val_metrics_f1: 0.5177\n",
            "Epoch 22/30\n",
            "91/91 [==============================] - 2s 25ms/step - loss: 0.3444 - accuracy: 0.8479 - metrics_recall: 0.7343 - metrics_precision: 0.8101 - metrics_f1: 0.7517 - val_loss: 0.6164 - val_accuracy: 0.6829 - val_metrics_recall: 0.6583 - val_metrics_precision: 0.5126 - val_metrics_f1: 0.5644\n",
            "Epoch 23/30\n",
            "91/91 [==============================] - 2s 25ms/step - loss: 0.3301 - accuracy: 0.8483 - metrics_recall: 0.7474 - metrics_precision: 0.8029 - metrics_f1: 0.7630 - val_loss: 0.6182 - val_accuracy: 0.6962 - val_metrics_recall: 0.6192 - val_metrics_precision: 0.5252 - val_metrics_f1: 0.5578\n",
            "Epoch 24/30\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.3367 - accuracy: 0.8467 - metrics_recall: 0.7495 - metrics_precision: 0.8128 - metrics_f1: 0.7590 - val_loss: 0.6119 - val_accuracy: 0.7051 - val_metrics_recall: 0.6015 - val_metrics_precision: 0.5384 - val_metrics_f1: 0.5582\n",
            "Epoch 25/30\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.3323 - accuracy: 0.8582 - metrics_recall: 0.7724 - metrics_precision: 0.8031 - metrics_f1: 0.7767 - val_loss: 0.5833 - val_accuracy: 0.7018 - val_metrics_recall: 0.5286 - val_metrics_precision: 0.5437 - val_metrics_f1: 0.5233\n",
            "Epoch 26/30\n",
            "91/91 [==============================] - 2s 25ms/step - loss: 0.3117 - accuracy: 0.8652 - metrics_recall: 0.7412 - metrics_precision: 0.8386 - metrics_f1: 0.7799 - val_loss: 0.6209 - val_accuracy: 0.6918 - val_metrics_recall: 0.5831 - val_metrics_precision: 0.5240 - val_metrics_f1: 0.5394\n",
            "Epoch 27/30\n",
            "91/91 [==============================] - 2s 25ms/step - loss: 0.3017 - accuracy: 0.8620 - metrics_recall: 0.7650 - metrics_precision: 0.8122 - metrics_f1: 0.7788 - val_loss: 0.6046 - val_accuracy: 0.7029 - val_metrics_recall: 0.5231 - val_metrics_precision: 0.5422 - val_metrics_f1: 0.5178\n",
            "Epoch 28/30\n",
            "91/91 [==============================] - 2s 25ms/step - loss: 0.3315 - accuracy: 0.8547 - metrics_recall: 0.7501 - metrics_precision: 0.8315 - metrics_f1: 0.7734 - val_loss: 0.6246 - val_accuracy: 0.7151 - val_metrics_recall: 0.4878 - val_metrics_precision: 0.5759 - val_metrics_f1: 0.5100\n",
            "Epoch 29/30\n",
            "91/91 [==============================] - 2s 25ms/step - loss: 0.2945 - accuracy: 0.8699 - metrics_recall: 0.7825 - metrics_precision: 0.8114 - metrics_f1: 0.7915 - val_loss: 0.6182 - val_accuracy: 0.6973 - val_metrics_recall: 0.5110 - val_metrics_precision: 0.5444 - val_metrics_f1: 0.5090\n",
            "Epoch 30/30\n",
            "91/91 [==============================] - 2s 26ms/step - loss: 0.2876 - accuracy: 0.8729 - metrics_recall: 0.7688 - metrics_precision: 0.8387 - metrics_f1: 0.7926 - val_loss: 0.6521 - val_accuracy: 0.6896 - val_metrics_recall: 0.6034 - val_metrics_precision: 0.5248 - val_metrics_f1: 0.5462\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0bb8238dd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJVL4SBLPB2P"
      },
      "source": [
        "#%tensorboard --logdir {logs_base_dir}"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_LnvWBcnoak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33943754-9daf-4939-a251-5a9e918d4b62"
      },
      "source": [
        "#results = model.evaluate(nppadded_testing, nptesting_labels, batch_size=batch_size)\n",
        "#print(\"test loss, test acc:\",results)\n",
        "\n",
        "(loss,accuracy, metrics_recall,metrics_precision,\n",
        "metrics_f1) = CNN16052101.evaluate(nppadded_testing, nptesting_labels, verbose=1)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6750 - accuracy: 0.6651 - metrics_recall: 0.4940 - metrics_precision: 0.5134 - metrics_f1: 0.4912\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KgjIkhpKmHc"
      },
      "source": [
        "make some predictions of test data and save it to variable. verbose=0 -> do not generate output\n",
        "Gute Quelle: https://deeplizard.com/learn/video/2f-NjDUvZIE "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89GWuxryKlcM"
      },
      "source": [
        "CNN_predictions07 = CNN16052101.predict(x=nppadded_testing)\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3jPDaDJK_cN"
      },
      "source": [
        "#for p in CNN_predictions07:\n",
        " # print(p)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eC9efJy4Lp21"
      },
      "source": [
        "rounded predictions: give prediction value of most likely prediction (0 or 1). Printing the output of rounded prediction shows the prediction made by the model on the data (which output is most likely)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsG-TJuQLvtk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebaefb98-324d-48c5-d7b7-e9b2b91244a1"
      },
      "source": [
        "prediction_rounded01 = np.round(CNN_predictions07)\n",
        "#np.argmax(CNN_predictions07,axis=-1)\n",
        "\n",
        "#for p in prediction_rounded01:\n",
        " # print(p)\n",
        "\n",
        "\n",
        "print(nptesting_labels[500:520])\n",
        "print(prediction_rounded01[500:520])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1]\n",
            "[[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egTtgpXgg8a2"
      },
      "source": [
        "https://deeplizard.com/learn/video/km7pxKy4UHU\n",
        "\n",
        "Quelle der def plot_confusion_matrix: https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSDXf7-_MITy"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0AMs1EzhBU1"
      },
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                        normalize=False,\n",
        "                        title='Confusion matrix',\n",
        "                        cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2JgEnlghCtl"
      },
      "source": [
        "cm = confusion_matrix(y_true=nptesting_labels, y_pred=prediction_rounded01)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckmF29whhFmX"
      },
      "source": [
        "plot_labels = ['no hatespeech','hatespeech']"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "2mpSE96rhK7K",
        "outputId": "42a542d4-a40c-4474-9e3b-c3818b8d8086"
      },
      "source": [
        "plot_confusion_matrix(cm=cm, classes=plot_labels, title='CNN Confusion 30')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix, without normalization\n",
            "[[1762  568]\n",
            " [ 615  587]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAAEmCAYAAACzoiEDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd5xU1fnH8c93lyogiIhSRFCxoLEggkgkdrGCFVEjlthLEmMsUUNiSYian91gI2BU7EZUBLFSFGmKigURLGABBBEBhcXn98c5S8aVnZ2td+7u887rvnbuuefee2Ywz5w59xSZGc4555JRkHQBnHOuLvMg7JxzCfIg7JxzCfIg7JxzCfIg7JxzCfIg7JxzCfIg7BwgqbGkpyQtlfRIJa5zvKTnqrJsrnbzIOwqRNJxkqZK+k7SF5KelfTLeOwvkkzSMRn568W0jnF/WNzvnpFnS0lZO65nu28lHQVsDGxoZkdX9CJmdr+Z7V8F5fkJSV3i+14St+cldck4Lkn/kPR13P4hSVVdDlf1PAi7cpN0AXAj8DdC4OoA3A70zci2GPirpMIsl1oMXF3F962ozYBZZlZUBdeqDp8TvihaAq2AkcCDGcdPB/oBOwI7AIcCZ9RwGV1FmJlvvuW8Ac2B74Cjs+T5C3A/MAMYGNPqAQZ0jPvDgP8DvgR+FdO2DP9JVvi+DQlB+vO43Qg0jMf2BOYBfwAWAF8AJ8djfwVWAavjPU6N7+G+jGt3jOWvF/dPAuYAy4C5wPEZ6RMyztsdmAIsjX93zzj2MnAVMDFe5zmgVQ7/BvWAc4AVGWmvAqdn7J8KTEr6vxffyt68JuzKqyfQCHiijHwGXAEMklS/lDwrCLXaa6rovpcBuwE7EWqE3YHLM45vQgjm7QhB6jZJG5jZoFiOh8ysqZndk60gkpoANwMHmlkzQqB9cx35WgLPxLwbEr50npG0YUa244CTgdZAA+DCMu79DfA9cEssc7HtCF96xWbENJfnPAi78toQWGQ5/Gw3s5HAQuA3WbLdAXSQdGAV3Pd44EozW2BmCwk13F9nHF8dj682s1GEWu/WZb2PUvwIbC+psZl9YWYz15HnYOBDM/uPmRWZ2QjgfUJTQbF/m9ksM1sJPEz4AimVmbUgfJGcC7yRcagpobZdbCnQ1NuF858HYVdeXwOtJNXLMf/lhBpqo3UdNLMfCD/Jr6qC+7YFPsnY/ySmrb1GiSC+ghC8ysXMlgP9gTOBLyQ9I2mbHMpTXKZ2Gftflrc88f5DgHsltY7J3wHrZ2RbH/jOzHyGrjznQdiV12vAD4SHQGUys7HAbODsLNn+DbQAjqjkfT8nPGAr1iGmVcRyYL2M/U0yD5rZGDPbD2hDqN3elUN5iss0v4JlylQQy1cc0GcSmmCK7RjTXJ7zIOzKxcyWAn8mtKf2k7SepPqSDpR0bSmnXQZclOWaRcAg4OJK3ncEcLmkjSS1ivnvK/+7BEIbb29JHSQ1By4tPiBpY0l9Y9vwD4Ra6I/ruMYoYKvYra6epP5AF+Dp8hZG0n6SdpZUKGl9QvvyEuC9mOVe4AJJ7SS1JTyAHFbe+7ia50HYlZuZ/RO4gNDUsBD4jNBG+d9S8k8EJpdx2RGEHguVue/VwFTgLeBtYDrl6AJX4l5jgYfitabx08BZEMvxOaGb3a+As9Zxja+BQwgB8WvCF9EhZraoAkVqQfiMlgIfAVsAfczs+3j8DuApwvt+h/BA8I4K3MfVMHmTkXPOJcdrws45lyAPws45lyAPws45lyAPws45l6BcO9y7GqZ6jU0NmiVdjDpj5207JF2EOuWTTz5m0aJFVTKar3D9zcyKVmbNYysXjjGzPlVxv6rmQThPqUEzGm59TNkZXZWY+PqtSRehTunVo1uVXcuKVpb5/5Xv37ytVZXdsIp5EHbOpZsEBdlmTM1vHoSdc+mn9D7e8iDsnEs5rwk751yyUjxjpwdh51y6CW+OcM655HhzhHPOJcubI5xzLiny5gjnnEuM8OYI55xLjteEnXMuOQIKvSbsnHPJ8QdzzjmXFG+OcM65ZPmDOeecS4jkzRHOOZcorwk751xSvE3YOeeS5c0RzjmXEAkK0hvK0lty55wrluKacHobUpxzrlhBYfatDJKGSlog6Z0S6edJel/STEnXZqRfKmm2pA8kHZCR3iemzZZ0SS5F95qwcy7dVCUP5oYBtwL3/u+y2gvoC+xoZj9Iah3TuwDHAtsBbYHnJW0VT7sN2A+YB0yRNNLM3s12Yw/Czrn0q2RzhJmNk9SxRPJZwGAz+yHmWRDT+wIPxvS5kmYD3eOx2WY2JxRJD8a8WYOwN0c451JNQEFBQdYNaCVpasZ2eg6X3grYQ9Lrkl6RtGtMbwd8lpFvXkwrLT0rrwk759JNcctukZl1K+eV6wEtgd2AXYGHJW1e7vLlcBPnnEsxoerpHTEPeNzMDJgs6UegFTAf2DQjX/uYRpb0UnlzhHMu9XJojqiI/wJ7AcQHbw2ARcBI4FhJDSV1AjoDk4EpQGdJnSQ1IDy8G1nWTbwm7JxLvcrWhCWNAPYktB3PAwYBQ4GhsdvaKmBgrBXPlPQw4YFbEXCOma2J1zkXGAMUAkPNbGZZ9/Yg7JxLNUmooNK9IwaUcuiEUvJfA1yzjvRRwKjy3NuDsHMu9aqpTbhGeBB2zqWeB2HnnEuKqHRzRJI8CDvnUs9rws45lxChynRDS5wHYedc+qW3IuxB2DmXcvLmCOecS5Q3R7haa8ig4zmw9/YsXLyMbkf/DYD/DD6Zzh03BqBFs8Z8s2wlux07GIDtO7fl1ssH0KxJI3780fjlCddSUCDuv/ZUNm/fijU/GqPGvc0VN5c5mtMBW2/ZkWZNm1FYWEi9evWY+PpUAG6/9RbuGHIbhYWF9DnwYP42+FpWr17NWaf/hjffmE7RmiKOP+FE/njxpQm/g+qn6ps7okZ4EHZZ/eepSQx56BXuvurEtWm/vuTfa18PvuBwln63EoDCwgKGXj2QU6+4l7dnzadl8yasLlpDwwb1uPHeFxg39UPq1yvk2TvOY/9eXXhuYtZpVl00+vmXaNWq1dr9V15+iaefepLJ02bQsGFDFiwI09w+9ugj/LDqB6a++TYrVqxg5x26cEz/AWzWsWNCJa8hKe+ilt46vKsRE6d/xOKlK0o9fuR+XXl49DQA9u25De98OJ+3Z4WJoxYvXc6PPxorv1/NuKkfArC6aA1vvv8Z7Vq3qP7C11J33vEvLrzoEho2bAhA69atgdAuumL5coqKili5ciUNGjSg2frrJ1nUGiMp65bPPAi7CuvVdQu+WryMjz5dCEDnDq0xg5G3ncOrD1zMBQP3/dk5zZs25qDev+ClyR/UdHFTSRKHHrg/u3ffhXvuuhOA2bNmMXHCePbYvQf77f0rpk6ZAsARRx7Fek2a0GnTNmy1eQd+9/sLadmyZZLFrzFpDsJ52RwhaRjwtJk9mmP+FsBxZnZ7tRasgiR9DHQzs0VJl6UqHdOnG4+Mnrp2v15hIbvvvDm/POE6Vny/imfvOJ/p733Ky5NnAaG5Yvjgk7h9xMt8PP/rpIqdKi+8PIF27dqxYMECDumzH1tvsw1Fa4pYvHgx4yZOYuqUKZxw3DG8N2sOUyZPprCgkDmffs6SJUvYd6892Huffem0eZXPQ553vDkieS2As5MuRF1SWFhA37135NEx09emzV/wDROmf8TX3yxn5ferGT1hJjtv8785rm+7fAAffbqQWx94ueYLnFLt2oXVcVq3bs1h/Q5nypTJtGvXnn6HH4Ekdu3enYKCAhYtWsTDDz7A/gf0oX79+rRu3ZqePXsxbdrUMu6QfmXVgvO9JlwtQVhSR0nvSborLhX9nKTG8dhOkiZJekvSE5I2KOUyvSW9KmmOpKPiuU0lvSBpuqS3JfWNeQcDW0h6U9J1Me8fJU2J9/lrTGsi6RlJMyS9I6l/TP9Y0rXxmpMlbRnTN5L0WLzOFEm9Mq4zNOZ9o7gckgolXR+v/Zak8zLez3kZ5d6maj/xmrd3j62Z9fFXzF/wzdq0sa++y3ZbtqVxo/oUFhawxy5b8t6cLwEYdPYhNG/WmAuveyypIqfO8uXLWbZs2drXz499ju22255DD+vHKy+/BMCHs2axatUqWrVqRfsOHXj5pRfX5p88eRJbb536/9RykuYgXJ3NEZ2BAWZ2WpwA+UjgPsKS0ueZ2SuSriRMnvy7dZzfBvglsA1hdvpHge+Bw83sW0mtgEmSRgKXANub2U4AkvaP9+9OGEszUlJvYCPgczM7OOZrnnG/pWb2C0knAjcChwA3ATeY2QRJHQiTNW8LXAa8aGanxKaQyZKeB04EOgI7mVmRpMwGuUVm1lXS2cCFwG9KvmGFxQfDAoT1m+byGVe74X8/iT126UyrFk2ZPfoqrhoyiuH/fY2jD9hl7QO5Yt8sW8nN973IhPsuwswYM2EmoyfMpF3rFlxyWh/en/Mlr424GIAhD73CsCdeS+ItpcaCr76i/1GHA1C0poj+xx7H/gf0YdWqVZzxm1PYZaftaVC/AXcPHY4kzjzrHE7/zcl03XE7zIxfDzyZX+ywQ8LvomakuTlCYaL4Kr5oWDp6rJl1jvsXA/WBW4C3zaxDTN8CeMTMupY4f1g8//64v8zMmkmqD9wA9AZ+BLYGOgGNCG3I28f81wNHAcXVtKbA34HxwHPAQzH/+Jj/Y2BvM5sT7/GlmW0oaQHweUbRNor3fDnesyimtwQOAK4GhpjZ2BLv52Ogl5nNl9QDuMbMfv7UKkPBeq2t4dbHZMviqtCSKbcmXYQ6pVePbkybNrVKImfDjTtbu+Nvyppn7g0HT6vAQp81ojprwj9kvF4DNK7E+cX/WMcTAuEuZrY6BrdG6zhXwN/N7I6fHZC6AgcBV0t6wcyujIcyv42KXxcAu5nZ9yWuIeBIM/ugRHou72cNefpA1Lk0kqAgxTXhGn0wZ2ZLgSWS9ohJvwZeKcclmgMLYgDeC9gspi8DmmXkGwOcIqkpgKR2klpLagusMLP7gOuAzBp4/4y/xb+TnwPWtutK2inj+ufFYIyknWP6WOAMSfViet3oH+RcotL9YC6JGtlAYIik9YA5wMnlOPd+4ClJbwNTgfcBzOxrSRMVFuR71sz+KGlb4LX4D/AdYa2oLYHrFJauXg2clXHtDSS9RaixFq83dT5wW0yvB4wDzgSuIrQbvyWpAJhLaEO+G9gqpq8G7gL8d65z1SzP42xW1dImnDbKw3683iZcs7xNuGZVZZtwozZbWceBt2TN88E/+tTJNmHnnKt2wtuEU8/MOuZTLdg5Vz4FBcq6lSX2+18QmzRLHvuDJIvdYlFws6TZcTxA14y8AyV9GLeBOZW9HO/TOefyj0KbcLYtB8OAPj+7tLQpsD/waUbygYRxCJ0J/fr/FfO2JIx76EEYozBIpQ9GW8uDsHMu1UTlR8yZ2Thg8ToO3QBcxE+7sPYF7rVgEtBCUhvCWIGxZrbYzJYQekv9LLCX5G3CzrmUy6nJoZWkzIk07jSzO7NeNUxHMN/MZpQI5O2AzzL258W00tKz8iDsnEu9HGq7i8rTOyJ2of0ToSmiWnlzhHMu1YpHzFXmwdw6bEGYEmFG7MLaHpguaRNgPrBpRt72Ma209Kw8CDvnUq8KHsz9hJm9bWatY8+pjoSmha5m9iVhQrETYy+J3QiTf31BGEm7v6QN4gO5/WNaVt4c4ZxLvcoOTZY0AtiT0HY8DxhkZveUkn0UYf6Z2cAK4qhfM1ss6SpgSsx3pZmt62HfT3gQds6lWxVM4GNmA8o43jHjtQHnlJJvKDC0PPf2IOycS7XQRS3pUlScB2HnXMrl/0xp2XgQds6lXprnjvAg7JxLtwr2gMgXHoSdc6kWZlFLb29bD8LOudTzmrBzziXIH8w551xCpAoPTc4LHoSdc6mX4opw6UFY0i38dA7NnzCz86ulRM45V06FtbQmPDXLMeecywthkp5aGITNbHjmvqT1zGxF9RfJOefKJ8UV4bKnspTUU9K7wPtxf0dJt1d7yZxzLkfVMJ9wjcmlh/ONhLWTvgYwsxlA7+oslHPO5UqAyvhfPsupd4SZfVaizWVN9RTHOefKSaq1D+aKfSZpd8Ak1Qd+C7xXvcVyzrncpfi5XE5B+EzgJsKqoZ8TlutY54TGzjlX0wQUpDgKlxmEzWwRcHwNlMU55yok3x++ZZNL74jNJT0laaGkBZKelLR5TRTOOefKUtYin/leSc6ld8QDwMNAG6At8AgwojoL5Zxz5VEgZd3yWS5BeD0z+4+ZFcXtPqBRdRfMOedyleYgnG3uiJbx5bOSLgEeJMwl0Z+w5LNzziUuPJhLuhQVl60mPI0wf8QxwBnAS8DLwFmEQOycc8lT9tFyuTy0kzQ0PvN6JyPtOknvS3pL0hOSWmQcu1TSbEkfSDogI71PTJsdK69lKjUIm1knM9s8/i25+YM551zekJR1y8EwoE+JtLHA9ma2AzALuDTeqwtwLLBdPOd2SYWSCoHbgAOBLsCAmDernEbMSdo+XnRtW7CZ3ZvLuc45V52qojnCzMZJ6lgi7bmM3UnAUfF1X+BBM/sBmCtpNtA9HpttZnMAJD0Y876b7d5lBmFJg4A9CUF4FCHKTwA8CDvn8kIOD99aScqcnvdOM7uzHLc4BXgovm5HCMrF5sU0gM9KpPco68K51ISPAnYE3jCzkyVtDNyXw3nOOVftpJyC8CIz61ax6+syoAi4vyLnlyWXILzSzH6UVCRpfWABsGl1FMY55yqiukbMSToJOATYx8yKVxqaz09jYPuYRpb0UuXST3hqfCp4F6HHxHTgtRzOc865GlEdI+Yk9QEuAg4rsaDFSOBYSQ0ldQI6A5OBKUBnSZ0kNSA8vBtZ1n1ymTvi7PhyiKTRwPpm9lb53o5zzlUPUfkBGZJGEJ59tZI0DxhE6A3REBgbe1hMMrMzzWympIcJD9yKgHPMbE28zrmESc4KgaFmNrOse2cbrNE12zEzm57j+3MVsOM2HXhpwk1JF6POKFrzY9JFqFNKXUG4IlT55ggzG7CO5Huy5L8GuGYd6aMo52C2bDXhf2Y5ZsDe5bmRc85Vl1zaVfNVtoU+96rJgjjnXEWI2rvkvXPOpUKKY7AHYedcuoUeEOmNwh6EnXOpV5jiRuFcVtaQpBMk/Tnud5DUvazznHOuJhSvMZfW+YRz+f64HegJFHfhWEaYKcg55/JCQRlbPsulOaKHmXWV9AaAmS2Jo0Gccy5xkmp974jVcZ5MA5C0EeA9251zeSPPWxyyyiUI3ww8AbSWdA1hVrXLq7VUzjmXIwH1anNN2MzulzQN2IfwfvuZ2XvVXjLnnMtRra4JS+oArACeykwzs0+rs2DOOZcT1f7BGs8Q2oNFWN6oE/ABYX0l55xLlIDCFFeFc2mO+EXmfpxd7exSsjvnXI2r7TXhnzCz6ZLKXDfJOedqQq2fwEfSBRm7BUBX4PNqK5FzzpVHJVbPyAe51ISbZbwuIrQRP1Y9xXHOufLL96HJ2WQNwnGQRjMzu7CGyuOcc+USmiOSLkXFZVveqJ6ZFUnqVZMFcs658hEF1M6a8GRC+++bkkYCjwDLiw+a2ePVXDbnnCuTVEtrwhkaAV8T1pQr7i9sgAdh51xeqK1twq1jz4h3+F/wLVali6U651xFiXT3jshWiS8EmsatWcbr4s055/JCYYGybmWRNFTSAknvZKS1lDRW0ofx7wYxXZJuljRb0ltxAFvxOQNj/g8lDcyl7Nlqwl+Y2ZW5XMQ555IiqmTi9mHArcC9GWmXAC+Y2WBJl8T9i4EDgc5x6wH8C+ghqSUwCOhGaC2YJmmkmS3JduNsZU9xBd85V2fEhT6zbWUxs3HA4hLJfYHh8fVwoF9G+r0WTAJaSGoDHACMNbPFMfCOBfqUde9sNeF9yiy5c84lLMcJfFpJmpqxf6eZ3VnGORub2Rfx9ZfAxvF1O+CzjHzzYlpp6VmVGoTNrOS3gnPO5aUcfrYvMrNuFb2+mZmkaumQkOLedc45ByAKCrJvFfRVbGYg/l0Q0+cDm2bkax/TSkvPyoOwcy7Vih/MVcNqyyOB4h4OA4EnM9JPjL0kdgOWxmaLMcD+kjaIPSn2j2lZlXsqS+ecyze5PHwr4/wRwJ6EtuN5hF4Og4GHJZ0KfAIcE7OPAg4CZhNWHToZQhOupKuAKTHflbk063oQds6lmyo/Ys7MBpRy6GcdFMzMgHNKuc5QYGh57u1B2DmXalXUTzgxHoSdc6lXW+eOcM65VEhxDPYg7JxLt9Ackd4o7EHYOZdy8uYI55xLUopjsAdh51y6STnNHZG30tyzwyVg6TffMPD4Y+i+83b06Lo9k19/jf8+/ig9u+1Ay6b1eWP6/+ZI+fSTj2mzYVP22G0X9thtF35//tkJljydtttqc3rssiO7d+9K7927A/DWjDfZq/fua9OmTpkMwI3/dz27d+/K7t270r3rDjRfrz6LF9eNKWCk7Fs+85qwK5dL/vh79tnvAIbf/zCrVq1i5YoVNG/egnsfeITfn3/Wz/J37LQF4ydNS6CktcczY16gVatWa/ev+NPFXHrZFex/wIGMGT2KK/50Cc+OfZHfXXAhv7sgLIw+6pmnuO3mm2jZsmVSxa5R8gdzri5YunQpr04cz+13hgFBDRo0oEGDBjRv0SLhktUtklj27bcAfLt0KW3atPlZnkcfepCjjulf00VLRI5TWeYtb45wOfv047m0atWKc844ld49u3H+2aezfPny7Od8MpfePbtx8AF78erE8TVU0tpDEv0O6cMePXdl6N1h+tvB19/A5ZdezDZbbMZll17EX67620/OWbFiBc+PHUPfw49MosiJSHNzRN4GYUkdM9d7yiF/P0ldqrNMFSXpJEm3Jl2OyipaU8SMN9/glNPOYNxrU1lvvSbc+M9/lJp/403a8Pb7cxn32lSuGXw9p538a76NNTiXm+deHMeESVN5/MlnuOuOfzFh/DjuuXMIg6/7J+9/9AmDr/0n55x52k/OefaZp+jRc/c60xQBoTki2//yWd4G4QroB+RlEK4t2rZtT9t27em2aw8ADjv8CGa8+Uap+Rs2bEjLDTcEYKedd6HT5pvz0exZNVLW2qJtu7Aww0atW3PoYf2YNnUKD9x3L4f1OwKAw488mmlTJ//knEcfeYijjzm2xsuaFCEKlX3LZ/kehAsl3SVppqTnJDWWdJqkKZJmSHpM0nqSdgcOA66T9KakLeI2WtI0SeMlbQMg6WhJ78Tzx8W0kyQ9KenluErqoOICSDpB0uR43TskFcb0/SW9Jmm6pEckNY3pu0p6NV5/sqRm8VJtY3k+lHRtjX6KVWTjTTahXfv2fDjrAwDGvfwiW2+zban5Fy1cyJo1awD4eO4c5syeTceOm9dIWWuD5cuXs2zZsrWvX3hhLF22245N2rRlwrhXAHjlpRfZYsvOa89ZunQpE8eP4+BD+yZS5kSU0RSR5zE47x/MdQYGmNlpkh4GjgQeN7O7ACRdDZxqZrdIGgk8bWaPxmMvAGea2YeSegC3A3sDfwYOMLP5kjKfKHUHtifMDzpF0jPAcqA/0MvMVku6HThe0ijgcmBfM1su6WLgAkmDgYeA/mY2RdL6wMp4/Z2AnYEfgA8k3WJmmetRpcK119/E6aecyKpVq+jYqRO3DbmHp0f+l4v/8FsWLVpI/yMO4xc77MhjI5/l1Ynj+fvVf6FevfoUFBTwz5tvY4M69BO5shZ89RXH9Q/tukVFRRzTfwD77d+HJk2acvGFv6eoqIhGjRpx821D1p7z1JNPsPe++9GkSZOkil3j0v5gTmFqzPwjqSNh5dLOcf9ioD4wHrgaaAE0BcaY2ZmShhGDcKyVLgQ+yLhkQzPbVtIQYAvgYUJA/1rSScDeZnZivNeVhJVXi4A/8b9lTRoDI4CphCWy58X0BsBrwI3AEDPrVeK9nEQI5KfF/WeBa8xsQol8pwOnA7TftMMub78/p9yfm6uYeoXp/T9xGvXevTvTp02tkg9921/sbP9+4qWseXp23mBaZdaYq075XhP+IeP1GkIQHAb0M7MZMbjtuY7zCoBvzGynkgdiwO4BHAxMk7RL8aGSWQlfssPN7NLMA5IOJXxBDCiR/otyvJefffZx9dc7AXbu2i0/vx2dy0cp/g7N9zbhdWkGfCGpPnB8RvqyeAwz+xaYK+logLgW1I7x9RZm9rqZ/ZlQWy5emG8/SS0lNSY85JsIvAAcJal1PLelpM2ASUAvSVvG9CaStiLUvNtI2jWmN5OU7190zqVegZR1y2dpDMJXAK8TguT7GekPAn+U9IakLQgB+lRJM4CZQPGTiuskvR27v70KzIjpk4HHgLeAx8xsqpm9S2j7fU7SW8BYoI2ZLQROAkbE9NeAbcxsFaEN+ZZ437FAo2r5FJxza6mMLZ/lbS3NzD4mPCgr3r8+4/C/1pF/Ij/votZnHfmOKJkWFwmcZ2b91pH/IcLDtpLpLwK7riN9CrBbieRhcSvOc0jJ85xzFSMqv9BnkvI2CDvnXE5S0A0tGw/CgJkNI6Om6pxLlxTH4FS2CTvnXAYhZd9yuor0+zgw7B1JIyQ1ktRJ0uuSZkt6SFKDmLdh3J8dj3esaOk9CDvnUq+yI+YktQPOB7qZ2fZAIXAs8A/gBjPbElgCnBpPORVYEtNviPkqxIOwcy7VwoO5Khm2XA9oHLuVrgd8QRhl+2g8PpzQfRVCb6vh8fWjwD6q4NNBD8LOudTLYRa1VpKmZmynZ55vZvOB64FPCcF3KTCNMOirKGabB7SLr9sBn8Vzi2L+DStSdn8w55xLvRzqoIuyDVuWtAGhdtsJ+AZ4hHV0ca0OXhN2zqVb1cyiti8w18wWmtlq4HGgF9AiY9Rre2B+fD2fONo2Hm8OfF2R4nsQds6lXhVM6v4psJvC1LgC9gHeBV4Cjop5BgJPxtcj4z7x+ItWwdnQvDnCOZdqAgoq2VHYzF6X9CgwnTB74huEybSeAR6M0+a+AdwTT7kH+I+k2YQZFys8i74HYedc+lXBaA0zGwQMKpE8hzDXeMm83wNHV/6uHoSdc7VAvq8jl40HYedc6lW2OSJJHuLBPU8AABDXSURBVISdc+nnQdg555IR5gxObxT2IOycSzd5c4RzziXLg7BzziUl/9eRy8aDsHMu1dKwjlw2HoSdc+mX4ijsQdg5l3reHOGccwlKbwj2IOycSzv5kvfOOZeY4uWN0sqDsHMu9VIcgz0IO+fSzx/MOedcktIbgz0IO+fSTT53hHPOJctnUXPOuSSlNwZ7EHbOpZ83RzjnXGJyXtY+L3kQds6lWtoHaxQkXQDnnKssKfuW2zXUQtKjkt6X9J6knpJaShor6cP4d4OYV5JuljRb0luSula07B6EnXOppzL+l6ObgNFmtg2wI/AecAnwgpl1Bl6I+wAHAp3jdjrwr4qW3YOwcy7VivsJZ9vKvoaaA72BewDMbJWZfQP0BYbHbMOBfvF1X+BeCyYBLSS1qUj5PQg759JPZWzQStLUjO30ElfoBCwE/i3pDUl3S2oCbGxmX8Q8XwIbx9ftgM8yzp8X08rNH8w551IvhyaHRWbWLcvxekBX4Dwze13STfyv6QEAMzNJVrmS/pzXhJ1zqVfZ5ghCTXaemb0e9x8lBOWvipsZ4t8F8fh8YNOM89vHtPKXvSInOedcXim7OSIrM/sS+EzS1jFpH+BdYCQwMKYNBJ6Mr0cCJ8ZeErsBSzOaLcrFmyOcc6kmqmwqy/OA+yU1AOYAJxMqqg9LOhX4BDgm5h0FHATMBlbEvBUisypv4nBVQNJCwj962rQCFiVdiDokrZ/3Zma2UVVcSNJowueQzSIz61MV96tqHoRdlZI0tYwHIK4K+eedft4m7JxzCfIg7JxzCfIg7KranUkXoI7xzzvlvE3YOecS5DVh55xLkAdh55xLkAdh55xLkAdh55xLkAdhl7ckFca/m0hqnHR5ahtJBSX2U7xIUHp5EHZ5R1InSb3MbI2kQ4HxwM2Srkm6bLWBpPUAzOxHSbtIOlJSI/OuUonwLmou70gaANxGWDZmb8LMVd8QJlj52sx+m2DxUk1SC2AQ8F9gFWG1iM+BlcAVwJtmVpRcCeserwm7vGNmI4BzgRuAxmY2BpgGXA20lHRHkuVLuSbAF0B/4E9AXzPbE3gDOB/YSZLPrliDPAi7vFHcJimps5k9APwO2FvSnrF2NgsYTFjPq0uCRU0lSTKz+cB9hEUstwR6AJjZn4BPCatJVHjlYFd+HoRd3ojLxxwG3CVpJzN7DPgLcLekX5nZj4TgcYqZvZtkWdMmBmCTtC9hFYgHgbuAXpIOBDCzy4GPgB+SK2nd423CLm/E2u1/gNPNbFpG+onAdcAAM3sxqfKlXQy2NwC/NbMxkjYlrBq8HTDKzJ5KtIB1lLf9uHzSHPi0OABLqm9mq83sXklFgNcYKij2iPgdcJaZvRRrxp9JegpoCBwuaRJh8nP/nGuQB2GXmIyfyAWxqeFz4HtJ2wIfmtlqSb2Bnc3spsxzkix3ShUCDQifMYTA+z2wBPg3sL6ZLUyobHWatwm7RGQE4EOAayT9k9BlagFwDnCmpL6EADGz+DwPwLnJeMi5maSGZrYMGAMMlrSBmX0fv+BGA5jZx8mVtm7zmrBLRAzAewFXAscCzxKaGy4CTgG2AHYFzjWz5xMraErFz/cg4DLgFUmtgZuB9YGJkv5NWD34T2a2OMGi1nn+YM4lRtJfgAmE4Hs1cJyZzc043tjMViZUvFSLDzkfAA4j/LLoChxpZt9K6k/41bHIzMZ7E0+yvCbskvQFYVRcG+AEM5sr6WSgg5n9Fe8qVW4ZAbURIQhvCewJHB8DcDfgcTNbXXyOB+BkeZuwqxEZbZS7SdpH0i7Ac8AOwN3AJzHtAuB1CHMbJFXetMmYfKe4YvUpcBxhWHIfM5sd+whfCmyQQBFdKbw5wtUYSQcQ+qleB9wDdAM6AKcSar0bA9eZ2Uj/iZy7jIec+wHHANOB2cBGhOaIl4GPCaMNB5nZkwkV1a2DN0e4ahdraS2B3wL9gE0JPR6+NLPpkl4idKFqZmafeAAunxiA9wZuJPQFvowwF8T1hC5pvyPUjC83s6f9880vXhN2NUbSn4HvgKOAk8xslqTjgLfN7O1kS5decd7lc4HJQBFwB3CYmc2TtJ6ZrcjI6wE4z3hN2FWLjJ/IGwPLYiBoSailbRQfEnUF/giclmRZ0y7Ou7yEMBfED8BBZvZlnIu5naS7i6en9ACcfzwIu2qRMRDjWuANSUVmNlDSFsBwSR8Tntr/xcymJljU1Mn4gtsZ6ER4kPkWMAX4OAbg7oQ24D/4/MD5zZsjXLWQtB2hLXIEIUAMAdYzs4PiSLgC4Aszm+Q/kcsvPoS7nTCrnAGvEPr+bg70AlYD15rZyMQK6XLiQdhVOUkbAjOAtwkDBFbE9KeBR8xseJLlS7s4t8ZNwMVm9kb8UtsFmGJmT0naDFhpZgv8Cy7/eT9hVyUy+gF3NLOvgTOBzsB+GdleB5omULzUy+gHDLAXYfrJ3gCxy9kK4MS4/4mZLYivPQDnOW8TdpWW0UZ5GPAHSefGrlCNgBsl7QpMJcxVcE6ihU2hjM93H+BrwpzLAN0lHRknv38F6ClpfTP7NrHCunLzIOwqLQaInsBfCfM/vCepuZk9KukL4CFC3+BD4zH/iVwOGV9wfwf+aGZvSnqM0BZ8RTy2BfAPD8Dp40HYVZVWhNpu2zgy7iBJawjdz04nDCTYjPAgyZWDpFbAxcDhsW/1DsCGwOOEQS69gId8ZYx08iDsKiTjJ3Irwk/kWcBXhOkSryVMUbkn0NnMRklqCfxd0gQz+y6pcqdUIWEC9j6SLiG0q/cGLiTMDbEK2EvSh2Y2Orliuorw3hGuwuLP4JOBeYQ+qk8Dq81sWRyIcR9wmplNjPmbxcnFXRYZX3A7EoLvQkLvh0OBZyysD3cMsLeZnSmpA7APMNrMvkiu5K4iPAi7ColTIt4FHAj8CxBh1i4DdiSsiHFR7DJVYGY/eltw7hQW5bwWGEaY6L6nmc2Jx/YCbiUMxBgd0wrNbE1CxXWV4M0RLifrCKAbE6ag7EKYD3iAma2ItbKFwNFm9k4870fw7lK5iF3R2hGGdx9GmGnuC+C7eKwNcDmhj/Do4n8XD8Dp5TVhV6bY1ewgM3s8/kTeEviIMGBgg3hsnqTDgUOA8zInjXHZSaoP1DOzlfGzbkCYcW4OYWKegfGBXF/CHMyNzWyx/7KoHbwm7HKxGugg6YP4+jDCw7i3gaVAF0kdCV3ULvMAnDtJ9YC9geVxpNsvCc0P+xOWJNrAzFZJ6gFcAnxgZu+D/7KoLbwm7HISJ4t5ElhoZrtkpO1BGMG1GrjPfEL2cotzAV8DbAJcaGaPSdqEsDrya4SeJ78mTHbkE7LXMh6EXakyg2n8ydyeMBy5B6HNd6GkTc3ss+J5az0A567E5zuM8PneALxhZp9LakZY7mkR8J6Zveifb+3jQditU0Y3qYOBnsAaMxskqQD4P8IDo78RhiGfYWbzEixu6mR8vu2B+UBDQlPEKcAoM7tP0kZAfTP7PMmyuurlE/i4dYoB4iBCoH0MGCjpUaC5mf2OMFfBxcDtHoDLL+ML7hHCZ3wuMI4wL8SBkq4D3icM93a1mNeE3TpJakzoB3w90Bb4E2FpooaE4bPfSGoR//pP5HKS9EvCfMCHE5ocdgPGE77YugA7A5+Y2QuJFdLVCA/Cbq3iQRUZ+82B1oTa2V6xC9U3wDOEblO+YkM5ZA6oiN3NZgEdgauBQYQ5Nj4F/mpmCzPO8y+5Wsy7qLniWm+Rma2W1IswIGCumU2T1IIwWGBTSU0Ik8YM9QCcu+Lh2hbWgtuLEHhnEj7XM4BTzGyGpKOAFoQvvrVB2ANw7eZBuI5TWAXjj8DIGIyHE9op75Z0QpwXeDZwFWG2rlPMbILXznIjaT3gGUk3E1YbuQ14l/AQbibhoed8SQ2AbYFTzWxmUuV1Nc+bI+q42PXsWsJMXQXAE2b2Qhz9Nhw4xMzGSepCWCPOF+Usp/hZXgIsBi6Jtd7jCDXitoS+1h8BI8zskcQK6hLhQbgOy5hYpz5hPoK9CD0h7oztv0cAjwL9zBeMrBSFhTkfBv5mZtfFkXL9ga0JM6UN8aHIdZN3UavDYgAuMLPVhIdDYwnzQuwqqYGZPQ4cA/yQZDlrAzMbS5j28yRJA2Kb+oPAB4RfH4tjPg/AdYzXhOuoEqO16plZUWyX/DPQDBgJjDezVSXzu4qLfa+vAm42X3Xa4TXhOidOhwgZ//YxANePAfdKwkoNR5KxMrIH4KphZqMIEx1dLKltHIHo6jCvCdchGUNl9yVMCDMH+MjM7ovH68duag2AjmY2K8ny1maSNsrsC+zqLv8WrkNiAP4VcAvwMmHOgnMk/SEeXx3biFd5AK5eHoBdMe8nXPe0B+4ys38DSHoduE7SaDObmTlizjlX/bwmXMtltAEXawyckLE/k7BKsrdLOZcAD8K1XHEThKSzJXUxs7uB1yW9oLAMfTdgB6B+siV1rm7yB3O1VMZDuB7AUMJQ2RXABOB+wii5jsCGwN99MIZzyfAgXItJ6k7ocnaRmb0laQBhysS3zOye2D2qhY/Uci453hxRu7UA9gX2i/uPABOB3ST9FhCwBLwfsHNJ8d4RtZiZPRfnf/i7pM/NbERcHaMQmFE8t61zLjkehGs5C6sfFwFXxfkghgMjki6Xcy7wNuE6QtJhwGBC88SX3h/YufzgQbgO8aGyzuUfD8LOOZcg7x3hnHMJ8iDsnHMJ8iDsnHMJ8iDsnHMJ8iDsEiFpjaQ3Jb0j6ZG4NHxFrzVM0lHx9d1xZejS8u4pafcK3ONjSa1yTS+R57ty3usvki4sbxldOnkQdklZaWY7mdn2hOWUzsw8GFcjLjcz+42ZvZsly55AuYOwc9XFg7DLB+OBLWMtdbykkcC7kgolXSdpiqS3JJ0BYYY4SbdK+kDS80Dr4gtJellSt/i6j6TpkmbEqTs7EoL972MtfA9JG0l6LN5jiqRe8dwNJT0naaakuwnzbGQl6b+SpsVzTi9x7IaY/oKkjWLaFpJGx3PGS9qmKj5Mly4+bNklKtZ4DwRGx6SuwPZmNjcGsqVmtqukhsBESc8BOwNbA12AjQnTdA4tcd2NgLuA3vFaLeNscUOA78zs+pjvAeAGM5sgqQMwBtgWGARMMLMrJR0MnJrD2zkl3qMxMEXSY2b2NdAEmGpmv5f053jtc4E7gTPN7MM45ejtwN4V+BhdinkQdklpLOnN+Ho8cA+hmWCymc2N6fsDOxS39wLNgc5Ab2BEnIDoc0kvruP6uwHjiq9lZotLKce+QJeMBUjWl9Q03uOIeO4zkpbk8J7Ol3R4fL1pLOvXwI/AQzH9PuDxeI/dgUcy7t0wh3u4WsaDsEvKSjPbKTMhBqPlmUnAeWY2pkS+g6qwHAXAbmb2/TrKkjNJexICek8zWyHpZaBRKdkt3vebkp+Bq3u8TdjlszHAWZLqA0jaSlITYBzQP7YZtwH2Wse5k4DekjrFc1vG9GVAs4x8zwHnFe9IKg6K44DjYtqBwAZllLU5sCQG4G0INfFiBUBxbf44QjPHt8BcSUfHe0jSjmXcw9VCHoRdPrub0N47XdI7wB2EX29PAB/GY/cCr5U8MU5UdDrhp/8M/tcc8BRwePGDOeB8oFt88Pcu/+ul8VdCEJ9JaJb4tIyyjgbqSXqPMFvdpIxjy4Hu8T3sTVjtBOB44NRYvplA3xw+E1fL+AQ+zjmXIK8JO+dcgjwIO+dcgjwIO+dcgjwIO+dcgjwIO+dcgjwIO+dcgjwIO+dcgv4fr+uqJLegNKUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}