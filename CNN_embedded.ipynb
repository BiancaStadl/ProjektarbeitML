{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN embedded.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNqWkr9jfw+43mLgkbQhj0U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BiancaStadl/ProjektarbeitML/blob/main/CNN_embedded.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXDOlIBymF0V"
      },
      "source": [
        "GloVe embeddings taken from:\n",
        "\n",
        "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. [pdf] [bib]\n",
        "\n",
        "hatespeechdata taken from (https://hatespeechdata.com/): Wiegand, M., Siegel, M. and Ruppenhofer, J., 2018. Overview of the GermEval 2018 Shared Task on the Identification of Offensive Language. In: Proceedings of GermEval 2018, 14th Conference on Natural Language Processing (KONVENS 2018). Vienna, Austria: Research Gate. available on: https://github.com/uds-lsv/GermEval-2018-Data (last checked: 09.05.2021)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlBmABDxfqII"
      },
      "source": [
        "wiki detox..https://colab.research.google.com/github/tensorflow/fairness-indicators/blob/master/g3doc/tutorials/Fairness_Indicators_TFCO_Wiki_Case_Study.ipynb#scrollTo=y6T5tlXcdW7J "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3xfitNdliBI"
      },
      "source": [
        "#import matplotlib.pyplot as plt -> für evtl Visualisierungen\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import string\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from keras import losses \n",
        "from keras import optimizers \n",
        "from keras import metrics \n",
        "\n",
        "#!pip install Tokenizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "#!pip install pad_sequences\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import preprocessing\n",
        "#from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTWJQ1iga_vS"
      },
      "source": [
        "Maximale Satzlänge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bq08Me5la_Cc"
      },
      "source": [
        "\n",
        "max_length = 60"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVYBMvYSotTH"
      },
      "source": [
        "url = \"https://github.com/uds-lsv/GermEval-2018-Data/archive/master.zip\"\n",
        "\n",
        "dataset = tf.keras.utils.get_file(\"GermEval-2018-Data-master.zip\", url, \n",
        "                                   extract=True, cache_dir='.',\n",
        "                                    cache_subdir='')\n",
        "\n",
        "dataset_dir = os.path.join(os.path.dirname(dataset), 'GermEval-2018-Data-master')\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cS14OUtfo34V"
      },
      "source": [
        "#os.listdir(dataset_dir)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2X429K6hpOVm"
      },
      "source": [
        "training_file = os.path.join(dataset_dir, 'germeval2018.training.txt')\n",
        "\n",
        "testing_file = os.path.join(dataset_dir, 'germeval2018.test.txt')\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uq8fG3LNtn_m"
      },
      "source": [
        "###Aufbereitung\n",
        "txt-Dateien lesen, und dabei jede Zeile splitten und teilen\n",
        "Twitter-Handler entfernen?\n",
        "Labels von Sätzen trennen, Labels in eigenen Array packen.\n",
        "\n",
        "####Ressourcen\n",
        "* https://www.w3schools.com/python/gloss_python_if_statement.asp\n",
        "* https://stackabuse.com/using-regex-for-text-manipulation-in-python/\n",
        "* https://www.tutorialspoint.com/python/string_splitlines.htm \n",
        "* https://note.nkmk.me/en/python-split-rsplit-splitlines-re/ \n",
        "* https://www.w3schools.com/python/python_regex.asp \n",
        "\n",
        "gäbe bei keras tf.keras.preprocessing.text_dataset_from_directory, aber dafür müssten die Daten auf bestimmte Weise in Verzeichnis organisiert sein, hier nicht der Fall.\n",
        "\n",
        "\n",
        "Einteilung der Daten: Testdaten\n",
        "Trainingsdaten -> noch ca 500 für Validierungsdaten\n",
        "\n",
        "labels -> \"other\", also nicht-negative Aussagen bekommen \"0\", negative Aussagen bekommen \"1\"\n",
        "\n",
        " Regex für Emojis  ->\n",
        "\n",
        "(\\u00a9|\\u00ae|[\\u2000-\\u3300]|\\ud83c[\\ud000-\\udfff]|\\ud83d[\\ud000-\\udfff]|\\ud83e[\\ud000-\\udfff])\n",
        "\n",
        "genommen von https://www.regextester.com/106421 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Py_cwD4eZkXo"
      },
      "source": [
        "def remove_clutter(string):\n",
        "   string = re.sub(\"@[^\\s]+\",\" \",string)\n",
        "   string = re.sub(\"#[^\\s]+\",\" \", string)\n",
        "   string = re.sub(\"\\u00a9\",\" \", string)\n",
        "   string = re.sub(\"\\u00ae\",\" \", string)\n",
        "   string = re.sub(\"[\\u2000-\\u3300]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83c[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83d[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83e[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"😜\", \" \",string)\n",
        "   string = re.sub(\"🍫\", \" \",string)\n",
        "   string = re.sub(\"😁\", \" \",string)\n",
        "   string = re.sub(\"🐖\", \" \",string)\n",
        "   string = re.sub(\"😡\", \" \",string)\n",
        "   string = re.sub(\"😇\", \" \",string)\n",
        "   string = re.sub(\"😬\", \" \",string)\n",
        "   string = re.sub(\"😃\", \" \",string)\n",
        "   string = re.sub(\"😂\", \" \",string)\n",
        "   string = re.sub(\"💙\", \" \",string)  \n",
        "   string = re.sub(\"😛\", \" \",string)\n",
        "   string = re.sub(\"🙏\", \" \",string)\n",
        "   string = re.sub(\"👍\", \" \",string)\n",
        "   string = re.sub(\"🖕\", \" \",string)\n",
        "   string = re.sub(\"😉\", \" \",string)\n",
        "   string = re.sub(\"💩\", \" \",string)\n",
        "   string = re.sub(\"🤢\", \" \",string)\n",
        "   string = re.sub(\"👏\", \" \",string)\n",
        "   string = re.sub(\"😨\", \" \",string)\n",
        "   string = re.sub(\"🤣\", \" \",string)\n",
        "   string = re.sub(\"🤡\", \" \",string)\n",
        "   string = re.sub(\"😈\", \" \",string)\n",
        "   string = re.sub(\"💃🏽\", \" \",string)\n",
        "   string = re.sub(\"👹\", \" \",string)\n",
        "   string = re.sub(\"🤘\", \" \",string)\n",
        "   string = re.sub(\"😱\", \" \",string)\n",
        "   string = re.sub(\"🤔\", \" \",string) \n",
        "   string = re.sub(\"🌈\", \" \",string) \n",
        "   string = re.sub(\"💕\", \" \",string) \n",
        "   string = re.sub(\"👩‍❤️‍👩\", \" \",string) \n",
        "   string = re.sub(\"😍\", \" \",string) \n",
        "   string = re.sub(\"👆\", \" \",string) \n",
        "   string = re.sub(\"😖\", \" \",string) \n",
        "   string = re.sub(\"👇\", \" \",string) \n",
        "   string = re.sub(\"🔥\", \" \",string) \n",
        "   string = re.sub(\"😘\", \" \",string) \n",
        "   string = re.sub(\"🎉\", \" \",string) \n",
        "   string = re.sub(\"🤬\", \" \",string) \n",
        "   string = re.sub(\"👊\", \" \",string)\n",
        "   string = re.sub(\"🇩🇪\", \" \",string)  \n",
        "   string = re.sub(\"💔\", \" \",string)\n",
        "   string = re.sub(\"🙈\", \" \",string)\n",
        "   string = re.sub(\"🤯\", \" \",string)\n",
        "   string = re.sub(\"🐟\", \" \",string)\n",
        "   string = re.sub(\"🛶\", \" \",string)\n",
        "   string = re.sub(\"😊\", \" \",string)\n",
        "   string = re.sub(\"😓\", \" \",string)\n",
        "   string = re.sub(\"😳\", \" \",string)\n",
        "   string = re.sub(\"🚀\", \" \",string)\n",
        "   string = re.sub(\"👎\", \" \",string)\n",
        "   string = re.sub(\"😎\", \" \",string)\n",
        "   string = re.sub(\"🐸\", \" \",string)\n",
        "   string = re.sub(\"📈\", \" \",string)\n",
        "   string = re.sub(\"🙂\", \" \",string)\n",
        "   string = re.sub(\"😅\", \" \",string)\n",
        "   string = re.sub(\"😆\", \" \",string)\n",
        "   string = re.sub(\"🙎🏿\", \" \",string)\n",
        "   string = re.sub(\"👎🏽\", \" \",string)\n",
        "   string = re.sub(\"🤭\", \" \",string)\n",
        "   string = re.sub(\"😤\", \" \",string)\n",
        "   string = re.sub(\"😚\", \" \",string)\n",
        "   string = re.sub(\"😊\", \" \",string)\n",
        "   string = re.sub(\"😲\", \" \",string)\n",
        "   string = re.sub(\"🤮\", \" \",string)\n",
        "   string = re.sub(\"🙄\", \" \",string)\n",
        "   string = re.sub(\"🤑\", \" \",string)\n",
        "   string = re.sub(\"🎅\", \" \",string)\n",
        "   string = re.sub(\"👋\", \" \",string)\n",
        "   string = re.sub(\"💪\", \" \",string)\n",
        "   string = re.sub(\"😄\", \" \",string)\n",
        "   string = re.sub(\"🧐\", \" \",string)\n",
        "   string = re.sub(\"😠\", \" \",string)\n",
        "   string = re.sub(\"🎈\", \" \",string)\n",
        "   string = re.sub(\"🚂\", \" \",string)\n",
        "   string = re.sub(\"😊\", \" \",string)\n",
        "   string = re.sub(\"🚇\", \" \",string)\n",
        "   string = re.sub(\"🚊\", \" \",string)\n",
        "   string = re.sub(\"🤷\", \" \",string)\n",
        "   string = re.sub(\"😥\", \" \",string)\n",
        "   string = re.sub(\"🙃\", \" \",string)\n",
        "   string = re.sub(\"🔩\", \" \",string)\n",
        "   string = re.sub(\"🔧\", \" \",string)\n",
        "   string = re.sub(\"🔨\", \" \",string)\n",
        "   string = re.sub(\"🛠\", \" \",string)\n",
        "   string = re.sub(\"💓\", \" \",string)\n",
        "   string = re.sub(\"💡\", \" \",string)\n",
        "   string = re.sub(\"🍸\", \" \",string)\n",
        "   string = re.sub(\"🥃\", \" \",string)\n",
        "   string = re.sub(\"🥂\", \" \",string)\n",
        "   string = re.sub(\"😷\", \" \",string)\n",
        "   string = re.sub(\"🤐\", \" \",string)\n",
        "   string = re.sub(\"🌎\", \" \",string)\n",
        "   string = re.sub(\"👑\", \" \",string)\n",
        "   string = re.sub(\"🤛\", \" \",string)\n",
        "   string = re.sub(\"😀\", \" \",string)\n",
        "   string = re.sub(\"🛤\", \" \",string)\n",
        "   string = re.sub(\"🎄\", \" \",string)\n",
        "   string = re.sub(\"📴\", \" \",string)\n",
        "   string = re.sub(\"🌭\", \" \",string)\n",
        "   string = re.sub(\"🤕\", \" \",string)\n",
        "   string = re.sub(\"😭\", \" \",string)\n",
        "   string = re.sub(\"🍾\", \" \",string)\n",
        "   string = re.sub(\"🍞\", \" \",string)\n",
        "   string = re.sub(\"🤦\", \" \",string)\n",
        "   string = re.sub(\"🤯\", \" \",string)\n",
        "   string = re.sub(\"🕯️\", \" \",string)\n",
        "\n",
        "   string = re.sub(\"OTHER|OFFENSE|ABUSE|INSULT\",\" \",string)\n",
        "   return string"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5asMgo4LtnRg"
      },
      "source": [
        "statementsForTraining = []\n",
        "sentimentsForTraining = []\n",
        "\n",
        "\n",
        "fileToRead = open(training_file, 'r')\n",
        "\n",
        "while True:\n",
        "  #next line in file\n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  findSentiment = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "\n",
        "\n",
        "  statementsForTraining.append(line)\n",
        "   #sentimentsForTraining.append(findSentiment.group(0))\n",
        "\n",
        "  if findSentiment.group(0) == \"OTHER\":  \n",
        "    sentimentsForTraining.append(0)\n",
        "  else:\n",
        "    sentimentsForTraining.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        " #print(\"{}: {}\".format(count,line.strip()))\n",
        "  \n",
        " # print(sentiment.group(0))\n",
        " \n",
        "fileToRead.close()\n",
        "\n",
        "training_sentences = statementsForTraining\n",
        "training_labels = sentimentsForTraining\n",
        "\n",
        "#print(training_sentences[9])\n",
        "#print(training_labels[9])\n",
        "\n",
        "#print(len(training_sentences))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsqZPENb98gD"
      },
      "source": [
        "##do the same with testdata\n",
        "statementsForTesting = []\n",
        "sentimentsForTesting = []\n",
        "\n",
        "fileToRead = open(testing_file, 'r')\n",
        "\n",
        "while True:\n",
        "  #next line in file\n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  sent = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "\n",
        "    \n",
        "\n",
        "  statementsForTesting.append(line)\n",
        "  #print(len(line))\n",
        "  #sentimentsForTesting.append(sent.group(0))\n",
        "\n",
        "  if sent.group(0) == \"OTHER\": \n",
        "    sentimentsForTesting.append(0)\n",
        "  else:\n",
        "    sentimentsForTesting.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        "\n",
        "fileToRead.close()\n",
        "\n",
        "\n",
        "testing_sentences = statementsForTesting\n",
        "testing_labels = sentimentsForTesting\n",
        "#print(len(testing_sentences))\n",
        "#print(testing_sentences)   \n",
        "#print(testing_labels)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRUvDLD5bMbO"
      },
      "source": [
        "Padding -> im Prinzip die Sätze alle auf die gleiche Länge bringen (in Theorieteil näher drauf eingehen) -> maxlen-Paramter ist für pad_sequences vorhanden, wenn nicht gesetzt -> alles wird auf die Länge des längsten Satzes aufgefüllt -> print(padded(shape)) gibt aus, wie viele Datensätze padded wurden und gibt an, wie viele Tokens der längste Datensatz hat\n",
        "print(padded[x]) gibt einen Satz aus (bereits tokenisiert)\n",
        "\n",
        "Padding -> sowohl für Trainigs- als auch für Testdaten\n",
        "\n",
        "Und: Daten als numpy-Arrays speichern (notwendig für tensorflow).\n",
        "\n",
        " -> Tokenizer https://towardsdatascience.com/text-classification-in-keras-part-2-how-to-use-the-keras-tokenizer-word-representations-fd571674df23 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3hFi7waTv5m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04a68356-601f-4840-dd0f-15cd2497daae"
      },
      "source": [
        "tokenizer = Tokenizer(oov_token=\"OOV\")\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "\n",
        "#creating a word index - nur die Trainigsdaten\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "validation_size = 500\n",
        "\n",
        "\n",
        "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "padded_training = pad_sequences(training_sequences, maxlen=max_length, padding='post')\n",
        "print(len(padded_training))\n",
        "\n",
        "validation_sequences = padded_training[0:validation_size]\n",
        "validation_labels = training_labels[0:validation_size]\n",
        "\n",
        "padded_training = padded_training[validation_size:]\n",
        "training_labels = training_labels[validation_size:]\n",
        "\n",
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
        "padded_testing = pad_sequences(testing_sequences, maxlen=max_length,  padding='post')\n",
        "\n",
        "#print(validation_sequences[499])\n",
        "print(padded_training[0])\n",
        "#print(len(validation_labels))\n",
        "#print(len(training_labels))\n",
        "\n",
        "\n",
        "nppadded_training = np.array(padded_training)\n",
        "nptraining_labels = np.array(training_labels)\n",
        "\n",
        "nppadded_validation = np.array(validation_sequences)\n",
        "npvalidation_labels = np.array(validation_labels)\n",
        "\n",
        "nppadded_testing = np.array(padded_testing)\n",
        "nptesting_labels = np.array(testing_labels)\n",
        "\n",
        "\n",
        "print(len(nppadded_training))\n",
        "print(len(nptraining_labels))\n",
        "print(len(word_index))\n",
        "\n",
        "#print(statementsForTraining[2])\n",
        "#print(nppadded_training[4])\n",
        "#print(nppadded_training.shape)\n",
        "#print(nptraining_labels[4])\n",
        "#print(nppadded_testing.shape)\n",
        "#print(word_index) \n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5009\n",
            "[  12 3982   11   41 6706 1040    4    5  202   39    3 2922   49 1360\n",
            "  810  495 3983    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0]\n",
            "4509\n",
            "4509\n",
            "15059\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tL3owrc8THkT"
      },
      "source": [
        "\n",
        "Dann: Embedding mit entweder word2vec oder glove\n",
        "Word2vec-Daten sind hier: http://vectors.nlpl.eu/repository/#\n",
        "Glove -> https://nlp.stanford.edu/projects/glove/ Da mal den Twitter-Vector runtergeladen\n",
        "Wenn Daten in GoogleDrive sind (wäre auch via url möglich..), muss Drive gemounted werden ( https://buomsoo-kim.github.io/colab/2020/05/09/Colab-mounting-google-drive.md/ ) aber auch hier https://enjoymachinelearning.com/posts/colab-with-google-drive/\n",
        "\n",
        "Die Word2vec vectors: http://vectors.nlpl.eu/repository/# \n",
        "\n",
        "glove-zitat:\n",
        "Citing GloVe\n",
        "\n",
        "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. [pdf] [bib]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zuO7T9ZTG57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cc12616-82f9-4fd2-8cd2-8c61ba73c59b"
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount(\"/content/drive\")\n",
        "os.listdir(\"/content/drive/MyDrive/Colab Notebooks\")\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['germeval_training.txt',\n",
              " 'glove.twitter.27B.50d.txt',\n",
              " 'glove.twitter.27B.200d.txt',\n",
              " 'glove.6B.200d.txt',\n",
              " 'glove.840B.300d.txt',\n",
              " 'tensorboard.gdoc',\n",
              " 'keras.gdoc',\n",
              " 'Vectorization CNN embedded_limited_vocab.ipynb',\n",
              " 'glove.42B.300d.txt',\n",
              " 'Embedding Glove Vergleich.ipynb',\n",
              " 'CNN embedded_limited_vocab.ipynb',\n",
              " 'LSTM_limited_vocab.ipynb',\n",
              " 'LSTM.ipynb',\n",
              " 'CNN embedded.ipynb']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7ToKO-sZLHK"
      },
      "source": [
        "\n",
        "Keras-Doc : https://keras.io/examples/nlp/pretrained_word_embeddings/#load-pretrained-word-embeddings \n",
        "embedding mit initializers.. weights müsste auch funktionieren\n",
        "\n",
        "Diese erstellte Matrix mit Embedding dann in die Embedding-Schicht einbinden,  Trainable auf False, weil sich die Werte nicht durch Training anpassen sollen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AShIVfC7ZQAH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4469ba3d-92a9-416c-91a2-a1221f0eb580"
      },
      "source": [
        "#Größe Vokabel -> wordindex + 2 (weil padding + OOV) \n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "vocabulary_size = len(word_index)+2\n",
        "\n",
        "# dann erstell ich ein Wörterbuch mit Namen \"embedding_vector\", dort sind dann\n",
        "#die keys drinnen, die in glove-Datei drinnen sind mit dem entsprechenden Key\n",
        "\n",
        "embedding_index_glove = {}\n",
        "f = open('/content/drive/MyDrive/Colab Notebooks/glove.twitter.27B.200d.txt')\n",
        "for line in f:\n",
        "  value = line.split()\n",
        "  word = value[0]\n",
        "  coef = np.asarray(value[1:],dtype='float32')\n",
        "  embedding_index_glove[word] = coef\n",
        "\n",
        "print(\"%d gefunden: \"% len(embedding_index_glove))\n",
        "\n",
        "#Dann noch eine Embedding-Matrix erstellen\n",
        "#zweiter Wert = Embedding-Dimension der Datei, in dem Fall 200\n",
        "\n",
        "glove_matrix = np.zeros((vocabulary_size,200))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    embedding_value = embedding_index_glove.get(word)\n",
        "    if embedding_value is not None:\n",
        "      glove_matrix[index] = embedding_value\n",
        "      hits+=1\n",
        "    else:\n",
        "      misses+=1\n",
        "\n",
        "print(\"hits %d and %d misses\"%(hits,misses))\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1193514 gefunden: \n",
            "hits 6747 and 8312 misses\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZmvOfwhV4N5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62113828-7154-4351-e3e5-f0550d0a92c4"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "print(\"vocab size: %d\"%vocabulary_size)\n",
        "CNN1605210290AEBN = tf.keras.Sequential()\n",
        "#Embedding -> hier dann auf das embedding verweisen, Input_dim -> die Anzahl der Wörter im word_index, output -> in dem Fall passend zum verwendeten Vektor\n",
        "#input-length -> auf 60  gepadded, trainable -> nein, weil nichts verändert werden soll\n",
        "#embeddings_initializer=keras.initializers.Constant(glove_matrix) vs weights = [glove_matrix]\n",
        "#Convolutional layers => filters = neurons.. mit 100? 265?\n",
        "#CNN1605210290AEBN.add(tf.keras.layers.Embedding(input_dim=vocabulary_size, output_dim=200, input_length=max_length))\n",
        "CNN1605210290AEBN.add(tf.keras.layers.Embedding(vocabulary_size, output_dim=200, input_length=60, embeddings_initializer = keras.initializers.Constant(glove_matrix), trainable= False))\n",
        "#CNN1605210290AEBN.add(tf.keras.layers.BatchNormalization())\n",
        "CNN1605210290AEBN.add(tf.keras.layers.Dropout(0.4))\n",
        "CNN1605210290AEBN.add(tf.keras.layers.Conv1D(filters=90, kernel_size=3, padding=\"valid\", activation=\"relu\"))\n",
        "#CNN1605210290AEBN.add(tf.keras.layers.BatchNormalization())\n",
        "CNN1605210290AEBN.add(tf.keras.layers.MaxPooling1D())\n",
        "#CNN1605210290AEBN.add(tf.keras.layers.BatchNormalization())\n",
        "CNN1605210290AEBN.add(tf.keras.layers.Conv1D(filters=90, kernel_size=3, padding=\"valid\", activation=\"relu\"))\n",
        "#CNN1605210290AEBN.add(tf.keras.layers.BatchNormalization())\n",
        "CNN1605210290AEBN.add(tf.keras.layers.GlobalAveragePooling1D())\n",
        "#CNN1605210290AEBN.add(tf.keras.layers.BatchNormalization())\n",
        "CNN1605210290AEBN.add(tf.keras.layers.Flatten())\n",
        "#CNN1605210290AEBN.add(tf.keras.layers.BatchNormalization())\n",
        "CNN1605210290AEBN.add(tf.keras.layers.Dense(260, activation=\"relu\"))\n",
        "#CNN1605210290AEBN.add(tf.keras.layers.BatchNormalization())\n",
        "CNN1605210290AEBN.add(tf.keras.layers.Dropout(0.4))\n",
        "CNN1605210290AEBN.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "CNN1605210290AEBN.summary()\n",
        "\n",
        "#nppadded_training = np.asmatrix(nppadded_training) not necessary\n",
        "#nppadded_testing = np.asmatrix(nppadded_testing)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab size: 15061\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 60, 200)           3012200   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 60, 200)           0         \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 58, 90)            54090     \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 29, 90)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 27, 90)            24390     \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 90)                0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 90)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 260)               23660     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 260)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 261       \n",
            "=================================================================\n",
            "Total params: 3,114,601\n",
            "Trainable params: 102,401\n",
            "Non-trainable params: 3,012,200\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEr4OzT-iHDe"
      },
      "source": [
        "#model.layers[2].get_weights()[0].shape\n",
        "#weights=np.random.rand(5,200,100)\n",
        "#bias=np.random.rand(100)\n",
        "#model.layers[2].set_weights([weights, bias])\n",
        "\n",
        "#model.layers[2].get_weights()[0]\n",
        "#https://androidkt.com/set-custom-weights-keras-using-numpy-array/"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UB7_3VPYesr9"
      },
      "source": [
        "F1-Score für jede Epoche https://aakashgoel12.medium.com/how-to-add-user-defined-function-get-f1-score-in-keras-metrics-3013f979ce0d\n",
        "\n",
        "Sehr gute Ressource für die verschiedenen Scores und Metriken https://neptune.ai/blog/evaluation-metrics-binary-classification#10  das und aakas verwendet\n",
        "\n",
        "hier: je eine Funktion für Recall, Precision, f1 https://neptune.ai/blog/keras-metrics \n",
        "\n",
        "https://keras.rstudio.com/reference/k_ones_like.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygyrbFJaMV9B"
      },
      "source": [
        "import keras.backend as K\n",
        "\n",
        "def metrics_recall(data_true, data_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(data_true,0,1)))\n",
        "\n",
        "    recall = true_positives / (possible_positives+K.epsilon())\n",
        "    return recall\n",
        "\n",
        "\n",
        "def metrics_precision(data_true, data_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "\n",
        "    positives_predicted = K.sum(K.round(K.clip(data_pred,0,1)))\n",
        "    precision = true_positives / (positives_predicted+K.epsilon())\n",
        "    return precision\n",
        "\n",
        "\n",
        "def metrics_f1(data_true, data_pred):\n",
        "    precision_data = metrics_precision(data_true, data_pred)\n",
        "    recall_data = metrics_recall(data_true, data_pred)\n",
        "    return 2*(precision_data*recall_data)/(precision_data+recall_data+K.epsilon())"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1ctlBrnuYJz"
      },
      "source": [
        "https://aakashgoel12.medium.com/how-to-add-user-defined-function-get-f1-score-in-keras-metrics-3013f979ce0d"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AfPD3_bWCm0"
      },
      "source": [
        "#CNN1605210290AEBN.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',metrics_recall,metrics_precision,metrics_f1])\n",
        "CNN1605210290AEBN.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',metrics_recall,metrics_precision,metrics_f1])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpChKUY-QEWI"
      },
      "source": [
        "https://www.tensorflow.org/tensorboard/tensorboard_in_notebooks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJfMgUhHBoD1"
      },
      "source": [
        "#%load_ext tensorboard\n",
        "#nur einmal pro Sitzung notwendig\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ISmMXLqP8Hc"
      },
      "source": [
        "\n",
        "logs_base_dir = \"./logs\"\n",
        "callbackForTB = tf.keras.callbacks.TensorBoard(logs_base_dir)\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ehh-EMXUQh8r"
      },
      "source": [
        "Early Stopping as defined in keras tensorflow documentation\n",
        "https://www.tensorflow.org/guide/keras/train_and_evaluate "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BY_t-PeQEjy"
      },
      "source": [
        "callbackEarlyStopping = [\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_loss\",\n",
        "        mode=\"min\",\n",
        "        patience=3,\n",
        "        verbose=1,\n",
        "    )\n",
        "]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2CHbXiP1LsF"
      },
      "source": [
        "training_epochs = 19\n",
        "batch_size = 90\n",
        "validation_split=0.2"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abV-QAxfW48r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d8c8a8e-c886-41f4-db2f-f12cd1ae783f"
      },
      "source": [
        "#Werte der Convolutional-Schichten variieren (Filter), Batch-Size variieren, kernel-size..\n",
        "CNN1605210290AEBN.fit(nppadded_training, nptraining_labels, batch_size=batch_size, validation_split=validation_split, epochs=training_epochs, callbacks=[callbackForTB])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/19\n",
            "41/41 [==============================] - 4s 77ms/step - loss: 0.6557 - accuracy: 0.6587 - metrics_recall: 0.0084 - metrics_precision: 0.0075 - metrics_f1: 0.0079 - val_loss: 0.6470 - val_accuracy: 0.6718 - val_metrics_recall: 0.0000e+00 - val_metrics_precision: 0.0000e+00 - val_metrics_f1: 0.0000e+00\n",
            "Epoch 2/19\n",
            "41/41 [==============================] - 3s 72ms/step - loss: 0.6405 - accuracy: 0.6626 - metrics_recall: 0.0000e+00 - metrics_precision: 0.0000e+00 - metrics_f1: 0.0000e+00 - val_loss: 0.6342 - val_accuracy: 0.6718 - val_metrics_recall: 0.0000e+00 - val_metrics_precision: 0.0000e+00 - val_metrics_f1: 0.0000e+00\n",
            "Epoch 3/19\n",
            "41/41 [==============================] - 3s 74ms/step - loss: 0.6293 - accuracy: 0.6626 - metrics_recall: 0.0000e+00 - metrics_precision: 0.0000e+00 - metrics_f1: 0.0000e+00 - val_loss: 0.6178 - val_accuracy: 0.6718 - val_metrics_recall: 0.0000e+00 - val_metrics_precision: 0.0000e+00 - val_metrics_f1: 0.0000e+00\n",
            "Epoch 4/19\n",
            "41/41 [==============================] - 3s 73ms/step - loss: 0.6037 - accuracy: 0.6668 - metrics_recall: 0.1119 - metrics_precision: 0.4076 - metrics_f1: 0.1488 - val_loss: 0.5947 - val_accuracy: 0.7018 - val_metrics_recall: 0.4129 - val_metrics_precision: 0.5737 - val_metrics_f1: 0.4563\n",
            "Epoch 5/19\n",
            "41/41 [==============================] - 3s 73ms/step - loss: 0.5861 - accuracy: 0.6748 - metrics_recall: 0.2025 - metrics_precision: 0.5601 - metrics_f1: 0.2674 - val_loss: 0.5741 - val_accuracy: 0.7040 - val_metrics_recall: 0.1248 - val_metrics_precision: 0.7337 - val_metrics_f1: 0.2075\n",
            "Epoch 6/19\n",
            "41/41 [==============================] - 3s 70ms/step - loss: 0.5714 - accuracy: 0.6937 - metrics_recall: 0.2443 - metrics_precision: 0.6182 - metrics_f1: 0.3212 - val_loss: 0.5592 - val_accuracy: 0.7195 - val_metrics_recall: 0.3045 - val_metrics_precision: 0.5943 - val_metrics_f1: 0.3958\n",
            "Epoch 7/19\n",
            "41/41 [==============================] - 3s 70ms/step - loss: 0.5583 - accuracy: 0.7133 - metrics_recall: 0.3829 - metrics_precision: 0.6265 - metrics_f1: 0.4573 - val_loss: 0.5598 - val_accuracy: 0.7228 - val_metrics_recall: 0.4469 - val_metrics_precision: 0.6280 - val_metrics_f1: 0.4944\n",
            "Epoch 8/19\n",
            "41/41 [==============================] - 3s 74ms/step - loss: 0.5470 - accuracy: 0.7244 - metrics_recall: 0.4084 - metrics_precision: 0.6992 - metrics_f1: 0.4839 - val_loss: 0.5549 - val_accuracy: 0.7251 - val_metrics_recall: 0.4695 - val_metrics_precision: 0.6194 - val_metrics_f1: 0.5103\n",
            "Epoch 9/19\n",
            "41/41 [==============================] - 3s 74ms/step - loss: 0.5155 - accuracy: 0.7408 - metrics_recall: 0.4646 - metrics_precision: 0.6704 - metrics_f1: 0.5293 - val_loss: 0.5344 - val_accuracy: 0.7350 - val_metrics_recall: 0.4411 - val_metrics_precision: 0.6611 - val_metrics_f1: 0.4999\n",
            "Epoch 10/19\n",
            "41/41 [==============================] - 3s 73ms/step - loss: 0.5164 - accuracy: 0.7300 - metrics_recall: 0.4402 - metrics_precision: 0.6691 - metrics_f1: 0.5040 - val_loss: 0.5377 - val_accuracy: 0.7306 - val_metrics_recall: 0.5903 - val_metrics_precision: 0.5926 - val_metrics_f1: 0.5778\n",
            "Epoch 11/19\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 0.5046 - accuracy: 0.7463 - metrics_recall: 0.5057 - metrics_precision: 0.6668 - metrics_f1: 0.5509 - val_loss: 0.5854 - val_accuracy: 0.6685 - val_metrics_recall: 0.7293 - val_metrics_precision: 0.4979 - val_metrics_f1: 0.5871\n",
            "Epoch 12/19\n",
            "41/41 [==============================] - 3s 75ms/step - loss: 0.4855 - accuracy: 0.7563 - metrics_recall: 0.5360 - metrics_precision: 0.7222 - metrics_f1: 0.5815 - val_loss: 0.5336 - val_accuracy: 0.7306 - val_metrics_recall: 0.4805 - val_metrics_precision: 0.6203 - val_metrics_f1: 0.5191\n",
            "Epoch 13/19\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 0.4520 - accuracy: 0.7840 - metrics_recall: 0.5848 - metrics_precision: 0.7039 - metrics_f1: 0.6322 - val_loss: 0.5253 - val_accuracy: 0.7361 - val_metrics_recall: 0.4817 - val_metrics_precision: 0.6386 - val_metrics_f1: 0.5264\n",
            "Epoch 14/19\n",
            "41/41 [==============================] - 3s 72ms/step - loss: 0.4333 - accuracy: 0.7968 - metrics_recall: 0.6229 - metrics_precision: 0.7507 - metrics_f1: 0.6650 - val_loss: 0.5259 - val_accuracy: 0.7350 - val_metrics_recall: 0.5253 - val_metrics_precision: 0.6202 - val_metrics_f1: 0.5498\n",
            "Epoch 15/19\n",
            "41/41 [==============================] - 3s 72ms/step - loss: 0.4085 - accuracy: 0.8131 - metrics_recall: 0.6443 - metrics_precision: 0.7714 - metrics_f1: 0.6906 - val_loss: 0.5350 - val_accuracy: 0.7184 - val_metrics_recall: 0.6307 - val_metrics_precision: 0.5618 - val_metrics_f1: 0.5844\n",
            "Epoch 16/19\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 0.4235 - accuracy: 0.8068 - metrics_recall: 0.6771 - metrics_precision: 0.7770 - metrics_f1: 0.6936 - val_loss: 0.5258 - val_accuracy: 0.7251 - val_metrics_recall: 0.4893 - val_metrics_precision: 0.6097 - val_metrics_f1: 0.5234\n",
            "Epoch 17/19\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 0.3873 - accuracy: 0.8148 - metrics_recall: 0.6423 - metrics_precision: 0.7908 - metrics_f1: 0.6985 - val_loss: 0.5412 - val_accuracy: 0.7228 - val_metrics_recall: 0.6296 - val_metrics_precision: 0.5677 - val_metrics_f1: 0.5869\n",
            "Epoch 18/19\n",
            "41/41 [==============================] - 3s 75ms/step - loss: 0.3661 - accuracy: 0.8364 - metrics_recall: 0.6953 - metrics_precision: 0.7726 - metrics_f1: 0.7209 - val_loss: 0.5454 - val_accuracy: 0.7251 - val_metrics_recall: 0.5262 - val_metrics_precision: 0.5936 - val_metrics_f1: 0.5422\n",
            "Epoch 19/19\n",
            "41/41 [==============================] - 3s 72ms/step - loss: 0.3604 - accuracy: 0.8403 - metrics_recall: 0.7031 - metrics_precision: 0.8226 - metrics_f1: 0.7466 - val_loss: 0.6539 - val_accuracy: 0.6608 - val_metrics_recall: 0.8107 - val_metrics_precision: 0.4893 - val_metrics_f1: 0.6078\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7c362270d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJVL4SBLPB2P"
      },
      "source": [
        "#%tensorboard --logdir {logs_base_dir}"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_LnvWBcnoak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ef70645-dc1d-4596-e6fe-5f60ddfeaa5b"
      },
      "source": [
        "#results = model.evaluate(nppadded_testing, nptesting_labels, batch_size=batch_size)\n",
        "#print(\"test loss, test acc:\",results)\n",
        "\n",
        "(loss,accuracy, metrics_recall,metrics_precision,\n",
        "metrics_f1) = CNN1605210290AEBN.evaluate(nppadded_testing, nptesting_labels, verbose=1)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "111/111 [==============================] - 1s 10ms/step - loss: 0.6919 - accuracy: 0.6195 - metrics_recall: 0.6457 - metrics_precision: 0.4609 - metrics_f1: 0.5271\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KgjIkhpKmHc"
      },
      "source": [
        "make some predictions of test data and save it to variable. verbose=0 -> do not generate output\n",
        "Gute Quelle: https://deeplizard.com/learn/video/2f-NjDUvZIE "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89GWuxryKlcM"
      },
      "source": [
        "CNN_predictions90AEBN = CNN1605210290AEBN.predict(x=nppadded_testing)\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3jPDaDJK_cN"
      },
      "source": [
        "#for p in CNN_predictions90AEBN:\n",
        " # print(p)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eC9efJy4Lp21"
      },
      "source": [
        "rounded predictions: give prediction value of most likely prediction (0 or 1). Printing the output of rounded prediction shows the prediction made by the model on the data (which output is most likely)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsG-TJuQLvtk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "206b7af6-cc7a-4fea-f44e-f5131b46399c"
      },
      "source": [
        "prediction_rounded90AEBN = np.round(CNN_predictions90AEBN)\n",
        "#np.argmax(CNN_predictions90AEBN,axis=-1)\n",
        "\n",
        "#for p in prediction_rounded90AEBN:\n",
        " # print(p)\n",
        "\n",
        "\n",
        "print(nptesting_labels[500:520])\n",
        "print(prediction_rounded90AEBN[500:520])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1]\n",
            "[[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egTtgpXgg8a2"
      },
      "source": [
        "https://deeplizard.com/learn/video/km7pxKy4UHU\n",
        "\n",
        "Quelle der def plot_confusion_matrix: https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSDXf7-_MITy"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0AMs1EzhBU1"
      },
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                        normalize=False,\n",
        "                        title='Confusion matrix',\n",
        "                        cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2JgEnlghCtl"
      },
      "source": [
        "cm = confusion_matrix(y_true=nptesting_labels, y_pred=prediction_rounded90AEBN)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckmF29whhFmX"
      },
      "source": [
        "plot_labels = ['no hatespeech','hatespeech']"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mpSE96rhK7K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "outputId": "2ba7820f-8e4f-4d16-938d-7e1132c38057"
      },
      "source": [
        "plot_confusion_matrix(cm=cm, classes=plot_labels, title='CNN Confusion 90 19 Epochs Batch size 90')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix, without normalization\n",
            "[[1418  912]\n",
            " [ 432  770]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}