{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN embedded.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOTLHb3yb66Je+s4CZzaN5m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BiancaStadl/ProjektarbeitML/blob/main/CNN_embedded.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXDOlIBymF0V"
      },
      "source": [
        "GloVe embeddings taken from:\n",
        "\n",
        "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. [pdf] [bib]\n",
        "\n",
        "hatespeechdata taken from (https://hatespeechdata.com/): Wiegand, M., Siegel, M. and Ruppenhofer, J., 2018. Overview of the GermEval 2018 Shared Task on the Identification of Offensive Language. In: Proceedings of GermEval 2018, 14th Conference on Natural Language Processing (KONVENS 2018). Vienna, Austria: Research Gate. available on: https://github.com/uds-lsv/GermEval-2018-Data (last checked: 09.05.2021)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlBmABDxfqII"
      },
      "source": [
        "wiki detox..https://colab.research.google.com/github/tensorflow/fairness-indicators/blob/master/g3doc/tutorials/Fairness_Indicators_TFCO_Wiki_Case_Study.ipynb#scrollTo=y6T5tlXcdW7J "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3xfitNdliBI"
      },
      "source": [
        "#import matplotlib.pyplot as plt -> für evtl Visualisierungen\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import string\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from keras import losses \n",
        "from keras import optimizers \n",
        "from keras import metrics \n",
        "\n",
        "#!pip install Tokenizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "#!pip install pad_sequences\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import preprocessing\n",
        "#from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTWJQ1iga_vS"
      },
      "source": [
        "Maximale Satzlänge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bq08Me5la_Cc"
      },
      "source": [
        "\n",
        "max_length = 60"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVYBMvYSotTH"
      },
      "source": [
        "url = \"https://github.com/uds-lsv/GermEval-2018-Data/archive/master.zip\"\n",
        "\n",
        "dataset = tf.keras.utils.get_file(\"GermEval-2018-Data-master.zip\", url, \n",
        "                                   extract=True, cache_dir='.',\n",
        "                                    cache_subdir='')\n",
        "\n",
        "dataset_dir = os.path.join(os.path.dirname(dataset), 'GermEval-2018-Data-master')\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cS14OUtfo34V"
      },
      "source": [
        "#os.listdir(dataset_dir)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2X429K6hpOVm"
      },
      "source": [
        "training_file = os.path.join(dataset_dir, 'germeval2018.training.txt')\n",
        "\n",
        "testing_file = os.path.join(dataset_dir, 'germeval2018.test.txt')\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uq8fG3LNtn_m"
      },
      "source": [
        "###Aufbereitung\n",
        "txt-Dateien lesen, und dabei jede Zeile splitten und teilen\n",
        "Twitter-Handler entfernen?\n",
        "Labels von Sätzen trennen, Labels in eigenen Array packen.\n",
        "\n",
        "####Ressourcen\n",
        "* https://www.w3schools.com/python/gloss_python_if_statement.asp\n",
        "* https://stackabuse.com/using-regex-for-text-manipulation-in-python/\n",
        "* https://www.tutorialspoint.com/python/string_splitlines.htm \n",
        "* https://note.nkmk.me/en/python-split-rsplit-splitlines-re/ \n",
        "* https://www.w3schools.com/python/python_regex.asp \n",
        "\n",
        "gäbe bei keras tf.keras.preprocessing.text_dataset_from_directory, aber dafür müssten die Daten auf bestimmte Weise in Verzeichnis organisiert sein, hier nicht der Fall.\n",
        "\n",
        "\n",
        "Einteilung der Daten: Testdaten\n",
        "Trainingsdaten -> noch ca 500 für Validierungsdaten\n",
        "\n",
        "labels -> \"other\", also nicht-negative Aussagen bekommen \"0\", negative Aussagen bekommen \"1\"\n",
        "\n",
        " Regex für Emojis  ->\n",
        "\n",
        "(\\u00a9|\\u00ae|[\\u2000-\\u3300]|\\ud83c[\\ud000-\\udfff]|\\ud83d[\\ud000-\\udfff]|\\ud83e[\\ud000-\\udfff])\n",
        "\n",
        "genommen von https://www.regextester.com/106421 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Py_cwD4eZkXo"
      },
      "source": [
        "def remove_clutter(string):\n",
        "   string = re.sub(\"@[^\\s]+\",\" \",string)\n",
        "   string = re.sub(\"#[^\\s]+\",\" \", string)\n",
        "   string = re.sub(\"\\u00a9\",\" \", string)\n",
        "   string = re.sub(\"\\u00ae\",\" \", string)\n",
        "   string = re.sub(\"[\\u2000-\\u3300]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83c[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83d[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83e[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"😜\", \" \",string)\n",
        "   string = re.sub(\"🍫\", \" \",string)\n",
        "   string = re.sub(\"😁\", \" \",string)\n",
        "   string = re.sub(\"🐖\", \" \",string)\n",
        "   string = re.sub(\"😡\", \" \",string)\n",
        "   string = re.sub(\"😇\", \" \",string)\n",
        "   string = re.sub(\"😬\", \" \",string)\n",
        "   string = re.sub(\"😃\", \" \",string)\n",
        "   string = re.sub(\"😂\", \" \",string)\n",
        "   string = re.sub(\"💙\", \" \",string)  \n",
        "   string = re.sub(\"😛\", \" \",string)\n",
        "   string = re.sub(\"🙏\", \" \",string)\n",
        "   string = re.sub(\"👍\", \" \",string)\n",
        "   string = re.sub(\"🖕\", \" \",string)\n",
        "   string = re.sub(\"😉\", \" \",string)\n",
        "   string = re.sub(\"💩\", \" \",string)\n",
        "   string = re.sub(\"🤢\", \" \",string)\n",
        "   string = re.sub(\"👏\", \" \",string)\n",
        "   string = re.sub(\"😨\", \" \",string)\n",
        "   string = re.sub(\"🤣\", \" \",string)\n",
        "   string = re.sub(\"🤡\", \" \",string)\n",
        "   string = re.sub(\"😈\", \" \",string)\n",
        "   string = re.sub(\"💃🏽\", \" \",string)\n",
        "   string = re.sub(\"👹\", \" \",string)\n",
        "   string = re.sub(\"🤘\", \" \",string)\n",
        "   string = re.sub(\"😱\", \" \",string)\n",
        "   string = re.sub(\"🤔\", \" \",string) \n",
        "   string = re.sub(\"🌈\", \" \",string) \n",
        "   string = re.sub(\"💕\", \" \",string) \n",
        "   string = re.sub(\"👩‍❤️‍👩\", \" \",string) \n",
        "   string = re.sub(\"😍\", \" \",string) \n",
        "   string = re.sub(\"👆\", \" \",string) \n",
        "   string = re.sub(\"😖\", \" \",string) \n",
        "   string = re.sub(\"👇\", \" \",string) \n",
        "   string = re.sub(\"🔥\", \" \",string) \n",
        "   string = re.sub(\"😘\", \" \",string) \n",
        "   string = re.sub(\"🎉\", \" \",string) \n",
        "   string = re.sub(\"🤬\", \" \",string) \n",
        "   string = re.sub(\"👊\", \" \",string)\n",
        "   string = re.sub(\"🇩🇪\", \" \",string)  \n",
        "   string = re.sub(\"💔\", \" \",string)\n",
        "   string = re.sub(\"🙈\", \" \",string)\n",
        "   string = re.sub(\"🤯\", \" \",string)\n",
        "   string = re.sub(\"🐟\", \" \",string)\n",
        "   string = re.sub(\"🛶\", \" \",string)\n",
        "   string = re.sub(\"😊\", \" \",string)\n",
        "   string = re.sub(\"😓\", \" \",string)\n",
        "   string = re.sub(\"😳\", \" \",string)\n",
        "   string = re.sub(\"🚀\", \" \",string)\n",
        "   string = re.sub(\"👎\", \" \",string)\n",
        "   string = re.sub(\"😎\", \" \",string)\n",
        "   string = re.sub(\"🐸\", \" \",string)\n",
        "   string = re.sub(\"📈\", \" \",string)\n",
        "   string = re.sub(\"🙂\", \" \",string)\n",
        "   string = re.sub(\"😅\", \" \",string)\n",
        "   string = re.sub(\"😆\", \" \",string)\n",
        "   string = re.sub(\"🙎🏿\", \" \",string)\n",
        "   string = re.sub(\"👎🏽\", \" \",string)\n",
        "   string = re.sub(\"🤭\", \" \",string)\n",
        "   string = re.sub(\"😤\", \" \",string)\n",
        "   string = re.sub(\"😚\", \" \",string)\n",
        "   string = re.sub(\"😊\", \" \",string)\n",
        "   string = re.sub(\"😲\", \" \",string)\n",
        "   string = re.sub(\"🤮\", \" \",string)\n",
        "   string = re.sub(\"🙄\", \" \",string)\n",
        "   string = re.sub(\"🤑\", \" \",string)\n",
        "   string = re.sub(\"🎅\", \" \",string)\n",
        "   string = re.sub(\"👋\", \" \",string)\n",
        "   string = re.sub(\"💪\", \" \",string)\n",
        "   string = re.sub(\"😄\", \" \",string)\n",
        "   string = re.sub(\"🧐\", \" \",string)\n",
        "   string = re.sub(\"😠\", \" \",string)\n",
        "   string = re.sub(\"🎈\", \" \",string)\n",
        "   string = re.sub(\"🚂\", \" \",string)\n",
        "   string = re.sub(\"😊\", \" \",string)\n",
        "   string = re.sub(\"🚇\", \" \",string)\n",
        "   string = re.sub(\"🚊\", \" \",string)\n",
        "   string = re.sub(\"🤷\", \" \",string)\n",
        "   string = re.sub(\"😥\", \" \",string)\n",
        "   string = re.sub(\"🙃\", \" \",string)\n",
        "   string = re.sub(\"🔩\", \" \",string)\n",
        "   string = re.sub(\"🔧\", \" \",string)\n",
        "   string = re.sub(\"🔨\", \" \",string)\n",
        "   string = re.sub(\"🛠\", \" \",string)\n",
        "   string = re.sub(\"💓\", \" \",string)\n",
        "   string = re.sub(\"💡\", \" \",string)\n",
        "   string = re.sub(\"🍸\", \" \",string)\n",
        "   string = re.sub(\"🥃\", \" \",string)\n",
        "   string = re.sub(\"🥂\", \" \",string)\n",
        "   string = re.sub(\"😷\", \" \",string)\n",
        "   string = re.sub(\"🤐\", \" \",string)\n",
        "   string = re.sub(\"🌎\", \" \",string)\n",
        "   string = re.sub(\"👑\", \" \",string)\n",
        "   string = re.sub(\"🤛\", \" \",string)\n",
        "   string = re.sub(\"😀\", \" \",string)\n",
        "   string = re.sub(\"🛤\", \" \",string)\n",
        "   string = re.sub(\"🎄\", \" \",string)\n",
        "   string = re.sub(\"📴\", \" \",string)\n",
        "   string = re.sub(\"🌭\", \" \",string)\n",
        "   string = re.sub(\"🤕\", \" \",string)\n",
        "   string = re.sub(\"😭\", \" \",string)\n",
        "   string = re.sub(\"🍾\", \" \",string)\n",
        "   string = re.sub(\"🍞\", \" \",string)\n",
        "   string = re.sub(\"🤦\", \" \",string)\n",
        "   string = re.sub(\"🤯\", \" \",string)\n",
        "   string = re.sub(\"🕯️\", \" \",string)\n",
        "\n",
        "   string = re.sub(\"OTHER|OFFENSE|ABUSE|INSULT\",\" \",string)\n",
        "   return string"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5asMgo4LtnRg"
      },
      "source": [
        "statementsForTraining = []\n",
        "sentimentsForTraining = []\n",
        "\n",
        "\n",
        "fileToRead = open(training_file, 'r')\n",
        "\n",
        "while True:\n",
        "  #next line in file\n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  findSentiment = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "\n",
        "\n",
        "  statementsForTraining.append(line)\n",
        "   #sentimentsForTraining.append(findSentiment.group(0))\n",
        "\n",
        "  if findSentiment.group(0) == \"OTHER\":  \n",
        "    sentimentsForTraining.append(0)\n",
        "  else:\n",
        "    sentimentsForTraining.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        " #print(\"{}: {}\".format(count,line.strip()))\n",
        "  \n",
        " # print(sentiment.group(0))\n",
        " \n",
        "fileToRead.close()\n",
        "\n",
        "training_sentences = statementsForTraining\n",
        "training_labels = sentimentsForTraining\n",
        "\n",
        "#print(training_sentences[9])\n",
        "#print(training_labels[9])\n",
        "\n",
        "#print(len(training_sentences))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsqZPENb98gD"
      },
      "source": [
        "##do the same with testdata\n",
        "statementsForTesting = []\n",
        "sentimentsForTesting = []\n",
        "\n",
        "fileToRead = open(testing_file, 'r')\n",
        "\n",
        "while True:\n",
        "  #next line in file\n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  sent = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "\n",
        "    \n",
        "\n",
        "  statementsForTesting.append(line)\n",
        "  #print(len(line))\n",
        "  #sentimentsForTesting.append(sent.group(0))\n",
        "\n",
        "  if sent.group(0) == \"OTHER\": \n",
        "    sentimentsForTesting.append(0)\n",
        "  else:\n",
        "    sentimentsForTesting.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        "\n",
        "fileToRead.close()\n",
        "\n",
        "\n",
        "testing_sentences = statementsForTesting\n",
        "testing_labels = sentimentsForTesting\n",
        "#print(len(testing_sentences))\n",
        "#print(testing_sentences)   \n",
        "#print(testing_labels)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRUvDLD5bMbO"
      },
      "source": [
        "Padding -> im Prinzip die Sätze alle auf die gleiche Länge bringen (in Theorieteil näher drauf eingehen) -> maxlen-Paramter ist für pad_sequences vorhanden, wenn nicht gesetzt -> alles wird auf die Länge des längsten Satzes aufgefüllt -> print(padded(shape)) gibt aus, wie viele Datensätze padded wurden und gibt an, wie viele Tokens der längste Datensatz hat\n",
        "print(padded[x]) gibt einen Satz aus (bereits tokenisiert)\n",
        "\n",
        "Padding -> sowohl für Trainigs- als auch für Testdaten\n",
        "\n",
        "Und: Daten als numpy-Arrays speichern (notwendig für tensorflow).\n",
        "\n",
        " -> Tokenizer https://towardsdatascience.com/text-classification-in-keras-part-2-how-to-use-the-keras-tokenizer-word-representations-fd571674df23 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3hFi7waTv5m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "977bb366-e4e1-4c5b-c3e5-d3d40bb6cfcd"
      },
      "source": [
        "tokenizer = Tokenizer(oov_token=\"OOV\")\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "\n",
        "#creating a word index - nur die Trainigsdaten\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "validation_size = 500\n",
        "\n",
        "\n",
        "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "padded_training = pad_sequences(training_sequences, maxlen=max_length, padding='post')\n",
        "print(len(padded_training))\n",
        "\n",
        "validation_sequences = padded_training[0:validation_size]\n",
        "validation_labels = training_labels[0:validation_size]\n",
        "\n",
        "padded_training = padded_training[validation_size:]\n",
        "training_labels = training_labels[validation_size:]\n",
        "\n",
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
        "padded_testing = pad_sequences(testing_sequences, maxlen=max_length,  padding='post')\n",
        "\n",
        "#print(validation_sequences[499])\n",
        "print(padded_training[0])\n",
        "#print(len(validation_labels))\n",
        "#print(len(training_labels))\n",
        "\n",
        "\n",
        "nppadded_training = np.array(padded_training)\n",
        "nptraining_labels = np.array(training_labels)\n",
        "\n",
        "nppadded_validation = np.array(validation_sequences)\n",
        "npvalidation_labels = np.array(validation_labels)\n",
        "\n",
        "nppadded_testing = np.array(padded_testing)\n",
        "nptesting_labels = np.array(testing_labels)\n",
        "\n",
        "\n",
        "print(len(nppadded_training))\n",
        "print(len(nptraining_labels))\n",
        "print(len(word_index))\n",
        "\n",
        "#print(statementsForTraining[2])\n",
        "#print(nppadded_training[4])\n",
        "#print(nppadded_training.shape)\n",
        "#print(nptraining_labels[4])\n",
        "#print(nppadded_testing.shape)\n",
        "#print(word_index) \n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5009\n",
            "[  12 3982   11   41 6706 1040    4    5  202   39    3 2922   49 1360\n",
            "  810  495 3983    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0]\n",
            "4509\n",
            "4509\n",
            "15059\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tL3owrc8THkT"
      },
      "source": [
        "\n",
        "Dann: Embedding mit entweder word2vec oder glove\n",
        "Word2vec-Daten sind hier: http://vectors.nlpl.eu/repository/#\n",
        "Glove -> https://nlp.stanford.edu/projects/glove/ Da mal den Twitter-Vector runtergeladen\n",
        "Wenn Daten in GoogleDrive sind (wäre auch via url möglich..), muss Drive gemounted werden ( https://buomsoo-kim.github.io/colab/2020/05/09/Colab-mounting-google-drive.md/ ) aber auch hier https://enjoymachinelearning.com/posts/colab-with-google-drive/\n",
        "\n",
        "Die Word2vec vectors: http://vectors.nlpl.eu/repository/# \n",
        "\n",
        "glove-zitat:\n",
        "Citing GloVe\n",
        "\n",
        "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. [pdf] [bib]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zuO7T9ZTG57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "870a43a7-9063-4790-cf36-a3da06fc3874"
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount(\"/content/drive\")\n",
        "os.listdir(\"/content/drive/MyDrive/Colab Notebooks\")\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['germeval_training.txt',\n",
              " 'glove.twitter.27B.50d.txt',\n",
              " 'glove.twitter.27B.200d.txt',\n",
              " 'glove.6B.200d.txt',\n",
              " 'glove.840B.300d.txt',\n",
              " 'tensorboard.gdoc',\n",
              " 'keras.gdoc',\n",
              " 'Vectorization CNN embedded_limited_vocab.ipynb',\n",
              " 'glove.42B.300d.txt',\n",
              " 'Embedding Glove Vergleich.ipynb',\n",
              " 'CNN embedded_limited_vocab.ipynb',\n",
              " 'LSTM_limited_vocab.ipynb',\n",
              " 'LSTM.ipynb',\n",
              " 'CNN embedded.ipynb']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7ToKO-sZLHK"
      },
      "source": [
        "\n",
        "Keras-Doc : https://keras.io/examples/nlp/pretrained_word_embeddings/#load-pretrained-word-embeddings \n",
        "embedding mit initializers.. weights müsste auch funktionieren\n",
        "\n",
        "Diese erstellte Matrix mit Embedding dann in die Embedding-Schicht einbinden,  Trainable auf False, weil sich die Werte nicht durch Training anpassen sollen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AShIVfC7ZQAH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35e56ab3-6023-4aae-cecb-a795d1354406"
      },
      "source": [
        "#Größe Vokabel -> wordindex + 2 (weil padding + OOV) \n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "vocabulary_size = len(word_index)+2\n",
        "\n",
        "# dann erstell ich ein Wörterbuch mit Namen \"embedding_vector\", dort sind dann\n",
        "#die keys drinnen, die in glove-Datei drinnen sind mit dem entsprechenden Key\n",
        "\n",
        "embedding_index_glove = {}\n",
        "f = open('/content/drive/MyDrive/Colab Notebooks/glove.twitter.27B.200d.txt')\n",
        "for line in f:\n",
        "  value = line.split()\n",
        "  word = value[0]\n",
        "  coef = np.asarray(value[1:],dtype='float32')\n",
        "  embedding_index_glove[word] = coef\n",
        "\n",
        "print(\"%d gefunden: \"% len(embedding_index_glove))\n",
        "\n",
        "#Dann noch eine Embedding-Matrix erstellen\n",
        "#zweiter Wert = Embedding-Dimension der Datei, in dem Fall 200\n",
        "\n",
        "glove_matrix = np.zeros((vocabulary_size,200))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    embedding_value = embedding_index_glove.get(word)\n",
        "    if embedding_value is not None:\n",
        "      glove_matrix[index] = embedding_value\n",
        "      hits+=1\n",
        "    else:\n",
        "      misses+=1\n",
        "\n",
        "print(\"hits %d and %d misses\"%(hits,misses))\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1193514 gefunden: \n",
            "hits 6747 and 8312 misses\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZmvOfwhV4N5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d23af68-e7d2-4eae-aa50-476398d3426e"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "print(\"vocab size: %d\"%vocabulary_size)\n",
        "CNN1605210290AEBN = tf.keras.Sequential()\n",
        "#Embedding -> hier dann auf das embedding verweisen, Input_dim -> die Anzahl der Wörter im word_index, output -> in dem Fall passend zum verwendeten Vektor\n",
        "#input-length -> auf 60  gepadded, trainable -> nein, weil nichts verändert werden soll\n",
        "#embeddings_initializer=keras.initializers.Constant(glove_matrix) vs weights = [glove_matrix]\n",
        "#Convolutional layers => filters = neurons.. mit 100? 265?\n",
        "#CNN1605210290AEBN.add(tf.keras.layers.Embedding(input_dim=vocabulary_size, output_dim=200, input_length=max_length))\n",
        "CNN1605210290AEBN.add(tf.keras.layers.Embedding(vocabulary_size, output_dim=200, input_length=60, embeddings_initializer = keras.initializers.Constant(glove_matrix), trainable= False))\n",
        "#CNN1605210290AEBN.add(tf.keras.layers.BatchNormalization())\n",
        "CNN1605210290AEBN.add(tf.keras.layers.Dropout(0.4))\n",
        "CNN1605210290AEBN.add(tf.keras.layers.Conv1D(filters=90, kernel_size=3, padding=\"valid\", activation=\"relu\"))\n",
        "#CNN1605210290AEBN.add(tf.keras.layers.BatchNormalization())\n",
        "CNN1605210290AEBN.add(tf.keras.layers.MaxPooling1D())\n",
        "#CNN1605210290AEBN.add(tf.keras.layers.BatchNormalization())\n",
        "CNN1605210290AEBN.add(tf.keras.layers.Conv1D(filters=90, kernel_size=3, padding=\"valid\", activation=\"relu\"))\n",
        "#CNN1605210290AEBN.add(tf.keras.layers.BatchNormalization())\n",
        "CNN1605210290AEBN.add(tf.keras.layers.GlobalAveragePooling1D())\n",
        "#CNN1605210290AEBN.add(tf.keras.layers.BatchNormalization())\n",
        "CNN1605210290AEBN.add(tf.keras.layers.Flatten())\n",
        "#CNN1605210290AEBN.add(tf.keras.layers.BatchNormalization())\n",
        "CNN1605210290AEBN.add(tf.keras.layers.Dense(260, activation=\"relu\"))\n",
        "#CNN1605210290AEBN.add(tf.keras.layers.BatchNormalization())\n",
        "CNN1605210290AEBN.add(tf.keras.layers.Dropout(0.4))\n",
        "CNN1605210290AEBN.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "CNN1605210290AEBN.summary()\n",
        "\n",
        "#nppadded_training = np.asmatrix(nppadded_training) not necessary\n",
        "#nppadded_testing = np.asmatrix(nppadded_testing)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab size: 15061\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 60, 200)           3012200   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 60, 200)           0         \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 58, 90)            54090     \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 29, 90)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 27, 90)            24390     \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 90)                0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 90)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 260)               23660     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 260)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 261       \n",
            "=================================================================\n",
            "Total params: 3,114,601\n",
            "Trainable params: 102,401\n",
            "Non-trainable params: 3,012,200\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEr4OzT-iHDe"
      },
      "source": [
        "#model.layers[2].get_weights()[0].shape\n",
        "#weights=np.random.rand(5,200,100)\n",
        "#bias=np.random.rand(100)\n",
        "#model.layers[2].set_weights([weights, bias])\n",
        "\n",
        "#model.layers[2].get_weights()[0]\n",
        "#https://androidkt.com/set-custom-weights-keras-using-numpy-array/"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UB7_3VPYesr9"
      },
      "source": [
        "F1-Score für jede Epoche https://aakashgoel12.medium.com/how-to-add-user-defined-function-get-f1-score-in-keras-metrics-3013f979ce0d\n",
        "\n",
        "Sehr gute Ressource für die verschiedenen Scores und Metriken https://neptune.ai/blog/evaluation-metrics-binary-classification#10  das und aakas verwendet\n",
        "\n",
        "hier: je eine Funktion für Recall, Precision, f1 https://neptune.ai/blog/keras-metrics \n",
        "\n",
        "https://keras.rstudio.com/reference/k_ones_like.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygyrbFJaMV9B"
      },
      "source": [
        "import keras.backend as K\n",
        "\n",
        "def metrics_recall(data_true, data_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(data_true,0,1)))\n",
        "\n",
        "    recall = true_positives / (possible_positives+K.epsilon())\n",
        "    return recall\n",
        "\n",
        "\n",
        "def metrics_precision(data_true, data_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "\n",
        "    positives_predicted = K.sum(K.round(K.clip(data_pred,0,1)))\n",
        "    precision = true_positives / (positives_predicted+K.epsilon())\n",
        "    return precision\n",
        "\n",
        "\n",
        "def metrics_f1(data_true, data_pred):\n",
        "    precision_data = metrics_precision(data_true, data_pred)\n",
        "    recall_data = metrics_recall(data_true, data_pred)\n",
        "    return 2*(precision_data*recall_data)/(precision_data+recall_data+K.epsilon())"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1ctlBrnuYJz"
      },
      "source": [
        "https://aakashgoel12.medium.com/how-to-add-user-defined-function-get-f1-score-in-keras-metrics-3013f979ce0d"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AfPD3_bWCm0"
      },
      "source": [
        "#CNN1605210290AEBN.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',metrics_recall,metrics_precision,metrics_f1])\n",
        "CNN1605210290AEBN.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',metrics_recall,metrics_precision,metrics_f1])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpChKUY-QEWI"
      },
      "source": [
        "https://www.tensorflow.org/tensorboard/tensorboard_in_notebooks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJfMgUhHBoD1"
      },
      "source": [
        "#%load_ext tensorboard\n",
        "#nur einmal pro Sitzung notwendig\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ISmMXLqP8Hc"
      },
      "source": [
        "\n",
        "logs_base_dir = \"./logs\"\n",
        "callbackForTB = tf.keras.callbacks.TensorBoard(logs_base_dir)\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ehh-EMXUQh8r"
      },
      "source": [
        "Early Stopping as defined in keras tensorflow documentation\n",
        "https://www.tensorflow.org/guide/keras/train_and_evaluate "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BY_t-PeQEjy"
      },
      "source": [
        "callbackEarlyStopping = [\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_loss\",\n",
        "        mode=\"min\",\n",
        "        patience=3,\n",
        "        verbose=1,\n",
        "    )\n",
        "]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2CHbXiP1LsF"
      },
      "source": [
        "training_epochs = 19\n",
        "batch_size = 120\n",
        "validation_split=0.2"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abV-QAxfW48r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "725f7bd0-e8f5-47ee-8123-2788d20f8398"
      },
      "source": [
        "#Werte der Convolutional-Schichten variieren (Filter), Batch-Size variieren, kernel-size..\n",
        "CNN1605210290AEBN.fit(nppadded_training, nptraining_labels, batch_size=batch_size, validation_split=validation_split, epochs=training_epochs, callbacks=[callbackForTB])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/19\n",
            "31/31 [==============================] - 4s 99ms/step - loss: 0.6591 - accuracy: 0.6601 - metrics_recall: 0.0227 - metrics_precision: 0.0141 - metrics_f1: 0.0174 - val_loss: 0.6475 - val_accuracy: 0.6718 - val_metrics_recall: 0.0000e+00 - val_metrics_precision: 0.0000e+00 - val_metrics_f1: 0.0000e+00\n",
            "Epoch 2/19\n",
            "31/31 [==============================] - 3s 90ms/step - loss: 0.6445 - accuracy: 0.6626 - metrics_recall: 0.0000e+00 - metrics_precision: 0.0000e+00 - metrics_f1: 0.0000e+00 - val_loss: 0.6369 - val_accuracy: 0.6718 - val_metrics_recall: 0.0000e+00 - val_metrics_precision: 0.0000e+00 - val_metrics_f1: 0.0000e+00\n",
            "Epoch 3/19\n",
            "31/31 [==============================] - 3s 96ms/step - loss: 0.6395 - accuracy: 0.6626 - metrics_recall: 0.0000e+00 - metrics_precision: 0.0000e+00 - metrics_f1: 0.0000e+00 - val_loss: 0.6290 - val_accuracy: 0.6718 - val_metrics_recall: 0.0000e+00 - val_metrics_precision: 0.0000e+00 - val_metrics_f1: 0.0000e+00\n",
            "Epoch 4/19\n",
            "31/31 [==============================] - 3s 90ms/step - loss: 0.6313 - accuracy: 0.6623 - metrics_recall: 0.0000e+00 - metrics_precision: 0.0000e+00 - metrics_f1: 0.0000e+00 - val_loss: 0.6137 - val_accuracy: 0.6718 - val_metrics_recall: 0.0000e+00 - val_metrics_precision: 0.0000e+00 - val_metrics_f1: 0.0000e+00\n",
            "Epoch 5/19\n",
            "31/31 [==============================] - 3s 93ms/step - loss: 0.6079 - accuracy: 0.6662 - metrics_recall: 0.0737 - metrics_precision: 0.4764 - metrics_f1: 0.1157 - val_loss: 0.6308 - val_accuracy: 0.6341 - val_metrics_recall: 0.4894 - val_metrics_precision: 0.4460 - val_metrics_f1: 0.4640\n",
            "Epoch 6/19\n",
            "31/31 [==============================] - 3s 89ms/step - loss: 0.5900 - accuracy: 0.6845 - metrics_recall: 0.2270 - metrics_precision: 0.5567 - metrics_f1: 0.3014 - val_loss: 0.5870 - val_accuracy: 0.6973 - val_metrics_recall: 0.1046 - val_metrics_precision: 0.6863 - val_metrics_f1: 0.1776\n",
            "Epoch 7/19\n",
            "31/31 [==============================] - 3s 94ms/step - loss: 0.5751 - accuracy: 0.7020 - metrics_recall: 0.2697 - metrics_precision: 0.6423 - metrics_f1: 0.3588 - val_loss: 0.6137 - val_accuracy: 0.6430 - val_metrics_recall: 0.5980 - val_metrics_precision: 0.4613 - val_metrics_f1: 0.5175\n",
            "Epoch 8/19\n",
            "31/31 [==============================] - 3s 94ms/step - loss: 0.5637 - accuracy: 0.6975 - metrics_recall: 0.3438 - metrics_precision: 0.6434 - metrics_f1: 0.4206 - val_loss: 0.5809 - val_accuracy: 0.6940 - val_metrics_recall: 0.5209 - val_metrics_precision: 0.5385 - val_metrics_f1: 0.5233\n",
            "Epoch 9/19\n",
            "31/31 [==============================] - 3s 94ms/step - loss: 0.5463 - accuracy: 0.7203 - metrics_recall: 0.4292 - metrics_precision: 0.6612 - metrics_f1: 0.4996 - val_loss: 0.5641 - val_accuracy: 0.7106 - val_metrics_recall: 0.4891 - val_metrics_precision: 0.5670 - val_metrics_f1: 0.5188\n",
            "Epoch 10/19\n",
            "31/31 [==============================] - 3s 95ms/step - loss: 0.5435 - accuracy: 0.7172 - metrics_recall: 0.4163 - metrics_precision: 0.6668 - metrics_f1: 0.4712 - val_loss: 0.5676 - val_accuracy: 0.7084 - val_metrics_recall: 0.4658 - val_metrics_precision: 0.5669 - val_metrics_f1: 0.5054\n",
            "Epoch 11/19\n",
            "31/31 [==============================] - 3s 90ms/step - loss: 0.5223 - accuracy: 0.7363 - metrics_recall: 0.4419 - metrics_precision: 0.6496 - metrics_f1: 0.5137 - val_loss: 0.5543 - val_accuracy: 0.7217 - val_metrics_recall: 0.5099 - val_metrics_precision: 0.5936 - val_metrics_f1: 0.5409\n",
            "Epoch 12/19\n",
            "31/31 [==============================] - 3s 94ms/step - loss: 0.4978 - accuracy: 0.7499 - metrics_recall: 0.4937 - metrics_precision: 0.6972 - metrics_f1: 0.5679 - val_loss: 0.5470 - val_accuracy: 0.7195 - val_metrics_recall: 0.4943 - val_metrics_precision: 0.5914 - val_metrics_f1: 0.5320\n",
            "Epoch 13/19\n",
            "31/31 [==============================] - 3s 94ms/step - loss: 0.5045 - accuracy: 0.7474 - metrics_recall: 0.5184 - metrics_precision: 0.6746 - metrics_f1: 0.5638 - val_loss: 0.5521 - val_accuracy: 0.7173 - val_metrics_recall: 0.5021 - val_metrics_precision: 0.5834 - val_metrics_f1: 0.5344\n",
            "Epoch 14/19\n",
            "31/31 [==============================] - 3s 94ms/step - loss: 0.4775 - accuracy: 0.7688 - metrics_recall: 0.5497 - metrics_precision: 0.7382 - metrics_f1: 0.6134 - val_loss: 0.5819 - val_accuracy: 0.7195 - val_metrics_recall: 0.2201 - val_metrics_precision: 0.7597 - val_metrics_f1: 0.3366\n",
            "Epoch 15/19\n",
            "31/31 [==============================] - 3s 98ms/step - loss: 0.4799 - accuracy: 0.7713 - metrics_recall: 0.5395 - metrics_precision: 0.7657 - metrics_f1: 0.6063 - val_loss: 0.5462 - val_accuracy: 0.7273 - val_metrics_recall: 0.3377 - val_metrics_precision: 0.6945 - val_metrics_f1: 0.4454\n",
            "Epoch 16/19\n",
            "31/31 [==============================] - 3s 89ms/step - loss: 0.4497 - accuracy: 0.7846 - metrics_recall: 0.5640 - metrics_precision: 0.7081 - metrics_f1: 0.6179 - val_loss: 0.5449 - val_accuracy: 0.7295 - val_metrics_recall: 0.4588 - val_metrics_precision: 0.6165 - val_metrics_f1: 0.5210\n",
            "Epoch 17/19\n",
            "31/31 [==============================] - 3s 90ms/step - loss: 0.4407 - accuracy: 0.7993 - metrics_recall: 0.6089 - metrics_precision: 0.7355 - metrics_f1: 0.6494 - val_loss: 0.5463 - val_accuracy: 0.7195 - val_metrics_recall: 0.4056 - val_metrics_precision: 0.6162 - val_metrics_f1: 0.4844\n",
            "Epoch 18/19\n",
            "31/31 [==============================] - 3s 95ms/step - loss: 0.4084 - accuracy: 0.8095 - metrics_recall: 0.6306 - metrics_precision: 0.7796 - metrics_f1: 0.6900 - val_loss: 0.5581 - val_accuracy: 0.6984 - val_metrics_recall: 0.4593 - val_metrics_precision: 0.5468 - val_metrics_f1: 0.4953\n",
            "Epoch 19/19\n",
            "31/31 [==============================] - 3s 95ms/step - loss: 0.3789 - accuracy: 0.8306 - metrics_recall: 0.7027 - metrics_precision: 0.7839 - metrics_f1: 0.7336 - val_loss: 0.5763 - val_accuracy: 0.6863 - val_metrics_recall: 0.6196 - val_metrics_precision: 0.5147 - val_metrics_f1: 0.5589\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb3c9398650>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJVL4SBLPB2P"
      },
      "source": [
        "#%tensorboard --logdir {logs_base_dir}"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_LnvWBcnoak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9a4879b-9708-43c6-a375-b9ea6dfcd120"
      },
      "source": [
        "#results = model.evaluate(nppadded_testing, nptesting_labels, batch_size=batch_size)\n",
        "#print(\"test loss, test acc:\",results)\n",
        "\n",
        "(loss,accuracy, metrics_recall,metrics_precision,\n",
        "metrics_f1) = CNN1605210290AEBN.evaluate(nppadded_testing, nptesting_labels, verbose=1)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "111/111 [==============================] - 1s 9ms/step - loss: 0.6163 - accuracy: 0.6687 - metrics_recall: 0.4722 - metrics_precision: 0.5219 - metrics_f1: 0.4833\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KgjIkhpKmHc"
      },
      "source": [
        "make some predictions of test data and save it to variable. verbose=0 -> do not generate output\n",
        "Gute Quelle: https://deeplizard.com/learn/video/2f-NjDUvZIE "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89GWuxryKlcM"
      },
      "source": [
        "CNN_predictions90AEBN = CNN1605210290AEBN.predict(x=nppadded_testing)\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3jPDaDJK_cN"
      },
      "source": [
        "#for p in CNN_predictions90AEBN:\n",
        " # print(p)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eC9efJy4Lp21"
      },
      "source": [
        "rounded predictions: give prediction value of most likely prediction (0 or 1). Printing the output of rounded prediction shows the prediction made by the model on the data (which output is most likely)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsG-TJuQLvtk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "914a00c8-4127-4643-e7f0-3b1dff0f386d"
      },
      "source": [
        "prediction_rounded90AEBN = np.round(CNN_predictions90AEBN)\n",
        "#np.argmax(CNN_predictions90AEBN,axis=-1)\n",
        "\n",
        "#for p in prediction_rounded90AEBN:\n",
        " # print(p)\n",
        "\n",
        "\n",
        "print(nptesting_labels[500:520])\n",
        "print(prediction_rounded90AEBN[500:520])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1]\n",
            "[[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egTtgpXgg8a2"
      },
      "source": [
        "https://deeplizard.com/learn/video/km7pxKy4UHU\n",
        "\n",
        "Quelle der def plot_confusion_matrix: https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSDXf7-_MITy"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0AMs1EzhBU1"
      },
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                        normalize=False,\n",
        "                        title='Confusion matrix',\n",
        "                        cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2JgEnlghCtl"
      },
      "source": [
        "cm = confusion_matrix(y_true=nptesting_labels, y_pred=prediction_rounded90AEBN)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckmF29whhFmX"
      },
      "source": [
        "plot_labels = ['no hatespeech','hatespeech']"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mpSE96rhK7K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "outputId": "ba732c0f-9ee0-478d-dd9f-530280c892a0"
      },
      "source": [
        "plot_confusion_matrix(cm=cm, classes=plot_labels, title='CNN Confusion 90 19 Epochs Batch size 120')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix, without normalization\n",
            "[[1800  530]\n",
            " [ 640  562]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}