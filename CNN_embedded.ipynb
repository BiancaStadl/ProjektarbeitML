{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN embedded.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPBw77OvYBIHKrBg/SC8dNp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BiancaStadl/ProjektarbeitML/blob/main/CNN_embedded.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXDOlIBymF0V"
      },
      "source": [
        "GloVe embeddings taken from:\n",
        "\n",
        "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. [pdf] [bib]\n",
        "\n",
        "hatespeechdata taken from (https://hatespeechdata.com/): Wiegand, M., Siegel, M. and Ruppenhofer, J., 2018. Overview of the GermEval 2018 Shared Task on the Identification of Offensive Language. In: Proceedings of GermEval 2018, 14th Conference on Natural Language Processing (KONVENS 2018). Vienna, Austria: Research Gate. available on: https://github.com/uds-lsv/GermEval-2018-Data (last checked: 09.05.2021)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlBmABDxfqII"
      },
      "source": [
        "wiki detox..https://colab.research.google.com/github/tensorflow/fairness-indicators/blob/master/g3doc/tutorials/Fairness_Indicators_TFCO_Wiki_Case_Study.ipynb#scrollTo=y6T5tlXcdW7J "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3xfitNdliBI"
      },
      "source": [
        "#import matplotlib.pyplot as plt -> für evtl Visualisierungen\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import string\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from keras import losses \n",
        "from keras import optimizers \n",
        "from keras import metrics \n",
        "\n",
        "#!pip install Tokenizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "#!pip install pad_sequences\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import preprocessing\n",
        "#from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTWJQ1iga_vS"
      },
      "source": [
        "Maximale Satzlänge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bq08Me5la_Cc"
      },
      "source": [
        "\n",
        "max_length = 60"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVYBMvYSotTH"
      },
      "source": [
        "url = \"https://github.com/uds-lsv/GermEval-2018-Data/archive/master.zip\"\n",
        "\n",
        "dataset = tf.keras.utils.get_file(\"GermEval-2018-Data-master.zip\", url, \n",
        "                                   extract=True, cache_dir='.',\n",
        "                                    cache_subdir='')\n",
        "\n",
        "dataset_dir = os.path.join(os.path.dirname(dataset), 'GermEval-2018-Data-master')\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cS14OUtfo34V"
      },
      "source": [
        "#os.listdir(dataset_dir)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2X429K6hpOVm"
      },
      "source": [
        "training_file = os.path.join(dataset_dir, 'germeval2018.training.txt')\n",
        "\n",
        "testing_file = os.path.join(dataset_dir, 'germeval2018.test.txt')\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uq8fG3LNtn_m"
      },
      "source": [
        "###Aufbereitung\n",
        "txt-Dateien lesen, und dabei jede Zeile splitten und teilen\n",
        "Twitter-Handler entfernen?\n",
        "Labels von Sätzen trennen, Labels in eigenen Array packen.\n",
        "\n",
        "####Ressourcen\n",
        "* https://www.w3schools.com/python/gloss_python_if_statement.asp\n",
        "* https://stackabuse.com/using-regex-for-text-manipulation-in-python/\n",
        "* https://www.tutorialspoint.com/python/string_splitlines.htm \n",
        "* https://note.nkmk.me/en/python-split-rsplit-splitlines-re/ \n",
        "* https://www.w3schools.com/python/python_regex.asp \n",
        "\n",
        "gäbe bei keras tf.keras.preprocessing.text_dataset_from_directory, aber dafür müssten die Daten auf bestimmte Weise in Verzeichnis organisiert sein, hier nicht der Fall.\n",
        "\n",
        "\n",
        "Einteilung der Daten: Testdaten\n",
        "Trainingsdaten -> noch ca 500 für Validierungsdaten\n",
        "\n",
        "labels -> \"other\", also nicht-negative Aussagen bekommen \"0\", negative Aussagen bekommen \"1\"\n",
        "\n",
        " Regex für Emojis  ->\n",
        "\n",
        "(\\u00a9|\\u00ae|[\\u2000-\\u3300]|\\ud83c[\\ud000-\\udfff]|\\ud83d[\\ud000-\\udfff]|\\ud83e[\\ud000-\\udfff])\n",
        "\n",
        "genommen von https://www.regextester.com/106421 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Py_cwD4eZkXo"
      },
      "source": [
        "def remove_clutter(string):\n",
        "   string = re.sub(\"@[^\\s]+\",\" \",string)\n",
        "   string = re.sub(\"#[^\\s]+\",\" \", string)\n",
        "   string = re.sub(\"\\u00a9\",\" \", string)\n",
        "   string = re.sub(\"\\u00ae\",\" \", string)\n",
        "   string = re.sub(\"[\\u2000-\\u3300]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83c[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83d[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83e[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"😜\", \" \",string)\n",
        "   string = re.sub(\"🍫\", \" \",string)\n",
        "   string = re.sub(\"😁\", \" \",string)\n",
        "   string = re.sub(\"🐖\", \" \",string)\n",
        "   string = re.sub(\"😡\", \" \",string)\n",
        "   string = re.sub(\"😇\", \" \",string)\n",
        "   string = re.sub(\"😬\", \" \",string)\n",
        "   string = re.sub(\"😃\", \" \",string)\n",
        "   string = re.sub(\"😂\", \" \",string)\n",
        "   string = re.sub(\"💙\", \" \",string)  \n",
        "   string = re.sub(\"😛\", \" \",string)\n",
        "   string = re.sub(\"🙏\", \" \",string)\n",
        "   string = re.sub(\"👍\", \" \",string)\n",
        "   string = re.sub(\"🖕\", \" \",string)\n",
        "   string = re.sub(\"😉\", \" \",string)\n",
        "   string = re.sub(\"💩\", \" \",string)\n",
        "   string = re.sub(\"🤢\", \" \",string)\n",
        "   string = re.sub(\"👏\", \" \",string)\n",
        "   string = re.sub(\"😨\", \" \",string)\n",
        "   string = re.sub(\"🤣\", \" \",string)\n",
        "   string = re.sub(\"🤡\", \" \",string)\n",
        "   string = re.sub(\"😈\", \" \",string)\n",
        "   string = re.sub(\"💃🏽\", \" \",string)\n",
        "   string = re.sub(\"👹\", \" \",string)\n",
        "   string = re.sub(\"🤘\", \" \",string)\n",
        "   string = re.sub(\"😱\", \" \",string)\n",
        "   string = re.sub(\"🤔\", \" \",string) \n",
        "   string = re.sub(\"🌈\", \" \",string) \n",
        "   string = re.sub(\"💕\", \" \",string) \n",
        "   string = re.sub(\"👩‍❤️‍👩\", \" \",string) \n",
        "   string = re.sub(\"😍\", \" \",string) \n",
        "   string = re.sub(\"👆\", \" \",string) \n",
        "   string = re.sub(\"😖\", \" \",string) \n",
        "   string = re.sub(\"👇\", \" \",string) \n",
        "   string = re.sub(\"🔥\", \" \",string) \n",
        "   string = re.sub(\"😘\", \" \",string) \n",
        "   string = re.sub(\"🎉\", \" \",string) \n",
        "   string = re.sub(\"🤬\", \" \",string) \n",
        "   string = re.sub(\"👊\", \" \",string)\n",
        "   string = re.sub(\"🇩🇪\", \" \",string)  \n",
        "   string = re.sub(\"💔\", \" \",string)\n",
        "   string = re.sub(\"🙈\", \" \",string)\n",
        "   string = re.sub(\"🤯\", \" \",string)\n",
        "   string = re.sub(\"🐟\", \" \",string)\n",
        "   string = re.sub(\"🛶\", \" \",string)\n",
        "   string = re.sub(\"😊\", \" \",string)\n",
        "   string = re.sub(\"😓\", \" \",string)\n",
        "   string = re.sub(\"😳\", \" \",string)\n",
        "   string = re.sub(\"🚀\", \" \",string)\n",
        "   string = re.sub(\"👎\", \" \",string)\n",
        "   string = re.sub(\"😎\", \" \",string)\n",
        "   string = re.sub(\"🐸\", \" \",string)\n",
        "   string = re.sub(\"📈\", \" \",string)\n",
        "   string = re.sub(\"🙂\", \" \",string)\n",
        "   string = re.sub(\"😅\", \" \",string)\n",
        "   string = re.sub(\"😆\", \" \",string)\n",
        "   string = re.sub(\"🙎🏿\", \" \",string)\n",
        "   string = re.sub(\"👎🏽\", \" \",string)\n",
        "   string = re.sub(\"🤭\", \" \",string)\n",
        "   string = re.sub(\"😤\", \" \",string)\n",
        "   string = re.sub(\"😚\", \" \",string)\n",
        "   string = re.sub(\"😊\", \" \",string)\n",
        "   string = re.sub(\"😲\", \" \",string)\n",
        "   string = re.sub(\"🤮\", \" \",string)\n",
        "   string = re.sub(\"🙄\", \" \",string)\n",
        "   string = re.sub(\"🤑\", \" \",string)\n",
        "   string = re.sub(\"🎅\", \" \",string)\n",
        "   string = re.sub(\"👋\", \" \",string)\n",
        "   string = re.sub(\"💪\", \" \",string)\n",
        "   string = re.sub(\"😄\", \" \",string)\n",
        "   string = re.sub(\"🧐\", \" \",string)\n",
        "   string = re.sub(\"😠\", \" \",string)\n",
        "   string = re.sub(\"🎈\", \" \",string)\n",
        "   string = re.sub(\"🚂\", \" \",string)\n",
        "   string = re.sub(\"😊\", \" \",string)\n",
        "   string = re.sub(\"🚇\", \" \",string)\n",
        "   string = re.sub(\"🚊\", \" \",string)\n",
        "   string = re.sub(\"🤷\", \" \",string)\n",
        "   string = re.sub(\"😥\", \" \",string)\n",
        "   string = re.sub(\"🙃\", \" \",string)\n",
        "   string = re.sub(\"🔩\", \" \",string)\n",
        "   string = re.sub(\"🔧\", \" \",string)\n",
        "   string = re.sub(\"🔨\", \" \",string)\n",
        "   string = re.sub(\"🛠\", \" \",string)\n",
        "   string = re.sub(\"💓\", \" \",string)\n",
        "   string = re.sub(\"💡\", \" \",string)\n",
        "   string = re.sub(\"🍸\", \" \",string)\n",
        "   string = re.sub(\"🥃\", \" \",string)\n",
        "   string = re.sub(\"🥂\", \" \",string)\n",
        "   string = re.sub(\"😷\", \" \",string)\n",
        "   string = re.sub(\"🤐\", \" \",string)\n",
        "   string = re.sub(\"🌎\", \" \",string)\n",
        "   string = re.sub(\"👑\", \" \",string)\n",
        "   string = re.sub(\"🤛\", \" \",string)\n",
        "   string = re.sub(\"😀\", \" \",string)\n",
        "   string = re.sub(\"🛤\", \" \",string)\n",
        "   string = re.sub(\"🎄\", \" \",string)\n",
        "   string = re.sub(\"📴\", \" \",string)\n",
        "   string = re.sub(\"🌭\", \" \",string)\n",
        "   string = re.sub(\"🤕\", \" \",string)\n",
        "   string = re.sub(\"😭\", \" \",string)\n",
        "   string = re.sub(\"🍾\", \" \",string)\n",
        "   string = re.sub(\"🍞\", \" \",string)\n",
        "   string = re.sub(\"🤦\", \" \",string)\n",
        "   string = re.sub(\"🤯\", \" \",string)\n",
        "   string = re.sub(\"🕯️\", \" \",string)\n",
        "\n",
        "   string = re.sub(\"OTHER|OFFENSE|ABUSE|INSULT\",\" \",string)\n",
        "   return string"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5asMgo4LtnRg"
      },
      "source": [
        "statementsForTraining = []\n",
        "sentimentsForTraining = []\n",
        "\n",
        "\n",
        "fileToRead = open(training_file, 'r')\n",
        "\n",
        "while True:\n",
        "  #next line in file\n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  findSentiment = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "\n",
        "\n",
        "  statementsForTraining.append(line)\n",
        "   #sentimentsForTraining.append(findSentiment.group(0))\n",
        "\n",
        "  if findSentiment.group(0) == \"OTHER\":  \n",
        "    sentimentsForTraining.append(0)\n",
        "  else:\n",
        "    sentimentsForTraining.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        " #print(\"{}: {}\".format(count,line.strip()))\n",
        "  \n",
        " # print(sentiment.group(0))\n",
        " \n",
        "fileToRead.close()\n",
        "\n",
        "training_sentences = statementsForTraining\n",
        "training_labels = sentimentsForTraining\n",
        "\n",
        "#print(training_sentences[9])\n",
        "#print(training_labels[9])\n",
        "\n",
        "#print(len(training_sentences))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsqZPENb98gD"
      },
      "source": [
        "##do the same with testdata\n",
        "statementsForTesting = []\n",
        "sentimentsForTesting = []\n",
        "\n",
        "fileToRead = open(testing_file, 'r')\n",
        "\n",
        "while True:\n",
        "  #next line in file\n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  sent = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "\n",
        "    \n",
        "\n",
        "  statementsForTesting.append(line)\n",
        "  #print(len(line))\n",
        "  #sentimentsForTesting.append(sent.group(0))\n",
        "\n",
        "  if sent.group(0) == \"OTHER\": \n",
        "    sentimentsForTesting.append(0)\n",
        "  else:\n",
        "    sentimentsForTesting.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        "\n",
        "fileToRead.close()\n",
        "\n",
        "\n",
        "testing_sentences = statementsForTesting\n",
        "testing_labels = sentimentsForTesting\n",
        "#print(len(testing_sentences))\n",
        "#print(testing_sentences)   \n",
        "#print(testing_labels)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRUvDLD5bMbO"
      },
      "source": [
        "Padding -> im Prinzip die Sätze alle auf die gleiche Länge bringen (in Theorieteil näher drauf eingehen) -> maxlen-Paramter ist für pad_sequences vorhanden, wenn nicht gesetzt -> alles wird auf die Länge des längsten Satzes aufgefüllt -> print(padded(shape)) gibt aus, wie viele Datensätze padded wurden und gibt an, wie viele Tokens der längste Datensatz hat\n",
        "print(padded[x]) gibt einen Satz aus (bereits tokenisiert)\n",
        "\n",
        "Padding -> sowohl für Trainigs- als auch für Testdaten\n",
        "\n",
        "Und: Daten als numpy-Arrays speichern (notwendig für tensorflow).\n",
        "\n",
        " -> Tokenizer https://towardsdatascience.com/text-classification-in-keras-part-2-how-to-use-the-keras-tokenizer-word-representations-fd571674df23 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3hFi7waTv5m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae2f8d94-b2fa-4dd2-ddf7-00e9f27a6d50"
      },
      "source": [
        "tokenizer = Tokenizer(oov_token=\"OOV\")\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "\n",
        "#creating a word index - nur die Trainigsdaten\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "validation_size = 500\n",
        "\n",
        "\n",
        "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "padded_training = pad_sequences(training_sequences, maxlen=max_length, padding='post')\n",
        "print(len(padded_training))\n",
        "\n",
        "validation_sequences = padded_training[0:validation_size]\n",
        "validation_labels = training_labels[0:validation_size]\n",
        "\n",
        "padded_training = padded_training[validation_size:]\n",
        "training_labels = training_labels[validation_size:]\n",
        "\n",
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
        "padded_testing = pad_sequences(testing_sequences, maxlen=max_length,  padding='post')\n",
        "\n",
        "#print(validation_sequences[499])\n",
        "print(padded_training[0])\n",
        "#print(len(validation_labels))\n",
        "#print(len(training_labels))\n",
        "\n",
        "\n",
        "nppadded_training = np.array(padded_training)\n",
        "nptraining_labels = np.array(training_labels)\n",
        "\n",
        "nppadded_validation = np.array(validation_sequences)\n",
        "npvalidation_labels = np.array(validation_labels)\n",
        "\n",
        "nppadded_testing = np.array(padded_testing)\n",
        "nptesting_labels = np.array(testing_labels)\n",
        "\n",
        "\n",
        "print(len(nppadded_training))\n",
        "print(len(nptraining_labels))\n",
        "print(len(word_index))\n",
        "\n",
        "#print(statementsForTraining[2])\n",
        "#print(nppadded_training[4])\n",
        "#print(nppadded_training.shape)\n",
        "#print(nptraining_labels[4])\n",
        "#print(nppadded_testing.shape)\n",
        "#print(word_index) \n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5009\n",
            "[  12 3982   11   41 6706 1040    4    5  202   39    3 2922   49 1360\n",
            "  810  495 3983    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0]\n",
            "4509\n",
            "4509\n",
            "15059\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tL3owrc8THkT"
      },
      "source": [
        "\n",
        "Dann: Embedding mit entweder word2vec oder glove\n",
        "Word2vec-Daten sind hier: http://vectors.nlpl.eu/repository/#\n",
        "Glove -> https://nlp.stanford.edu/projects/glove/ Da mal den Twitter-Vector runtergeladen\n",
        "Wenn Daten in GoogleDrive sind (wäre auch via url möglich..), muss Drive gemounted werden ( https://buomsoo-kim.github.io/colab/2020/05/09/Colab-mounting-google-drive.md/ ) aber auch hier https://enjoymachinelearning.com/posts/colab-with-google-drive/\n",
        "\n",
        "Die Word2vec vectors: http://vectors.nlpl.eu/repository/# \n",
        "\n",
        "glove-zitat:\n",
        "Citing GloVe\n",
        "\n",
        "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. [pdf] [bib]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zuO7T9ZTG57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fe6aa7e-beb3-420e-9f07-2dccc3ff6acf"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "os.listdir(\"/content/drive/MyDrive/Colab Notebooks\")\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['germeval_training.txt',\n",
              " 'glove.twitter.27B.50d.txt',\n",
              " 'glove.twitter.27B.200d.txt',\n",
              " 'glove.6B.200d.txt',\n",
              " 'glove.840B.300d.txt',\n",
              " 'tensorboard.gdoc',\n",
              " 'keras.gdoc',\n",
              " 'Vectorization CNN embedded_limited_vocab.ipynb',\n",
              " 'glove.42B.300d.txt',\n",
              " 'Embedding Glove Vergleich.ipynb',\n",
              " 'CNN embedded_limited_vocab.ipynb',\n",
              " 'LSTM_limited_vocab.ipynb',\n",
              " 'LSTM.ipynb',\n",
              " 'CNN embedded.ipynb']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7ToKO-sZLHK"
      },
      "source": [
        "\n",
        "Keras-Doc : https://keras.io/examples/nlp/pretrained_word_embeddings/#load-pretrained-word-embeddings \n",
        "embedding mit initializers.. weights müsste auch funktionieren\n",
        "\n",
        "Diese erstellte Matrix mit Embedding dann in die Embedding-Schicht einbinden,  Trainable auf False, weil sich die Werte nicht durch Training anpassen sollen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AShIVfC7ZQAH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5336ddf6-1d56-4b8c-caaf-a0a748593d7e"
      },
      "source": [
        "#Größe Vokabel -> wordindex + 2 (weil padding + OOV) \n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "vocabulary_size = len(word_index)+2\n",
        "\n",
        "# dann erstell ich ein Wörterbuch mit Namen \"embedding_vector\", dort sind dann\n",
        "#die keys drinnen, die in glove-Datei drinnen sind mit dem entsprechenden Key\n",
        "\n",
        "embedding_index_glove = {}\n",
        "f = open('/content/drive/MyDrive/Colab Notebooks/glove.twitter.27B.200d.txt')\n",
        "for line in f:\n",
        "  value = line.split()\n",
        "  word = value[0]\n",
        "  coef = np.asarray(value[1:],dtype='float32')\n",
        "  embedding_index_glove[word] = coef\n",
        "\n",
        "print(\"%d gefunden: \"% len(embedding_index_glove))\n",
        "\n",
        "#Dann noch eine Embedding-Matrix erstellen\n",
        "#zweiter Wert = Embedding-Dimension der Datei, in dem Fall 200\n",
        "\n",
        "glove_matrix = np.zeros((vocabulary_size,200))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    embedding_value = embedding_index_glove.get(word)\n",
        "    if embedding_value is not None:\n",
        "      glove_matrix[index] = embedding_value\n",
        "      hits+=1\n",
        "    else:\n",
        "      misses+=1\n",
        "\n",
        "print(\"hits %d and %d misses\"%(hits,misses))\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1193514 gefunden: \n",
            "hits 6747 and 8312 misses\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZmvOfwhV4N5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71b992bf-fddf-42a1-c270-723416d48ea3"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "print(\"vocab size: %d\"%vocabulary_size)\n",
        "CNN16052103 = tf.keras.Sequential()\n",
        "#Embedding -> hier dann auf das embedding verweisen, Input_dim -> die Anzahl der Wörter im word_index, output -> in dem Fall passend zum verwendeten Vektor\n",
        "#input-length -> auf 60  gepadded, trainable -> nein, weil nichts verändert werden soll\n",
        "#embeddings_initializer=keras.initializers.Constant(glove_matrix) vs weights = [glove_matrix]\n",
        "#Convolutional layers => filters = neurons.. mit 100? 265?\n",
        "CNN16052103.add(tf.keras.layers.Embedding(vocabulary_size, output_dim=200, input_length=60, embeddings_initializer = keras.initializers.Constant(glove_matrix), trainable= False))\n",
        "CNN16052103.add(tf.keras.layers.Dropout(0.4))\n",
        "CNN16052103.add(tf.keras.layers.Conv1D(filters=50, kernel_size=3, padding=\"valid\", activation=\"relu\"))\n",
        "CNN16052103.add(tf.keras.layers.MaxPooling1D())\n",
        "CNN16052103.add(tf.keras.layers.Conv1D(filters=50, kernel_size=3, padding=\"valid\", activation=\"relu\"))\n",
        "CNN16052103.add(tf.keras.layers.GlobalAveragePooling1D())\n",
        "CNN16052103.add(tf.keras.layers.Flatten())\n",
        "CNN16052103.add(tf.keras.layers.Dense(260, activation=\"relu\"))\n",
        "CNN16052103.add(tf.keras.layers.Dropout(0.4))\n",
        "CNN16052103.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "CNN16052103.summary()\n",
        "\n",
        "#nppadded_training = np.asmatrix(nppadded_training) not necessary\n",
        "#nppadded_testing = np.asmatrix(nppadded_testing)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab size: 15061\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 60, 200)           3012200   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 60, 200)           0         \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 58, 50)            30050     \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 29, 50)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 27, 50)            7550      \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 260)               13260     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 260)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 261       \n",
            "=================================================================\n",
            "Total params: 3,063,321\n",
            "Trainable params: 51,121\n",
            "Non-trainable params: 3,012,200\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEr4OzT-iHDe"
      },
      "source": [
        "#model.layers[2].get_weights()[0].shape\n",
        "#weights=np.random.rand(5,200,100)\n",
        "#bias=np.random.rand(100)\n",
        "#model.layers[2].set_weights([weights, bias])\n",
        "\n",
        "#model.layers[2].get_weights()[0]\n",
        "#https://androidkt.com/set-custom-weights-keras-using-numpy-array/"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UB7_3VPYesr9"
      },
      "source": [
        "F1-Score für jede Epoche https://aakashgoel12.medium.com/how-to-add-user-defined-function-get-f1-score-in-keras-metrics-3013f979ce0d\n",
        "\n",
        "Sehr gute Ressource für die verschiedenen Scores und Metriken https://neptune.ai/blog/evaluation-metrics-binary-classification#10  das und aakas verwendet\n",
        "\n",
        "hier: je eine Funktion für Recall, Precision, f1 https://neptune.ai/blog/keras-metrics \n",
        "\n",
        "https://keras.rstudio.com/reference/k_ones_like.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygyrbFJaMV9B"
      },
      "source": [
        "import keras.backend as K\n",
        "\n",
        "def metrics_recall(data_true, data_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(data_true,0,1)))\n",
        "\n",
        "    recall = true_positives / (possible_positives+K.epsilon())\n",
        "    return recall\n",
        "\n",
        "\n",
        "def metrics_precision(data_true, data_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "\n",
        "    positives_predicted = K.sum(K.round(K.clip(data_pred,0,1)))\n",
        "    precision = true_positives / (positives_predicted+K.epsilon())\n",
        "    return precision\n",
        "\n",
        "\n",
        "def metrics_f1(data_true, data_pred):\n",
        "    precision_data = metrics_precision(data_true, data_pred)\n",
        "    recall_data = metrics_recall(data_true, data_pred)\n",
        "    return 2*(precision_data*recall_data)/(precision_data+recall_data+K.epsilon())"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1ctlBrnuYJz"
      },
      "source": [
        "https://aakashgoel12.medium.com/how-to-add-user-defined-function-get-f1-score-in-keras-metrics-3013f979ce0d"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AfPD3_bWCm0"
      },
      "source": [
        "CNN16052103.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',metrics_recall,metrics_precision,metrics_f1])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpChKUY-QEWI"
      },
      "source": [
        "https://www.tensorflow.org/tensorboard/tensorboard_in_notebooks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJfMgUhHBoD1"
      },
      "source": [
        "#%reload_ext tensorboard\n",
        "#nur einmal pro Sitzung notwendig\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ISmMXLqP8Hc"
      },
      "source": [
        "\n",
        "logs_base_dir = \"./logs\"\n",
        "callbackForTB = tf.keras.callbacks.TensorBoard(logs_base_dir)\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2CHbXiP1LsF"
      },
      "source": [
        "training_epochs = 30\n",
        "batch_size = 40\n",
        "validation_split=0.2"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abV-QAxfW48r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5def7734-c273-45c5-c45e-659fd0181b49"
      },
      "source": [
        "#Werte der Convolutional-Schichten variieren (Filter), Batch-Size variieren, kernel-size..\n",
        "CNN16052103.fit(nppadded_training, nptraining_labels, batch_size=batch_size, validation_split=validation_split, epochs=training_epochs, callbacks=[callbackForTB])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "91/91 [==============================] - 4s 32ms/step - loss: 0.6591 - accuracy: 0.6430 - metrics_recall: 0.0284 - metrics_precision: 0.0440 - metrics_f1: 0.0270 - val_loss: 0.6354 - val_accuracy: 0.6718 - val_metrics_recall: 0.0000e+00 - val_metrics_precision: 0.0000e+00 - val_metrics_f1: 0.0000e+00\n",
            "Epoch 2/30\n",
            "91/91 [==============================] - 2s 27ms/step - loss: 0.6302 - accuracy: 0.6738 - metrics_recall: 1.0708e-04 - metrics_precision: 8.5664e-04 - metrics_f1: 1.9036e-04 - val_loss: 0.6117 - val_accuracy: 0.6718 - val_metrics_recall: 0.0000e+00 - val_metrics_precision: 0.0000e+00 - val_metrics_f1: 0.0000e+00\n",
            "Epoch 3/30\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.6166 - accuracy: 0.6583 - metrics_recall: 0.0535 - metrics_precision: 0.2706 - metrics_f1: 0.0816 - val_loss: 0.5922 - val_accuracy: 0.6741 - val_metrics_recall: 0.0311 - val_metrics_precision: 0.3043 - val_metrics_f1: 0.0556\n",
            "Epoch 4/30\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.5884 - accuracy: 0.6696 - metrics_recall: 0.1387 - metrics_precision: 0.4511 - metrics_f1: 0.1964 - val_loss: 0.5701 - val_accuracy: 0.7129 - val_metrics_recall: 0.4174 - val_metrics_precision: 0.5971 - val_metrics_f1: 0.4753\n",
            "Epoch 5/30\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.5600 - accuracy: 0.7089 - metrics_recall: 0.4009 - metrics_precision: 0.6230 - metrics_f1: 0.4648 - val_loss: 0.5689 - val_accuracy: 0.6984 - val_metrics_recall: 0.1379 - val_metrics_precision: 0.6087 - val_metrics_f1: 0.2170\n",
            "Epoch 6/30\n",
            "91/91 [==============================] - 3s 30ms/step - loss: 0.5448 - accuracy: 0.7189 - metrics_recall: 0.3304 - metrics_precision: 0.5868 - metrics_f1: 0.3966 - val_loss: 0.5626 - val_accuracy: 0.7206 - val_metrics_recall: 0.3949 - val_metrics_precision: 0.6236 - val_metrics_f1: 0.4653\n",
            "Epoch 7/30\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.5382 - accuracy: 0.7253 - metrics_recall: 0.4515 - metrics_precision: 0.6754 - metrics_f1: 0.5067 - val_loss: 0.5456 - val_accuracy: 0.7173 - val_metrics_recall: 0.3133 - val_metrics_precision: 0.6645 - val_metrics_f1: 0.4070\n",
            "Epoch 8/30\n",
            "91/91 [==============================] - 3s 30ms/step - loss: 0.5163 - accuracy: 0.7352 - metrics_recall: 0.4831 - metrics_precision: 0.6785 - metrics_f1: 0.5415 - val_loss: 0.5359 - val_accuracy: 0.7184 - val_metrics_recall: 0.4842 - val_metrics_precision: 0.5816 - val_metrics_f1: 0.5157\n",
            "Epoch 9/30\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.4910 - accuracy: 0.7572 - metrics_recall: 0.5260 - metrics_precision: 0.7032 - metrics_f1: 0.5745 - val_loss: 0.5390 - val_accuracy: 0.7051 - val_metrics_recall: 0.5688 - val_metrics_precision: 0.5463 - val_metrics_f1: 0.5438\n",
            "Epoch 10/30\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.4692 - accuracy: 0.7697 - metrics_recall: 0.5617 - metrics_precision: 0.7013 - metrics_f1: 0.6043 - val_loss: 0.5525 - val_accuracy: 0.6962 - val_metrics_recall: 0.6632 - val_metrics_precision: 0.5311 - val_metrics_f1: 0.5760\n",
            "Epoch 11/30\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.4629 - accuracy: 0.7738 - metrics_recall: 0.6328 - metrics_precision: 0.7023 - metrics_f1: 0.6414 - val_loss: 0.5294 - val_accuracy: 0.7129 - val_metrics_recall: 0.5503 - val_metrics_precision: 0.5648 - val_metrics_f1: 0.5423\n",
            "Epoch 12/30\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.4424 - accuracy: 0.7866 - metrics_recall: 0.5760 - metrics_precision: 0.7176 - metrics_f1: 0.6076 - val_loss: 0.5526 - val_accuracy: 0.7051 - val_metrics_recall: 0.5885 - val_metrics_precision: 0.5505 - val_metrics_f1: 0.5543\n",
            "Epoch 13/30\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.4003 - accuracy: 0.8209 - metrics_recall: 0.6695 - metrics_precision: 0.7749 - metrics_f1: 0.7027 - val_loss: 0.5399 - val_accuracy: 0.7140 - val_metrics_recall: 0.5512 - val_metrics_precision: 0.5684 - val_metrics_f1: 0.5419\n",
            "Epoch 14/30\n",
            "91/91 [==============================] - 3s 30ms/step - loss: 0.3995 - accuracy: 0.8175 - metrics_recall: 0.6587 - metrics_precision: 0.7748 - metrics_f1: 0.6942 - val_loss: 0.5491 - val_accuracy: 0.7195 - val_metrics_recall: 0.6135 - val_metrics_precision: 0.5734 - val_metrics_f1: 0.5765\n",
            "Epoch 15/30\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.3844 - accuracy: 0.8266 - metrics_recall: 0.6773 - metrics_precision: 0.7966 - metrics_f1: 0.7133 - val_loss: 0.5618 - val_accuracy: 0.7029 - val_metrics_recall: 0.6261 - val_metrics_precision: 0.5444 - val_metrics_f1: 0.5692\n",
            "Epoch 16/30\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.3646 - accuracy: 0.8364 - metrics_recall: 0.6994 - metrics_precision: 0.7842 - metrics_f1: 0.7222 - val_loss: 0.6119 - val_accuracy: 0.6796 - val_metrics_recall: 0.7607 - val_metrics_precision: 0.5073 - val_metrics_f1: 0.5982\n",
            "Epoch 17/30\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.3424 - accuracy: 0.8489 - metrics_recall: 0.7384 - metrics_precision: 0.8071 - metrics_f1: 0.7524 - val_loss: 0.6220 - val_accuracy: 0.6785 - val_metrics_recall: 0.7561 - val_metrics_precision: 0.5071 - val_metrics_f1: 0.5951\n",
            "Epoch 18/30\n",
            "91/91 [==============================] - 3s 30ms/step - loss: 0.3252 - accuracy: 0.8645 - metrics_recall: 0.7797 - metrics_precision: 0.8281 - metrics_f1: 0.7857 - val_loss: 0.5751 - val_accuracy: 0.7395 - val_metrics_recall: 0.5744 - val_metrics_precision: 0.6125 - val_metrics_f1: 0.5766\n",
            "Epoch 19/30\n",
            "91/91 [==============================] - 3s 30ms/step - loss: 0.3183 - accuracy: 0.8558 - metrics_recall: 0.7640 - metrics_precision: 0.8182 - metrics_f1: 0.7791 - val_loss: 0.5587 - val_accuracy: 0.7217 - val_metrics_recall: 0.5696 - val_metrics_precision: 0.5743 - val_metrics_f1: 0.5591\n",
            "Epoch 20/30\n",
            "91/91 [==============================] - 3s 31ms/step - loss: 0.3204 - accuracy: 0.8566 - metrics_recall: 0.7473 - metrics_precision: 0.8273 - metrics_f1: 0.7744 - val_loss: 0.6183 - val_accuracy: 0.6851 - val_metrics_recall: 0.7033 - val_metrics_precision: 0.5130 - val_metrics_f1: 0.5817\n",
            "Epoch 21/30\n",
            "91/91 [==============================] - 3s 31ms/step - loss: 0.3135 - accuracy: 0.8615 - metrics_recall: 0.7764 - metrics_precision: 0.8243 - metrics_f1: 0.7878 - val_loss: 0.6129 - val_accuracy: 0.7162 - val_metrics_recall: 0.5455 - val_metrics_precision: 0.5699 - val_metrics_f1: 0.5451\n",
            "Epoch 22/30\n",
            "91/91 [==============================] - 3s 30ms/step - loss: 0.2858 - accuracy: 0.8757 - metrics_recall: 0.7817 - metrics_precision: 0.8472 - metrics_f1: 0.8019 - val_loss: 0.7073 - val_accuracy: 0.6452 - val_metrics_recall: 0.7414 - val_metrics_precision: 0.4734 - val_metrics_f1: 0.5670\n",
            "Epoch 23/30\n",
            "91/91 [==============================] - 3s 30ms/step - loss: 0.2881 - accuracy: 0.8724 - metrics_recall: 0.8096 - metrics_precision: 0.8284 - metrics_f1: 0.8097 - val_loss: 0.6893 - val_accuracy: 0.6696 - val_metrics_recall: 0.7801 - val_metrics_precision: 0.4986 - val_metrics_f1: 0.5978\n",
            "Epoch 24/30\n",
            "91/91 [==============================] - 3s 30ms/step - loss: 0.2770 - accuracy: 0.8868 - metrics_recall: 0.8329 - metrics_precision: 0.8417 - metrics_f1: 0.8270 - val_loss: 0.7028 - val_accuracy: 0.6552 - val_metrics_recall: 0.7609 - val_metrics_precision: 0.4821 - val_metrics_f1: 0.5799\n",
            "Epoch 25/30\n",
            "91/91 [==============================] - 3s 31ms/step - loss: 0.2656 - accuracy: 0.8820 - metrics_recall: 0.8158 - metrics_precision: 0.8423 - metrics_f1: 0.8175 - val_loss: 0.6328 - val_accuracy: 0.7251 - val_metrics_recall: 0.5559 - val_metrics_precision: 0.5888 - val_metrics_f1: 0.5561\n",
            "Epoch 26/30\n",
            "91/91 [==============================] - 3s 30ms/step - loss: 0.2558 - accuracy: 0.8861 - metrics_recall: 0.8060 - metrics_precision: 0.8491 - metrics_f1: 0.8187 - val_loss: 0.7160 - val_accuracy: 0.6696 - val_metrics_recall: 0.6475 - val_metrics_precision: 0.4929 - val_metrics_f1: 0.5501\n",
            "Epoch 27/30\n",
            "91/91 [==============================] - 3s 31ms/step - loss: 0.2520 - accuracy: 0.8924 - metrics_recall: 0.8216 - metrics_precision: 0.8508 - metrics_f1: 0.8280 - val_loss: 0.7749 - val_accuracy: 0.7262 - val_metrics_recall: 0.3384 - val_metrics_precision: 0.6558 - val_metrics_f1: 0.4256\n",
            "Epoch 28/30\n",
            "91/91 [==============================] - 3s 31ms/step - loss: 0.2919 - accuracy: 0.8824 - metrics_recall: 0.8153 - metrics_precision: 0.8683 - metrics_f1: 0.8233 - val_loss: 0.6347 - val_accuracy: 0.7106 - val_metrics_recall: 0.5214 - val_metrics_precision: 0.5562 - val_metrics_f1: 0.5270\n",
            "Epoch 29/30\n",
            "91/91 [==============================] - 3s 31ms/step - loss: 0.2405 - accuracy: 0.9010 - metrics_recall: 0.8279 - metrics_precision: 0.8707 - metrics_f1: 0.8409 - val_loss: 0.7270 - val_accuracy: 0.6574 - val_metrics_recall: 0.7449 - val_metrics_precision: 0.4835 - val_metrics_f1: 0.5766\n",
            "Epoch 30/30\n",
            "91/91 [==============================] - 3s 31ms/step - loss: 0.2354 - accuracy: 0.9084 - metrics_recall: 0.8647 - metrics_precision: 0.8755 - metrics_f1: 0.8594 - val_loss: 0.6844 - val_accuracy: 0.7195 - val_metrics_recall: 0.5076 - val_metrics_precision: 0.5716 - val_metrics_f1: 0.5290\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fad24753250>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJVL4SBLPB2P"
      },
      "source": [
        "#%tensorboard --logdir {logs_base_dir}"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_LnvWBcnoak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ceafeb2a-442c-4431-9ad6-35e663c5b523"
      },
      "source": [
        "#results = model.evaluate(nppadded_testing, nptesting_labels, batch_size=batch_size)\n",
        "#print(\"test loss, test acc:\",results)\n",
        "\n",
        "(loss,accuracy, metrics_recall,metrics_precision,\n",
        "metrics_f1) = CNN16052103.evaluate(nppadded_testing, nptesting_labels, verbose=1)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "111/111 [==============================] - 1s 6ms/step - loss: 0.7351 - accuracy: 0.6815 - metrics_recall: 0.4294 - metrics_precision: 0.5382 - metrics_f1: 0.4610\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KgjIkhpKmHc"
      },
      "source": [
        "make some predictions of test data and save it to variable. verbose=0 -> do not generate output\n",
        "Gute Quelle: https://deeplizard.com/learn/video/2f-NjDUvZIE "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89GWuxryKlcM"
      },
      "source": [
        "CNN_predictions03 = CNN16052103.predict(x=nppadded_testing)\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3jPDaDJK_cN"
      },
      "source": [
        "#for p in CNN_predictions03:\n",
        " # print(p)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eC9efJy4Lp21"
      },
      "source": [
        "rounded predictions: give prediction value of most likely prediction (0 or 1). Printing the output of rounded prediction shows the prediction made by the model on the data (which output is most likely)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsG-TJuQLvtk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ece850c8-0de0-4354-8a88-35f07c3e9d9d"
      },
      "source": [
        "prediction_rounded03 = np.round(CNN_predictions03)\n",
        "#np.argmax(CNN_predictions03,axis=-1)\n",
        "\n",
        "#for p in prediction_rounded03:\n",
        " # print(p)\n",
        "\n",
        "\n",
        "print(nptesting_labels[500:520])\n",
        "print(prediction_rounded03[500:520])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1]\n",
            "[[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egTtgpXgg8a2"
      },
      "source": [
        "https://deeplizard.com/learn/video/km7pxKy4UHU\n",
        "\n",
        "Quelle der def plot_confusion_matrix: https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSDXf7-_MITy"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0AMs1EzhBU1"
      },
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                        normalize=False,\n",
        "                        title='Confusion matrix',\n",
        "                        cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2JgEnlghCtl"
      },
      "source": [
        "cm = confusion_matrix(y_true=nptesting_labels, y_pred=prediction_rounded03)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckmF29whhFmX"
      },
      "source": [
        "plot_labels = ['no hatespeech','hatespeech']"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "2mpSE96rhK7K",
        "outputId": "63675ff3-cc10-4bde-ffce-1d974f26b689"
      },
      "source": [
        "plot_confusion_matrix(cm=cm, classes=plot_labels, title='CNN Confusion 50')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix, without normalization\n",
            "[[1894  436]\n",
            " [ 689  513]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}