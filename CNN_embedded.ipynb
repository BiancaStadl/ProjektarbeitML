{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN embedded.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO6pwaZHia7E2UhvpipVpfK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BiancaStadl/ProjektarbeitML/blob/main/CNN_embedded.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXDOlIBymF0V"
      },
      "source": [
        "GloVe embeddings taken from:\n",
        "\n",
        "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. [pdf] [bib]\n",
        "\n",
        "hatespeechdata taken from (https://hatespeechdata.com/): Wiegand, M., Siegel, M. and Ruppenhofer, J., 2018. Overview of the GermEval 2018 Shared Task on the Identification of Offensive Language. In: Proceedings of GermEval 2018, 14th Conference on Natural Language Processing (KONVENS 2018). Vienna, Austria: Research Gate. available on: https://github.com/uds-lsv/GermEval-2018-Data (last checked: 09.05.2021)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlBmABDxfqII"
      },
      "source": [
        "wiki detox..https://colab.research.google.com/github/tensorflow/fairness-indicators/blob/master/g3doc/tutorials/Fairness_Indicators_TFCO_Wiki_Case_Study.ipynb#scrollTo=y6T5tlXcdW7J "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3xfitNdliBI"
      },
      "source": [
        "#import matplotlib.pyplot as plt -> für evtl Visualisierungen\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import string\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from keras import losses \n",
        "from keras import optimizers \n",
        "from keras import metrics \n",
        "\n",
        "#!pip install Tokenizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "#!pip install pad_sequences\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import preprocessing\n",
        "#from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTWJQ1iga_vS"
      },
      "source": [
        "Maximale Satzlänge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bq08Me5la_Cc"
      },
      "source": [
        "\n",
        "max_length = 60"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVYBMvYSotTH"
      },
      "source": [
        "url = \"https://github.com/uds-lsv/GermEval-2018-Data/archive/master.zip\"\n",
        "\n",
        "dataset = tf.keras.utils.get_file(\"GermEval-2018-Data-master.zip\", url, \n",
        "                                   extract=True, cache_dir='.',\n",
        "                                    cache_subdir='')\n",
        "\n",
        "dataset_dir = os.path.join(os.path.dirname(dataset), 'GermEval-2018-Data-master')\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cS14OUtfo34V"
      },
      "source": [
        "#os.listdir(dataset_dir)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2X429K6hpOVm"
      },
      "source": [
        "training_file = os.path.join(dataset_dir, 'germeval2018.training.txt')\n",
        "\n",
        "testing_file = os.path.join(dataset_dir, 'germeval2018.test.txt')\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uq8fG3LNtn_m"
      },
      "source": [
        "###Aufbereitung\n",
        "txt-Dateien lesen, und dabei jede Zeile splitten und teilen\n",
        "Twitter-Handler entfernen?\n",
        "Labels von Sätzen trennen, Labels in eigenen Array packen.\n",
        "\n",
        "####Ressourcen\n",
        "* https://www.w3schools.com/python/gloss_python_if_statement.asp\n",
        "* https://stackabuse.com/using-regex-for-text-manipulation-in-python/\n",
        "* https://www.tutorialspoint.com/python/string_splitlines.htm \n",
        "* https://note.nkmk.me/en/python-split-rsplit-splitlines-re/ \n",
        "* https://www.w3schools.com/python/python_regex.asp \n",
        "\n",
        "gäbe bei keras tf.keras.preprocessing.text_dataset_from_directory, aber dafür müssten die Daten auf bestimmte Weise in Verzeichnis organisiert sein, hier nicht der Fall.\n",
        "\n",
        "\n",
        "Einteilung der Daten: Testdaten\n",
        "Trainingsdaten -> noch ca 500 für Validierungsdaten\n",
        "\n",
        "labels -> \"other\", also nicht-negative Aussagen bekommen \"0\", negative Aussagen bekommen \"1\"\n",
        "\n",
        " Regex für Emojis  ->\n",
        "\n",
        "(\\u00a9|\\u00ae|[\\u2000-\\u3300]|\\ud83c[\\ud000-\\udfff]|\\ud83d[\\ud000-\\udfff]|\\ud83e[\\ud000-\\udfff])\n",
        "\n",
        "genommen von https://www.regextester.com/106421 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Py_cwD4eZkXo"
      },
      "source": [
        "def remove_clutter(string):\n",
        "   string = re.sub(\"@[^\\s]+\",\" \",string)\n",
        "   string = re.sub(\"#[^\\s]+\",\" \", string)\n",
        "   string = re.sub(\"\\u00a9\",\" \", string)\n",
        "   string = re.sub(\"\\u00ae\",\" \", string)\n",
        "   string = re.sub(\"[\\u2000-\\u3300]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83c[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83d[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83e[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"😜\", \" \",string)\n",
        "   string = re.sub(\"🍫\", \" \",string)\n",
        "   string = re.sub(\"😁\", \" \",string)\n",
        "   string = re.sub(\"🐖\", \" \",string)\n",
        "   string = re.sub(\"😡\", \" \",string)\n",
        "   string = re.sub(\"😇\", \" \",string)\n",
        "   string = re.sub(\"😬\", \" \",string)\n",
        "   string = re.sub(\"😃\", \" \",string)\n",
        "   string = re.sub(\"😂\", \" \",string)\n",
        "   string = re.sub(\"💙\", \" \",string)  \n",
        "   string = re.sub(\"😛\", \" \",string)\n",
        "   string = re.sub(\"🙏\", \" \",string)\n",
        "   string = re.sub(\"👍\", \" \",string)\n",
        "   string = re.sub(\"🖕\", \" \",string)\n",
        "   string = re.sub(\"😉\", \" \",string)\n",
        "   string = re.sub(\"💩\", \" \",string)\n",
        "   string = re.sub(\"🤢\", \" \",string)\n",
        "   string = re.sub(\"👏\", \" \",string)\n",
        "   string = re.sub(\"😨\", \" \",string)\n",
        "   string = re.sub(\"🤣\", \" \",string)\n",
        "   string = re.sub(\"🤡\", \" \",string)\n",
        "   string = re.sub(\"😈\", \" \",string)\n",
        "   string = re.sub(\"💃🏽\", \" \",string)\n",
        "   string = re.sub(\"👹\", \" \",string)\n",
        "   string = re.sub(\"🤘\", \" \",string)\n",
        "   string = re.sub(\"😱\", \" \",string)\n",
        "   string = re.sub(\"🤔\", \" \",string) \n",
        "   string = re.sub(\"🌈\", \" \",string) \n",
        "   string = re.sub(\"💕\", \" \",string) \n",
        "   string = re.sub(\"👩‍❤️‍👩\", \" \",string) \n",
        "   string = re.sub(\"😍\", \" \",string) \n",
        "   string = re.sub(\"👆\", \" \",string) \n",
        "   string = re.sub(\"😖\", \" \",string) \n",
        "   string = re.sub(\"👇\", \" \",string) \n",
        "   string = re.sub(\"🔥\", \" \",string) \n",
        "   string = re.sub(\"😘\", \" \",string) \n",
        "   string = re.sub(\"🎉\", \" \",string) \n",
        "   string = re.sub(\"🤬\", \" \",string) \n",
        "   string = re.sub(\"👊\", \" \",string)\n",
        "   string = re.sub(\"🇩🇪\", \" \",string)  \n",
        "   string = re.sub(\"💔\", \" \",string)\n",
        "   string = re.sub(\"🙈\", \" \",string)\n",
        "   string = re.sub(\"🤯\", \" \",string)\n",
        "   string = re.sub(\"🐟\", \" \",string)\n",
        "   string = re.sub(\"🛶\", \" \",string)\n",
        "   string = re.sub(\"😊\", \" \",string)\n",
        "   string = re.sub(\"😓\", \" \",string)\n",
        "   string = re.sub(\"😳\", \" \",string)\n",
        "   string = re.sub(\"🚀\", \" \",string)\n",
        "   string = re.sub(\"👎\", \" \",string)\n",
        "   string = re.sub(\"😎\", \" \",string)\n",
        "   string = re.sub(\"🐸\", \" \",string)\n",
        "   string = re.sub(\"📈\", \" \",string)\n",
        "   string = re.sub(\"🙂\", \" \",string)\n",
        "   string = re.sub(\"😅\", \" \",string)\n",
        "   string = re.sub(\"😆\", \" \",string)\n",
        "   string = re.sub(\"🙎🏿\", \" \",string)\n",
        "   string = re.sub(\"👎🏽\", \" \",string)\n",
        "   string = re.sub(\"🤭\", \" \",string)\n",
        "   string = re.sub(\"😤\", \" \",string)\n",
        "   string = re.sub(\"😚\", \" \",string)\n",
        "   string = re.sub(\"😊\", \" \",string)\n",
        "   string = re.sub(\"😲\", \" \",string)\n",
        "   string = re.sub(\"🤮\", \" \",string)\n",
        "   string = re.sub(\"🙄\", \" \",string)\n",
        "   string = re.sub(\"🤑\", \" \",string)\n",
        "   string = re.sub(\"🎅\", \" \",string)\n",
        "   string = re.sub(\"👋\", \" \",string)\n",
        "   string = re.sub(\"💪\", \" \",string)\n",
        "   string = re.sub(\"😄\", \" \",string)\n",
        "   string = re.sub(\"🧐\", \" \",string)\n",
        "   string = re.sub(\"😠\", \" \",string)\n",
        "   string = re.sub(\"🎈\", \" \",string)\n",
        "   string = re.sub(\"🚂\", \" \",string)\n",
        "   string = re.sub(\"😊\", \" \",string)\n",
        "   string = re.sub(\"🚇\", \" \",string)\n",
        "   string = re.sub(\"🚊\", \" \",string)\n",
        "   string = re.sub(\"🤷\", \" \",string)\n",
        "   string = re.sub(\"😥\", \" \",string)\n",
        "   string = re.sub(\"🙃\", \" \",string)\n",
        "   string = re.sub(\"🔩\", \" \",string)\n",
        "   string = re.sub(\"🔧\", \" \",string)\n",
        "   string = re.sub(\"🔨\", \" \",string)\n",
        "   string = re.sub(\"🛠\", \" \",string)\n",
        "   string = re.sub(\"💓\", \" \",string)\n",
        "   string = re.sub(\"💡\", \" \",string)\n",
        "   string = re.sub(\"🍸\", \" \",string)\n",
        "   string = re.sub(\"🥃\", \" \",string)\n",
        "   string = re.sub(\"🥂\", \" \",string)\n",
        "   string = re.sub(\"😷\", \" \",string)\n",
        "   string = re.sub(\"🤐\", \" \",string)\n",
        "   string = re.sub(\"🌎\", \" \",string)\n",
        "   string = re.sub(\"👑\", \" \",string)\n",
        "   string = re.sub(\"🤛\", \" \",string)\n",
        "   string = re.sub(\"😀\", \" \",string)\n",
        "   string = re.sub(\"🛤\", \" \",string)\n",
        "   string = re.sub(\"🎄\", \" \",string)\n",
        "   string = re.sub(\"📴\", \" \",string)\n",
        "   string = re.sub(\"🌭\", \" \",string)\n",
        "   string = re.sub(\"🤕\", \" \",string)\n",
        "   string = re.sub(\"😭\", \" \",string)\n",
        "   string = re.sub(\"🍾\", \" \",string)\n",
        "   string = re.sub(\"🍞\", \" \",string)\n",
        "   string = re.sub(\"🤦\", \" \",string)\n",
        "   string = re.sub(\"🤯\", \" \",string)\n",
        "   string = re.sub(\"🕯️\", \" \",string)\n",
        "\n",
        "   string = re.sub(\"OTHER|OFFENSE|ABUSE|INSULT\",\" \",string)\n",
        "   return string"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5asMgo4LtnRg"
      },
      "source": [
        "statementsForTraining = []\n",
        "sentimentsForTraining = []\n",
        "\n",
        "\n",
        "fileToRead = open(training_file, 'r')\n",
        "\n",
        "while True:\n",
        "  #next line in file\n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  findSentiment = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "\n",
        "\n",
        "  statementsForTraining.append(line)\n",
        "   #sentimentsForTraining.append(findSentiment.group(0))\n",
        "\n",
        "  if findSentiment.group(0) == \"OTHER\":  \n",
        "    sentimentsForTraining.append(0)\n",
        "  else:\n",
        "    sentimentsForTraining.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        " #print(\"{}: {}\".format(count,line.strip()))\n",
        "  \n",
        " # print(sentiment.group(0))\n",
        " \n",
        "fileToRead.close()\n",
        "\n",
        "training_sentences = statementsForTraining\n",
        "training_labels = sentimentsForTraining\n",
        "\n",
        "#print(training_sentences[9])\n",
        "#print(training_labels[9])\n",
        "\n",
        "#print(len(training_sentences))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsqZPENb98gD"
      },
      "source": [
        "##do the same with testdata\n",
        "statementsForTesting = []\n",
        "sentimentsForTesting = []\n",
        "\n",
        "fileToRead = open(testing_file, 'r')\n",
        "\n",
        "while True:\n",
        "  #next line in file\n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  sent = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "\n",
        "    \n",
        "\n",
        "  statementsForTesting.append(line)\n",
        "  #print(len(line))\n",
        "  #sentimentsForTesting.append(sent.group(0))\n",
        "\n",
        "  if sent.group(0) == \"OTHER\": \n",
        "    sentimentsForTesting.append(0)\n",
        "  else:\n",
        "    sentimentsForTesting.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        "\n",
        "fileToRead.close()\n",
        "\n",
        "\n",
        "testing_sentences = statementsForTesting\n",
        "testing_labels = sentimentsForTesting\n",
        "#print(len(testing_sentences))\n",
        "#print(testing_sentences)   \n",
        "#print(testing_labels)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRUvDLD5bMbO"
      },
      "source": [
        "Padding -> im Prinzip die Sätze alle auf die gleiche Länge bringen (in Theorieteil näher drauf eingehen) -> maxlen-Paramter ist für pad_sequences vorhanden, wenn nicht gesetzt -> alles wird auf die Länge des längsten Satzes aufgefüllt -> print(padded(shape)) gibt aus, wie viele Datensätze padded wurden und gibt an, wie viele Tokens der längste Datensatz hat\n",
        "print(padded[x]) gibt einen Satz aus (bereits tokenisiert)\n",
        "\n",
        "Padding -> sowohl für Trainigs- als auch für Testdaten\n",
        "\n",
        "Und: Daten als numpy-Arrays speichern (notwendig für tensorflow).\n",
        "\n",
        " -> Tokenizer https://towardsdatascience.com/text-classification-in-keras-part-2-how-to-use-the-keras-tokenizer-word-representations-fd571674df23 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3hFi7waTv5m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f643fc4-0dbc-4a74-dbf5-f2e60db4326b"
      },
      "source": [
        "tokenizer = Tokenizer(oov_token=\"OOV\")\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "\n",
        "#creating a word index - nur die Trainigsdaten\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "validation_size = 500\n",
        "\n",
        "\n",
        "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "padded_training = pad_sequences(training_sequences, maxlen=max_length, padding='post')\n",
        "print(len(padded_training))\n",
        "\n",
        "validation_sequences = padded_training[0:validation_size]\n",
        "validation_labels = training_labels[0:validation_size]\n",
        "\n",
        "padded_training = padded_training[validation_size:]\n",
        "training_labels = training_labels[validation_size:]\n",
        "\n",
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
        "padded_testing = pad_sequences(testing_sequences, maxlen=max_length,  padding='post')\n",
        "\n",
        "#print(validation_sequences[499])\n",
        "print(padded_training[0])\n",
        "#print(len(validation_labels))\n",
        "#print(len(training_labels))\n",
        "\n",
        "\n",
        "nppadded_training = np.array(padded_training)\n",
        "nptraining_labels = np.array(training_labels)\n",
        "\n",
        "nppadded_validation = np.array(validation_sequences)\n",
        "npvalidation_labels = np.array(validation_labels)\n",
        "\n",
        "nppadded_testing = np.array(padded_testing)\n",
        "nptesting_labels = np.array(testing_labels)\n",
        "\n",
        "\n",
        "print(len(nppadded_training))\n",
        "print(len(nptraining_labels))\n",
        "print(len(word_index))\n",
        "\n",
        "#print(statementsForTraining[2])\n",
        "#print(nppadded_training[4])\n",
        "#print(nppadded_training.shape)\n",
        "#print(nptraining_labels[4])\n",
        "#print(nppadded_testing.shape)\n",
        "#print(word_index) \n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5009\n",
            "[  12 3982   11   41 6706 1040    4    5  202   39    3 2922   49 1360\n",
            "  810  495 3983    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0]\n",
            "4509\n",
            "4509\n",
            "15059\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tL3owrc8THkT"
      },
      "source": [
        "\n",
        "Dann: Embedding mit entweder word2vec oder glove\n",
        "Word2vec-Daten sind hier: http://vectors.nlpl.eu/repository/#\n",
        "Glove -> https://nlp.stanford.edu/projects/glove/ Da mal den Twitter-Vector runtergeladen\n",
        "Wenn Daten in GoogleDrive sind (wäre auch via url möglich..), muss Drive gemounted werden ( https://buomsoo-kim.github.io/colab/2020/05/09/Colab-mounting-google-drive.md/ ) aber auch hier https://enjoymachinelearning.com/posts/colab-with-google-drive/\n",
        "\n",
        "Die Word2vec vectors: http://vectors.nlpl.eu/repository/# \n",
        "\n",
        "glove-zitat:\n",
        "Citing GloVe\n",
        "\n",
        "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. [pdf] [bib]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zuO7T9ZTG57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18e6b61e-9d07-4f64-93de-a468fdd71722"
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount(\"/content/drive\")\n",
        "os.listdir(\"/content/drive/MyDrive/Colab Notebooks\")\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['germeval_training.txt',\n",
              " 'glove.twitter.27B.50d.txt',\n",
              " 'glove.twitter.27B.200d.txt',\n",
              " 'glove.6B.200d.txt',\n",
              " 'glove.840B.300d.txt',\n",
              " 'tensorboard.gdoc',\n",
              " 'keras.gdoc',\n",
              " 'Vectorization CNN embedded_limited_vocab.ipynb',\n",
              " 'glove.42B.300d.txt',\n",
              " 'Embedding Glove Vergleich.ipynb',\n",
              " 'CNN embedded_limited_vocab.ipynb',\n",
              " 'LSTM_limited_vocab.ipynb',\n",
              " 'LSTM.ipynb',\n",
              " 'CNN embedded.ipynb']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7ToKO-sZLHK"
      },
      "source": [
        "\n",
        "Keras-Doc : https://keras.io/examples/nlp/pretrained_word_embeddings/#load-pretrained-word-embeddings \n",
        "embedding mit initializers.. weights müsste auch funktionieren\n",
        "\n",
        "Diese erstellte Matrix mit Embedding dann in die Embedding-Schicht einbinden,  Trainable auf False, weil sich die Werte nicht durch Training anpassen sollen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AShIVfC7ZQAH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba4ce514-34d4-4e2f-b05e-066cb65c25ef"
      },
      "source": [
        "#Größe Vokabel -> wordindex + 2 (weil padding + OOV) \n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "vocabulary_size = len(word_index)+2\n",
        "\n",
        "# dann erstell ich ein Wörterbuch mit Namen \"embedding_vector\", dort sind dann\n",
        "#die keys drinnen, die in glove-Datei drinnen sind mit dem entsprechenden Key\n",
        "\n",
        "embedding_index_glove = {}\n",
        "f = open('/content/drive/MyDrive/Colab Notebooks/glove.twitter.27B.200d.txt')\n",
        "for line in f:\n",
        "  value = line.split()\n",
        "  word = value[0]\n",
        "  coef = np.asarray(value[1:],dtype='float32')\n",
        "  embedding_index_glove[word] = coef\n",
        "\n",
        "print(\"%d gefunden: \"% len(embedding_index_glove))\n",
        "\n",
        "#Dann noch eine Embedding-Matrix erstellen\n",
        "#zweiter Wert = Embedding-Dimension der Datei, in dem Fall 200\n",
        "\n",
        "glove_matrix = np.zeros((vocabulary_size,200))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    embedding_value = embedding_index_glove.get(word)\n",
        "    if embedding_value is not None:\n",
        "      glove_matrix[index] = embedding_value\n",
        "      hits+=1\n",
        "    else:\n",
        "      misses+=1\n",
        "\n",
        "print(\"hits %d and %d misses\"%(hits,misses))\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1193514 gefunden: \n",
            "hits 6747 and 8312 misses\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZmvOfwhV4N5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77f437c6-5111-4563-9abe-2d142c838afc"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "print(\"vocab size: %d\"%vocabulary_size)\n",
        "CNN1605210290AEBN = tf.keras.Sequential()\n",
        "#Embedding -> hier dann auf das embedding verweisen, Input_dim -> die Anzahl der Wörter im word_index, output -> in dem Fall passend zum verwendeten Vektor\n",
        "#input-length -> auf 60  gepadded, trainable -> nein, weil nichts verändert werden soll\n",
        "#embeddings_initializer=keras.initializers.Constant(glove_matrix) vs weights = [glove_matrix]\n",
        "#Convolutional layers => filters = neurons.. mit 100? 265?\n",
        "#CNN1605210290AEBN.add(tf.keras.layers.Embedding(input_dim=vocabulary_size, output_dim=200, input_length=max_length))\n",
        "CNN1605210290AEBN.add(tf.keras.layers.Embedding(vocabulary_size, output_dim=200, input_length=60, embeddings_initializer = keras.initializers.Constant(glove_matrix), trainable= False))\n",
        "#CNN1605210290AEBN.add(tf.keras.layers.BatchNormalization())\n",
        "CNN1605210290AEBN.add(tf.keras.layers.Dropout(0.4))\n",
        "CNN1605210290AEBN.add(tf.keras.layers.Conv1D(filters=90, kernel_size=3, padding=\"valid\", activation=\"relu\"))\n",
        "#CNN1605210290AEBN.add(tf.keras.layers.BatchNormalization())\n",
        "CNN1605210290AEBN.add(tf.keras.layers.MaxPooling1D())\n",
        "#CNN1605210290AEBN.add(tf.keras.layers.BatchNormalization())\n",
        "CNN1605210290AEBN.add(tf.keras.layers.Conv1D(filters=90, kernel_size=3, padding=\"valid\", activation=\"relu\"))\n",
        "#CNN1605210290AEBN.add(tf.keras.layers.BatchNormalization())\n",
        "CNN1605210290AEBN.add(tf.keras.layers.GlobalAveragePooling1D())\n",
        "#CNN1605210290AEBN.add(tf.keras.layers.BatchNormalization())\n",
        "CNN1605210290AEBN.add(tf.keras.layers.Flatten())\n",
        "#CNN1605210290AEBN.add(tf.keras.layers.BatchNormalization())\n",
        "CNN1605210290AEBN.add(tf.keras.layers.Dense(260, activation=\"relu\"))\n",
        "#CNN1605210290AEBN.add(tf.keras.layers.BatchNormalization())\n",
        "CNN1605210290AEBN.add(tf.keras.layers.Dropout(0.4))\n",
        "CNN1605210290AEBN.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "CNN1605210290AEBN.summary()\n",
        "\n",
        "#nppadded_training = np.asmatrix(nppadded_training) not necessary\n",
        "#nppadded_testing = np.asmatrix(nppadded_testing)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab size: 15061\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 60, 200)           3012200   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 60, 200)           0         \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 58, 90)            54090     \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 29, 90)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 27, 90)            24390     \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 90)                0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 90)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 260)               23660     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 260)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 261       \n",
            "=================================================================\n",
            "Total params: 3,114,601\n",
            "Trainable params: 102,401\n",
            "Non-trainable params: 3,012,200\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEr4OzT-iHDe"
      },
      "source": [
        "#model.layers[2].get_weights()[0].shape\n",
        "#weights=np.random.rand(5,200,100)\n",
        "#bias=np.random.rand(100)\n",
        "#model.layers[2].set_weights([weights, bias])\n",
        "\n",
        "#model.layers[2].get_weights()[0]\n",
        "#https://androidkt.com/set-custom-weights-keras-using-numpy-array/"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UB7_3VPYesr9"
      },
      "source": [
        "F1-Score für jede Epoche https://aakashgoel12.medium.com/how-to-add-user-defined-function-get-f1-score-in-keras-metrics-3013f979ce0d\n",
        "\n",
        "Sehr gute Ressource für die verschiedenen Scores und Metriken https://neptune.ai/blog/evaluation-metrics-binary-classification#10  das und aakas verwendet\n",
        "\n",
        "hier: je eine Funktion für Recall, Precision, f1 https://neptune.ai/blog/keras-metrics \n",
        "\n",
        "https://keras.rstudio.com/reference/k_ones_like.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygyrbFJaMV9B"
      },
      "source": [
        "import keras.backend as K\n",
        "\n",
        "def metrics_recall(data_true, data_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(data_true,0,1)))\n",
        "\n",
        "    recall = true_positives / (possible_positives+K.epsilon())\n",
        "    return recall\n",
        "\n",
        "\n",
        "def metrics_precision(data_true, data_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "\n",
        "    positives_predicted = K.sum(K.round(K.clip(data_pred,0,1)))\n",
        "    precision = true_positives / (positives_predicted+K.epsilon())\n",
        "    return precision\n",
        "\n",
        "\n",
        "def metrics_f1(data_true, data_pred):\n",
        "    precision_data = metrics_precision(data_true, data_pred)\n",
        "    recall_data = metrics_recall(data_true, data_pred)\n",
        "    return 2*(precision_data*recall_data)/(precision_data+recall_data+K.epsilon())"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1ctlBrnuYJz"
      },
      "source": [
        "https://aakashgoel12.medium.com/how-to-add-user-defined-function-get-f1-score-in-keras-metrics-3013f979ce0d"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AfPD3_bWCm0"
      },
      "source": [
        "#CNN1605210290AEBN.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',metrics_recall,metrics_precision,metrics_f1])\n",
        "CNN1605210290AEBN.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',metrics_recall,metrics_precision,metrics_f1])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpChKUY-QEWI"
      },
      "source": [
        "https://www.tensorflow.org/tensorboard/tensorboard_in_notebooks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJfMgUhHBoD1"
      },
      "source": [
        "#%load_ext tensorboard\n",
        "#nur einmal pro Sitzung notwendig\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ISmMXLqP8Hc"
      },
      "source": [
        "\n",
        "logs_base_dir = \"./logs\"\n",
        "callbackForTB = tf.keras.callbacks.TensorBoard(logs_base_dir)\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ehh-EMXUQh8r"
      },
      "source": [
        "Early Stopping as defined in keras tensorflow documentation\n",
        "https://www.tensorflow.org/guide/keras/train_and_evaluate "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BY_t-PeQEjy"
      },
      "source": [
        "callbackEarlyStopping = [\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_loss\",\n",
        "        mode=\"min\",\n",
        "        patience=3,\n",
        "        verbose=1,\n",
        "    )\n",
        "]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2CHbXiP1LsF"
      },
      "source": [
        "training_epochs = 19\n",
        "batch_size = 150\n",
        "validation_split=0.2"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abV-QAxfW48r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "366d0ce5-6850-4cba-a9a5-e8047fd1c96b"
      },
      "source": [
        "#Werte der Convolutional-Schichten variieren (Filter), Batch-Size variieren, kernel-size..\n",
        "CNN1605210290AEBN.fit(nppadded_training, nptraining_labels, batch_size=batch_size, validation_split=validation_split, epochs=training_epochs, callbacks=[callbackForTB])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/19\n",
            "25/25 [==============================] - 4s 125ms/step - loss: 0.6628 - accuracy: 0.6551 - metrics_recall: 0.0269 - metrics_precision: 0.0145 - metrics_f1: 0.0189 - val_loss: 0.6500 - val_accuracy: 0.6718 - val_metrics_recall: 0.0000e+00 - val_metrics_precision: 0.0000e+00 - val_metrics_f1: 0.0000e+00\n",
            "Epoch 2/19\n",
            "25/25 [==============================] - 3s 111ms/step - loss: 0.6463 - accuracy: 0.6626 - metrics_recall: 0.0000e+00 - metrics_precision: 0.0000e+00 - metrics_f1: 0.0000e+00 - val_loss: 0.6438 - val_accuracy: 0.6718 - val_metrics_recall: 0.0000e+00 - val_metrics_precision: 0.0000e+00 - val_metrics_f1: 0.0000e+00\n",
            "Epoch 3/19\n",
            "25/25 [==============================] - 3s 106ms/step - loss: 0.6417 - accuracy: 0.6626 - metrics_recall: 0.0000e+00 - metrics_precision: 0.0000e+00 - metrics_f1: 0.0000e+00 - val_loss: 0.6391 - val_accuracy: 0.6718 - val_metrics_recall: 0.0000e+00 - val_metrics_precision: 0.0000e+00 - val_metrics_f1: 0.0000e+00\n",
            "Epoch 4/19\n",
            "25/25 [==============================] - 3s 113ms/step - loss: 0.6343 - accuracy: 0.6626 - metrics_recall: 0.0000e+00 - metrics_precision: 0.0000e+00 - metrics_f1: 0.0000e+00 - val_loss: 0.6206 - val_accuracy: 0.6718 - val_metrics_recall: 0.0000e+00 - val_metrics_precision: 0.0000e+00 - val_metrics_f1: 0.0000e+00\n",
            "Epoch 5/19\n",
            "25/25 [==============================] - 3s 113ms/step - loss: 0.6253 - accuracy: 0.6596 - metrics_recall: 0.0222 - metrics_precision: 0.1281 - metrics_f1: 0.0345 - val_loss: 0.6071 - val_accuracy: 0.6707 - val_metrics_recall: 0.0000e+00 - val_metrics_precision: 0.0000e+00 - val_metrics_f1: 0.0000e+00\n",
            "Epoch 6/19\n",
            "25/25 [==============================] - 3s 106ms/step - loss: 0.6070 - accuracy: 0.6607 - metrics_recall: 0.0707 - metrics_precision: 0.3078 - metrics_f1: 0.1032 - val_loss: 0.5865 - val_accuracy: 0.6863 - val_metrics_recall: 0.0826 - val_metrics_precision: 0.5739 - val_metrics_f1: 0.1432\n",
            "Epoch 7/19\n",
            "25/25 [==============================] - 3s 111ms/step - loss: 0.5805 - accuracy: 0.6798 - metrics_recall: 0.2184 - metrics_precision: 0.5620 - metrics_f1: 0.2802 - val_loss: 0.6032 - val_accuracy: 0.6918 - val_metrics_recall: 0.1018 - val_metrics_precision: 0.5976 - val_metrics_f1: 0.1699\n",
            "Epoch 8/19\n",
            "25/25 [==============================] - 3s 111ms/step - loss: 0.5846 - accuracy: 0.6853 - metrics_recall: 0.2419 - metrics_precision: 0.6753 - metrics_f1: 0.3089 - val_loss: 0.5784 - val_accuracy: 0.7106 - val_metrics_recall: 0.4272 - val_metrics_precision: 0.5975 - val_metrics_f1: 0.4612\n",
            "Epoch 9/19\n",
            "25/25 [==============================] - 3s 107ms/step - loss: 0.5610 - accuracy: 0.6975 - metrics_recall: 0.3434 - metrics_precision: 0.5721 - metrics_f1: 0.4171 - val_loss: 0.5968 - val_accuracy: 0.7007 - val_metrics_recall: 0.1395 - val_metrics_precision: 0.6059 - val_metrics_f1: 0.2229\n",
            "Epoch 10/19\n",
            "25/25 [==============================] - 3s 113ms/step - loss: 0.5758 - accuracy: 0.6912 - metrics_recall: 0.3453 - metrics_precision: 0.5958 - metrics_f1: 0.3864 - val_loss: 0.5631 - val_accuracy: 0.7129 - val_metrics_recall: 0.2525 - val_metrics_precision: 0.5552 - val_metrics_f1: 0.3428\n",
            "Epoch 11/19\n",
            "25/25 [==============================] - 3s 110ms/step - loss: 0.5354 - accuracy: 0.7189 - metrics_recall: 0.3601 - metrics_precision: 0.6257 - metrics_f1: 0.4515 - val_loss: 0.5607 - val_accuracy: 0.6962 - val_metrics_recall: 0.5878 - val_metrics_precision: 0.5337 - val_metrics_f1: 0.5443\n",
            "Epoch 12/19\n",
            "25/25 [==============================] - 3s 106ms/step - loss: 0.5216 - accuracy: 0.7388 - metrics_recall: 0.5158 - metrics_precision: 0.6648 - metrics_f1: 0.5691 - val_loss: 0.5527 - val_accuracy: 0.7184 - val_metrics_recall: 0.4192 - val_metrics_precision: 0.6268 - val_metrics_f1: 0.4581\n",
            "Epoch 13/19\n",
            "25/25 [==============================] - 3s 111ms/step - loss: 0.5238 - accuracy: 0.7383 - metrics_recall: 0.4638 - metrics_precision: 0.6824 - metrics_f1: 0.5282 - val_loss: 0.5868 - val_accuracy: 0.6486 - val_metrics_recall: 0.7073 - val_metrics_precision: 0.4792 - val_metrics_f1: 0.5660\n",
            "Epoch 14/19\n",
            "25/25 [==============================] - 3s 108ms/step - loss: 0.5175 - accuracy: 0.7316 - metrics_recall: 0.5379 - metrics_precision: 0.6691 - metrics_f1: 0.5613 - val_loss: 0.5472 - val_accuracy: 0.7251 - val_metrics_recall: 0.4304 - val_metrics_precision: 0.6390 - val_metrics_f1: 0.4724\n",
            "Epoch 15/19\n",
            "25/25 [==============================] - 3s 111ms/step - loss: 0.4890 - accuracy: 0.7607 - metrics_recall: 0.5767 - metrics_precision: 0.7170 - metrics_f1: 0.6168 - val_loss: 0.5374 - val_accuracy: 0.7317 - val_metrics_recall: 0.4777 - val_metrics_precision: 0.6332 - val_metrics_f1: 0.5112\n",
            "Epoch 16/19\n",
            "25/25 [==============================] - 3s 106ms/step - loss: 0.4788 - accuracy: 0.7649 - metrics_recall: 0.5454 - metrics_precision: 0.7164 - metrics_f1: 0.5946 - val_loss: 0.5327 - val_accuracy: 0.7306 - val_metrics_recall: 0.5137 - val_metrics_precision: 0.6171 - val_metrics_f1: 0.5301\n",
            "Epoch 17/19\n",
            "25/25 [==============================] - 3s 111ms/step - loss: 0.4686 - accuracy: 0.7743 - metrics_recall: 0.5707 - metrics_precision: 0.7436 - metrics_f1: 0.6293 - val_loss: 0.5335 - val_accuracy: 0.7239 - val_metrics_recall: 0.5080 - val_metrics_precision: 0.6691 - val_metrics_f1: 0.5684\n",
            "Epoch 18/19\n",
            "25/25 [==============================] - 3s 106ms/step - loss: 0.4465 - accuracy: 0.7840 - metrics_recall: 0.5659 - metrics_precision: 0.7002 - metrics_f1: 0.6186 - val_loss: 0.5356 - val_accuracy: 0.7129 - val_metrics_recall: 0.5465 - val_metrics_precision: 0.5682 - val_metrics_f1: 0.5350\n",
            "Epoch 19/19\n",
            "25/25 [==============================] - 3s 111ms/step - loss: 0.4312 - accuracy: 0.7932 - metrics_recall: 0.5991 - metrics_precision: 0.7367 - metrics_f1: 0.6570 - val_loss: 0.5875 - val_accuracy: 0.6851 - val_metrics_recall: 0.7481 - val_metrics_precision: 0.5151 - val_metrics_f1: 0.6041\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb1462b1a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJVL4SBLPB2P"
      },
      "source": [
        "#%tensorboard --logdir {logs_base_dir}"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_LnvWBcnoak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "170850ce-e846-4dea-c6a4-070702e6aff7"
      },
      "source": [
        "#results = model.evaluate(nppadded_testing, nptesting_labels, batch_size=batch_size)\n",
        "#print(\"test loss, test acc:\",results)\n",
        "\n",
        "(loss,accuracy, metrics_recall,metrics_precision,\n",
        "metrics_f1) = CNN1605210290AEBN.evaluate(nppadded_testing, nptesting_labels, verbose=1)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "111/111 [==============================] - 1s 8ms/step - loss: 0.6335 - accuracy: 0.6387 - metrics_recall: 0.5385 - metrics_precision: 0.4762 - metrics_f1: 0.4952\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KgjIkhpKmHc"
      },
      "source": [
        "make some predictions of test data and save it to variable. verbose=0 -> do not generate output\n",
        "Gute Quelle: https://deeplizard.com/learn/video/2f-NjDUvZIE "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89GWuxryKlcM"
      },
      "source": [
        "CNN_predictions90AEBN = CNN1605210290AEBN.predict(x=nppadded_testing)\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3jPDaDJK_cN"
      },
      "source": [
        "#for p in CNN_predictions90AEBN:\n",
        " # print(p)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eC9efJy4Lp21"
      },
      "source": [
        "rounded predictions: give prediction value of most likely prediction (0 or 1). Printing the output of rounded prediction shows the prediction made by the model on the data (which output is most likely)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsG-TJuQLvtk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45c09a8c-4fed-47b1-edfa-0e1225ece307"
      },
      "source": [
        "prediction_rounded90AEBN = np.round(CNN_predictions90AEBN)\n",
        "#np.argmax(CNN_predictions90AEBN,axis=-1)\n",
        "\n",
        "#for p in prediction_rounded90AEBN:\n",
        " # print(p)\n",
        "\n",
        "\n",
        "print(nptesting_labels[500:520])\n",
        "print(prediction_rounded90AEBN[500:520])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1]\n",
            "[[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egTtgpXgg8a2"
      },
      "source": [
        "https://deeplizard.com/learn/video/km7pxKy4UHU\n",
        "\n",
        "Quelle der def plot_confusion_matrix: https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSDXf7-_MITy"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0AMs1EzhBU1"
      },
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                        normalize=False,\n",
        "                        title='Confusion matrix',\n",
        "                        cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2JgEnlghCtl"
      },
      "source": [
        "cm = confusion_matrix(y_true=nptesting_labels, y_pred=prediction_rounded90AEBN)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckmF29whhFmX"
      },
      "source": [
        "plot_labels = ['no hatespeech','hatespeech']"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mpSE96rhK7K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "outputId": "5e067e46-3d6c-4ecf-e15e-d143ae6f01db"
      },
      "source": [
        "plot_confusion_matrix(cm=cm, classes=plot_labels, title='CNN Confusion 90 19 Epochs Batch size 150')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix, without normalization\n",
            "[[1610  720]\n",
            " [ 556  646]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}