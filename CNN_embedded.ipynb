{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN embedded.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPUqU+hubrHP1zMlPh19UP+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BiancaStadl/ProjektarbeitML/blob/main/CNN_embedded.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXDOlIBymF0V"
      },
      "source": [
        "GloVe embeddings taken from:\n",
        "\n",
        "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. [pdf] [bib]\n",
        "\n",
        "hatespeechdata taken from (https://hatespeechdata.com/): Wiegand, M., Siegel, M. and Ruppenhofer, J., 2018. Overview of the GermEval 2018 Shared Task on the Identification of Offensive Language. In: Proceedings of GermEval 2018, 14th Conference on Natural Language Processing (KONVENS 2018). Vienna, Austria: Research Gate. available on: https://github.com/uds-lsv/GermEval-2018-Data (last checked: 09.05.2021)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlBmABDxfqII"
      },
      "source": [
        "wiki detox..https://colab.research.google.com/github/tensorflow/fairness-indicators/blob/master/g3doc/tutorials/Fairness_Indicators_TFCO_Wiki_Case_Study.ipynb#scrollTo=y6T5tlXcdW7J "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3xfitNdliBI"
      },
      "source": [
        "#import matplotlib.pyplot as plt -> für evtl Visualisierungen\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import string\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from keras import losses \n",
        "from keras import optimizers \n",
        "from keras import metrics \n",
        "\n",
        "#!pip install Tokenizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "#!pip install pad_sequences\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import preprocessing\n",
        "#from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTWJQ1iga_vS"
      },
      "source": [
        "Maximale Satzlänge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bq08Me5la_Cc"
      },
      "source": [
        "\n",
        "max_length = 60"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVYBMvYSotTH"
      },
      "source": [
        "url = \"https://github.com/uds-lsv/GermEval-2018-Data/archive/master.zip\"\n",
        "\n",
        "dataset = tf.keras.utils.get_file(\"GermEval-2018-Data-master.zip\", url, \n",
        "                                   extract=True, cache_dir='.',\n",
        "                                    cache_subdir='')\n",
        "\n",
        "dataset_dir = os.path.join(os.path.dirname(dataset), 'GermEval-2018-Data-master')\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cS14OUtfo34V"
      },
      "source": [
        "#os.listdir(dataset_dir)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2X429K6hpOVm"
      },
      "source": [
        "training_file = os.path.join(dataset_dir, 'germeval2018.training.txt')\n",
        "\n",
        "testing_file = os.path.join(dataset_dir, 'germeval2018.test.txt')\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uq8fG3LNtn_m"
      },
      "source": [
        "###Aufbereitung\n",
        "txt-Dateien lesen, und dabei jede Zeile splitten und teilen\n",
        "Twitter-Handler entfernen?\n",
        "Labels von Sätzen trennen, Labels in eigenen Array packen.\n",
        "\n",
        "####Ressourcen\n",
        "* https://www.w3schools.com/python/gloss_python_if_statement.asp\n",
        "* https://stackabuse.com/using-regex-for-text-manipulation-in-python/\n",
        "* https://www.tutorialspoint.com/python/string_splitlines.htm \n",
        "* https://note.nkmk.me/en/python-split-rsplit-splitlines-re/ \n",
        "* https://www.w3schools.com/python/python_regex.asp \n",
        "\n",
        "gäbe bei keras tf.keras.preprocessing.text_dataset_from_directory, aber dafür müssten die Daten auf bestimmte Weise in Verzeichnis organisiert sein, hier nicht der Fall.\n",
        "\n",
        "\n",
        "Einteilung der Daten: Testdaten\n",
        "Trainingsdaten -> noch ca 500 für Validierungsdaten\n",
        "\n",
        "labels -> \"other\", also nicht-negative Aussagen bekommen \"0\", negative Aussagen bekommen \"1\"\n",
        "\n",
        " Regex für Emojis  ->\n",
        "\n",
        "(\\u00a9|\\u00ae|[\\u2000-\\u3300]|\\ud83c[\\ud000-\\udfff]|\\ud83d[\\ud000-\\udfff]|\\ud83e[\\ud000-\\udfff])\n",
        "\n",
        "genommen von https://www.regextester.com/106421 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Py_cwD4eZkXo"
      },
      "source": [
        "def remove_clutter(string):\n",
        "   string = re.sub(\"@[^\\s]+\",\" \",string)\n",
        "   string = re.sub(\"#[^\\s]+\",\" \", string)\n",
        "   string = re.sub(\"\\u00a9\",\" \", string)\n",
        "   string = re.sub(\"\\u00ae\",\" \", string)\n",
        "   string = re.sub(\"[\\u2000-\\u3300]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83c[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83d[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83e[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"😜\", \" \",string)\n",
        "   string = re.sub(\"🍫\", \" \",string)\n",
        "   string = re.sub(\"😁\", \" \",string)\n",
        "   string = re.sub(\"🐖\", \" \",string)\n",
        "   string = re.sub(\"😡\", \" \",string)\n",
        "   string = re.sub(\"😇\", \" \",string)\n",
        "   string = re.sub(\"😬\", \" \",string)\n",
        "   string = re.sub(\"😃\", \" \",string)\n",
        "   string = re.sub(\"😂\", \" \",string)\n",
        "   string = re.sub(\"💙\", \" \",string)  \n",
        "   string = re.sub(\"😛\", \" \",string)\n",
        "   string = re.sub(\"🙏\", \" \",string)\n",
        "   string = re.sub(\"👍\", \" \",string)\n",
        "   string = re.sub(\"🖕\", \" \",string)\n",
        "   string = re.sub(\"😉\", \" \",string)\n",
        "   string = re.sub(\"💩\", \" \",string)\n",
        "   string = re.sub(\"🤢\", \" \",string)\n",
        "   string = re.sub(\"👏\", \" \",string)\n",
        "   string = re.sub(\"😨\", \" \",string)\n",
        "   string = re.sub(\"🤣\", \" \",string)\n",
        "   string = re.sub(\"🤡\", \" \",string)\n",
        "   string = re.sub(\"😈\", \" \",string)\n",
        "   string = re.sub(\"💃🏽\", \" \",string)\n",
        "   string = re.sub(\"👹\", \" \",string)\n",
        "   string = re.sub(\"🤘\", \" \",string)\n",
        "   string = re.sub(\"😱\", \" \",string)\n",
        "   string = re.sub(\"🤔\", \" \",string) \n",
        "   string = re.sub(\"🌈\", \" \",string) \n",
        "   string = re.sub(\"💕\", \" \",string) \n",
        "   string = re.sub(\"👩‍❤️‍👩\", \" \",string) \n",
        "   string = re.sub(\"😍\", \" \",string) \n",
        "   string = re.sub(\"👆\", \" \",string) \n",
        "   string = re.sub(\"😖\", \" \",string) \n",
        "   string = re.sub(\"👇\", \" \",string) \n",
        "   string = re.sub(\"🔥\", \" \",string) \n",
        "   string = re.sub(\"😘\", \" \",string) \n",
        "   string = re.sub(\"🎉\", \" \",string) \n",
        "   string = re.sub(\"🤬\", \" \",string) \n",
        "   string = re.sub(\"👊\", \" \",string)\n",
        "   string = re.sub(\"🇩🇪\", \" \",string)  \n",
        "   string = re.sub(\"💔\", \" \",string)\n",
        "   string = re.sub(\"🙈\", \" \",string)\n",
        "   string = re.sub(\"🤯\", \" \",string)\n",
        "   string = re.sub(\"🐟\", \" \",string)\n",
        "   string = re.sub(\"🛶\", \" \",string)\n",
        "   string = re.sub(\"😊\", \" \",string)\n",
        "   string = re.sub(\"😓\", \" \",string)\n",
        "   string = re.sub(\"😳\", \" \",string)\n",
        "   string = re.sub(\"🚀\", \" \",string)\n",
        "   string = re.sub(\"👎\", \" \",string)\n",
        "   string = re.sub(\"😎\", \" \",string)\n",
        "   string = re.sub(\"🐸\", \" \",string)\n",
        "   string = re.sub(\"📈\", \" \",string)\n",
        "   string = re.sub(\"🙂\", \" \",string)\n",
        "   string = re.sub(\"😅\", \" \",string)\n",
        "   string = re.sub(\"😆\", \" \",string)\n",
        "   string = re.sub(\"🙎🏿\", \" \",string)\n",
        "   string = re.sub(\"👎🏽\", \" \",string)\n",
        "   string = re.sub(\"🤭\", \" \",string)\n",
        "   string = re.sub(\"😤\", \" \",string)\n",
        "   string = re.sub(\"😚\", \" \",string)\n",
        "   string = re.sub(\"😊\", \" \",string)\n",
        "   string = re.sub(\"😲\", \" \",string)\n",
        "   string = re.sub(\"🤮\", \" \",string)\n",
        "   string = re.sub(\"🙄\", \" \",string)\n",
        "   string = re.sub(\"🤑\", \" \",string)\n",
        "   string = re.sub(\"🎅\", \" \",string)\n",
        "   string = re.sub(\"👋\", \" \",string)\n",
        "   string = re.sub(\"💪\", \" \",string)\n",
        "   string = re.sub(\"😄\", \" \",string)\n",
        "   string = re.sub(\"🧐\", \" \",string)\n",
        "   string = re.sub(\"😠\", \" \",string)\n",
        "   string = re.sub(\"🎈\", \" \",string)\n",
        "   string = re.sub(\"🚂\", \" \",string)\n",
        "   string = re.sub(\"😊\", \" \",string)\n",
        "   string = re.sub(\"🚇\", \" \",string)\n",
        "   string = re.sub(\"🚊\", \" \",string)\n",
        "   string = re.sub(\"🤷\", \" \",string)\n",
        "   string = re.sub(\"😥\", \" \",string)\n",
        "   string = re.sub(\"🙃\", \" \",string)\n",
        "   string = re.sub(\"🔩\", \" \",string)\n",
        "   string = re.sub(\"🔧\", \" \",string)\n",
        "   string = re.sub(\"🔨\", \" \",string)\n",
        "   string = re.sub(\"🛠\", \" \",string)\n",
        "   string = re.sub(\"💓\", \" \",string)\n",
        "   string = re.sub(\"💡\", \" \",string)\n",
        "   string = re.sub(\"🍸\", \" \",string)\n",
        "   string = re.sub(\"🥃\", \" \",string)\n",
        "   string = re.sub(\"🥂\", \" \",string)\n",
        "   string = re.sub(\"😷\", \" \",string)\n",
        "   string = re.sub(\"🤐\", \" \",string)\n",
        "   string = re.sub(\"🌎\", \" \",string)\n",
        "   string = re.sub(\"👑\", \" \",string)\n",
        "   string = re.sub(\"🤛\", \" \",string)\n",
        "   string = re.sub(\"😀\", \" \",string)\n",
        "   string = re.sub(\"🛤\", \" \",string)\n",
        "   string = re.sub(\"🎄\", \" \",string)\n",
        "   string = re.sub(\"📴\", \" \",string)\n",
        "   string = re.sub(\"🌭\", \" \",string)\n",
        "   string = re.sub(\"🤕\", \" \",string)\n",
        "   string = re.sub(\"😭\", \" \",string)\n",
        "   string = re.sub(\"🍾\", \" \",string)\n",
        "   string = re.sub(\"🍞\", \" \",string)\n",
        "   string = re.sub(\"🤦\", \" \",string)\n",
        "   string = re.sub(\"🤯\", \" \",string)\n",
        "   string = re.sub(\"🕯️\", \" \",string)\n",
        "\n",
        "   string = re.sub(\"OTHER|OFFENSE|ABUSE|INSULT\",\" \",string)\n",
        "   return string"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5asMgo4LtnRg"
      },
      "source": [
        "statementsForTraining = []\n",
        "sentimentsForTraining = []\n",
        "\n",
        "\n",
        "fileToRead = open(training_file, 'r')\n",
        "\n",
        "while True:\n",
        "  #next line in file\n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  findSentiment = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "\n",
        "\n",
        "  statementsForTraining.append(line)\n",
        "   #sentimentsForTraining.append(findSentiment.group(0))\n",
        "\n",
        "  if findSentiment.group(0) == \"OTHER\":  \n",
        "    sentimentsForTraining.append(0)\n",
        "  else:\n",
        "    sentimentsForTraining.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        " #print(\"{}: {}\".format(count,line.strip()))\n",
        "  \n",
        " # print(sentiment.group(0))\n",
        " \n",
        "fileToRead.close()\n",
        "\n",
        "training_sentences = statementsForTraining\n",
        "training_labels = sentimentsForTraining\n",
        "\n",
        "#print(training_sentences[9])\n",
        "#print(training_labels[9])\n",
        "\n",
        "#print(len(training_sentences))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsqZPENb98gD"
      },
      "source": [
        "##do the same with testdata\n",
        "statementsForTesting = []\n",
        "sentimentsForTesting = []\n",
        "\n",
        "fileToRead = open(testing_file, 'r')\n",
        "\n",
        "while True:\n",
        "  #next line in file\n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  sent = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "\n",
        "    \n",
        "\n",
        "  statementsForTesting.append(line)\n",
        "  #print(len(line))\n",
        "  #sentimentsForTesting.append(sent.group(0))\n",
        "\n",
        "  if sent.group(0) == \"OTHER\": \n",
        "    sentimentsForTesting.append(0)\n",
        "  else:\n",
        "    sentimentsForTesting.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        "\n",
        "fileToRead.close()\n",
        "\n",
        "\n",
        "testing_sentences = statementsForTesting\n",
        "testing_labels = sentimentsForTesting\n",
        "#print(len(testing_sentences))\n",
        "#print(testing_sentences)   \n",
        "#print(testing_labels)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRUvDLD5bMbO"
      },
      "source": [
        "Padding -> im Prinzip die Sätze alle auf die gleiche Länge bringen (in Theorieteil näher drauf eingehen) -> maxlen-Paramter ist für pad_sequences vorhanden, wenn nicht gesetzt -> alles wird auf die Länge des längsten Satzes aufgefüllt -> print(padded(shape)) gibt aus, wie viele Datensätze padded wurden und gibt an, wie viele Tokens der längste Datensatz hat\n",
        "print(padded[x]) gibt einen Satz aus (bereits tokenisiert)\n",
        "\n",
        "Padding -> sowohl für Trainigs- als auch für Testdaten\n",
        "\n",
        "Und: Daten als numpy-Arrays speichern (notwendig für tensorflow).\n",
        "\n",
        " -> Tokenizer https://towardsdatascience.com/text-classification-in-keras-part-2-how-to-use-the-keras-tokenizer-word-representations-fd571674df23 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3hFi7waTv5m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "058f9e83-b6bc-4b09-daf5-997aca6d8de3"
      },
      "source": [
        "tokenizer = Tokenizer(oov_token=\"OOV\")\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "\n",
        "#creating a word index - nur die Trainigsdaten\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "validation_size = 500\n",
        "\n",
        "\n",
        "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "padded_training = pad_sequences(training_sequences, maxlen=max_length, padding='post')\n",
        "print(len(padded_training))\n",
        "\n",
        "validation_sequences = padded_training[0:validation_size]\n",
        "validation_labels = training_labels[0:validation_size]\n",
        "\n",
        "padded_training = padded_training[validation_size:]\n",
        "training_labels = training_labels[validation_size:]\n",
        "\n",
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
        "padded_testing = pad_sequences(testing_sequences, maxlen=max_length,  padding='post')\n",
        "\n",
        "#print(validation_sequences[499])\n",
        "print(padded_training[0])\n",
        "#print(len(validation_labels))\n",
        "#print(len(training_labels))\n",
        "\n",
        "\n",
        "nppadded_training = np.array(padded_training)\n",
        "nptraining_labels = np.array(training_labels)\n",
        "\n",
        "nppadded_validation = np.array(validation_sequences)\n",
        "npvalidation_labels = np.array(validation_labels)\n",
        "\n",
        "nppadded_testing = np.array(padded_testing)\n",
        "nptesting_labels = np.array(testing_labels)\n",
        "\n",
        "\n",
        "print(len(nppadded_training))\n",
        "print(len(nptraining_labels))\n",
        "print(len(word_index))\n",
        "\n",
        "#print(statementsForTraining[2])\n",
        "#print(nppadded_training[4])\n",
        "#print(nppadded_training.shape)\n",
        "#print(nptraining_labels[4])\n",
        "#print(nppadded_testing.shape)\n",
        "#print(word_index) \n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5009\n",
            "[  12 3982   11   41 6706 1040    4    5  202   39    3 2922   49 1360\n",
            "  810  495 3983    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0]\n",
            "4509\n",
            "4509\n",
            "15059\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tL3owrc8THkT"
      },
      "source": [
        "\n",
        "Dann: Embedding mit entweder word2vec oder glove\n",
        "Word2vec-Daten sind hier: http://vectors.nlpl.eu/repository/#\n",
        "Glove -> https://nlp.stanford.edu/projects/glove/ Da mal den Twitter-Vector runtergeladen\n",
        "Wenn Daten in GoogleDrive sind (wäre auch via url möglich..), muss Drive gemounted werden ( https://buomsoo-kim.github.io/colab/2020/05/09/Colab-mounting-google-drive.md/ ) aber auch hier https://enjoymachinelearning.com/posts/colab-with-google-drive/\n",
        "\n",
        "Die Word2vec vectors: http://vectors.nlpl.eu/repository/# \n",
        "\n",
        "glove-zitat:\n",
        "Citing GloVe\n",
        "\n",
        "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. [pdf] [bib]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zuO7T9ZTG57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60221c82-731b-44b5-d77e-a14e451ce8a9"
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount(\"/content/drive\")\n",
        "os.listdir(\"/content/drive/MyDrive/Colab Notebooks\")\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['germeval_training.txt',\n",
              " 'glove.twitter.27B.50d.txt',\n",
              " 'glove.twitter.27B.200d.txt',\n",
              " 'glove.6B.200d.txt',\n",
              " 'glove.840B.300d.txt',\n",
              " 'tensorboard.gdoc',\n",
              " 'keras.gdoc',\n",
              " 'Vectorization CNN embedded_limited_vocab.ipynb',\n",
              " 'glove.42B.300d.txt',\n",
              " 'Embedding Glove Vergleich.ipynb',\n",
              " 'CNN embedded_limited_vocab.ipynb',\n",
              " 'LSTM_limited_vocab.ipynb',\n",
              " 'LSTM.ipynb',\n",
              " 'CNN embedded.ipynb']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7ToKO-sZLHK"
      },
      "source": [
        "\n",
        "Keras-Doc : https://keras.io/examples/nlp/pretrained_word_embeddings/#load-pretrained-word-embeddings \n",
        "embedding mit initializers.. weights müsste auch funktionieren\n",
        "\n",
        "Diese erstellte Matrix mit Embedding dann in die Embedding-Schicht einbinden,  Trainable auf False, weil sich die Werte nicht durch Training anpassen sollen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AShIVfC7ZQAH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c365735a-0fae-4e47-cae7-79d83574dccd"
      },
      "source": [
        "#Größe Vokabel -> wordindex + 2 (weil padding + OOV) \n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "vocabulary_size = len(word_index)+2\n",
        "\n",
        "# dann erstell ich ein Wörterbuch mit Namen \"embedding_vector\", dort sind dann\n",
        "#die keys drinnen, die in glove-Datei drinnen sind mit dem entsprechenden Key\n",
        "\n",
        "embedding_index_glove = {}\n",
        "f = open('/content/drive/MyDrive/Colab Notebooks/glove.twitter.27B.200d.txt')\n",
        "for line in f:\n",
        "  value = line.split()\n",
        "  word = value[0]\n",
        "  coef = np.asarray(value[1:],dtype='float32')\n",
        "  embedding_index_glove[word] = coef\n",
        "\n",
        "print(\"%d gefunden: \"% len(embedding_index_glove))\n",
        "\n",
        "#Dann noch eine Embedding-Matrix erstellen\n",
        "#zweiter Wert = Embedding-Dimension der Datei, in dem Fall 200\n",
        "\n",
        "glove_matrix = np.zeros((vocabulary_size,200))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    embedding_value = embedding_index_glove.get(word)\n",
        "    if embedding_value is not None:\n",
        "      glove_matrix[index] = embedding_value\n",
        "      hits+=1\n",
        "    else:\n",
        "      misses+=1\n",
        "\n",
        "print(\"hits %d and %d misses\"%(hits,misses))\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1193514 gefunden: \n",
            "hits 6747 and 8312 misses\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZmvOfwhV4N5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecc7ead9-f6eb-4308-d155-aaf74de1827f"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "print(\"vocab size: %d\"%vocabulary_size)\n",
        "CNN1605210290AEBN = tf.keras.Sequential()\n",
        "#Embedding -> hier dann auf das embedding verweisen, Input_dim -> die Anzahl der Wörter im word_index, output -> in dem Fall passend zum verwendeten Vektor\n",
        "#input-length -> auf 60  gepadded, trainable -> nein, weil nichts verändert werden soll\n",
        "#embeddings_initializer=keras.initializers.Constant(glove_matrix) vs weights = [glove_matrix]\n",
        "#Convolutional layers => filters = neurons.. mit 100? 265?\n",
        "#CNN1605210290AEBN.add(tf.keras.layers.Embedding(input_dim=vocabulary_size, output_dim=200, input_length=max_length))\n",
        "CNN1605210290AEBN.add(tf.keras.layers.Embedding(vocabulary_size, output_dim=200, input_length=60, embeddings_initializer = keras.initializers.Constant(glove_matrix), trainable= False))\n",
        "CNN1605210290AEBN.add(tf.keras.layers.BatchNormalization())\n",
        "CNN1605210290AEBN.add(tf.keras.layers.Dropout(0.4))\n",
        "CNN1605210290AEBN.add(tf.keras.layers.Conv1D(filters=50, kernel_size=3, padding=\"valid\", activation=\"relu\"))\n",
        "CNN1605210290AEBN.add(tf.keras.layers.BatchNormalization())\n",
        "CNN1605210290AEBN.add(tf.keras.layers.MaxPooling1D())\n",
        "CNN1605210290AEBN.add(tf.keras.layers.BatchNormalization())\n",
        "CNN1605210290AEBN.add(tf.keras.layers.Conv1D(filters=50, kernel_size=3, padding=\"valid\", activation=\"relu\"))\n",
        "CNN1605210290AEBN.add(tf.keras.layers.BatchNormalization())\n",
        "CNN1605210290AEBN.add(tf.keras.layers.GlobalAveragePooling1D())\n",
        "CNN1605210290AEBN.add(tf.keras.layers.BatchNormalization())\n",
        "CNN1605210290AEBN.add(tf.keras.layers.Flatten())\n",
        "CNN1605210290AEBN.add(tf.keras.layers.Dense(260, activation=\"relu\"))\n",
        "CNN1605210290AEBN.add(tf.keras.layers.BatchNormalization())\n",
        "CNN1605210290AEBN.add(tf.keras.layers.Dropout(0.4))\n",
        "CNN1605210290AEBN.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "CNN1605210290AEBN.summary()\n",
        "\n",
        "#nppadded_training = np.asmatrix(nppadded_training) not necessary\n",
        "#nppadded_testing = np.asmatrix(nppadded_testing)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab size: 15061\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 60, 200)           3012200   \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 60, 200)           800       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 60, 200)           0         \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 58, 50)            30050     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 58, 50)            200       \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 29, 50)            0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 29, 50)            200       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 27, 50)            7550      \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 27, 50)            200       \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 50)                200       \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 260)               13260     \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 260)               1040      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 260)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 261       \n",
            "=================================================================\n",
            "Total params: 3,065,961\n",
            "Trainable params: 52,441\n",
            "Non-trainable params: 3,013,520\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEr4OzT-iHDe"
      },
      "source": [
        "#model.layers[2].get_weights()[0].shape\n",
        "#weights=np.random.rand(5,200,100)\n",
        "#bias=np.random.rand(100)\n",
        "#model.layers[2].set_weights([weights, bias])\n",
        "\n",
        "#model.layers[2].get_weights()[0]\n",
        "#https://androidkt.com/set-custom-weights-keras-using-numpy-array/"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UB7_3VPYesr9"
      },
      "source": [
        "F1-Score für jede Epoche https://aakashgoel12.medium.com/how-to-add-user-defined-function-get-f1-score-in-keras-metrics-3013f979ce0d\n",
        "\n",
        "Sehr gute Ressource für die verschiedenen Scores und Metriken https://neptune.ai/blog/evaluation-metrics-binary-classification#10  das und aakas verwendet\n",
        "\n",
        "hier: je eine Funktion für Recall, Precision, f1 https://neptune.ai/blog/keras-metrics \n",
        "\n",
        "https://keras.rstudio.com/reference/k_ones_like.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygyrbFJaMV9B"
      },
      "source": [
        "import keras.backend as K\n",
        "\n",
        "def metrics_recall(data_true, data_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(data_true,0,1)))\n",
        "\n",
        "    recall = true_positives / (possible_positives+K.epsilon())\n",
        "    return recall\n",
        "\n",
        "\n",
        "def metrics_precision(data_true, data_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "\n",
        "    positives_predicted = K.sum(K.round(K.clip(data_pred,0,1)))\n",
        "    precision = true_positives / (positives_predicted+K.epsilon())\n",
        "    return precision\n",
        "\n",
        "\n",
        "def metrics_f1(data_true, data_pred):\n",
        "    precision_data = metrics_precision(data_true, data_pred)\n",
        "    recall_data = metrics_recall(data_true, data_pred)\n",
        "    return 2*(precision_data*recall_data)/(precision_data+recall_data+K.epsilon())"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1ctlBrnuYJz"
      },
      "source": [
        "https://aakashgoel12.medium.com/how-to-add-user-defined-function-get-f1-score-in-keras-metrics-3013f979ce0d"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AfPD3_bWCm0"
      },
      "source": [
        "#CNN1605210290AEBN.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',metrics_recall,metrics_precision,metrics_f1])\n",
        "CNN1605210290AEBN.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',metrics_recall,metrics_precision,metrics_f1])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpChKUY-QEWI"
      },
      "source": [
        "https://www.tensorflow.org/tensorboard/tensorboard_in_notebooks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJfMgUhHBoD1"
      },
      "source": [
        "#%load_ext tensorboard\n",
        "#nur einmal pro Sitzung notwendig\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ISmMXLqP8Hc"
      },
      "source": [
        "\n",
        "logs_base_dir = \"./logs\"\n",
        "callbackForTB = tf.keras.callbacks.TensorBoard(logs_base_dir)\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ehh-EMXUQh8r"
      },
      "source": [
        "Early Stopping as defined in keras tensorflow documentation\n",
        "https://www.tensorflow.org/guide/keras/train_and_evaluate "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BY_t-PeQEjy"
      },
      "source": [
        "callbackEarlyStopping = [\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_loss\",\n",
        "        mode=\"min\",\n",
        "        patience=3,\n",
        "        verbose=1,\n",
        "    )\n",
        "]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2CHbXiP1LsF"
      },
      "source": [
        "training_epochs = 19\n",
        "batch_size = 90\n",
        "validation_split=0.2"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abV-QAxfW48r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e10a9cd8-b5dd-4d0b-d80c-54012c8dc9ee"
      },
      "source": [
        "#Werte der Convolutional-Schichten variieren (Filter), Batch-Size variieren, kernel-size..\n",
        "CNN1605210290AEBN.fit(nppadded_training, nptraining_labels, batch_size=batch_size, validation_split=validation_split, epochs=training_epochs, callbacks=[callbackForTB])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/19\n",
            "41/41 [==============================] - 6s 98ms/step - loss: 0.8122 - accuracy: 0.5589 - metrics_recall: 0.4078 - metrics_precision: 0.3606 - metrics_f1: 0.3796 - val_loss: 0.6367 - val_accuracy: 0.6718 - val_metrics_recall: 0.0000e+00 - val_metrics_precision: 0.0000e+00 - val_metrics_f1: 0.0000e+00\n",
            "Epoch 2/19\n",
            "41/41 [==============================] - 3s 84ms/step - loss: 0.7308 - accuracy: 0.6091 - metrics_recall: 0.3056 - metrics_precision: 0.3899 - metrics_f1: 0.3376 - val_loss: 0.6305 - val_accuracy: 0.6718 - val_metrics_recall: 0.0000e+00 - val_metrics_precision: 0.0000e+00 - val_metrics_f1: 0.0000e+00\n",
            "Epoch 3/19\n",
            "41/41 [==============================] - 4s 88ms/step - loss: 0.6881 - accuracy: 0.6393 - metrics_recall: 0.3259 - metrics_precision: 0.4436 - metrics_f1: 0.3719 - val_loss: 0.6254 - val_accuracy: 0.6718 - val_metrics_recall: 0.0000e+00 - val_metrics_precision: 0.0000e+00 - val_metrics_f1: 0.0000e+00\n",
            "Epoch 4/19\n",
            "41/41 [==============================] - 3s 84ms/step - loss: 0.6550 - accuracy: 0.6698 - metrics_recall: 0.3970 - metrics_precision: 0.5145 - metrics_f1: 0.4449 - val_loss: 0.6222 - val_accuracy: 0.6718 - val_metrics_recall: 0.0000e+00 - val_metrics_precision: 0.0000e+00 - val_metrics_f1: 0.0000e+00\n",
            "Epoch 5/19\n",
            "41/41 [==============================] - 4s 88ms/step - loss: 0.6444 - accuracy: 0.6754 - metrics_recall: 0.3624 - metrics_precision: 0.5265 - metrics_f1: 0.4249 - val_loss: 0.6147 - val_accuracy: 0.6718 - val_metrics_recall: 0.0000e+00 - val_metrics_precision: 0.0000e+00 - val_metrics_f1: 0.0000e+00\n",
            "Epoch 6/19\n",
            "41/41 [==============================] - 3s 84ms/step - loss: 0.6239 - accuracy: 0.6762 - metrics_recall: 0.3982 - metrics_precision: 0.5406 - metrics_f1: 0.4518 - val_loss: 0.6026 - val_accuracy: 0.6984 - val_metrics_recall: 0.2178 - val_metrics_precision: 0.7199 - val_metrics_f1: 0.2975\n",
            "Epoch 7/19\n",
            "41/41 [==============================] - 4s 89ms/step - loss: 0.5935 - accuracy: 0.6964 - metrics_recall: 0.4362 - metrics_precision: 0.5652 - metrics_f1: 0.4881 - val_loss: 0.5934 - val_accuracy: 0.7129 - val_metrics_recall: 0.2158 - val_metrics_precision: 0.6292 - val_metrics_f1: 0.3149\n",
            "Epoch 8/19\n",
            "41/41 [==============================] - 4s 87ms/step - loss: 0.5836 - accuracy: 0.7017 - metrics_recall: 0.4575 - metrics_precision: 0.5793 - metrics_f1: 0.5064 - val_loss: 0.5888 - val_accuracy: 0.7173 - val_metrics_recall: 0.2466 - val_metrics_precision: 0.6196 - val_metrics_f1: 0.3487\n",
            "Epoch 9/19\n",
            "41/41 [==============================] - 4s 89ms/step - loss: 0.5679 - accuracy: 0.7225 - metrics_recall: 0.4652 - metrics_precision: 0.6137 - metrics_f1: 0.5245 - val_loss: 0.5662 - val_accuracy: 0.7162 - val_metrics_recall: 0.3982 - val_metrics_precision: 0.6585 - val_metrics_f1: 0.4875\n",
            "Epoch 10/19\n",
            "41/41 [==============================] - 4s 86ms/step - loss: 0.5442 - accuracy: 0.7250 - metrics_recall: 0.4780 - metrics_precision: 0.6382 - metrics_f1: 0.5410 - val_loss: 0.6191 - val_accuracy: 0.7106 - val_metrics_recall: 0.2638 - val_metrics_precision: 0.7503 - val_metrics_f1: 0.3577\n",
            "Epoch 11/19\n",
            "41/41 [==============================] - 4s 86ms/step - loss: 0.5263 - accuracy: 0.7452 - metrics_recall: 0.5496 - metrics_precision: 0.6564 - metrics_f1: 0.5932 - val_loss: 0.6272 - val_accuracy: 0.7106 - val_metrics_recall: 0.2491 - val_metrics_precision: 0.7677 - val_metrics_f1: 0.3378\n",
            "Epoch 12/19\n",
            "41/41 [==============================] - 4s 89ms/step - loss: 0.5235 - accuracy: 0.7430 - metrics_recall: 0.5149 - metrics_precision: 0.6595 - metrics_f1: 0.5723 - val_loss: 0.6387 - val_accuracy: 0.7062 - val_metrics_recall: 0.1437 - val_metrics_precision: 0.7282 - val_metrics_f1: 0.2319\n",
            "Epoch 13/19\n",
            "41/41 [==============================] - 4s 89ms/step - loss: 0.5170 - accuracy: 0.7413 - metrics_recall: 0.5306 - metrics_precision: 0.6540 - metrics_f1: 0.5785 - val_loss: 0.5596 - val_accuracy: 0.7273 - val_metrics_recall: 0.4141 - val_metrics_precision: 0.6405 - val_metrics_f1: 0.4756\n",
            "Epoch 14/19\n",
            "41/41 [==============================] - 4s 89ms/step - loss: 0.4969 - accuracy: 0.7549 - metrics_recall: 0.5540 - metrics_precision: 0.6461 - metrics_f1: 0.5921 - val_loss: 0.5448 - val_accuracy: 0.7129 - val_metrics_recall: 0.4869 - val_metrics_precision: 0.5799 - val_metrics_f1: 0.5116\n",
            "Epoch 15/19\n",
            "41/41 [==============================] - 4s 86ms/step - loss: 0.4796 - accuracy: 0.7652 - metrics_recall: 0.5680 - metrics_precision: 0.6663 - metrics_f1: 0.6087 - val_loss: 0.5535 - val_accuracy: 0.7217 - val_metrics_recall: 0.3413 - val_metrics_precision: 0.5853 - val_metrics_f1: 0.4264\n",
            "Epoch 16/19\n",
            "41/41 [==============================] - 4s 88ms/step - loss: 0.4756 - accuracy: 0.7710 - metrics_recall: 0.5924 - metrics_precision: 0.6842 - metrics_f1: 0.6262 - val_loss: 0.5779 - val_accuracy: 0.7140 - val_metrics_recall: 0.4438 - val_metrics_precision: 0.5290 - val_metrics_f1: 0.4800\n",
            "Epoch 17/19\n",
            "41/41 [==============================] - 4s 89ms/step - loss: 0.4597 - accuracy: 0.7857 - metrics_recall: 0.6119 - metrics_precision: 0.7219 - metrics_f1: 0.6578 - val_loss: 0.5510 - val_accuracy: 0.7228 - val_metrics_recall: 0.5371 - val_metrics_precision: 0.5862 - val_metrics_f1: 0.5472\n",
            "Epoch 18/19\n",
            "41/41 [==============================] - 4s 86ms/step - loss: 0.4531 - accuracy: 0.7893 - metrics_recall: 0.6322 - metrics_precision: 0.7234 - metrics_f1: 0.6690 - val_loss: 0.6709 - val_accuracy: 0.7217 - val_metrics_recall: 0.3547 - val_metrics_precision: 0.6617 - val_metrics_f1: 0.4225\n",
            "Epoch 19/19\n",
            "41/41 [==============================] - 4s 85ms/step - loss: 0.4430 - accuracy: 0.7948 - metrics_recall: 0.6259 - metrics_precision: 0.7092 - metrics_f1: 0.6606 - val_loss: 0.5883 - val_accuracy: 0.7284 - val_metrics_recall: 0.4346 - val_metrics_precision: 0.6372 - val_metrics_f1: 0.4928\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2f10349f90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJVL4SBLPB2P"
      },
      "source": [
        "#%tensorboard --logdir {logs_base_dir}"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_LnvWBcnoak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4484e258-df1b-4e3d-e72f-6b30cc7ffe15"
      },
      "source": [
        "#results = model.evaluate(nppadded_testing, nptesting_labels, batch_size=batch_size)\n",
        "#print(\"test loss, test acc:\",results)\n",
        "\n",
        "(loss,accuracy, metrics_recall,metrics_precision,\n",
        "metrics_f1) = CNN1605210290AEBN.evaluate(nppadded_testing, nptesting_labels, verbose=1)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "111/111 [==============================] - 1s 7ms/step - loss: 0.6666 - accuracy: 0.6877 - metrics_recall: 0.2454 - metrics_precision: 0.6141 - metrics_f1: 0.3338\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KgjIkhpKmHc"
      },
      "source": [
        "make some predictions of test data and save it to variable. verbose=0 -> do not generate output\n",
        "Gute Quelle: https://deeplizard.com/learn/video/2f-NjDUvZIE "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89GWuxryKlcM"
      },
      "source": [
        "CNN_predictions90AEBN = CNN1605210290AEBN.predict(x=nppadded_testing)\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3jPDaDJK_cN"
      },
      "source": [
        "#for p in CNN_predictions90AEBN:\n",
        " # print(p)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eC9efJy4Lp21"
      },
      "source": [
        "rounded predictions: give prediction value of most likely prediction (0 or 1). Printing the output of rounded prediction shows the prediction made by the model on the data (which output is most likely)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsG-TJuQLvtk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23a4202c-17d8-4936-cb04-a4663c2a9f08"
      },
      "source": [
        "prediction_rounded90AEBN = np.round(CNN_predictions90AEBN)\n",
        "#np.argmax(CNN_predictions90AEBN,axis=-1)\n",
        "\n",
        "#for p in prediction_rounded90AEBN:\n",
        " # print(p)\n",
        "\n",
        "\n",
        "print(nptesting_labels[500:520])\n",
        "print(prediction_rounded90AEBN[500:520])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1]\n",
            "[[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egTtgpXgg8a2"
      },
      "source": [
        "https://deeplizard.com/learn/video/km7pxKy4UHU\n",
        "\n",
        "Quelle der def plot_confusion_matrix: https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSDXf7-_MITy"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0AMs1EzhBU1"
      },
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                        normalize=False,\n",
        "                        title='Confusion matrix',\n",
        "                        cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2JgEnlghCtl"
      },
      "source": [
        "cm = confusion_matrix(y_true=nptesting_labels, y_pred=prediction_rounded90AEBN)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckmF29whhFmX"
      },
      "source": [
        "plot_labels = ['no hatespeech','hatespeech']"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mpSE96rhK7K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "outputId": "55ee27a1-2600-4cff-b843-fd1754170e4c"
      },
      "source": [
        "plot_confusion_matrix(cm=cm, classes=plot_labels, title='CNN Confusion 90 19 Epochs Batch size 90, kernel size 3, batch normalization')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix, without normalization\n",
            "[[2136  194]\n",
            " [ 909  293]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}