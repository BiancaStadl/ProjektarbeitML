{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN embedded.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNIJp3GyyZJFimsGWjsqiqi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BiancaStadl/ProjektarbeitML/blob/main/CNN_embedded.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXDOlIBymF0V"
      },
      "source": [
        "GloVe embeddings taken from:\n",
        "\n",
        "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. [pdf] [bib]\n",
        "\n",
        "hatespeechdata taken from (https://hatespeechdata.com/): Wiegand, M., Siegel, M. and Ruppenhofer, J., 2018. Overview of the GermEval 2018 Shared Task on the Identification of Offensive Language. In: Proceedings of GermEval 2018, 14th Conference on Natural Language Processing (KONVENS 2018). Vienna, Austria: Research Gate. available on: https://github.com/uds-lsv/GermEval-2018-Data (last checked: 09.05.2021)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlBmABDxfqII"
      },
      "source": [
        "wiki detox..https://colab.research.google.com/github/tensorflow/fairness-indicators/blob/master/g3doc/tutorials/Fairness_Indicators_TFCO_Wiki_Case_Study.ipynb#scrollTo=y6T5tlXcdW7J "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3xfitNdliBI"
      },
      "source": [
        "#import matplotlib.pyplot as plt -> f√ºr evtl Visualisierungen\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import string\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from keras import losses \n",
        "from keras import optimizers \n",
        "from keras import metrics \n",
        "\n",
        "#!pip install Tokenizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "#!pip install pad_sequences\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import preprocessing\n",
        "#from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTWJQ1iga_vS"
      },
      "source": [
        "Maximale Satzl√§nge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bq08Me5la_Cc"
      },
      "source": [
        "\n",
        "max_length = 60"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVYBMvYSotTH"
      },
      "source": [
        "url = \"https://github.com/uds-lsv/GermEval-2018-Data/archive/master.zip\"\n",
        "\n",
        "dataset = tf.keras.utils.get_file(\"GermEval-2018-Data-master.zip\", url, \n",
        "                                   extract=True, cache_dir='.',\n",
        "                                    cache_subdir='')\n",
        "\n",
        "dataset_dir = os.path.join(os.path.dirname(dataset), 'GermEval-2018-Data-master')\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cS14OUtfo34V"
      },
      "source": [
        "#os.listdir(dataset_dir)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2X429K6hpOVm"
      },
      "source": [
        "training_file = os.path.join(dataset_dir, 'germeval2018.training.txt')\n",
        "\n",
        "testing_file = os.path.join(dataset_dir, 'germeval2018.test.txt')\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uq8fG3LNtn_m"
      },
      "source": [
        "###Aufbereitung\n",
        "txt-Dateien lesen, und dabei jede Zeile splitten und teilen\n",
        "Twitter-Handler entfernen?\n",
        "Labels von S√§tzen trennen, Labels in eigenen Array packen.\n",
        "\n",
        "####Ressourcen\n",
        "* https://www.w3schools.com/python/gloss_python_if_statement.asp\n",
        "* https://stackabuse.com/using-regex-for-text-manipulation-in-python/\n",
        "* https://www.tutorialspoint.com/python/string_splitlines.htm \n",
        "* https://note.nkmk.me/en/python-split-rsplit-splitlines-re/ \n",
        "* https://www.w3schools.com/python/python_regex.asp \n",
        "\n",
        "g√§be bei keras tf.keras.preprocessing.text_dataset_from_directory, aber daf√ºr m√ºssten die Daten auf bestimmte Weise in Verzeichnis organisiert sein, hier nicht der Fall.\n",
        "\n",
        "\n",
        "Einteilung der Daten: Testdaten\n",
        "Trainingsdaten -> noch ca 500 f√ºr Validierungsdaten\n",
        "\n",
        "labels -> \"other\", also nicht-negative Aussagen bekommen \"0\", negative Aussagen bekommen \"1\"\n",
        "\n",
        " Regex f√ºr Emojis  ->\n",
        "\n",
        "(\\u00a9|\\u00ae|[\\u2000-\\u3300]|\\ud83c[\\ud000-\\udfff]|\\ud83d[\\ud000-\\udfff]|\\ud83e[\\ud000-\\udfff])\n",
        "\n",
        "genommen von https://www.regextester.com/106421 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Py_cwD4eZkXo"
      },
      "source": [
        "def remove_clutter(string):\n",
        "   string = re.sub(\"@[^\\s]+\",\" \",string)\n",
        "   string = re.sub(\"#[^\\s]+\",\" \", string)\n",
        "   string = re.sub(\"\\u00a9\",\" \", string)\n",
        "   string = re.sub(\"\\u00ae\",\" \", string)\n",
        "   string = re.sub(\"[\\u2000-\\u3300]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83c[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83d[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83e[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"üòú\", \" \",string)\n",
        "   string = re.sub(\"üç´\", \" \",string)\n",
        "   string = re.sub(\"üòÅ\", \" \",string)\n",
        "   string = re.sub(\"üêñ\", \" \",string)\n",
        "   string = re.sub(\"üò°\", \" \",string)\n",
        "   string = re.sub(\"üòá\", \" \",string)\n",
        "   string = re.sub(\"üò¨\", \" \",string)\n",
        "   string = re.sub(\"üòÉ\", \" \",string)\n",
        "   string = re.sub(\"üòÇ\", \" \",string)\n",
        "   string = re.sub(\"üíô\", \" \",string)  \n",
        "   string = re.sub(\"üòõ\", \" \",string)\n",
        "   string = re.sub(\"üôè\", \" \",string)\n",
        "   string = re.sub(\"üëç\", \" \",string)\n",
        "   string = re.sub(\"üñï\", \" \",string)\n",
        "   string = re.sub(\"üòâ\", \" \",string)\n",
        "   string = re.sub(\"üí©\", \" \",string)\n",
        "   string = re.sub(\"ü§¢\", \" \",string)\n",
        "   string = re.sub(\"üëè\", \" \",string)\n",
        "   string = re.sub(\"üò®\", \" \",string)\n",
        "   string = re.sub(\"ü§£\", \" \",string)\n",
        "   string = re.sub(\"ü§°\", \" \",string)\n",
        "   string = re.sub(\"üòà\", \" \",string)\n",
        "   string = re.sub(\"üíÉüèΩ\", \" \",string)\n",
        "   string = re.sub(\"üëπ\", \" \",string)\n",
        "   string = re.sub(\"ü§ò\", \" \",string)\n",
        "   string = re.sub(\"üò±\", \" \",string)\n",
        "   string = re.sub(\"ü§î\", \" \",string) \n",
        "   string = re.sub(\"üåà\", \" \",string) \n",
        "   string = re.sub(\"üíï\", \" \",string) \n",
        "   string = re.sub(\"üë©‚Äç‚ù§Ô∏è‚Äçüë©\", \" \",string) \n",
        "   string = re.sub(\"üòç\", \" \",string) \n",
        "   string = re.sub(\"üëÜ\", \" \",string) \n",
        "   string = re.sub(\"üòñ\", \" \",string) \n",
        "   string = re.sub(\"üëá\", \" \",string) \n",
        "   string = re.sub(\"üî•\", \" \",string) \n",
        "   string = re.sub(\"üòò\", \" \",string) \n",
        "   string = re.sub(\"üéâ\", \" \",string) \n",
        "   string = re.sub(\"ü§¨\", \" \",string) \n",
        "   string = re.sub(\"üëä\", \" \",string)\n",
        "   string = re.sub(\"üá©üá™\", \" \",string)  \n",
        "   string = re.sub(\"üíî\", \" \",string)\n",
        "   string = re.sub(\"üôà\", \" \",string)\n",
        "   string = re.sub(\"ü§Ø\", \" \",string)\n",
        "   string = re.sub(\"üêü\", \" \",string)\n",
        "   string = re.sub(\"üõ∂\", \" \",string)\n",
        "   string = re.sub(\"üòä\", \" \",string)\n",
        "   string = re.sub(\"üòì\", \" \",string)\n",
        "   string = re.sub(\"üò≥\", \" \",string)\n",
        "   string = re.sub(\"üöÄ\", \" \",string)\n",
        "   string = re.sub(\"üëé\", \" \",string)\n",
        "   string = re.sub(\"üòé\", \" \",string)\n",
        "   string = re.sub(\"üê∏\", \" \",string)\n",
        "   string = re.sub(\"üìà\", \" \",string)\n",
        "   string = re.sub(\"üôÇ\", \" \",string)\n",
        "   string = re.sub(\"üòÖ\", \" \",string)\n",
        "   string = re.sub(\"üòÜ\", \" \",string)\n",
        "   string = re.sub(\"üôéüèø\", \" \",string)\n",
        "   string = re.sub(\"üëéüèΩ\", \" \",string)\n",
        "   string = re.sub(\"ü§≠\", \" \",string)\n",
        "   string = re.sub(\"üò§\", \" \",string)\n",
        "   string = re.sub(\"üòö\", \" \",string)\n",
        "   string = re.sub(\"üòä\", \" \",string)\n",
        "   string = re.sub(\"üò≤\", \" \",string)\n",
        "   string = re.sub(\"ü§Æ\", \" \",string)\n",
        "   string = re.sub(\"üôÑ\", \" \",string)\n",
        "   string = re.sub(\"ü§ë\", \" \",string)\n",
        "   string = re.sub(\"üéÖ\", \" \",string)\n",
        "   string = re.sub(\"üëã\", \" \",string)\n",
        "   string = re.sub(\"üí™\", \" \",string)\n",
        "   string = re.sub(\"üòÑ\", \" \",string)\n",
        "   string = re.sub(\"üßê\", \" \",string)\n",
        "   string = re.sub(\"üò†\", \" \",string)\n",
        "   string = re.sub(\"üéà\", \" \",string)\n",
        "   string = re.sub(\"üöÇ\", \" \",string)\n",
        "   string = re.sub(\"üòä\", \" \",string)\n",
        "   string = re.sub(\"üöá\", \" \",string)\n",
        "   string = re.sub(\"üöä\", \" \",string)\n",
        "   string = re.sub(\"ü§∑\", \" \",string)\n",
        "   string = re.sub(\"üò•\", \" \",string)\n",
        "   string = re.sub(\"üôÉ\", \" \",string)\n",
        "   string = re.sub(\"üî©\", \" \",string)\n",
        "   string = re.sub(\"üîß\", \" \",string)\n",
        "   string = re.sub(\"üî®\", \" \",string)\n",
        "   string = re.sub(\"üõ†\", \" \",string)\n",
        "   string = re.sub(\"üíì\", \" \",string)\n",
        "   string = re.sub(\"üí°\", \" \",string)\n",
        "   string = re.sub(\"üç∏\", \" \",string)\n",
        "   string = re.sub(\"ü•É\", \" \",string)\n",
        "   string = re.sub(\"ü•Ç\", \" \",string)\n",
        "   string = re.sub(\"üò∑\", \" \",string)\n",
        "   string = re.sub(\"ü§ê\", \" \",string)\n",
        "   string = re.sub(\"üåé\", \" \",string)\n",
        "   string = re.sub(\"üëë\", \" \",string)\n",
        "   string = re.sub(\"ü§õ\", \" \",string)\n",
        "   string = re.sub(\"üòÄ\", \" \",string)\n",
        "   string = re.sub(\"üõ§\", \" \",string)\n",
        "   string = re.sub(\"üéÑ\", \" \",string)\n",
        "   string = re.sub(\"üì¥\", \" \",string)\n",
        "   string = re.sub(\"üå≠\", \" \",string)\n",
        "   string = re.sub(\"ü§ï\", \" \",string)\n",
        "   string = re.sub(\"üò≠\", \" \",string)\n",
        "   string = re.sub(\"üçæ\", \" \",string)\n",
        "   string = re.sub(\"üçû\", \" \",string)\n",
        "   string = re.sub(\"ü§¶\", \" \",string)\n",
        "   string = re.sub(\"ü§Ø\", \" \",string)\n",
        "   string = re.sub(\"üïØÔ∏è\", \" \",string)\n",
        "\n",
        "   string = re.sub(\"OTHER|OFFENSE|ABUSE|INSULT\",\" \",string)\n",
        "   return string"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5asMgo4LtnRg"
      },
      "source": [
        "statementsForTraining = []\n",
        "sentimentsForTraining = []\n",
        "\n",
        "\n",
        "fileToRead = open(training_file, 'r')\n",
        "\n",
        "while True:\n",
        "  #next line in file\n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  findSentiment = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "\n",
        "\n",
        "  statementsForTraining.append(line)\n",
        "   #sentimentsForTraining.append(findSentiment.group(0))\n",
        "\n",
        "  if findSentiment.group(0) == \"OTHER\":  \n",
        "    sentimentsForTraining.append(0)\n",
        "  else:\n",
        "    sentimentsForTraining.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        " #print(\"{}: {}\".format(count,line.strip()))\n",
        "  \n",
        " # print(sentiment.group(0))\n",
        " \n",
        "fileToRead.close()\n",
        "\n",
        "training_sentences = statementsForTraining\n",
        "training_labels = sentimentsForTraining\n",
        "\n",
        "#print(training_sentences[9])\n",
        "#print(training_labels[9])\n",
        "\n",
        "#print(len(training_sentences))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsqZPENb98gD"
      },
      "source": [
        "##do the same with testdata\n",
        "statementsForTesting = []\n",
        "sentimentsForTesting = []\n",
        "\n",
        "fileToRead = open(testing_file, 'r')\n",
        "\n",
        "while True:\n",
        "  #next line in file\n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  sent = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "\n",
        "    \n",
        "\n",
        "  statementsForTesting.append(line)\n",
        "  #print(len(line))\n",
        "  #sentimentsForTesting.append(sent.group(0))\n",
        "\n",
        "  if sent.group(0) == \"OTHER\": \n",
        "    sentimentsForTesting.append(0)\n",
        "  else:\n",
        "    sentimentsForTesting.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        "\n",
        "fileToRead.close()\n",
        "\n",
        "\n",
        "testing_sentences = statementsForTesting\n",
        "testing_labels = sentimentsForTesting\n",
        "#print(len(testing_sentences))\n",
        "#print(testing_sentences)   \n",
        "#print(testing_labels)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRUvDLD5bMbO"
      },
      "source": [
        "Padding -> im Prinzip die S√§tze alle auf die gleiche L√§nge bringen (in Theorieteil n√§her drauf eingehen) -> maxlen-Paramter ist f√ºr pad_sequences vorhanden, wenn nicht gesetzt -> alles wird auf die L√§nge des l√§ngsten Satzes aufgef√ºllt -> print(padded(shape)) gibt aus, wie viele Datens√§tze padded wurden und gibt an, wie viele Tokens der l√§ngste Datensatz hat\n",
        "print(padded[x]) gibt einen Satz aus (bereits tokenisiert)\n",
        "\n",
        "Padding -> sowohl f√ºr Trainigs- als auch f√ºr Testdaten\n",
        "\n",
        "Und: Daten als numpy-Arrays speichern (notwendig f√ºr tensorflow).\n",
        "\n",
        " -> Tokenizer https://towardsdatascience.com/text-classification-in-keras-part-2-how-to-use-the-keras-tokenizer-word-representations-fd571674df23 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3hFi7waTv5m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76233ee3-c9b6-43ea-e6d6-50b5efc15fd9"
      },
      "source": [
        "tokenizer = Tokenizer(oov_token=\"OOV\")\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "\n",
        "#creating a word index - nur die Trainigsdaten\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "validation_size = 500\n",
        "\n",
        "\n",
        "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "padded_training = pad_sequences(training_sequences, maxlen=max_length, padding='post')\n",
        "print(len(padded_training))\n",
        "\n",
        "validation_sequences = padded_training[0:validation_size]\n",
        "validation_labels = training_labels[0:validation_size]\n",
        "\n",
        "padded_training = padded_training[validation_size:]\n",
        "training_labels = training_labels[validation_size:]\n",
        "\n",
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
        "padded_testing = pad_sequences(testing_sequences, maxlen=max_length,  padding='post')\n",
        "\n",
        "#print(validation_sequences[499])\n",
        "print(padded_training[0])\n",
        "#print(len(validation_labels))\n",
        "#print(len(training_labels))\n",
        "\n",
        "\n",
        "nppadded_training = np.array(padded_training)\n",
        "nptraining_labels = np.array(training_labels)\n",
        "\n",
        "nppadded_validation = np.array(validation_sequences)\n",
        "npvalidation_labels = np.array(validation_labels)\n",
        "\n",
        "nppadded_testing = np.array(padded_testing)\n",
        "nptesting_labels = np.array(testing_labels)\n",
        "\n",
        "\n",
        "print(len(nppadded_training))\n",
        "print(len(nptraining_labels))\n",
        "print(len(word_index))\n",
        "\n",
        "#print(statementsForTraining[2])\n",
        "#print(nppadded_training[4])\n",
        "#print(nppadded_training.shape)\n",
        "#print(nptraining_labels[4])\n",
        "#print(nppadded_testing.shape)\n",
        "#print(word_index) \n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5009\n",
            "[  12 3982   11   41 6706 1040    4    5  202   39    3 2922   49 1360\n",
            "  810  495 3983    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0]\n",
            "4509\n",
            "4509\n",
            "15059\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tL3owrc8THkT"
      },
      "source": [
        "\n",
        "Dann: Embedding mit entweder word2vec oder glove\n",
        "Word2vec-Daten sind hier: http://vectors.nlpl.eu/repository/#\n",
        "Glove -> https://nlp.stanford.edu/projects/glove/ Da mal den Twitter-Vector runtergeladen\n",
        "Wenn Daten in GoogleDrive sind (w√§re auch via url m√∂glich..), muss Drive gemounted werden ( https://buomsoo-kim.github.io/colab/2020/05/09/Colab-mounting-google-drive.md/ ) aber auch hier https://enjoymachinelearning.com/posts/colab-with-google-drive/\n",
        "\n",
        "Die Word2vec vectors: http://vectors.nlpl.eu/repository/# \n",
        "\n",
        "glove-zitat:\n",
        "Citing GloVe\n",
        "\n",
        "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. [pdf] [bib]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zuO7T9ZTG57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac920fd9-a571-4f76-beb5-40ddd1f9eba5"
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount(\"/content/drive\")\n",
        "os.listdir(\"/content/drive/MyDrive/Colab Notebooks\")\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['germeval_training.txt',\n",
              " 'glove.twitter.27B.50d.txt',\n",
              " 'glove.twitter.27B.200d.txt',\n",
              " 'glove.6B.200d.txt',\n",
              " 'glove.840B.300d.txt',\n",
              " 'tensorboard.gdoc',\n",
              " 'keras.gdoc',\n",
              " 'Vectorization CNN embedded_limited_vocab.ipynb',\n",
              " 'glove.42B.300d.txt',\n",
              " 'Embedding Glove Vergleich.ipynb',\n",
              " 'CNN embedded_limited_vocab.ipynb',\n",
              " 'LSTM_limited_vocab.ipynb',\n",
              " 'LSTM.ipynb',\n",
              " 'CNN embedded.ipynb']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7ToKO-sZLHK"
      },
      "source": [
        "\n",
        "Keras-Doc : https://keras.io/examples/nlp/pretrained_word_embeddings/#load-pretrained-word-embeddings \n",
        "embedding mit initializers.. weights m√ºsste auch funktionieren\n",
        "\n",
        "Diese erstellte Matrix mit Embedding dann in die Embedding-Schicht einbinden,  Trainable auf False, weil sich die Werte nicht durch Training anpassen sollen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AShIVfC7ZQAH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56e380d1-5cc7-4f7a-e245-74822b2e9fbd"
      },
      "source": [
        "#Gr√∂√üe Vokabel -> wordindex + 2 (weil padding + OOV) \n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "vocabulary_size = len(word_index)+2\n",
        "\n",
        "# dann erstell ich ein W√∂rterbuch mit Namen \"embedding_vector\", dort sind dann\n",
        "#die keys drinnen, die in glove-Datei drinnen sind mit dem entsprechenden Key\n",
        "\n",
        "embedding_index_glove = {}\n",
        "f = open('/content/drive/MyDrive/Colab Notebooks/glove.twitter.27B.200d.txt')\n",
        "for line in f:\n",
        "  value = line.split()\n",
        "  word = value[0]\n",
        "  coef = np.asarray(value[1:],dtype='float32')\n",
        "  embedding_index_glove[word] = coef\n",
        "\n",
        "print(\"%d gefunden: \"% len(embedding_index_glove))\n",
        "\n",
        "#Dann noch eine Embedding-Matrix erstellen\n",
        "#zweiter Wert = Embedding-Dimension der Datei, in dem Fall 200\n",
        "\n",
        "glove_matrix = np.zeros((vocabulary_size,200))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    embedding_value = embedding_index_glove.get(word)\n",
        "    if embedding_value is not None:\n",
        "      glove_matrix[index] = embedding_value\n",
        "      hits+=1\n",
        "    else:\n",
        "      misses+=1\n",
        "\n",
        "print(\"hits %d and %d misses\"%(hits,misses))\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1193514 gefunden: \n",
            "hits 6747 and 8312 misses\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZmvOfwhV4N5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d10a015-efb2-4bb4-b235-318bd25eea76"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "print(\"vocab size: %d\"%vocabulary_size)\n",
        "CNN16052102ES07 = tf.keras.Sequential()\n",
        "#Embedding -> hier dann auf das embedding verweisen, Input_dim -> die Anzahl der W√∂rter im word_index, output -> in dem Fall passend zum verwendeten Vektor\n",
        "#input-length -> auf 60  gepadded, trainable -> nein, weil nichts ver√§ndert werden soll\n",
        "#embeddings_initializer=keras.initializers.Constant(glove_matrix) vs weights = [glove_matrix]\n",
        "#Convolutional layers => filters = neurons.. mit 100? 265?\n",
        "#CNN16052102ES07.add(tf.keras.layers.Embedding(input_dim=vocabulary_size, output_dim=200, input_length=max_length))\n",
        "CNN16052102ES07.add(tf.keras.layers.Embedding(vocabulary_size, output_dim=200, input_length=60, embeddings_initializer = keras.initializers.Constant(glove_matrix), trainable= False))\n",
        "CNN16052102ES07.add(tf.keras.layers.Dropout(0.4))\n",
        "CNN16052102ES07.add(tf.keras.layers.Conv1D(filters=120, kernel_size=3, padding=\"valid\", activation=\"relu\"))\n",
        "CNN16052102ES07.add(tf.keras.layers.MaxPooling1D())\n",
        "CNN16052102ES07.add(tf.keras.layers.Conv1D(filters=120, kernel_size=3, padding=\"valid\", activation=\"relu\"))\n",
        "CNN16052102ES07.add(tf.keras.layers.GlobalAveragePooling1D())\n",
        "CNN16052102ES07.add(tf.keras.layers.Flatten())\n",
        "CNN16052102ES07.add(tf.keras.layers.Dense(260, activation=\"relu\"))\n",
        "CNN16052102ES07.add(tf.keras.layers.Dropout(0.4))\n",
        "CNN16052102ES07.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "CNN16052102ES07.summary()\n",
        "\n",
        "#nppadded_training = np.asmatrix(nppadded_training) not necessary\n",
        "#nppadded_testing = np.asmatrix(nppadded_testing)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab size: 15061\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 60, 200)           3012200   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 60, 200)           0         \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 58, 120)           72120     \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 29, 120)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 27, 120)           43320     \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 120)               0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 120)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 260)               31460     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 260)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 261       \n",
            "=================================================================\n",
            "Total params: 3,159,361\n",
            "Trainable params: 147,161\n",
            "Non-trainable params: 3,012,200\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEr4OzT-iHDe"
      },
      "source": [
        "#model.layers[2].get_weights()[0].shape\n",
        "#weights=np.random.rand(5,200,100)\n",
        "#bias=np.random.rand(100)\n",
        "#model.layers[2].set_weights([weights, bias])\n",
        "\n",
        "#model.layers[2].get_weights()[0]\n",
        "#https://androidkt.com/set-custom-weights-keras-using-numpy-array/"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UB7_3VPYesr9"
      },
      "source": [
        "F1-Score f√ºr jede Epoche https://aakashgoel12.medium.com/how-to-add-user-defined-function-get-f1-score-in-keras-metrics-3013f979ce0d\n",
        "\n",
        "Sehr gute Ressource f√ºr die verschiedenen Scores und Metriken https://neptune.ai/blog/evaluation-metrics-binary-classification#10  das und aakas verwendet\n",
        "\n",
        "hier: je eine Funktion f√ºr Recall, Precision, f1 https://neptune.ai/blog/keras-metrics \n",
        "\n",
        "https://keras.rstudio.com/reference/k_ones_like.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygyrbFJaMV9B"
      },
      "source": [
        "import keras.backend as K\n",
        "\n",
        "def metrics_recall(data_true, data_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(data_true,0,1)))\n",
        "\n",
        "    recall = true_positives / (possible_positives+K.epsilon())\n",
        "    return recall\n",
        "\n",
        "\n",
        "def metrics_precision(data_true, data_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "\n",
        "    positives_predicted = K.sum(K.round(K.clip(data_pred,0,1)))\n",
        "    precision = true_positives / (positives_predicted+K.epsilon())\n",
        "    return precision\n",
        "\n",
        "\n",
        "def metrics_f1(data_true, data_pred):\n",
        "    precision_data = metrics_precision(data_true, data_pred)\n",
        "    recall_data = metrics_recall(data_true, data_pred)\n",
        "    return 2*(precision_data*recall_data)/(precision_data+recall_data+K.epsilon())"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1ctlBrnuYJz"
      },
      "source": [
        "https://aakashgoel12.medium.com/how-to-add-user-defined-function-get-f1-score-in-keras-metrics-3013f979ce0d"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AfPD3_bWCm0"
      },
      "source": [
        "CNN16052102ES07.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',metrics_recall,metrics_precision,metrics_f1])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpChKUY-QEWI"
      },
      "source": [
        "https://www.tensorflow.org/tensorboard/tensorboard_in_notebooks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJfMgUhHBoD1"
      },
      "source": [
        "#%load_ext tensorboard\n",
        "#nur einmal pro Sitzung notwendig\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ISmMXLqP8Hc"
      },
      "source": [
        "\n",
        "logs_base_dir = \"./logs\"\n",
        "callbackForTB = tf.keras.callbacks.TensorBoard(logs_base_dir)\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ehh-EMXUQh8r"
      },
      "source": [
        "Early Stopping as defined in keras tensorflow documentation\n",
        "https://www.tensorflow.org/guide/keras/train_and_evaluate "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BY_t-PeQEjy"
      },
      "source": [
        "callbackEarlyStopping = [\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_accuracy\",\n",
        "        mode=\"max\",\n",
        "        patience=3,\n",
        "        verbose=1,\n",
        "    )\n",
        "]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2CHbXiP1LsF"
      },
      "source": [
        "training_epochs = 30\n",
        "batch_size = 40\n",
        "validation_split=0.2"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abV-QAxfW48r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cddbc72d-fb0d-4d3c-e0e4-311c06c01ca2"
      },
      "source": [
        "#Werte der Convolutional-Schichten variieren (Filter), Batch-Size variieren, kernel-size..\n",
        "CNN16052102ES07.fit(nppadded_training, nptraining_labels, batch_size=batch_size, validation_split=validation_split, epochs=training_epochs, callbacks=[callbackForTB,callbackEarlyStopping])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "91/91 [==============================] - 6s 49ms/step - loss: 0.6617 - accuracy: 0.6445 - metrics_recall: 0.0555 - metrics_precision: 0.0216 - metrics_f1: 0.0311 - val_loss: 0.6322 - val_accuracy: 0.6718 - val_metrics_recall: 0.0000e+00 - val_metrics_precision: 0.0000e+00 - val_metrics_f1: 0.0000e+00\n",
            "Epoch 2/30\n",
            "91/91 [==============================] - 4s 42ms/step - loss: 0.6398 - accuracy: 0.6559 - metrics_recall: 7.7613e-04 - metrics_precision: 0.0089 - metrics_f1: 0.0014 - val_loss: 0.6201 - val_accuracy: 0.6718 - val_metrics_recall: 0.0000e+00 - val_metrics_precision: 0.0000e+00 - val_metrics_f1: 0.0000e+00\n",
            "Epoch 3/30\n",
            "91/91 [==============================] - 4s 42ms/step - loss: 0.6149 - accuracy: 0.6624 - metrics_recall: 0.0603 - metrics_precision: 0.1837 - metrics_f1: 0.0773 - val_loss: 0.6029 - val_accuracy: 0.6707 - val_metrics_recall: 0.0071 - val_metrics_precision: 0.0870 - val_metrics_f1: 0.0130\n",
            "Epoch 4/30\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.5944 - accuracy: 0.6799 - metrics_recall: 0.1833 - metrics_precision: 0.4475 - metrics_f1: 0.2353 - val_loss: 0.5657 - val_accuracy: 0.7018 - val_metrics_recall: 0.3881 - val_metrics_precision: 0.5693 - val_metrics_f1: 0.4475\n",
            "Epoch 5/30\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.5543 - accuracy: 0.7070 - metrics_recall: 0.4139 - metrics_precision: 0.6433 - metrics_f1: 0.4615 - val_loss: 0.5505 - val_accuracy: 0.7173 - val_metrics_recall: 0.4427 - val_metrics_precision: 0.5923 - val_metrics_f1: 0.4914\n",
            "Epoch 6/30\n",
            "91/91 [==============================] - 4s 42ms/step - loss: 0.5167 - accuracy: 0.7411 - metrics_recall: 0.4535 - metrics_precision: 0.6527 - metrics_f1: 0.5119 - val_loss: 0.5403 - val_accuracy: 0.7140 - val_metrics_recall: 0.2872 - val_metrics_precision: 0.6209 - val_metrics_f1: 0.3809\n",
            "Epoch 7/30\n",
            "91/91 [==============================] - 4s 40ms/step - loss: 0.4867 - accuracy: 0.7599 - metrics_recall: 0.4721 - metrics_precision: 0.7323 - metrics_f1: 0.5485 - val_loss: 0.5379 - val_accuracy: 0.7151 - val_metrics_recall: 0.4799 - val_metrics_precision: 0.5656 - val_metrics_f1: 0.5069\n",
            "Epoch 8/30\n",
            "91/91 [==============================] - 4s 40ms/step - loss: 0.4513 - accuracy: 0.7770 - metrics_recall: 0.5991 - metrics_precision: 0.7086 - metrics_f1: 0.6375 - val_loss: 0.5356 - val_accuracy: 0.7140 - val_metrics_recall: 0.5071 - val_metrics_precision: 0.5746 - val_metrics_f1: 0.5225\n",
            "Epoch 00008: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe40cbd3810>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJVL4SBLPB2P"
      },
      "source": [
        "#%tensorboard --logdir {logs_base_dir}"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_LnvWBcnoak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d21ef5b-3dee-46a0-a286-be59d558db57"
      },
      "source": [
        "#results = model.evaluate(nppadded_testing, nptesting_labels, batch_size=batch_size)\n",
        "#print(\"test loss, test acc:\",results)\n",
        "\n",
        "(loss,accuracy, metrics_recall,metrics_precision,\n",
        "metrics_f1) = CNN16052102ES07.evaluate(nppadded_testing, nptesting_labels, verbose=1)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "111/111 [==============================] - 1s 12ms/step - loss: 0.5796 - accuracy: 0.6823 - metrics_recall: 0.3597 - metrics_precision: 0.5507 - metrics_f1: 0.4196\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KgjIkhpKmHc"
      },
      "source": [
        "make some predictions of test data and save it to variable. verbose=0 -> do not generate output\n",
        "Gute Quelle: https://deeplizard.com/learn/video/2f-NjDUvZIE "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89GWuxryKlcM"
      },
      "source": [
        "CNN_predictions06 = CNN16052102ES07.predict(x=nppadded_testing)\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3jPDaDJK_cN"
      },
      "source": [
        "#for p in CNN_predictions06:\n",
        " # print(p)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eC9efJy4Lp21"
      },
      "source": [
        "rounded predictions: give prediction value of most likely prediction (0 or 1). Printing the output of rounded prediction shows the prediction made by the model on the data (which output is most likely)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsG-TJuQLvtk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c47dfa9-5326-4c7d-b2ea-b8ea0bf889fa"
      },
      "source": [
        "prediction_rounded06 = np.round(CNN_predictions06)\n",
        "#np.argmax(CNN_predictions06,axis=-1)\n",
        "\n",
        "#for p in prediction_rounded06:\n",
        " # print(p)\n",
        "\n",
        "\n",
        "print(nptesting_labels[500:520])\n",
        "print(prediction_rounded06[500:520])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1]\n",
            "[[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egTtgpXgg8a2"
      },
      "source": [
        "https://deeplizard.com/learn/video/km7pxKy4UHU\n",
        "\n",
        "Quelle der def plot_confusion_matrix: https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSDXf7-_MITy"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0AMs1EzhBU1"
      },
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                        normalize=False,\n",
        "                        title='Confusion matrix',\n",
        "                        cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2JgEnlghCtl"
      },
      "source": [
        "cm = confusion_matrix(y_true=nptesting_labels, y_pred=prediction_rounded06)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckmF29whhFmX"
      },
      "source": [
        "plot_labels = ['no hatespeech','hatespeech']"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "2mpSE96rhK7K",
        "outputId": "789adcd8-d6fa-4927-919a-89edb316a206"
      },
      "source": [
        "plot_confusion_matrix(cm=cm, classes=plot_labels, title='CNN Confusion 120 EarlyStopping max acc')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix, without normalization\n",
            "[[1986  344]\n",
            " [ 778  424]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}