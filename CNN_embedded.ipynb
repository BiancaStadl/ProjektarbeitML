{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN embedded.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOhQQDgQpwveEFWbuD7RVn4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BiancaStadl/ProjektarbeitML/blob/main/CNN_embedded.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXDOlIBymF0V"
      },
      "source": [
        "GloVe embeddings taken from:\n",
        "\n",
        "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. [pdf] [bib]\n",
        "\n",
        "hatespeechdata taken from (https://hatespeechdata.com/): Wiegand, M., Siegel, M. and Ruppenhofer, J., 2018. Overview of the GermEval 2018 Shared Task on the Identification of Offensive Language. In: Proceedings of GermEval 2018, 14th Conference on Natural Language Processing (KONVENS 2018). Vienna, Austria: Research Gate. available on: https://github.com/uds-lsv/GermEval-2018-Data (last checked: 09.05.2021)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlBmABDxfqII"
      },
      "source": [
        "wiki detox..https://colab.research.google.com/github/tensorflow/fairness-indicators/blob/master/g3doc/tutorials/Fairness_Indicators_TFCO_Wiki_Case_Study.ipynb#scrollTo=y6T5tlXcdW7J "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3xfitNdliBI"
      },
      "source": [
        "#import matplotlib.pyplot as plt -> f√ºr evtl Visualisierungen\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import string\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from keras import losses \n",
        "from keras import optimizers \n",
        "from keras import metrics \n",
        "\n",
        "#!pip install Tokenizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "#!pip install pad_sequences\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import preprocessing\n",
        "#from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTWJQ1iga_vS"
      },
      "source": [
        "Maximale Satzl√§nge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bq08Me5la_Cc"
      },
      "source": [
        "\n",
        "max_length = 60"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVYBMvYSotTH"
      },
      "source": [
        "url = \"https://github.com/uds-lsv/GermEval-2018-Data/archive/master.zip\"\n",
        "\n",
        "dataset = tf.keras.utils.get_file(\"GermEval-2018-Data-master.zip\", url, \n",
        "                                   extract=True, cache_dir='.',\n",
        "                                    cache_subdir='')\n",
        "\n",
        "dataset_dir = os.path.join(os.path.dirname(dataset), 'GermEval-2018-Data-master')\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cS14OUtfo34V"
      },
      "source": [
        "#os.listdir(dataset_dir)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2X429K6hpOVm"
      },
      "source": [
        "training_file = os.path.join(dataset_dir, 'germeval2018.training.txt')\n",
        "\n",
        "testing_file = os.path.join(dataset_dir, 'germeval2018.test.txt')\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uq8fG3LNtn_m"
      },
      "source": [
        "###Aufbereitung\n",
        "txt-Dateien lesen, und dabei jede Zeile splitten und teilen\n",
        "Twitter-Handler entfernen?\n",
        "Labels von S√§tzen trennen, Labels in eigenen Array packen.\n",
        "\n",
        "####Ressourcen\n",
        "* https://www.w3schools.com/python/gloss_python_if_statement.asp\n",
        "* https://stackabuse.com/using-regex-for-text-manipulation-in-python/\n",
        "* https://www.tutorialspoint.com/python/string_splitlines.htm \n",
        "* https://note.nkmk.me/en/python-split-rsplit-splitlines-re/ \n",
        "* https://www.w3schools.com/python/python_regex.asp \n",
        "\n",
        "g√§be bei keras tf.keras.preprocessing.text_dataset_from_directory, aber daf√ºr m√ºssten die Daten auf bestimmte Weise in Verzeichnis organisiert sein, hier nicht der Fall.\n",
        "\n",
        "\n",
        "Einteilung der Daten: Testdaten\n",
        "Trainingsdaten -> noch ca 500 f√ºr Validierungsdaten\n",
        "\n",
        "labels -> \"other\", also nicht-negative Aussagen bekommen \"0\", negative Aussagen bekommen \"1\"\n",
        "\n",
        " Regex f√ºr Emojis  ->\n",
        "\n",
        "(\\u00a9|\\u00ae|[\\u2000-\\u3300]|\\ud83c[\\ud000-\\udfff]|\\ud83d[\\ud000-\\udfff]|\\ud83e[\\ud000-\\udfff])\n",
        "\n",
        "genommen von https://www.regextester.com/106421 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Py_cwD4eZkXo"
      },
      "source": [
        "def remove_clutter(string):\n",
        "   string = re.sub(\"@[^\\s]+\",\" \",string)\n",
        "   string = re.sub(\"#[^\\s]+\",\" \", string)\n",
        "   string = re.sub(\"\\u00a9\",\" \", string)\n",
        "   string = re.sub(\"\\u00ae\",\" \", string)\n",
        "   string = re.sub(\"[\\u2000-\\u3300]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83c[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83d[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83e[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"üòú\", \" \",string)\n",
        "   string = re.sub(\"üç´\", \" \",string)\n",
        "   string = re.sub(\"üòÅ\", \" \",string)\n",
        "   string = re.sub(\"üêñ\", \" \",string)\n",
        "   string = re.sub(\"üò°\", \" \",string)\n",
        "   string = re.sub(\"üòá\", \" \",string)\n",
        "   string = re.sub(\"üò¨\", \" \",string)\n",
        "   string = re.sub(\"üòÉ\", \" \",string)\n",
        "   string = re.sub(\"üòÇ\", \" \",string)\n",
        "   string = re.sub(\"üíô\", \" \",string)  \n",
        "   string = re.sub(\"üòõ\", \" \",string)\n",
        "   string = re.sub(\"üôè\", \" \",string)\n",
        "   string = re.sub(\"üëç\", \" \",string)\n",
        "   string = re.sub(\"üñï\", \" \",string)\n",
        "   string = re.sub(\"üòâ\", \" \",string)\n",
        "   string = re.sub(\"üí©\", \" \",string)\n",
        "   string = re.sub(\"ü§¢\", \" \",string)\n",
        "   string = re.sub(\"üëè\", \" \",string)\n",
        "   string = re.sub(\"üò®\", \" \",string)\n",
        "   string = re.sub(\"ü§£\", \" \",string)\n",
        "   string = re.sub(\"ü§°\", \" \",string)\n",
        "   string = re.sub(\"üòà\", \" \",string)\n",
        "   string = re.sub(\"üíÉüèΩ\", \" \",string)\n",
        "   string = re.sub(\"üëπ\", \" \",string)\n",
        "   string = re.sub(\"ü§ò\", \" \",string)\n",
        "   string = re.sub(\"üò±\", \" \",string)\n",
        "   string = re.sub(\"ü§î\", \" \",string) \n",
        "   string = re.sub(\"üåà\", \" \",string) \n",
        "   string = re.sub(\"üíï\", \" \",string) \n",
        "   string = re.sub(\"üë©‚Äç‚ù§Ô∏è‚Äçüë©\", \" \",string) \n",
        "   string = re.sub(\"üòç\", \" \",string) \n",
        "   string = re.sub(\"üëÜ\", \" \",string) \n",
        "   string = re.sub(\"üòñ\", \" \",string) \n",
        "   string = re.sub(\"üëá\", \" \",string) \n",
        "   string = re.sub(\"üî•\", \" \",string) \n",
        "   string = re.sub(\"üòò\", \" \",string) \n",
        "   string = re.sub(\"üéâ\", \" \",string) \n",
        "   string = re.sub(\"ü§¨\", \" \",string) \n",
        "   string = re.sub(\"üëä\", \" \",string)\n",
        "   string = re.sub(\"üá©üá™\", \" \",string)  \n",
        "   string = re.sub(\"üíî\", \" \",string)\n",
        "   string = re.sub(\"üôà\", \" \",string)\n",
        "   string = re.sub(\"ü§Ø\", \" \",string)\n",
        "   string = re.sub(\"üêü\", \" \",string)\n",
        "   string = re.sub(\"üõ∂\", \" \",string)\n",
        "   string = re.sub(\"üòä\", \" \",string)\n",
        "   string = re.sub(\"üòì\", \" \",string)\n",
        "   string = re.sub(\"üò≥\", \" \",string)\n",
        "   string = re.sub(\"üöÄ\", \" \",string)\n",
        "   string = re.sub(\"üëé\", \" \",string)\n",
        "   string = re.sub(\"üòé\", \" \",string)\n",
        "   string = re.sub(\"üê∏\", \" \",string)\n",
        "   string = re.sub(\"üìà\", \" \",string)\n",
        "   string = re.sub(\"üôÇ\", \" \",string)\n",
        "   string = re.sub(\"üòÖ\", \" \",string)\n",
        "   string = re.sub(\"üòÜ\", \" \",string)\n",
        "   string = re.sub(\"üôéüèø\", \" \",string)\n",
        "   string = re.sub(\"üëéüèΩ\", \" \",string)\n",
        "   string = re.sub(\"ü§≠\", \" \",string)\n",
        "   string = re.sub(\"üò§\", \" \",string)\n",
        "   string = re.sub(\"üòö\", \" \",string)\n",
        "   string = re.sub(\"üòä\", \" \",string)\n",
        "   string = re.sub(\"üò≤\", \" \",string)\n",
        "   string = re.sub(\"ü§Æ\", \" \",string)\n",
        "   string = re.sub(\"üôÑ\", \" \",string)\n",
        "   string = re.sub(\"ü§ë\", \" \",string)\n",
        "   string = re.sub(\"üéÖ\", \" \",string)\n",
        "   string = re.sub(\"üëã\", \" \",string)\n",
        "   string = re.sub(\"üí™\", \" \",string)\n",
        "   string = re.sub(\"üòÑ\", \" \",string)\n",
        "   string = re.sub(\"üßê\", \" \",string)\n",
        "   string = re.sub(\"üò†\", \" \",string)\n",
        "   string = re.sub(\"üéà\", \" \",string)\n",
        "   string = re.sub(\"üöÇ\", \" \",string)\n",
        "   string = re.sub(\"üòä\", \" \",string)\n",
        "   string = re.sub(\"üöá\", \" \",string)\n",
        "   string = re.sub(\"üöä\", \" \",string)\n",
        "   string = re.sub(\"ü§∑\", \" \",string)\n",
        "   string = re.sub(\"üò•\", \" \",string)\n",
        "   string = re.sub(\"üôÉ\", \" \",string)\n",
        "   string = re.sub(\"üî©\", \" \",string)\n",
        "   string = re.sub(\"üîß\", \" \",string)\n",
        "   string = re.sub(\"üî®\", \" \",string)\n",
        "   string = re.sub(\"üõ†\", \" \",string)\n",
        "   string = re.sub(\"üíì\", \" \",string)\n",
        "   string = re.sub(\"üí°\", \" \",string)\n",
        "   string = re.sub(\"üç∏\", \" \",string)\n",
        "   string = re.sub(\"ü•É\", \" \",string)\n",
        "   string = re.sub(\"ü•Ç\", \" \",string)\n",
        "   string = re.sub(\"üò∑\", \" \",string)\n",
        "   string = re.sub(\"ü§ê\", \" \",string)\n",
        "   string = re.sub(\"üåé\", \" \",string)\n",
        "   string = re.sub(\"üëë\", \" \",string)\n",
        "   string = re.sub(\"ü§õ\", \" \",string)\n",
        "   string = re.sub(\"üòÄ\", \" \",string)\n",
        "   string = re.sub(\"üõ§\", \" \",string)\n",
        "   string = re.sub(\"üéÑ\", \" \",string)\n",
        "   string = re.sub(\"üì¥\", \" \",string)\n",
        "   string = re.sub(\"üå≠\", \" \",string)\n",
        "   string = re.sub(\"ü§ï\", \" \",string)\n",
        "   string = re.sub(\"üò≠\", \" \",string)\n",
        "   string = re.sub(\"üçæ\", \" \",string)\n",
        "   string = re.sub(\"üçû\", \" \",string)\n",
        "   string = re.sub(\"ü§¶\", \" \",string)\n",
        "   string = re.sub(\"ü§Ø\", \" \",string)\n",
        "   string = re.sub(\"üïØÔ∏è\", \" \",string)\n",
        "\n",
        "   string = re.sub(\"OTHER|OFFENSE|ABUSE|INSULT\",\" \",string)\n",
        "   return string"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5asMgo4LtnRg"
      },
      "source": [
        "statementsForTraining = []\n",
        "sentimentsForTraining = []\n",
        "\n",
        "\n",
        "fileToRead = open(training_file, 'r')\n",
        "\n",
        "while True:\n",
        "  #next line in file\n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  findSentiment = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "\n",
        "\n",
        "  statementsForTraining.append(line)\n",
        "   #sentimentsForTraining.append(findSentiment.group(0))\n",
        "\n",
        "  if findSentiment.group(0) == \"OTHER\":  \n",
        "    sentimentsForTraining.append(0)\n",
        "  else:\n",
        "    sentimentsForTraining.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        " #print(\"{}: {}\".format(count,line.strip()))\n",
        "  \n",
        " # print(sentiment.group(0))\n",
        " \n",
        "fileToRead.close()\n",
        "\n",
        "training_sentences = statementsForTraining\n",
        "training_labels = sentimentsForTraining\n",
        "\n",
        "#print(training_sentences[9])\n",
        "#print(training_labels[9])\n",
        "\n",
        "#print(len(training_sentences))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsqZPENb98gD"
      },
      "source": [
        "##do the same with testdata\n",
        "statementsForTesting = []\n",
        "sentimentsForTesting = []\n",
        "\n",
        "fileToRead = open(testing_file, 'r')\n",
        "\n",
        "while True:\n",
        "  #next line in file\n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  sent = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "\n",
        "    \n",
        "\n",
        "  statementsForTesting.append(line)\n",
        "  #print(len(line))\n",
        "  #sentimentsForTesting.append(sent.group(0))\n",
        "\n",
        "  if sent.group(0) == \"OTHER\": \n",
        "    sentimentsForTesting.append(0)\n",
        "  else:\n",
        "    sentimentsForTesting.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        "\n",
        "fileToRead.close()\n",
        "\n",
        "\n",
        "testing_sentences = statementsForTesting\n",
        "testing_labels = sentimentsForTesting\n",
        "#print(len(testing_sentences))\n",
        "#print(testing_sentences)   \n",
        "#print(testing_labels)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRUvDLD5bMbO"
      },
      "source": [
        "Padding -> im Prinzip die S√§tze alle auf die gleiche L√§nge bringen (in Theorieteil n√§her drauf eingehen) -> maxlen-Paramter ist f√ºr pad_sequences vorhanden, wenn nicht gesetzt -> alles wird auf die L√§nge des l√§ngsten Satzes aufgef√ºllt -> print(padded(shape)) gibt aus, wie viele Datens√§tze padded wurden und gibt an, wie viele Tokens der l√§ngste Datensatz hat\n",
        "print(padded[x]) gibt einen Satz aus (bereits tokenisiert)\n",
        "\n",
        "Padding -> sowohl f√ºr Trainigs- als auch f√ºr Testdaten\n",
        "\n",
        "Und: Daten als numpy-Arrays speichern (notwendig f√ºr tensorflow).\n",
        "\n",
        " -> Tokenizer https://towardsdatascience.com/text-classification-in-keras-part-2-how-to-use-the-keras-tokenizer-word-representations-fd571674df23 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3hFi7waTv5m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52ec0726-8d97-404a-95b1-6e1e8d654341"
      },
      "source": [
        "tokenizer = Tokenizer(oov_token=\"OOV\")\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "\n",
        "#creating a word index - nur die Trainigsdaten\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "validation_size = 500\n",
        "\n",
        "\n",
        "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "padded_training = pad_sequences(training_sequences, maxlen=max_length, padding='post')\n",
        "print(len(padded_training))\n",
        "\n",
        "validation_sequences = padded_training[0:validation_size]\n",
        "validation_labels = training_labels[0:validation_size]\n",
        "\n",
        "padded_training = padded_training[validation_size:]\n",
        "training_labels = training_labels[validation_size:]\n",
        "\n",
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
        "padded_testing = pad_sequences(testing_sequences, maxlen=max_length,  padding='post')\n",
        "\n",
        "#print(validation_sequences[499])\n",
        "print(padded_training[0])\n",
        "#print(len(validation_labels))\n",
        "#print(len(training_labels))\n",
        "\n",
        "\n",
        "nppadded_training = np.array(padded_training)\n",
        "nptraining_labels = np.array(training_labels)\n",
        "\n",
        "nppadded_validation = np.array(validation_sequences)\n",
        "npvalidation_labels = np.array(validation_labels)\n",
        "\n",
        "nppadded_testing = np.array(padded_testing)\n",
        "nptesting_labels = np.array(testing_labels)\n",
        "\n",
        "\n",
        "print(len(nppadded_training))\n",
        "print(len(nptraining_labels))\n",
        "print(len(word_index))\n",
        "\n",
        "#print(statementsForTraining[2])\n",
        "#print(nppadded_training[4])\n",
        "#print(nppadded_training.shape)\n",
        "#print(nptraining_labels[4])\n",
        "#print(nppadded_testing.shape)\n",
        "#print(word_index) \n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5009\n",
            "[  12 3982   11   41 6706 1040    4    5  202   39    3 2922   49 1360\n",
            "  810  495 3983    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0]\n",
            "4509\n",
            "4509\n",
            "15059\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tL3owrc8THkT"
      },
      "source": [
        "\n",
        "Dann: Embedding mit entweder word2vec oder glove\n",
        "Word2vec-Daten sind hier: http://vectors.nlpl.eu/repository/#\n",
        "Glove -> https://nlp.stanford.edu/projects/glove/ Da mal den Twitter-Vector runtergeladen\n",
        "Wenn Daten in GoogleDrive sind (w√§re auch via url m√∂glich..), muss Drive gemounted werden ( https://buomsoo-kim.github.io/colab/2020/05/09/Colab-mounting-google-drive.md/ ) aber auch hier https://enjoymachinelearning.com/posts/colab-with-google-drive/\n",
        "\n",
        "Die Word2vec vectors: http://vectors.nlpl.eu/repository/# \n",
        "\n",
        "glove-zitat:\n",
        "Citing GloVe\n",
        "\n",
        "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. [pdf] [bib]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zuO7T9ZTG57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e52921f5-2ffd-46cb-9a99-0eea2fbb89d6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "os.listdir(\"/content/drive/MyDrive/Colab Notebooks\")\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['germeval_training.txt',\n",
              " 'glove.twitter.27B.50d.txt',\n",
              " 'glove.twitter.27B.200d.txt',\n",
              " 'glove.6B.200d.txt',\n",
              " 'glove.840B.300d.txt',\n",
              " 'tensorboard.gdoc',\n",
              " 'keras.gdoc',\n",
              " 'Vectorization CNN embedded_limited_vocab.ipynb',\n",
              " 'glove.42B.300d.txt',\n",
              " 'Embedding Glove Vergleich.ipynb',\n",
              " 'CNN embedded_limited_vocab.ipynb',\n",
              " 'LSTM_limited_vocab.ipynb',\n",
              " 'LSTM.ipynb',\n",
              " 'CNN embedded.ipynb']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7ToKO-sZLHK"
      },
      "source": [
        "\n",
        "Keras-Doc : https://keras.io/examples/nlp/pretrained_word_embeddings/#load-pretrained-word-embeddings \n",
        "embedding mit initializers.. weights m√ºsste auch funktionieren\n",
        "\n",
        "Diese erstellte Matrix mit Embedding dann in die Embedding-Schicht einbinden,  Trainable auf False, weil sich die Werte nicht durch Training anpassen sollen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AShIVfC7ZQAH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f781d89a-54f1-4ce4-b9c9-858cf3c3dba3"
      },
      "source": [
        "#Gr√∂√üe Vokabel -> wordindex + 2 (weil padding + OOV) \n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "vocabulary_size = len(word_index)+2\n",
        "\n",
        "# dann erstell ich ein W√∂rterbuch mit Namen \"embedding_vector\", dort sind dann\n",
        "#die keys drinnen, die in glove-Datei drinnen sind mit dem entsprechenden Key\n",
        "\n",
        "embedding_index_glove = {}\n",
        "f = open('/content/drive/MyDrive/Colab Notebooks/glove.twitter.27B.200d.txt')\n",
        "for line in f:\n",
        "  value = line.split()\n",
        "  word = value[0]\n",
        "  coef = np.asarray(value[1:],dtype='float32')\n",
        "  embedding_index_glove[word] = coef\n",
        "\n",
        "print(\"%d gefunden: \"% len(embedding_index_glove))\n",
        "\n",
        "#Dann noch eine Embedding-Matrix erstellen\n",
        "#zweiter Wert = Embedding-Dimension der Datei, in dem Fall 200\n",
        "\n",
        "glove_matrix = np.zeros((vocabulary_size,200))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    embedding_value = embedding_index_glove.get(word)\n",
        "    if embedding_value is not None:\n",
        "      glove_matrix[index] = embedding_value\n",
        "      hits+=1\n",
        "    else:\n",
        "      misses+=1\n",
        "\n",
        "print(\"hits %d and %d misses\"%(hits,misses))\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1193514 gefunden: \n",
            "hits 6747 and 8312 misses\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZmvOfwhV4N5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4df57666-11a9-4c9e-8dd9-d7b614ce6505"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "print(\"vocab size: %d\"%vocabulary_size)\n",
        "CNN16052102EIEM02 = tf.keras.Sequential()\n",
        "#Embedding -> hier dann auf das embedding verweisen, Input_dim -> die Anzahl der W√∂rter im word_index, output -> in dem Fall passend zum verwendeten Vektor\n",
        "#input-length -> auf 60  gepadded, trainable -> nein, weil nichts ver√§ndert werden soll\n",
        "#embeddings_initializer=keras.initializers.Constant(glove_matrix) vs weights = [glove_matrix]\n",
        "#Convolutional layers => filters = neurons.. mit 100? 265?\n",
        "CNN16052102EIEM02.add(tf.keras.layers.Embedding(input_dim=vocabulary_size, output_dim=200, input_length=max_length))\n",
        "#CNN16052102EIEM02.add(tf.keras.layers.Embedding(vocabulary_size, output_dim=200, input_length=60, embeddings_initializer = keras.initializers.Constant(glove_matrix), trainable= False))\n",
        "CNN16052102EIEM02.add(tf.keras.layers.Dropout(0.4))\n",
        "CNN16052102EIEM02.add(tf.keras.layers.Conv1D(filters=120, kernel_size=3, padding=\"valid\", activation=\"relu\"))\n",
        "CNN16052102EIEM02.add(tf.keras.layers.MaxPooling1D())\n",
        "CNN16052102EIEM02.add(tf.keras.layers.Conv1D(filters=120, kernel_size=3, padding=\"valid\", activation=\"relu\"))\n",
        "CNN16052102EIEM02.add(tf.keras.layers.GlobalAveragePooling1D())\n",
        "CNN16052102EIEM02.add(tf.keras.layers.Flatten())\n",
        "CNN16052102EIEM02.add(tf.keras.layers.Dense(260, activation=\"relu\"))\n",
        "CNN16052102EIEM02.add(tf.keras.layers.Dropout(0.4))\n",
        "CNN16052102EIEM02.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "CNN16052102EIEM02.summary()\n",
        "\n",
        "#nppadded_training = np.asmatrix(nppadded_training) not necessary\n",
        "#nppadded_testing = np.asmatrix(nppadded_testing)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab size: 15061\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 60, 200)           3012200   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 60, 200)           0         \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 58, 120)           72120     \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 29, 120)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 27, 120)           43320     \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 120)               0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 120)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 260)               31460     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 260)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 261       \n",
            "=================================================================\n",
            "Total params: 3,159,361\n",
            "Trainable params: 3,159,361\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEr4OzT-iHDe"
      },
      "source": [
        "#model.layers[2].get_weights()[0].shape\n",
        "#weights=np.random.rand(5,200,100)\n",
        "#bias=np.random.rand(100)\n",
        "#model.layers[2].set_weights([weights, bias])\n",
        "\n",
        "#model.layers[2].get_weights()[0]\n",
        "#https://androidkt.com/set-custom-weights-keras-using-numpy-array/"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UB7_3VPYesr9"
      },
      "source": [
        "F1-Score f√ºr jede Epoche https://aakashgoel12.medium.com/how-to-add-user-defined-function-get-f1-score-in-keras-metrics-3013f979ce0d\n",
        "\n",
        "Sehr gute Ressource f√ºr die verschiedenen Scores und Metriken https://neptune.ai/blog/evaluation-metrics-binary-classification#10  das und aakas verwendet\n",
        "\n",
        "hier: je eine Funktion f√ºr Recall, Precision, f1 https://neptune.ai/blog/keras-metrics \n",
        "\n",
        "https://keras.rstudio.com/reference/k_ones_like.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygyrbFJaMV9B"
      },
      "source": [
        "import keras.backend as K\n",
        "\n",
        "def metrics_recall(data_true, data_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(data_true,0,1)))\n",
        "\n",
        "    recall = true_positives / (possible_positives+K.epsilon())\n",
        "    return recall\n",
        "\n",
        "\n",
        "def metrics_precision(data_true, data_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "\n",
        "    positives_predicted = K.sum(K.round(K.clip(data_pred,0,1)))\n",
        "    precision = true_positives / (positives_predicted+K.epsilon())\n",
        "    return precision\n",
        "\n",
        "\n",
        "def metrics_f1(data_true, data_pred):\n",
        "    precision_data = metrics_precision(data_true, data_pred)\n",
        "    recall_data = metrics_recall(data_true, data_pred)\n",
        "    return 2*(precision_data*recall_data)/(precision_data+recall_data+K.epsilon())"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1ctlBrnuYJz"
      },
      "source": [
        "https://aakashgoel12.medium.com/how-to-add-user-defined-function-get-f1-score-in-keras-metrics-3013f979ce0d"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AfPD3_bWCm0"
      },
      "source": [
        "CNN16052102EIEM02.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',metrics_recall,metrics_precision,metrics_f1])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpChKUY-QEWI"
      },
      "source": [
        "https://www.tensorflow.org/tensorboard/tensorboard_in_notebooks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJfMgUhHBoD1"
      },
      "source": [
        "#%load_ext tensorboard\n",
        "#nur einmal pro Sitzung notwendig\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ISmMXLqP8Hc"
      },
      "source": [
        "\n",
        "logs_base_dir = \"./logs\"\n",
        "callbackForTB = tf.keras.callbacks.TensorBoard(logs_base_dir)\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ehh-EMXUQh8r"
      },
      "source": [
        "Early Stopping as defined in keras tensorflow documentation\n",
        "https://www.tensorflow.org/guide/keras/train_and_evaluate "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BY_t-PeQEjy"
      },
      "source": [
        "callbackEarlyStopping = [\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_loss\",\n",
        "        mode=\"min\",\n",
        "        patience=3,\n",
        "        verbose=1,\n",
        "    )\n",
        "]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2CHbXiP1LsF"
      },
      "source": [
        "training_epochs = 30\n",
        "batch_size = 40\n",
        "validation_split=0.2"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abV-QAxfW48r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f18518ad-08e2-47c5-a9dd-e6a9d491815c"
      },
      "source": [
        "#Werte der Convolutional-Schichten variieren (Filter), Batch-Size variieren, kernel-size..\n",
        "CNN16052102EIEM02.fit(nppadded_training, nptraining_labels, batch_size=batch_size, validation_split=validation_split, epochs=6, callbacks=[callbackForTB])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "91/91 [==============================] - 9s 85ms/step - loss: 0.6424 - accuracy: 0.6659 - metrics_recall: 0.0000e+00 - metrics_precision: 0.0000e+00 - metrics_f1: 0.0000e+00 - val_loss: 0.6441 - val_accuracy: 0.6718 - val_metrics_recall: 0.0000e+00 - val_metrics_precision: 0.0000e+00 - val_metrics_f1: 0.0000e+00\n",
            "Epoch 2/6\n",
            "91/91 [==============================] - 7s 79ms/step - loss: 0.6104 - accuracy: 0.6755 - metrics_recall: 0.0841 - metrics_precision: 0.1481 - metrics_f1: 0.0982 - val_loss: 0.5265 - val_accuracy: 0.7350 - val_metrics_recall: 0.5030 - val_metrics_precision: 0.6223 - val_metrics_f1: 0.5415\n",
            "Epoch 3/6\n",
            "91/91 [==============================] - 7s 79ms/step - loss: 0.2289 - accuracy: 0.9146 - metrics_recall: 0.8302 - metrics_precision: 0.9020 - metrics_f1: 0.8581 - val_loss: 0.6763 - val_accuracy: 0.6973 - val_metrics_recall: 0.6676 - val_metrics_precision: 0.5265 - val_metrics_f1: 0.5749\n",
            "Epoch 4/6\n",
            "91/91 [==============================] - 7s 79ms/step - loss: 0.0849 - accuracy: 0.9740 - metrics_recall: 0.9592 - metrics_precision: 0.9641 - metrics_f1: 0.9598 - val_loss: 1.0695 - val_accuracy: 0.7239 - val_metrics_recall: 0.4858 - val_metrics_precision: 0.5836 - val_metrics_f1: 0.5219\n",
            "Epoch 5/6\n",
            "91/91 [==============================] - 7s 79ms/step - loss: 0.0230 - accuracy: 0.9936 - metrics_recall: 0.9881 - metrics_precision: 0.9939 - metrics_f1: 0.9907 - val_loss: 1.3002 - val_accuracy: 0.7206 - val_metrics_recall: 0.5479 - val_metrics_precision: 0.5681 - val_metrics_f1: 0.5471\n",
            "Epoch 6/6\n",
            "91/91 [==============================] - 7s 79ms/step - loss: 0.0085 - accuracy: 0.9975 - metrics_recall: 0.9957 - metrics_precision: 0.9975 - metrics_f1: 0.9965 - val_loss: 1.5630 - val_accuracy: 0.7195 - val_metrics_recall: 0.6052 - val_metrics_precision: 0.5689 - val_metrics_f1: 0.5732\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f84f6a2b910>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJVL4SBLPB2P"
      },
      "source": [
        "#%tensorboard --logdir {logs_base_dir}"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_LnvWBcnoak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4c62f6a-f8d0-4208-a1bd-4ae98cda5e3c"
      },
      "source": [
        "#results = model.evaluate(nppadded_testing, nptesting_labels, batch_size=batch_size)\n",
        "#print(\"test loss, test acc:\",results)\n",
        "\n",
        "(loss,accuracy, metrics_recall,metrics_precision,\n",
        "metrics_f1) = CNN16052102EIEM02.evaluate(nppadded_testing, nptesting_labels, verbose=1)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "111/111 [==============================] - 1s 9ms/step - loss: 1.7826 - accuracy: 0.6356 - metrics_recall: 0.6365 - metrics_precision: 0.4776 - metrics_f1: 0.5345\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KgjIkhpKmHc"
      },
      "source": [
        "make some predictions of test data and save it to variable. verbose=0 -> do not generate output\n",
        "Gute Quelle: https://deeplizard.com/learn/video/2f-NjDUvZIE "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89GWuxryKlcM"
      },
      "source": [
        "CNN_predictions08 = CNN16052102EIEM02.predict(x=nppadded_testing)\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3jPDaDJK_cN"
      },
      "source": [
        "#for p in CNN_predictions08:\n",
        " # print(p)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eC9efJy4Lp21"
      },
      "source": [
        "rounded predictions: give prediction value of most likely prediction (0 or 1). Printing the output of rounded prediction shows the prediction made by the model on the data (which output is most likely)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsG-TJuQLvtk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7bc7718-1a45-4b02-ba06-b67f84648623"
      },
      "source": [
        "prediction_rounded08 = np.round(CNN_predictions08)\n",
        "#np.argmax(CNN_predictions08,axis=-1)\n",
        "\n",
        "#for p in prediction_rounded08:\n",
        " # print(p)\n",
        "\n",
        "\n",
        "print(nptesting_labels[500:520])\n",
        "print(prediction_rounded08[500:520])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1]\n",
            "[[0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egTtgpXgg8a2"
      },
      "source": [
        "https://deeplizard.com/learn/video/km7pxKy4UHU\n",
        "\n",
        "Quelle der def plot_confusion_matrix: https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSDXf7-_MITy"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0AMs1EzhBU1"
      },
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                        normalize=False,\n",
        "                        title='Confusion matrix',\n",
        "                        cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2JgEnlghCtl"
      },
      "source": [
        "cm = confusion_matrix(y_true=nptesting_labels, y_pred=prediction_rounded08)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckmF29whhFmX"
      },
      "source": [
        "plot_labels = ['no hatespeech','hatespeech']"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "2mpSE96rhK7K",
        "outputId": "cb7421b2-1eb0-4fa3-c534-9bd19a6e0c29"
      },
      "source": [
        "plot_confusion_matrix(cm=cm, classes=plot_labels, title='CNN Confusion 120 eigenes Embedding')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix, without normalization\n",
            "[[1489  841]\n",
            " [ 446  756]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}