{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN embedded.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNYIPCjfGXAShZDnabsNxle",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BiancaStadl/ProjektarbeitML/blob/main/CNN_embedded.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXDOlIBymF0V"
      },
      "source": [
        "GloVe embeddings taken from:\n",
        "\n",
        "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. [pdf] [bib]\n",
        "\n",
        "hatespeechdata taken from (https://hatespeechdata.com/): Wiegand, M., Siegel, M. and Ruppenhofer, J., 2018. Overview of the GermEval 2018 Shared Task on the Identification of Offensive Language. In: Proceedings of GermEval 2018, 14th Conference on Natural Language Processing (KONVENS 2018). Vienna, Austria: Research Gate. available on: https://github.com/uds-lsv/GermEval-2018-Data (last checked: 09.05.2021)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlBmABDxfqII"
      },
      "source": [
        "wiki detox..https://colab.research.google.com/github/tensorflow/fairness-indicators/blob/master/g3doc/tutorials/Fairness_Indicators_TFCO_Wiki_Case_Study.ipynb#scrollTo=y6T5tlXcdW7J "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3xfitNdliBI"
      },
      "source": [
        "#import matplotlib.pyplot as plt -> f√ºr evtl Visualisierungen\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import string\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from keras import losses \n",
        "from keras import optimizers \n",
        "from keras import metrics \n",
        "\n",
        "#!pip install Tokenizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "#!pip install pad_sequences\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import preprocessing\n",
        "#from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTWJQ1iga_vS"
      },
      "source": [
        "Maximale Satzl√§nge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bq08Me5la_Cc"
      },
      "source": [
        "\n",
        "max_length = 60"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVYBMvYSotTH"
      },
      "source": [
        "url = \"https://github.com/uds-lsv/GermEval-2018-Data/archive/master.zip\"\n",
        "\n",
        "dataset = tf.keras.utils.get_file(\"GermEval-2018-Data-master.zip\", url, \n",
        "                                   extract=True, cache_dir='.',\n",
        "                                    cache_subdir='')\n",
        "\n",
        "dataset_dir = os.path.join(os.path.dirname(dataset), 'GermEval-2018-Data-master')\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cS14OUtfo34V"
      },
      "source": [
        "#os.listdir(dataset_dir)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2X429K6hpOVm"
      },
      "source": [
        "training_file = os.path.join(dataset_dir, 'germeval2018.training.txt')\n",
        "\n",
        "testing_file = os.path.join(dataset_dir, 'germeval2018.test.txt')\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uq8fG3LNtn_m"
      },
      "source": [
        "###Aufbereitung\n",
        "txt-Dateien lesen, und dabei jede Zeile splitten und teilen\n",
        "Twitter-Handler entfernen?\n",
        "Labels von S√§tzen trennen, Labels in eigenen Array packen.\n",
        "\n",
        "####Ressourcen\n",
        "* https://www.w3schools.com/python/gloss_python_if_statement.asp\n",
        "* https://stackabuse.com/using-regex-for-text-manipulation-in-python/\n",
        "* https://www.tutorialspoint.com/python/string_splitlines.htm \n",
        "* https://note.nkmk.me/en/python-split-rsplit-splitlines-re/ \n",
        "* https://www.w3schools.com/python/python_regex.asp \n",
        "\n",
        "g√§be bei keras tf.keras.preprocessing.text_dataset_from_directory, aber daf√ºr m√ºssten die Daten auf bestimmte Weise in Verzeichnis organisiert sein, hier nicht der Fall.\n",
        "\n",
        "\n",
        "Einteilung der Daten: Testdaten\n",
        "Trainingsdaten -> noch ca 500 f√ºr Validierungsdaten\n",
        "\n",
        "labels -> \"other\", also nicht-negative Aussagen bekommen \"0\", negative Aussagen bekommen \"1\"\n",
        "\n",
        " Regex f√ºr Emojis  ->\n",
        "\n",
        "(\\u00a9|\\u00ae|[\\u2000-\\u3300]|\\ud83c[\\ud000-\\udfff]|\\ud83d[\\ud000-\\udfff]|\\ud83e[\\ud000-\\udfff])\n",
        "\n",
        "genommen von https://www.regextester.com/106421 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Py_cwD4eZkXo"
      },
      "source": [
        "def remove_clutter(string):\n",
        "   string = re.sub(\"@[^\\s]+\",\" \",string)\n",
        "   string = re.sub(\"#[^\\s]+\",\" \", string)\n",
        "   string = re.sub(\"\\u00a9\",\" \", string)\n",
        "   string = re.sub(\"\\u00ae\",\" \", string)\n",
        "   string = re.sub(\"[\\u2000-\\u3300]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83c[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83d[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83e[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"üòú\", \" \",string)\n",
        "   string = re.sub(\"üç´\", \" \",string)\n",
        "   string = re.sub(\"üòÅ\", \" \",string)\n",
        "   string = re.sub(\"üêñ\", \" \",string)\n",
        "   string = re.sub(\"üò°\", \" \",string)\n",
        "   string = re.sub(\"üòá\", \" \",string)\n",
        "   string = re.sub(\"üò¨\", \" \",string)\n",
        "   string = re.sub(\"üòÉ\", \" \",string)\n",
        "   string = re.sub(\"üòÇ\", \" \",string)\n",
        "   string = re.sub(\"üíô\", \" \",string)  \n",
        "   string = re.sub(\"üòõ\", \" \",string)\n",
        "   string = re.sub(\"üôè\", \" \",string)\n",
        "   string = re.sub(\"üëç\", \" \",string)\n",
        "   string = re.sub(\"üñï\", \" \",string)\n",
        "   string = re.sub(\"üòâ\", \" \",string)\n",
        "   string = re.sub(\"üí©\", \" \",string)\n",
        "   string = re.sub(\"ü§¢\", \" \",string)\n",
        "   string = re.sub(\"üëè\", \" \",string)\n",
        "   string = re.sub(\"üò®\", \" \",string)\n",
        "   string = re.sub(\"ü§£\", \" \",string)\n",
        "   string = re.sub(\"ü§°\", \" \",string)\n",
        "   string = re.sub(\"üòà\", \" \",string)\n",
        "   string = re.sub(\"üíÉüèΩ\", \" \",string)\n",
        "   string = re.sub(\"üëπ\", \" \",string)\n",
        "   string = re.sub(\"ü§ò\", \" \",string)\n",
        "   string = re.sub(\"üò±\", \" \",string)\n",
        "   string = re.sub(\"ü§î\", \" \",string) \n",
        "   string = re.sub(\"üåà\", \" \",string) \n",
        "   string = re.sub(\"üíï\", \" \",string) \n",
        "   string = re.sub(\"üë©‚Äç‚ù§Ô∏è‚Äçüë©\", \" \",string) \n",
        "   string = re.sub(\"üòç\", \" \",string) \n",
        "   string = re.sub(\"üëÜ\", \" \",string) \n",
        "   string = re.sub(\"üòñ\", \" \",string) \n",
        "   string = re.sub(\"üëá\", \" \",string) \n",
        "   string = re.sub(\"üî•\", \" \",string) \n",
        "   string = re.sub(\"üòò\", \" \",string) \n",
        "   string = re.sub(\"üéâ\", \" \",string) \n",
        "   string = re.sub(\"ü§¨\", \" \",string) \n",
        "   string = re.sub(\"üëä\", \" \",string)\n",
        "   string = re.sub(\"üá©üá™\", \" \",string)  \n",
        "   string = re.sub(\"üíî\", \" \",string)\n",
        "   string = re.sub(\"üôà\", \" \",string)\n",
        "   string = re.sub(\"ü§Ø\", \" \",string)\n",
        "   string = re.sub(\"üêü\", \" \",string)\n",
        "   string = re.sub(\"üõ∂\", \" \",string)\n",
        "   string = re.sub(\"üòä\", \" \",string)\n",
        "   string = re.sub(\"üòì\", \" \",string)\n",
        "   string = re.sub(\"üò≥\", \" \",string)\n",
        "   string = re.sub(\"üöÄ\", \" \",string)\n",
        "   string = re.sub(\"üëé\", \" \",string)\n",
        "   string = re.sub(\"üòé\", \" \",string)\n",
        "   string = re.sub(\"üê∏\", \" \",string)\n",
        "   string = re.sub(\"üìà\", \" \",string)\n",
        "   string = re.sub(\"üôÇ\", \" \",string)\n",
        "   string = re.sub(\"üòÖ\", \" \",string)\n",
        "   string = re.sub(\"üòÜ\", \" \",string)\n",
        "   string = re.sub(\"üôéüèø\", \" \",string)\n",
        "   string = re.sub(\"üëéüèΩ\", \" \",string)\n",
        "   string = re.sub(\"ü§≠\", \" \",string)\n",
        "   string = re.sub(\"üò§\", \" \",string)\n",
        "   string = re.sub(\"üòö\", \" \",string)\n",
        "   string = re.sub(\"üòä\", \" \",string)\n",
        "   string = re.sub(\"üò≤\", \" \",string)\n",
        "   string = re.sub(\"ü§Æ\", \" \",string)\n",
        "   string = re.sub(\"üôÑ\", \" \",string)\n",
        "   string = re.sub(\"ü§ë\", \" \",string)\n",
        "   string = re.sub(\"üéÖ\", \" \",string)\n",
        "   string = re.sub(\"üëã\", \" \",string)\n",
        "   string = re.sub(\"üí™\", \" \",string)\n",
        "   string = re.sub(\"üòÑ\", \" \",string)\n",
        "   string = re.sub(\"üßê\", \" \",string)\n",
        "   string = re.sub(\"üò†\", \" \",string)\n",
        "   string = re.sub(\"üéà\", \" \",string)\n",
        "   string = re.sub(\"üöÇ\", \" \",string)\n",
        "   string = re.sub(\"üòä\", \" \",string)\n",
        "   string = re.sub(\"üöá\", \" \",string)\n",
        "   string = re.sub(\"üöä\", \" \",string)\n",
        "   string = re.sub(\"ü§∑\", \" \",string)\n",
        "   string = re.sub(\"üò•\", \" \",string)\n",
        "   string = re.sub(\"üôÉ\", \" \",string)\n",
        "   string = re.sub(\"üî©\", \" \",string)\n",
        "   string = re.sub(\"üîß\", \" \",string)\n",
        "   string = re.sub(\"üî®\", \" \",string)\n",
        "   string = re.sub(\"üõ†\", \" \",string)\n",
        "   string = re.sub(\"üíì\", \" \",string)\n",
        "   string = re.sub(\"üí°\", \" \",string)\n",
        "   string = re.sub(\"üç∏\", \" \",string)\n",
        "   string = re.sub(\"ü•É\", \" \",string)\n",
        "   string = re.sub(\"ü•Ç\", \" \",string)\n",
        "   string = re.sub(\"üò∑\", \" \",string)\n",
        "   string = re.sub(\"ü§ê\", \" \",string)\n",
        "   string = re.sub(\"üåé\", \" \",string)\n",
        "   string = re.sub(\"üëë\", \" \",string)\n",
        "   string = re.sub(\"ü§õ\", \" \",string)\n",
        "   string = re.sub(\"üòÄ\", \" \",string)\n",
        "   string = re.sub(\"üõ§\", \" \",string)\n",
        "   string = re.sub(\"üéÑ\", \" \",string)\n",
        "   string = re.sub(\"üì¥\", \" \",string)\n",
        "   string = re.sub(\"üå≠\", \" \",string)\n",
        "   string = re.sub(\"ü§ï\", \" \",string)\n",
        "   string = re.sub(\"üò≠\", \" \",string)\n",
        "   string = re.sub(\"üçæ\", \" \",string)\n",
        "   string = re.sub(\"üçû\", \" \",string)\n",
        "   string = re.sub(\"ü§¶\", \" \",string)\n",
        "   string = re.sub(\"ü§Ø\", \" \",string)\n",
        "   string = re.sub(\"üïØÔ∏è\", \" \",string)\n",
        "\n",
        "   string = re.sub(\"OTHER|OFFENSE|ABUSE|INSULT\",\" \",string)\n",
        "   return string"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5asMgo4LtnRg"
      },
      "source": [
        "statementsForTraining = []\n",
        "sentimentsForTraining = []\n",
        "\n",
        "\n",
        "fileToRead = open(training_file, 'r')\n",
        "\n",
        "while True:\n",
        "  #next line in file\n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  findSentiment = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "\n",
        "\n",
        "  statementsForTraining.append(line)\n",
        "   #sentimentsForTraining.append(findSentiment.group(0))\n",
        "\n",
        "  if findSentiment.group(0) == \"OTHER\":  \n",
        "    sentimentsForTraining.append(0)\n",
        "  else:\n",
        "    sentimentsForTraining.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        " #print(\"{}: {}\".format(count,line.strip()))\n",
        "  \n",
        " # print(sentiment.group(0))\n",
        " \n",
        "fileToRead.close()\n",
        "\n",
        "training_sentences = statementsForTraining\n",
        "training_labels = sentimentsForTraining\n",
        "\n",
        "#print(training_sentences[9])\n",
        "#print(training_labels[9])\n",
        "\n",
        "#print(len(training_sentences))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsqZPENb98gD"
      },
      "source": [
        "##do the same with testdata\n",
        "statementsForTesting = []\n",
        "sentimentsForTesting = []\n",
        "\n",
        "fileToRead = open(testing_file, 'r')\n",
        "\n",
        "while True:\n",
        "  #next line in file\n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  sent = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "\n",
        "    \n",
        "\n",
        "  statementsForTesting.append(line)\n",
        "  #print(len(line))\n",
        "  #sentimentsForTesting.append(sent.group(0))\n",
        "\n",
        "  if sent.group(0) == \"OTHER\": \n",
        "    sentimentsForTesting.append(0)\n",
        "  else:\n",
        "    sentimentsForTesting.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        "\n",
        "fileToRead.close()\n",
        "\n",
        "\n",
        "testing_sentences = statementsForTesting\n",
        "testing_labels = sentimentsForTesting\n",
        "#print(len(testing_sentences))\n",
        "#print(testing_sentences)   \n",
        "#print(testing_labels)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRUvDLD5bMbO"
      },
      "source": [
        "Padding -> im Prinzip die S√§tze alle auf die gleiche L√§nge bringen (in Theorieteil n√§her drauf eingehen) -> maxlen-Paramter ist f√ºr pad_sequences vorhanden, wenn nicht gesetzt -> alles wird auf die L√§nge des l√§ngsten Satzes aufgef√ºllt -> print(padded(shape)) gibt aus, wie viele Datens√§tze padded wurden und gibt an, wie viele Tokens der l√§ngste Datensatz hat\n",
        "print(padded[x]) gibt einen Satz aus (bereits tokenisiert)\n",
        "\n",
        "Padding -> sowohl f√ºr Trainigs- als auch f√ºr Testdaten\n",
        "\n",
        "Und: Daten als numpy-Arrays speichern (notwendig f√ºr tensorflow).\n",
        "\n",
        " -> Tokenizer https://towardsdatascience.com/text-classification-in-keras-part-2-how-to-use-the-keras-tokenizer-word-representations-fd571674df23 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3hFi7waTv5m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77062d77-11ad-4aa9-854d-28dff5366c52"
      },
      "source": [
        "tokenizer = Tokenizer(oov_token=\"OOV\")\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "\n",
        "#creating a word index - nur die Trainigsdaten\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "validation_size = 500\n",
        "\n",
        "\n",
        "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "padded_training = pad_sequences(training_sequences, maxlen=max_length, padding='post')\n",
        "print(len(padded_training))\n",
        "\n",
        "validation_sequences = padded_training[0:validation_size]\n",
        "validation_labels = training_labels[0:validation_size]\n",
        "\n",
        "padded_training = padded_training[validation_size:]\n",
        "training_labels = training_labels[validation_size:]\n",
        "\n",
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
        "padded_testing = pad_sequences(testing_sequences, maxlen=max_length,  padding='post')\n",
        "\n",
        "#print(validation_sequences[499])\n",
        "print(padded_training[0])\n",
        "#print(len(validation_labels))\n",
        "#print(len(training_labels))\n",
        "\n",
        "\n",
        "nppadded_training = np.array(padded_training)\n",
        "nptraining_labels = np.array(training_labels)\n",
        "\n",
        "nppadded_validation = np.array(validation_sequences)\n",
        "npvalidation_labels = np.array(validation_labels)\n",
        "\n",
        "nppadded_testing = np.array(padded_testing)\n",
        "nptesting_labels = np.array(testing_labels)\n",
        "\n",
        "\n",
        "print(len(nppadded_training))\n",
        "print(len(nptraining_labels))\n",
        "print(len(word_index))\n",
        "\n",
        "#print(statementsForTraining[2])\n",
        "#print(nppadded_training[4])\n",
        "#print(nppadded_training.shape)\n",
        "#print(nptraining_labels[4])\n",
        "#print(nppadded_testing.shape)\n",
        "#print(word_index) \n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5009\n",
            "[  12 3982   11   41 6706 1040    4    5  202   39    3 2922   49 1360\n",
            "  810  495 3983    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0]\n",
            "4509\n",
            "4509\n",
            "15059\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tL3owrc8THkT"
      },
      "source": [
        "\n",
        "Dann: Embedding mit entweder word2vec oder glove\n",
        "Word2vec-Daten sind hier: http://vectors.nlpl.eu/repository/#\n",
        "Glove -> https://nlp.stanford.edu/projects/glove/ Da mal den Twitter-Vector runtergeladen\n",
        "Wenn Daten in GoogleDrive sind (w√§re auch via url m√∂glich..), muss Drive gemounted werden ( https://buomsoo-kim.github.io/colab/2020/05/09/Colab-mounting-google-drive.md/ ) aber auch hier https://enjoymachinelearning.com/posts/colab-with-google-drive/\n",
        "\n",
        "Die Word2vec vectors: http://vectors.nlpl.eu/repository/# \n",
        "\n",
        "glove-zitat:\n",
        "Citing GloVe\n",
        "\n",
        "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. [pdf] [bib]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zuO7T9ZTG57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f51ffa5f-4743-4aaf-dd71-f5c6a5f9362b"
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount(\"/content/drive\")\n",
        "os.listdir(\"/content/drive/MyDrive/Colab Notebooks\")\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['germeval_training.txt',\n",
              " 'glove.twitter.27B.50d.txt',\n",
              " 'glove.twitter.27B.200d.txt',\n",
              " 'glove.6B.200d.txt',\n",
              " 'glove.840B.300d.txt',\n",
              " 'tensorboard.gdoc',\n",
              " 'keras.gdoc',\n",
              " 'Vectorization CNN embedded_limited_vocab.ipynb',\n",
              " 'glove.42B.300d.txt',\n",
              " 'Embedding Glove Vergleich.ipynb',\n",
              " 'CNN embedded_limited_vocab.ipynb',\n",
              " 'LSTM_limited_vocab.ipynb',\n",
              " 'LSTM.ipynb',\n",
              " 'CNN embedded.ipynb']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7ToKO-sZLHK"
      },
      "source": [
        "\n",
        "Keras-Doc : https://keras.io/examples/nlp/pretrained_word_embeddings/#load-pretrained-word-embeddings \n",
        "embedding mit initializers.. weights m√ºsste auch funktionieren\n",
        "\n",
        "Diese erstellte Matrix mit Embedding dann in die Embedding-Schicht einbinden,  Trainable auf False, weil sich die Werte nicht durch Training anpassen sollen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AShIVfC7ZQAH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "797047c0-5124-4953-a7b5-783227526078"
      },
      "source": [
        "#Gr√∂√üe Vokabel -> wordindex + 2 (weil padding + OOV) \n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "vocabulary_size = len(word_index)+2\n",
        "\n",
        "# dann erstell ich ein W√∂rterbuch mit Namen \"embedding_vector\", dort sind dann\n",
        "#die keys drinnen, die in glove-Datei drinnen sind mit dem entsprechenden Key\n",
        "\n",
        "embedding_index_glove = {}\n",
        "f = open('/content/drive/MyDrive/Colab Notebooks/glove.twitter.27B.200d.txt')\n",
        "for line in f:\n",
        "  value = line.split()\n",
        "  word = value[0]\n",
        "  coef = np.asarray(value[1:],dtype='float32')\n",
        "  embedding_index_glove[word] = coef\n",
        "\n",
        "print(\"%d gefunden: \"% len(embedding_index_glove))\n",
        "\n",
        "#Dann noch eine Embedding-Matrix erstellen\n",
        "#zweiter Wert = Embedding-Dimension der Datei, in dem Fall 200\n",
        "\n",
        "glove_matrix = np.zeros((vocabulary_size,200))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    embedding_value = embedding_index_glove.get(word)\n",
        "    if embedding_value is not None:\n",
        "      glove_matrix[index] = embedding_value\n",
        "      hits+=1\n",
        "    else:\n",
        "      misses+=1\n",
        "\n",
        "print(\"hits %d and %d misses\"%(hits,misses))\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1193514 gefunden: \n",
            "hits 6747 and 8312 misses\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZmvOfwhV4N5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efe98bc2-1536-4c6b-8446-ec0c4729e763"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "print(\"vocab size: %d\"%vocabulary_size)\n",
        "CNN16052102ES02 = tf.keras.Sequential()\n",
        "#Embedding -> hier dann auf das embedding verweisen, Input_dim -> die Anzahl der W√∂rter im word_index, output -> in dem Fall passend zum verwendeten Vektor\n",
        "#input-length -> auf 60  gepadded, trainable -> nein, weil nichts ver√§ndert werden soll\n",
        "#embeddings_initializer=keras.initializers.Constant(glove_matrix) vs weights = [glove_matrix]\n",
        "#Convolutional layers => filters = neurons.. mit 100? 265?\n",
        "#CNN16052102ES02.add(tf.keras.layers.Embedding(input_dim=vocabulary_size, output_dim=200, input_length=max_length))\n",
        "CNN16052102ES02.add(tf.keras.layers.Embedding(vocabulary_size, output_dim=200, input_length=60, embeddings_initializer = keras.initializers.Constant(glove_matrix), trainable= False))\n",
        "CNN16052102ES02.add(tf.keras.layers.Dropout(0.4))\n",
        "CNN16052102ES02.add(tf.keras.layers.Conv1D(filters=120, kernel_size=3, padding=\"valid\", activation=\"relu\"))\n",
        "CNN16052102ES02.add(tf.keras.layers.MaxPooling1D())\n",
        "CNN16052102ES02.add(tf.keras.layers.Conv1D(filters=120, kernel_size=3, padding=\"valid\", activation=\"relu\"))\n",
        "CNN16052102ES02.add(tf.keras.layers.GlobalAveragePooling1D())\n",
        "CNN16052102ES02.add(tf.keras.layers.Flatten())\n",
        "CNN16052102ES02.add(tf.keras.layers.Dense(260, activation=\"relu\"))\n",
        "CNN16052102ES02.add(tf.keras.layers.Dropout(0.4))\n",
        "CNN16052102ES02.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "CNN16052102ES02.summary()\n",
        "\n",
        "#nppadded_training = np.asmatrix(nppadded_training) not necessary\n",
        "#nppadded_testing = np.asmatrix(nppadded_testing)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab size: 15061\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 60, 200)           3012200   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 60, 200)           0         \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 58, 120)           72120     \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 29, 120)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 27, 120)           43320     \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 120)               0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 120)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 260)               31460     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 260)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 261       \n",
            "=================================================================\n",
            "Total params: 3,159,361\n",
            "Trainable params: 147,161\n",
            "Non-trainable params: 3,012,200\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEr4OzT-iHDe"
      },
      "source": [
        "#model.layers[2].get_weights()[0].shape\n",
        "#weights=np.random.rand(5,200,100)\n",
        "#bias=np.random.rand(100)\n",
        "#model.layers[2].set_weights([weights, bias])\n",
        "\n",
        "#model.layers[2].get_weights()[0]\n",
        "#https://androidkt.com/set-custom-weights-keras-using-numpy-array/"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UB7_3VPYesr9"
      },
      "source": [
        "F1-Score f√ºr jede Epoche https://aakashgoel12.medium.com/how-to-add-user-defined-function-get-f1-score-in-keras-metrics-3013f979ce0d\n",
        "\n",
        "Sehr gute Ressource f√ºr die verschiedenen Scores und Metriken https://neptune.ai/blog/evaluation-metrics-binary-classification#10  das und aakas verwendet\n",
        "\n",
        "hier: je eine Funktion f√ºr Recall, Precision, f1 https://neptune.ai/blog/keras-metrics \n",
        "\n",
        "https://keras.rstudio.com/reference/k_ones_like.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygyrbFJaMV9B"
      },
      "source": [
        "import keras.backend as K\n",
        "\n",
        "def metrics_recall(data_true, data_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(data_true,0,1)))\n",
        "\n",
        "    recall = true_positives / (possible_positives+K.epsilon())\n",
        "    return recall\n",
        "\n",
        "\n",
        "def metrics_precision(data_true, data_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "\n",
        "    positives_predicted = K.sum(K.round(K.clip(data_pred,0,1)))\n",
        "    precision = true_positives / (positives_predicted+K.epsilon())\n",
        "    return precision\n",
        "\n",
        "\n",
        "def metrics_f1(data_true, data_pred):\n",
        "    precision_data = metrics_precision(data_true, data_pred)\n",
        "    recall_data = metrics_recall(data_true, data_pred)\n",
        "    return 2*(precision_data*recall_data)/(precision_data+recall_data+K.epsilon())"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1ctlBrnuYJz"
      },
      "source": [
        "https://aakashgoel12.medium.com/how-to-add-user-defined-function-get-f1-score-in-keras-metrics-3013f979ce0d"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AfPD3_bWCm0"
      },
      "source": [
        "CNN16052102ES02.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',metrics_recall,metrics_precision,metrics_f1])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpChKUY-QEWI"
      },
      "source": [
        "https://www.tensorflow.org/tensorboard/tensorboard_in_notebooks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJfMgUhHBoD1"
      },
      "source": [
        "#%load_ext tensorboard\n",
        "#nur einmal pro Sitzung notwendig\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ISmMXLqP8Hc"
      },
      "source": [
        "\n",
        "logs_base_dir = \"./logs\"\n",
        "callbackForTB = tf.keras.callbacks.TensorBoard(logs_base_dir)\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ehh-EMXUQh8r"
      },
      "source": [
        "Early Stopping as defined in keras tensorflow documentation\n",
        "https://www.tensorflow.org/guide/keras/train_and_evaluate "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BY_t-PeQEjy"
      },
      "source": [
        "callbackEarlyStopping = [\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_loss\",\n",
        "        min_delta=0.001,\n",
        "        patience=3,\n",
        "        verbose=1,\n",
        "    )\n",
        "]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2CHbXiP1LsF"
      },
      "source": [
        "training_epochs = 30\n",
        "batch_size = 40\n",
        "validation_split=0.2"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abV-QAxfW48r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc6d7467-0ce6-4d25-952b-529a88d3eb4f"
      },
      "source": [
        "#Werte der Convolutional-Schichten variieren (Filter), Batch-Size variieren, kernel-size..\n",
        "CNN16052102ES02.fit(nppadded_training, nptraining_labels, batch_size=batch_size, validation_split=validation_split, epochs=training_epochs, callbacks=[callbackForTB,callbackEarlyStopping])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "91/91 [==============================] - 5s 43ms/step - loss: 0.6484 - accuracy: 0.6713 - metrics_recall: 0.0123 - metrics_precision: 0.0111 - metrics_f1: 0.0117 - val_loss: 0.6290 - val_accuracy: 0.6718 - val_metrics_recall: 0.0000e+00 - val_metrics_precision: 0.0000e+00 - val_metrics_f1: 0.0000e+00\n",
            "Epoch 2/30\n",
            "91/91 [==============================] - 3s 37ms/step - loss: 0.6273 - accuracy: 0.6652 - metrics_recall: 0.0016 - metrics_precision: 0.0208 - metrics_f1: 0.0028 - val_loss: 0.6057 - val_accuracy: 0.6718 - val_metrics_recall: 0.0000e+00 - val_metrics_precision: 0.0000e+00 - val_metrics_f1: 0.0000e+00\n",
            "Epoch 3/30\n",
            "91/91 [==============================] - 3s 37ms/step - loss: 0.6269 - accuracy: 0.6542 - metrics_recall: 0.0562 - metrics_precision: 0.2243 - metrics_f1: 0.0817 - val_loss: 0.5857 - val_accuracy: 0.6940 - val_metrics_recall: 0.0857 - val_metrics_precision: 0.6522 - val_metrics_f1: 0.1476\n",
            "Epoch 4/30\n",
            "91/91 [==============================] - 3s 36ms/step - loss: 0.5816 - accuracy: 0.6870 - metrics_recall: 0.1981 - metrics_precision: 0.6048 - metrics_f1: 0.2723 - val_loss: 0.5760 - val_accuracy: 0.7095 - val_metrics_recall: 0.3372 - val_metrics_precision: 0.6192 - val_metrics_f1: 0.4240\n",
            "Epoch 5/30\n",
            "91/91 [==============================] - 3s 37ms/step - loss: 0.5365 - accuracy: 0.7273 - metrics_recall: 0.3680 - metrics_precision: 0.7022 - metrics_f1: 0.4464 - val_loss: 0.5557 - val_accuracy: 0.7206 - val_metrics_recall: 0.2497 - val_metrics_precision: 0.7234 - val_metrics_f1: 0.3563\n",
            "Epoch 6/30\n",
            "91/91 [==============================] - 3s 36ms/step - loss: 0.5285 - accuracy: 0.7291 - metrics_recall: 0.3951 - metrics_precision: 0.7128 - metrics_f1: 0.4753 - val_loss: 0.5468 - val_accuracy: 0.7195 - val_metrics_recall: 0.2395 - val_metrics_precision: 0.7168 - val_metrics_f1: 0.3427\n",
            "Epoch 7/30\n",
            "91/91 [==============================] - 3s 37ms/step - loss: 0.4914 - accuracy: 0.7579 - metrics_recall: 0.4805 - metrics_precision: 0.7539 - metrics_f1: 0.5472 - val_loss: 0.5665 - val_accuracy: 0.6851 - val_metrics_recall: 0.6564 - val_metrics_precision: 0.5133 - val_metrics_f1: 0.5642\n",
            "Epoch 8/30\n",
            "91/91 [==============================] - 3s 36ms/step - loss: 0.4643 - accuracy: 0.7865 - metrics_recall: 0.5850 - metrics_precision: 0.7397 - metrics_f1: 0.6195 - val_loss: 0.5862 - val_accuracy: 0.6674 - val_metrics_recall: 0.7072 - val_metrics_precision: 0.4932 - val_metrics_f1: 0.5702\n",
            "Epoch 9/30\n",
            "91/91 [==============================] - 3s 36ms/step - loss: 0.4416 - accuracy: 0.7983 - metrics_recall: 0.6156 - metrics_precision: 0.7436 - metrics_f1: 0.6348 - val_loss: 0.5372 - val_accuracy: 0.7184 - val_metrics_recall: 0.4856 - val_metrics_precision: 0.5778 - val_metrics_f1: 0.5119\n",
            "Epoch 10/30\n",
            "91/91 [==============================] - 3s 36ms/step - loss: 0.4051 - accuracy: 0.8056 - metrics_recall: 0.6119 - metrics_precision: 0.7414 - metrics_f1: 0.6512 - val_loss: 0.5635 - val_accuracy: 0.6951 - val_metrics_recall: 0.6190 - val_metrics_precision: 0.5224 - val_metrics_f1: 0.5558\n",
            "Epoch 11/30\n",
            "91/91 [==============================] - 3s 37ms/step - loss: 0.3874 - accuracy: 0.8230 - metrics_recall: 0.7243 - metrics_precision: 0.7759 - metrics_f1: 0.7310 - val_loss: 0.5531 - val_accuracy: 0.7239 - val_metrics_recall: 0.4203 - val_metrics_precision: 0.6060 - val_metrics_f1: 0.4798\n",
            "Epoch 12/30\n",
            "91/91 [==============================] - 3s 36ms/step - loss: 0.3297 - accuracy: 0.8493 - metrics_recall: 0.7006 - metrics_precision: 0.8154 - metrics_f1: 0.7382 - val_loss: 0.8181 - val_accuracy: 0.5931 - val_metrics_recall: 0.8592 - val_metrics_precision: 0.4415 - val_metrics_f1: 0.5738\n",
            "Epoch 00012: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f002f9f4550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJVL4SBLPB2P"
      },
      "source": [
        "#%tensorboard --logdir {logs_base_dir}"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_LnvWBcnoak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9073f33-f4ec-4d29-dadd-80d15b2da779"
      },
      "source": [
        "#results = model.evaluate(nppadded_testing, nptesting_labels, batch_size=batch_size)\n",
        "#print(\"test loss, test acc:\",results)\n",
        "\n",
        "(loss,accuracy, metrics_recall,metrics_precision,\n",
        "metrics_f1) = CNN16052102ES02.evaluate(nppadded_testing, nptesting_labels, verbose=1)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "111/111 [==============================] - 1s 9ms/step - loss: 0.8226 - accuracy: 0.5603 - metrics_recall: 0.7622 - metrics_precision: 0.4223 - metrics_f1: 0.5343\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KgjIkhpKmHc"
      },
      "source": [
        "make some predictions of test data and save it to variable. verbose=0 -> do not generate output\n",
        "Gute Quelle: https://deeplizard.com/learn/video/2f-NjDUvZIE "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89GWuxryKlcM"
      },
      "source": [
        "CNN_predictions06 = CNN16052102ES02.predict(x=nppadded_testing)\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3jPDaDJK_cN"
      },
      "source": [
        "#for p in CNN_predictions06:\n",
        " # print(p)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eC9efJy4Lp21"
      },
      "source": [
        "rounded predictions: give prediction value of most likely prediction (0 or 1). Printing the output of rounded prediction shows the prediction made by the model on the data (which output is most likely)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsG-TJuQLvtk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c6d9406-17fc-413a-b597-14bb8b11d866"
      },
      "source": [
        "prediction_rounded06 = np.round(CNN_predictions06)\n",
        "#np.argmax(CNN_predictions06,axis=-1)\n",
        "\n",
        "#for p in prediction_rounded06:\n",
        " # print(p)\n",
        "\n",
        "\n",
        "print(nptesting_labels[500:520])\n",
        "print(prediction_rounded06[500:520])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1]\n",
            "[[0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egTtgpXgg8a2"
      },
      "source": [
        "https://deeplizard.com/learn/video/km7pxKy4UHU\n",
        "\n",
        "Quelle der def plot_confusion_matrix: https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSDXf7-_MITy"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0AMs1EzhBU1"
      },
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                        normalize=False,\n",
        "                        title='Confusion matrix',\n",
        "                        cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2JgEnlghCtl"
      },
      "source": [
        "cm = confusion_matrix(y_true=nptesting_labels, y_pred=prediction_rounded06)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckmF29whhFmX"
      },
      "source": [
        "plot_labels = ['no hatespeech','hatespeech']"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "2mpSE96rhK7K",
        "outputId": "25f8728d-1b7b-4197-ad55-c8e354732434"
      },
      "source": [
        "plot_confusion_matrix(cm=cm, classes=plot_labels, title='CNN Confusion 120 EarlyStopping 0.001')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix, without normalization\n",
            "[[1069 1261]\n",
            " [ 292  910]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}