{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN embedded.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPofUL2X8y9txQz2n/JNMPU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BiancaStadl/ProjektarbeitML/blob/main/CNN_embedded.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXDOlIBymF0V"
      },
      "source": [
        "GloVe embeddings taken from:\n",
        "\n",
        "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. [pdf] [bib]\n",
        "\n",
        "hatespeechdata taken from (https://hatespeechdata.com/): Wiegand, M., Siegel, M. and Ruppenhofer, J., 2018. Overview of the GermEval 2018 Shared Task on the Identification of Offensive Language. In: Proceedings of GermEval 2018, 14th Conference on Natural Language Processing (KONVENS 2018). Vienna, Austria: Research Gate. available on: https://github.com/uds-lsv/GermEval-2018-Data (last checked: 09.05.2021)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlBmABDxfqII"
      },
      "source": [
        "wiki detox..https://colab.research.google.com/github/tensorflow/fairness-indicators/blob/master/g3doc/tutorials/Fairness_Indicators_TFCO_Wiki_Case_Study.ipynb#scrollTo=y6T5tlXcdW7J "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3xfitNdliBI"
      },
      "source": [
        "#import matplotlib.pyplot as plt -> f√ºr evtl Visualisierungen\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import string\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from keras import losses \n",
        "from keras import optimizers \n",
        "from keras import metrics \n",
        "\n",
        "#!pip install Tokenizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "#!pip install pad_sequences\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import preprocessing\n",
        "#from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTWJQ1iga_vS"
      },
      "source": [
        "Maximale Satzl√§nge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bq08Me5la_Cc"
      },
      "source": [
        "\n",
        "max_length = 60"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVYBMvYSotTH"
      },
      "source": [
        "url = \"https://github.com/uds-lsv/GermEval-2018-Data/archive/master.zip\"\n",
        "\n",
        "dataset = tf.keras.utils.get_file(\"GermEval-2018-Data-master.zip\", url, \n",
        "                                   extract=True, cache_dir='.',\n",
        "                                    cache_subdir='')\n",
        "\n",
        "dataset_dir = os.path.join(os.path.dirname(dataset), 'GermEval-2018-Data-master')\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cS14OUtfo34V"
      },
      "source": [
        "#os.listdir(dataset_dir)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2X429K6hpOVm"
      },
      "source": [
        "training_file = os.path.join(dataset_dir, 'germeval2018.training.txt')\n",
        "\n",
        "testing_file = os.path.join(dataset_dir, 'germeval2018.test.txt')\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uq8fG3LNtn_m"
      },
      "source": [
        "###Aufbereitung\n",
        "txt-Dateien lesen, und dabei jede Zeile splitten und teilen\n",
        "Twitter-Handler entfernen?\n",
        "Labels von S√§tzen trennen, Labels in eigenen Array packen.\n",
        "\n",
        "####Ressourcen\n",
        "* https://www.w3schools.com/python/gloss_python_if_statement.asp\n",
        "* https://stackabuse.com/using-regex-for-text-manipulation-in-python/\n",
        "* https://www.tutorialspoint.com/python/string_splitlines.htm \n",
        "* https://note.nkmk.me/en/python-split-rsplit-splitlines-re/ \n",
        "* https://www.w3schools.com/python/python_regex.asp \n",
        "\n",
        "g√§be bei keras tf.keras.preprocessing.text_dataset_from_directory, aber daf√ºr m√ºssten die Daten auf bestimmte Weise in Verzeichnis organisiert sein, hier nicht der Fall.\n",
        "\n",
        "\n",
        "Einteilung der Daten: Testdaten\n",
        "Trainingsdaten -> noch ca 500 f√ºr Validierungsdaten\n",
        "\n",
        "labels -> \"other\", also nicht-negative Aussagen bekommen \"0\", negative Aussagen bekommen \"1\"\n",
        "\n",
        " Regex f√ºr Emojis  ->\n",
        "\n",
        "(\\u00a9|\\u00ae|[\\u2000-\\u3300]|\\ud83c[\\ud000-\\udfff]|\\ud83d[\\ud000-\\udfff]|\\ud83e[\\ud000-\\udfff])\n",
        "\n",
        "genommen von https://www.regextester.com/106421 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Py_cwD4eZkXo"
      },
      "source": [
        "def remove_clutter(string):\n",
        "   string = re.sub(\"@[^\\s]+\",\" \",string)\n",
        "   string = re.sub(\"#[^\\s]+\",\" \", string)\n",
        "   string = re.sub(\"\\u00a9\",\" \", string)\n",
        "   string = re.sub(\"\\u00ae\",\" \", string)\n",
        "   string = re.sub(\"[\\u2000-\\u3300]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83c[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83d[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83e[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"üòú\", \" \",string)\n",
        "   string = re.sub(\"üç´\", \" \",string)\n",
        "   string = re.sub(\"üòÅ\", \" \",string)\n",
        "   string = re.sub(\"üêñ\", \" \",string)\n",
        "   string = re.sub(\"üò°\", \" \",string)\n",
        "   string = re.sub(\"üòá\", \" \",string)\n",
        "   string = re.sub(\"üò¨\", \" \",string)\n",
        "   string = re.sub(\"üòÉ\", \" \",string)\n",
        "   string = re.sub(\"üòÇ\", \" \",string)\n",
        "   string = re.sub(\"üíô\", \" \",string)  \n",
        "   string = re.sub(\"üòõ\", \" \",string)\n",
        "   string = re.sub(\"üôè\", \" \",string)\n",
        "   string = re.sub(\"üëç\", \" \",string)\n",
        "   string = re.sub(\"üñï\", \" \",string)\n",
        "   string = re.sub(\"üòâ\", \" \",string)\n",
        "   string = re.sub(\"üí©\", \" \",string)\n",
        "   string = re.sub(\"ü§¢\", \" \",string)\n",
        "   string = re.sub(\"üëè\", \" \",string)\n",
        "   string = re.sub(\"üò®\", \" \",string)\n",
        "   string = re.sub(\"ü§£\", \" \",string)\n",
        "   string = re.sub(\"ü§°\", \" \",string)\n",
        "   string = re.sub(\"üòà\", \" \",string)\n",
        "   string = re.sub(\"üíÉüèΩ\", \" \",string)\n",
        "   string = re.sub(\"üëπ\", \" \",string)\n",
        "   string = re.sub(\"ü§ò\", \" \",string)\n",
        "   string = re.sub(\"üò±\", \" \",string)\n",
        "   string = re.sub(\"ü§î\", \" \",string) \n",
        "   string = re.sub(\"üåà\", \" \",string) \n",
        "   string = re.sub(\"üíï\", \" \",string) \n",
        "   string = re.sub(\"üë©‚Äç‚ù§Ô∏è‚Äçüë©\", \" \",string) \n",
        "   string = re.sub(\"üòç\", \" \",string) \n",
        "   string = re.sub(\"üëÜ\", \" \",string) \n",
        "   string = re.sub(\"üòñ\", \" \",string) \n",
        "   string = re.sub(\"üëá\", \" \",string) \n",
        "   string = re.sub(\"üî•\", \" \",string) \n",
        "   string = re.sub(\"üòò\", \" \",string) \n",
        "   string = re.sub(\"üéâ\", \" \",string) \n",
        "   string = re.sub(\"ü§¨\", \" \",string) \n",
        "   string = re.sub(\"üëä\", \" \",string)\n",
        "   string = re.sub(\"üá©üá™\", \" \",string)  \n",
        "   string = re.sub(\"üíî\", \" \",string)\n",
        "   string = re.sub(\"üôà\", \" \",string)\n",
        "   string = re.sub(\"ü§Ø\", \" \",string)\n",
        "   string = re.sub(\"üêü\", \" \",string)\n",
        "   string = re.sub(\"üõ∂\", \" \",string)\n",
        "   string = re.sub(\"üòä\", \" \",string)\n",
        "   string = re.sub(\"üòì\", \" \",string)\n",
        "   string = re.sub(\"üò≥\", \" \",string)\n",
        "   string = re.sub(\"üöÄ\", \" \",string)\n",
        "   string = re.sub(\"üëé\", \" \",string)\n",
        "   string = re.sub(\"üòé\", \" \",string)\n",
        "   string = re.sub(\"üê∏\", \" \",string)\n",
        "   string = re.sub(\"üìà\", \" \",string)\n",
        "   string = re.sub(\"üôÇ\", \" \",string)\n",
        "   string = re.sub(\"üòÖ\", \" \",string)\n",
        "   string = re.sub(\"üòÜ\", \" \",string)\n",
        "   string = re.sub(\"üôéüèø\", \" \",string)\n",
        "   string = re.sub(\"üëéüèΩ\", \" \",string)\n",
        "   string = re.sub(\"ü§≠\", \" \",string)\n",
        "   string = re.sub(\"üò§\", \" \",string)\n",
        "   string = re.sub(\"üòö\", \" \",string)\n",
        "   string = re.sub(\"üòä\", \" \",string)\n",
        "   string = re.sub(\"üò≤\", \" \",string)\n",
        "   string = re.sub(\"ü§Æ\", \" \",string)\n",
        "   string = re.sub(\"üôÑ\", \" \",string)\n",
        "   string = re.sub(\"ü§ë\", \" \",string)\n",
        "   string = re.sub(\"üéÖ\", \" \",string)\n",
        "   string = re.sub(\"üëã\", \" \",string)\n",
        "   string = re.sub(\"üí™\", \" \",string)\n",
        "   string = re.sub(\"üòÑ\", \" \",string)\n",
        "   string = re.sub(\"üßê\", \" \",string)\n",
        "   string = re.sub(\"üò†\", \" \",string)\n",
        "   string = re.sub(\"üéà\", \" \",string)\n",
        "   string = re.sub(\"üöÇ\", \" \",string)\n",
        "   string = re.sub(\"üòä\", \" \",string)\n",
        "   string = re.sub(\"üöá\", \" \",string)\n",
        "   string = re.sub(\"üöä\", \" \",string)\n",
        "   string = re.sub(\"ü§∑\", \" \",string)\n",
        "   string = re.sub(\"üò•\", \" \",string)\n",
        "   string = re.sub(\"üôÉ\", \" \",string)\n",
        "   string = re.sub(\"üî©\", \" \",string)\n",
        "   string = re.sub(\"üîß\", \" \",string)\n",
        "   string = re.sub(\"üî®\", \" \",string)\n",
        "   string = re.sub(\"üõ†\", \" \",string)\n",
        "   string = re.sub(\"üíì\", \" \",string)\n",
        "   string = re.sub(\"üí°\", \" \",string)\n",
        "   string = re.sub(\"üç∏\", \" \",string)\n",
        "   string = re.sub(\"ü•É\", \" \",string)\n",
        "   string = re.sub(\"ü•Ç\", \" \",string)\n",
        "   string = re.sub(\"üò∑\", \" \",string)\n",
        "   string = re.sub(\"ü§ê\", \" \",string)\n",
        "   string = re.sub(\"üåé\", \" \",string)\n",
        "   string = re.sub(\"üëë\", \" \",string)\n",
        "   string = re.sub(\"ü§õ\", \" \",string)\n",
        "   string = re.sub(\"üòÄ\", \" \",string)\n",
        "   string = re.sub(\"üõ§\", \" \",string)\n",
        "   string = re.sub(\"üéÑ\", \" \",string)\n",
        "   string = re.sub(\"üì¥\", \" \",string)\n",
        "   string = re.sub(\"üå≠\", \" \",string)\n",
        "   string = re.sub(\"ü§ï\", \" \",string)\n",
        "   string = re.sub(\"üò≠\", \" \",string)\n",
        "   string = re.sub(\"üçæ\", \" \",string)\n",
        "   string = re.sub(\"üçû\", \" \",string)\n",
        "   string = re.sub(\"ü§¶\", \" \",string)\n",
        "   string = re.sub(\"ü§Ø\", \" \",string)\n",
        "   string = re.sub(\"üïØÔ∏è\", \" \",string)\n",
        "\n",
        "   string = re.sub(\"OTHER|OFFENSE|ABUSE|INSULT\",\" \",string)\n",
        "   return string"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5asMgo4LtnRg"
      },
      "source": [
        "statementsForTraining = []\n",
        "sentimentsForTraining = []\n",
        "\n",
        "\n",
        "fileToRead = open(training_file, 'r')\n",
        "\n",
        "while True:\n",
        "  #next line in file\n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  findSentiment = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "\n",
        "\n",
        "  statementsForTraining.append(line)\n",
        "   #sentimentsForTraining.append(findSentiment.group(0))\n",
        "\n",
        "  if findSentiment.group(0) == \"OTHER\":  \n",
        "    sentimentsForTraining.append(0)\n",
        "  else:\n",
        "    sentimentsForTraining.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        " #print(\"{}: {}\".format(count,line.strip()))\n",
        "  \n",
        " # print(sentiment.group(0))\n",
        " \n",
        "fileToRead.close()\n",
        "\n",
        "training_sentences = statementsForTraining\n",
        "training_labels = sentimentsForTraining\n",
        "\n",
        "#print(training_sentences[9])\n",
        "#print(training_labels[9])\n",
        "\n",
        "#print(len(training_sentences))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsqZPENb98gD"
      },
      "source": [
        "##do the same with testdata\n",
        "statementsForTesting = []\n",
        "sentimentsForTesting = []\n",
        "\n",
        "fileToRead = open(testing_file, 'r')\n",
        "\n",
        "while True:\n",
        "  #next line in file\n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  sent = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "\n",
        "    \n",
        "\n",
        "  statementsForTesting.append(line)\n",
        "  #print(len(line))\n",
        "  #sentimentsForTesting.append(sent.group(0))\n",
        "\n",
        "  if sent.group(0) == \"OTHER\": \n",
        "    sentimentsForTesting.append(0)\n",
        "  else:\n",
        "    sentimentsForTesting.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        "\n",
        "fileToRead.close()\n",
        "\n",
        "\n",
        "testing_sentences = statementsForTesting\n",
        "testing_labels = sentimentsForTesting\n",
        "#print(len(testing_sentences))\n",
        "#print(testing_sentences)   \n",
        "#print(testing_labels)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRUvDLD5bMbO"
      },
      "source": [
        "Padding -> im Prinzip die S√§tze alle auf die gleiche L√§nge bringen (in Theorieteil n√§her drauf eingehen) -> maxlen-Paramter ist f√ºr pad_sequences vorhanden, wenn nicht gesetzt -> alles wird auf die L√§nge des l√§ngsten Satzes aufgef√ºllt -> print(padded(shape)) gibt aus, wie viele Datens√§tze padded wurden und gibt an, wie viele Tokens der l√§ngste Datensatz hat\n",
        "print(padded[x]) gibt einen Satz aus (bereits tokenisiert)\n",
        "\n",
        "Padding -> sowohl f√ºr Trainigs- als auch f√ºr Testdaten\n",
        "\n",
        "Und: Daten als numpy-Arrays speichern (notwendig f√ºr tensorflow).\n",
        "\n",
        " -> Tokenizer https://towardsdatascience.com/text-classification-in-keras-part-2-how-to-use-the-keras-tokenizer-word-representations-fd571674df23 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3hFi7waTv5m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb4bc88b-18a1-484e-8e60-a03982ff74da"
      },
      "source": [
        "tokenizer = Tokenizer(oov_token=\"OOV\")\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "\n",
        "#creating a word index - nur die Trainigsdaten\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "validation_size = 500\n",
        "\n",
        "\n",
        "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "padded_training = pad_sequences(training_sequences, maxlen=max_length, padding='post')\n",
        "print(len(padded_training))\n",
        "\n",
        "validation_sequences = padded_training[0:validation_size]\n",
        "validation_labels = training_labels[0:validation_size]\n",
        "\n",
        "padded_training = padded_training[validation_size:]\n",
        "training_labels = training_labels[validation_size:]\n",
        "\n",
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
        "padded_testing = pad_sequences(testing_sequences, maxlen=max_length,  padding='post')\n",
        "\n",
        "#print(validation_sequences[499])\n",
        "print(padded_training[0])\n",
        "#print(len(validation_labels))\n",
        "#print(len(training_labels))\n",
        "\n",
        "\n",
        "nppadded_training = np.array(padded_training)\n",
        "nptraining_labels = np.array(training_labels)\n",
        "\n",
        "nppadded_validation = np.array(validation_sequences)\n",
        "npvalidation_labels = np.array(validation_labels)\n",
        "\n",
        "nppadded_testing = np.array(padded_testing)\n",
        "nptesting_labels = np.array(testing_labels)\n",
        "\n",
        "\n",
        "print(len(nppadded_training))\n",
        "print(len(nptraining_labels))\n",
        "print(len(word_index))\n",
        "\n",
        "#print(statementsForTraining[2])\n",
        "#print(nppadded_training[4])\n",
        "#print(nppadded_training.shape)\n",
        "#print(nptraining_labels[4])\n",
        "#print(nppadded_testing.shape)\n",
        "#print(word_index) \n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5009\n",
            "[  12 3982   11   41 6706 1040    4    5  202   39    3 2922   49 1360\n",
            "  810  495 3983    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0]\n",
            "4509\n",
            "4509\n",
            "15059\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tL3owrc8THkT"
      },
      "source": [
        "\n",
        "Dann: Embedding mit entweder word2vec oder glove\n",
        "Word2vec-Daten sind hier: http://vectors.nlpl.eu/repository/#\n",
        "Glove -> https://nlp.stanford.edu/projects/glove/ Da mal den Twitter-Vector runtergeladen\n",
        "Wenn Daten in GoogleDrive sind (w√§re auch via url m√∂glich..), muss Drive gemounted werden ( https://buomsoo-kim.github.io/colab/2020/05/09/Colab-mounting-google-drive.md/ ) aber auch hier https://enjoymachinelearning.com/posts/colab-with-google-drive/\n",
        "\n",
        "Die Word2vec vectors: http://vectors.nlpl.eu/repository/# \n",
        "\n",
        "glove-zitat:\n",
        "Citing GloVe\n",
        "\n",
        "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. [pdf] [bib]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zuO7T9ZTG57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3a3395c-9343-449c-fa84-30f939e5bc1c"
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount(\"/content/drive\")\n",
        "os.listdir(\"/content/drive/MyDrive/Colab Notebooks\")\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['germeval_training.txt',\n",
              " 'glove.twitter.27B.50d.txt',\n",
              " 'glove.twitter.27B.200d.txt',\n",
              " 'glove.6B.200d.txt',\n",
              " 'glove.840B.300d.txt',\n",
              " 'tensorboard.gdoc',\n",
              " 'keras.gdoc',\n",
              " 'Vectorization CNN embedded_limited_vocab.ipynb',\n",
              " 'glove.42B.300d.txt',\n",
              " 'Embedding Glove Vergleich.ipynb',\n",
              " 'CNN embedded_limited_vocab.ipynb',\n",
              " 'LSTM_limited_vocab.ipynb',\n",
              " 'LSTM.ipynb',\n",
              " 'CNN embedded.ipynb']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7ToKO-sZLHK"
      },
      "source": [
        "\n",
        "Keras-Doc : https://keras.io/examples/nlp/pretrained_word_embeddings/#load-pretrained-word-embeddings \n",
        "embedding mit initializers.. weights m√ºsste auch funktionieren\n",
        "\n",
        "Diese erstellte Matrix mit Embedding dann in die Embedding-Schicht einbinden,  Trainable auf False, weil sich die Werte nicht durch Training anpassen sollen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AShIVfC7ZQAH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "438eefb0-5431-48aa-c8a8-5559e22431a5"
      },
      "source": [
        "#Gr√∂√üe Vokabel -> wordindex + 2 (weil padding + OOV) \n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "vocabulary_size = len(word_index)+2\n",
        "\n",
        "# dann erstell ich ein W√∂rterbuch mit Namen \"embedding_vector\", dort sind dann\n",
        "#die keys drinnen, die in glove-Datei drinnen sind mit dem entsprechenden Key\n",
        "\n",
        "embedding_index_glove = {}\n",
        "f = open('/content/drive/MyDrive/Colab Notebooks/glove.twitter.27B.200d.txt')\n",
        "for line in f:\n",
        "  value = line.split()\n",
        "  word = value[0]\n",
        "  coef = np.asarray(value[1:],dtype='float32')\n",
        "  embedding_index_glove[word] = coef\n",
        "\n",
        "print(\"%d gefunden: \"% len(embedding_index_glove))\n",
        "\n",
        "#Dann noch eine Embedding-Matrix erstellen\n",
        "#zweiter Wert = Embedding-Dimension der Datei, in dem Fall 200\n",
        "\n",
        "glove_matrix = np.zeros((vocabulary_size,200))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    embedding_value = embedding_index_glove.get(word)\n",
        "    if embedding_value is not None:\n",
        "      glove_matrix[index] = embedding_value\n",
        "      hits+=1\n",
        "    else:\n",
        "      misses+=1\n",
        "\n",
        "print(\"hits %d and %d misses\"%(hits,misses))\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1193514 gefunden: \n",
            "hits 6747 and 8312 misses\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZmvOfwhV4N5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6bc1e5c-31be-469f-92ec-cc08bb95e9b0"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "print(\"vocab size: %d\"%vocabulary_size)\n",
        "CNN16052102ES09 = tf.keras.Sequential()\n",
        "#Embedding -> hier dann auf das embedding verweisen, Input_dim -> die Anzahl der W√∂rter im word_index, output -> in dem Fall passend zum verwendeten Vektor\n",
        "#input-length -> auf 60  gepadded, trainable -> nein, weil nichts ver√§ndert werden soll\n",
        "#embeddings_initializer=keras.initializers.Constant(glove_matrix) vs weights = [glove_matrix]\n",
        "#Convolutional layers => filters = neurons.. mit 100? 265?\n",
        "#CNN16052102ES09.add(tf.keras.layers.Embedding(input_dim=vocabulary_size, output_dim=200, input_length=max_length))\n",
        "CNN16052102ES09.add(tf.keras.layers.Embedding(vocabulary_size, output_dim=200, input_length=60, embeddings_initializer = keras.initializers.Constant(glove_matrix), trainable= False))\n",
        "CNN16052102ES09.add(tf.keras.layers.Dropout(0.4))\n",
        "CNN16052102ES09.add(tf.keras.layers.Conv1D(filters=50, kernel_size=3, padding=\"valid\", activation=\"relu\"))\n",
        "CNN16052102ES09.add(tf.keras.layers.MaxPooling1D())\n",
        "CNN16052102ES09.add(tf.keras.layers.Conv1D(filters=50, kernel_size=3, padding=\"valid\", activation=\"relu\"))\n",
        "CNN16052102ES09.add(tf.keras.layers.GlobalAveragePooling1D())\n",
        "CNN16052102ES09.add(tf.keras.layers.Flatten())\n",
        "CNN16052102ES09.add(tf.keras.layers.Dense(260, activation=\"relu\"))\n",
        "CNN16052102ES09.add(tf.keras.layers.Dropout(0.4))\n",
        "CNN16052102ES09.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "CNN16052102ES09.summary()\n",
        "\n",
        "#nppadded_training = np.asmatrix(nppadded_training) not necessary\n",
        "#nppadded_testing = np.asmatrix(nppadded_testing)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab size: 15061\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 60, 200)           3012200   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 60, 200)           0         \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 58, 50)            30050     \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 29, 50)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 27, 50)            7550      \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 260)               13260     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 260)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 261       \n",
            "=================================================================\n",
            "Total params: 3,063,321\n",
            "Trainable params: 51,121\n",
            "Non-trainable params: 3,012,200\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEr4OzT-iHDe"
      },
      "source": [
        "#model.layers[2].get_weights()[0].shape\n",
        "#weights=np.random.rand(5,200,100)\n",
        "#bias=np.random.rand(100)\n",
        "#model.layers[2].set_weights([weights, bias])\n",
        "\n",
        "#model.layers[2].get_weights()[0]\n",
        "#https://androidkt.com/set-custom-weights-keras-using-numpy-array/"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UB7_3VPYesr9"
      },
      "source": [
        "F1-Score f√ºr jede Epoche https://aakashgoel12.medium.com/how-to-add-user-defined-function-get-f1-score-in-keras-metrics-3013f979ce0d\n",
        "\n",
        "Sehr gute Ressource f√ºr die verschiedenen Scores und Metriken https://neptune.ai/blog/evaluation-metrics-binary-classification#10  das und aakas verwendet\n",
        "\n",
        "hier: je eine Funktion f√ºr Recall, Precision, f1 https://neptune.ai/blog/keras-metrics \n",
        "\n",
        "https://keras.rstudio.com/reference/k_ones_like.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygyrbFJaMV9B"
      },
      "source": [
        "import keras.backend as K\n",
        "\n",
        "def metrics_recall(data_true, data_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(data_true,0,1)))\n",
        "\n",
        "    recall = true_positives / (possible_positives+K.epsilon())\n",
        "    return recall\n",
        "\n",
        "\n",
        "def metrics_precision(data_true, data_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "\n",
        "    positives_predicted = K.sum(K.round(K.clip(data_pred,0,1)))\n",
        "    precision = true_positives / (positives_predicted+K.epsilon())\n",
        "    return precision\n",
        "\n",
        "\n",
        "def metrics_f1(data_true, data_pred):\n",
        "    precision_data = metrics_precision(data_true, data_pred)\n",
        "    recall_data = metrics_recall(data_true, data_pred)\n",
        "    return 2*(precision_data*recall_data)/(precision_data+recall_data+K.epsilon())"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1ctlBrnuYJz"
      },
      "source": [
        "https://aakashgoel12.medium.com/how-to-add-user-defined-function-get-f1-score-in-keras-metrics-3013f979ce0d"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AfPD3_bWCm0"
      },
      "source": [
        "CNN16052102ES09.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',metrics_recall,metrics_precision,metrics_f1])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpChKUY-QEWI"
      },
      "source": [
        "https://www.tensorflow.org/tensorboard/tensorboard_in_notebooks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJfMgUhHBoD1"
      },
      "source": [
        "#%load_ext tensorboard\n",
        "#nur einmal pro Sitzung notwendig\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ISmMXLqP8Hc"
      },
      "source": [
        "\n",
        "logs_base_dir = \"./logs\"\n",
        "callbackForTB = tf.keras.callbacks.TensorBoard(logs_base_dir)\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ehh-EMXUQh8r"
      },
      "source": [
        "Early Stopping as defined in keras tensorflow documentation\n",
        "https://www.tensorflow.org/guide/keras/train_and_evaluate "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BY_t-PeQEjy"
      },
      "source": [
        "callbackEarlyStopping = [\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_loss\",\n",
        "        mode=\"min\",\n",
        "        patience=3,\n",
        "        verbose=1,\n",
        "    )\n",
        "]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2CHbXiP1LsF"
      },
      "source": [
        "training_epochs = 30\n",
        "batch_size = 40\n",
        "validation_split=0.2"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abV-QAxfW48r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08cc7d1b-0dd4-4719-fe37-346de5bc6c2f"
      },
      "source": [
        "#Werte der Convolutional-Schichten variieren (Filter), Batch-Size variieren, kernel-size..\n",
        "CNN16052102ES09.fit(nppadded_training, nptraining_labels, batch_size=batch_size, validation_split=validation_split, epochs=training_epochs, callbacks=[callbackForTB,callbackEarlyStopping])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "91/91 [==============================] - 4s 32ms/step - loss: 0.6608 - accuracy: 0.6495 - metrics_recall: 0.0574 - metrics_precision: 0.0266 - metrics_f1: 0.0294 - val_loss: 0.6392 - val_accuracy: 0.6718 - val_metrics_recall: 0.0000e+00 - val_metrics_precision: 0.0000e+00 - val_metrics_f1: 0.0000e+00\n",
            "Epoch 2/30\n",
            "91/91 [==============================] - 3s 31ms/step - loss: 0.6423 - accuracy: 0.6568 - metrics_recall: 0.0000e+00 - metrics_precision: 0.0000e+00 - metrics_f1: 0.0000e+00 - val_loss: 0.6289 - val_accuracy: 0.6718 - val_metrics_recall: 0.0000e+00 - val_metrics_precision: 0.0000e+00 - val_metrics_f1: 0.0000e+00\n",
            "Epoch 3/30\n",
            "91/91 [==============================] - 3s 31ms/step - loss: 0.6336 - accuracy: 0.6535 - metrics_recall: 0.0050 - metrics_precision: 0.0180 - metrics_f1: 0.0066 - val_loss: 0.6540 - val_accuracy: 0.6308 - val_metrics_recall: 0.3805 - val_metrics_precision: 0.4280 - val_metrics_f1: 0.3913\n",
            "Epoch 4/30\n",
            "91/91 [==============================] - 3s 31ms/step - loss: 0.6260 - accuracy: 0.6599 - metrics_recall: 0.0482 - metrics_precision: 0.1524 - metrics_f1: 0.0686 - val_loss: 0.5801 - val_accuracy: 0.6907 - val_metrics_recall: 0.1228 - val_metrics_precision: 0.6790 - val_metrics_f1: 0.1990\n",
            "Epoch 5/30\n",
            "91/91 [==============================] - 3s 31ms/step - loss: 0.5777 - accuracy: 0.6795 - metrics_recall: 0.2432 - metrics_precision: 0.5798 - metrics_f1: 0.3163 - val_loss: 0.5773 - val_accuracy: 0.6984 - val_metrics_recall: 0.1466 - val_metrics_precision: 0.7500 - val_metrics_f1: 0.2365\n",
            "Epoch 6/30\n",
            "91/91 [==============================] - 3s 31ms/step - loss: 0.5646 - accuracy: 0.6994 - metrics_recall: 0.2549 - metrics_precision: 0.6080 - metrics_f1: 0.3381 - val_loss: 0.5606 - val_accuracy: 0.7118 - val_metrics_recall: 0.2819 - val_metrics_precision: 0.7017 - val_metrics_f1: 0.3852\n",
            "Epoch 7/30\n",
            "91/91 [==============================] - 3s 31ms/step - loss: 0.5353 - accuracy: 0.7186 - metrics_recall: 0.3565 - metrics_precision: 0.6717 - metrics_f1: 0.4377 - val_loss: 0.5620 - val_accuracy: 0.6951 - val_metrics_recall: 0.5257 - val_metrics_precision: 0.5456 - val_metrics_f1: 0.5192\n",
            "Epoch 8/30\n",
            "91/91 [==============================] - 3s 31ms/step - loss: 0.5254 - accuracy: 0.7233 - metrics_recall: 0.4191 - metrics_precision: 0.6550 - metrics_f1: 0.4954 - val_loss: 0.5451 - val_accuracy: 0.7228 - val_metrics_recall: 0.4876 - val_metrics_precision: 0.6054 - val_metrics_f1: 0.5227\n",
            "Epoch 9/30\n",
            "91/91 [==============================] - 3s 31ms/step - loss: 0.5053 - accuracy: 0.7500 - metrics_recall: 0.5338 - metrics_precision: 0.6896 - metrics_f1: 0.5764 - val_loss: 0.5406 - val_accuracy: 0.7162 - val_metrics_recall: 0.5529 - val_metrics_precision: 0.5869 - val_metrics_f1: 0.5517\n",
            "Epoch 10/30\n",
            "91/91 [==============================] - 3s 31ms/step - loss: 0.4944 - accuracy: 0.7543 - metrics_recall: 0.5443 - metrics_precision: 0.6820 - metrics_f1: 0.5733 - val_loss: 0.5842 - val_accuracy: 0.7173 - val_metrics_recall: 0.2011 - val_metrics_precision: 0.7021 - val_metrics_f1: 0.3027\n",
            "Epoch 11/30\n",
            "91/91 [==============================] - 3s 31ms/step - loss: 0.4622 - accuracy: 0.7725 - metrics_recall: 0.5556 - metrics_precision: 0.7490 - metrics_f1: 0.6009 - val_loss: 0.5371 - val_accuracy: 0.7084 - val_metrics_recall: 0.5602 - val_metrics_precision: 0.5578 - val_metrics_f1: 0.5464\n",
            "Epoch 12/30\n",
            "91/91 [==============================] - 3s 31ms/step - loss: 0.4542 - accuracy: 0.7755 - metrics_recall: 0.6163 - metrics_precision: 0.6941 - metrics_f1: 0.6283 - val_loss: 0.5440 - val_accuracy: 0.7273 - val_metrics_recall: 0.3742 - val_metrics_precision: 0.6695 - val_metrics_f1: 0.4640\n",
            "Epoch 13/30\n",
            "91/91 [==============================] - 3s 31ms/step - loss: 0.4384 - accuracy: 0.8003 - metrics_recall: 0.6294 - metrics_precision: 0.7583 - metrics_f1: 0.6648 - val_loss: 0.5455 - val_accuracy: 0.7317 - val_metrics_recall: 0.4140 - val_metrics_precision: 0.6550 - val_metrics_f1: 0.4894\n",
            "Epoch 14/30\n",
            "91/91 [==============================] - 3s 32ms/step - loss: 0.4154 - accuracy: 0.8081 - metrics_recall: 0.6685 - metrics_precision: 0.7687 - metrics_f1: 0.6980 - val_loss: 0.5496 - val_accuracy: 0.7206 - val_metrics_recall: 0.4274 - val_metrics_precision: 0.5967 - val_metrics_f1: 0.4853\n",
            "Epoch 00014: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa055a5c990>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJVL4SBLPB2P"
      },
      "source": [
        "#%tensorboard --logdir {logs_base_dir}"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_LnvWBcnoak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dff684ba-21a3-468c-90ac-b5e182a57db7"
      },
      "source": [
        "#results = model.evaluate(nppadded_testing, nptesting_labels, batch_size=batch_size)\n",
        "#print(\"test loss, test acc:\",results)\n",
        "\n",
        "(loss,accuracy, metrics_recall,metrics_precision,\n",
        "metrics_f1) = CNN16052102ES09.evaluate(nppadded_testing, nptesting_labels, verbose=1)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5994 - accuracy: 0.6962 - metrics_recall: 0.3131 - metrics_precision: 0.6191 - metrics_f1: 0.3988\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KgjIkhpKmHc"
      },
      "source": [
        "make some predictions of test data and save it to variable. verbose=0 -> do not generate output\n",
        "Gute Quelle: https://deeplizard.com/learn/video/2f-NjDUvZIE "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89GWuxryKlcM"
      },
      "source": [
        "CNN_predictions06 = CNN16052102ES09.predict(x=nppadded_testing)\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3jPDaDJK_cN"
      },
      "source": [
        "#for p in CNN_predictions06:\n",
        " # print(p)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eC9efJy4Lp21"
      },
      "source": [
        "rounded predictions: give prediction value of most likely prediction (0 or 1). Printing the output of rounded prediction shows the prediction made by the model on the data (which output is most likely)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsG-TJuQLvtk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5c4f883-069c-4907-9cc0-bea6192cfb0e"
      },
      "source": [
        "prediction_rounded06 = np.round(CNN_predictions06)\n",
        "#np.argmax(CNN_predictions06,axis=-1)\n",
        "\n",
        "#for p in prediction_rounded06:\n",
        " # print(p)\n",
        "\n",
        "\n",
        "print(nptesting_labels[500:520])\n",
        "print(prediction_rounded06[500:520])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1]\n",
            "[[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egTtgpXgg8a2"
      },
      "source": [
        "https://deeplizard.com/learn/video/km7pxKy4UHU\n",
        "\n",
        "Quelle der def plot_confusion_matrix: https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSDXf7-_MITy"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0AMs1EzhBU1"
      },
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                        normalize=False,\n",
        "                        title='Confusion matrix',\n",
        "                        cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2JgEnlghCtl"
      },
      "source": [
        "cm = confusion_matrix(y_true=nptesting_labels, y_pred=prediction_rounded06)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckmF29whhFmX"
      },
      "source": [
        "plot_labels = ['no hatespeech','hatespeech']"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "2mpSE96rhK7K",
        "outputId": "bbf45eda-5fed-4a7b-df87-48fc8cf0ce92"
      },
      "source": [
        "plot_confusion_matrix(cm=cm, classes=plot_labels, title='CNN Confusion 50 EarlyStopping min loss')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix, without normalization\n",
            "[[2084  246]\n",
            " [ 827  375]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}