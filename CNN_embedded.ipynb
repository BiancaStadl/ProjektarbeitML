{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN embedded.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO4LCZyBpdk30GZhUS7t75L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BiancaStadl/ProjektarbeitML/blob/main/CNN_embedded.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXDOlIBymF0V"
      },
      "source": [
        "GloVe embeddings taken from:\n",
        "\n",
        "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. [pdf] [bib]\n",
        "\n",
        "hatespeechdata taken from (https://hatespeechdata.com/): Wiegand, M., Siegel, M. and Ruppenhofer, J., 2018. Overview of the GermEval 2018 Shared Task on the Identification of Offensive Language. In: Proceedings of GermEval 2018, 14th Conference on Natural Language Processing (KONVENS 2018). Vienna, Austria: Research Gate. available on: https://github.com/uds-lsv/GermEval-2018-Data (last checked: 09.05.2021)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlBmABDxfqII"
      },
      "source": [
        "wiki detox..https://colab.research.google.com/github/tensorflow/fairness-indicators/blob/master/g3doc/tutorials/Fairness_Indicators_TFCO_Wiki_Case_Study.ipynb#scrollTo=y6T5tlXcdW7J "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3xfitNdliBI"
      },
      "source": [
        "#import matplotlib.pyplot as plt -> f√ºr evtl Visualisierungen\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import string\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from keras import losses \n",
        "from keras import optimizers \n",
        "from keras import metrics \n",
        "\n",
        "#!pip install Tokenizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "#!pip install pad_sequences\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import preprocessing\n",
        "#from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTWJQ1iga_vS"
      },
      "source": [
        "Maximale Satzl√§nge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bq08Me5la_Cc"
      },
      "source": [
        "\n",
        "max_length = 60"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVYBMvYSotTH"
      },
      "source": [
        "url = \"https://github.com/uds-lsv/GermEval-2018-Data/archive/master.zip\"\n",
        "\n",
        "dataset = tf.keras.utils.get_file(\"GermEval-2018-Data-master.zip\", url, \n",
        "                                   extract=True, cache_dir='.',\n",
        "                                    cache_subdir='')\n",
        "\n",
        "dataset_dir = os.path.join(os.path.dirname(dataset), 'GermEval-2018-Data-master')\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cS14OUtfo34V"
      },
      "source": [
        "#os.listdir(dataset_dir)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2X429K6hpOVm"
      },
      "source": [
        "training_file = os.path.join(dataset_dir, 'germeval2018.training.txt')\n",
        "\n",
        "testing_file = os.path.join(dataset_dir, 'germeval2018.test.txt')\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uq8fG3LNtn_m"
      },
      "source": [
        "###Aufbereitung\n",
        "txt-Dateien lesen, und dabei jede Zeile splitten und teilen\n",
        "Twitter-Handler entfernen?\n",
        "Labels von S√§tzen trennen, Labels in eigenen Array packen.\n",
        "\n",
        "####Ressourcen\n",
        "* https://www.w3schools.com/python/gloss_python_if_statement.asp\n",
        "* https://stackabuse.com/using-regex-for-text-manipulation-in-python/\n",
        "* https://www.tutorialspoint.com/python/string_splitlines.htm \n",
        "* https://note.nkmk.me/en/python-split-rsplit-splitlines-re/ \n",
        "* https://www.w3schools.com/python/python_regex.asp \n",
        "\n",
        "g√§be bei keras tf.keras.preprocessing.text_dataset_from_directory, aber daf√ºr m√ºssten die Daten auf bestimmte Weise in Verzeichnis organisiert sein, hier nicht der Fall.\n",
        "\n",
        "\n",
        "Einteilung der Daten: Testdaten\n",
        "Trainingsdaten -> noch ca 500 f√ºr Validierungsdaten\n",
        "\n",
        "labels -> \"other\", also nicht-negative Aussagen bekommen \"0\", negative Aussagen bekommen \"1\"\n",
        "\n",
        " Regex f√ºr Emojis  ->\n",
        "\n",
        "(\\u00a9|\\u00ae|[\\u2000-\\u3300]|\\ud83c[\\ud000-\\udfff]|\\ud83d[\\ud000-\\udfff]|\\ud83e[\\ud000-\\udfff])\n",
        "\n",
        "genommen von https://www.regextester.com/106421 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Py_cwD4eZkXo"
      },
      "source": [
        "def remove_clutter(string):\n",
        "   string = re.sub(\"@[^\\s]+\",\" \",string)\n",
        "   string = re.sub(\"#[^\\s]+\",\" \", string)\n",
        "   string = re.sub(\"\\u00a9\",\" \", string)\n",
        "   string = re.sub(\"\\u00ae\",\" \", string)\n",
        "   string = re.sub(\"[\\u2000-\\u3300]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83c[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83d[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83e[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"üòú\", \" \",string)\n",
        "   string = re.sub(\"üç´\", \" \",string)\n",
        "   string = re.sub(\"üòÅ\", \" \",string)\n",
        "   string = re.sub(\"üêñ\", \" \",string)\n",
        "   string = re.sub(\"üò°\", \" \",string)\n",
        "   string = re.sub(\"üòá\", \" \",string)\n",
        "   string = re.sub(\"üò¨\", \" \",string)\n",
        "   string = re.sub(\"üòÉ\", \" \",string)\n",
        "   string = re.sub(\"üòÇ\", \" \",string)\n",
        "   string = re.sub(\"üíô\", \" \",string)  \n",
        "   string = re.sub(\"üòõ\", \" \",string)\n",
        "   string = re.sub(\"üôè\", \" \",string)\n",
        "   string = re.sub(\"üëç\", \" \",string)\n",
        "   string = re.sub(\"üñï\", \" \",string)\n",
        "   string = re.sub(\"üòâ\", \" \",string)\n",
        "   string = re.sub(\"üí©\", \" \",string)\n",
        "   string = re.sub(\"ü§¢\", \" \",string)\n",
        "   string = re.sub(\"üëè\", \" \",string)\n",
        "   string = re.sub(\"üò®\", \" \",string)\n",
        "   string = re.sub(\"ü§£\", \" \",string)\n",
        "   string = re.sub(\"ü§°\", \" \",string)\n",
        "   string = re.sub(\"üòà\", \" \",string)\n",
        "   string = re.sub(\"üíÉüèΩ\", \" \",string)\n",
        "   string = re.sub(\"üëπ\", \" \",string)\n",
        "   string = re.sub(\"ü§ò\", \" \",string)\n",
        "   string = re.sub(\"üò±\", \" \",string)\n",
        "   string = re.sub(\"ü§î\", \" \",string) \n",
        "   string = re.sub(\"üåà\", \" \",string) \n",
        "   string = re.sub(\"üíï\", \" \",string) \n",
        "   string = re.sub(\"üë©‚Äç‚ù§Ô∏è‚Äçüë©\", \" \",string) \n",
        "   string = re.sub(\"üòç\", \" \",string) \n",
        "   string = re.sub(\"üëÜ\", \" \",string) \n",
        "   string = re.sub(\"üòñ\", \" \",string) \n",
        "   string = re.sub(\"üëá\", \" \",string) \n",
        "   string = re.sub(\"üî•\", \" \",string) \n",
        "   string = re.sub(\"üòò\", \" \",string) \n",
        "   string = re.sub(\"üéâ\", \" \",string) \n",
        "   string = re.sub(\"ü§¨\", \" \",string) \n",
        "   string = re.sub(\"üëä\", \" \",string)\n",
        "   string = re.sub(\"üá©üá™\", \" \",string)  \n",
        "   string = re.sub(\"üíî\", \" \",string)\n",
        "   string = re.sub(\"üôà\", \" \",string)\n",
        "   string = re.sub(\"ü§Ø\", \" \",string)\n",
        "   string = re.sub(\"üêü\", \" \",string)\n",
        "   string = re.sub(\"üõ∂\", \" \",string)\n",
        "   string = re.sub(\"üòä\", \" \",string)\n",
        "   string = re.sub(\"üòì\", \" \",string)\n",
        "   string = re.sub(\"üò≥\", \" \",string)\n",
        "   string = re.sub(\"üöÄ\", \" \",string)\n",
        "   string = re.sub(\"üëé\", \" \",string)\n",
        "   string = re.sub(\"üòé\", \" \",string)\n",
        "   string = re.sub(\"üê∏\", \" \",string)\n",
        "   string = re.sub(\"üìà\", \" \",string)\n",
        "   string = re.sub(\"üôÇ\", \" \",string)\n",
        "   string = re.sub(\"üòÖ\", \" \",string)\n",
        "   string = re.sub(\"üòÜ\", \" \",string)\n",
        "   string = re.sub(\"üôéüèø\", \" \",string)\n",
        "   string = re.sub(\"üëéüèΩ\", \" \",string)\n",
        "   string = re.sub(\"ü§≠\", \" \",string)\n",
        "   string = re.sub(\"üò§\", \" \",string)\n",
        "   string = re.sub(\"üòö\", \" \",string)\n",
        "   string = re.sub(\"üòä\", \" \",string)\n",
        "   string = re.sub(\"üò≤\", \" \",string)\n",
        "   string = re.sub(\"ü§Æ\", \" \",string)\n",
        "   string = re.sub(\"üôÑ\", \" \",string)\n",
        "   string = re.sub(\"ü§ë\", \" \",string)\n",
        "   string = re.sub(\"üéÖ\", \" \",string)\n",
        "   string = re.sub(\"üëã\", \" \",string)\n",
        "   string = re.sub(\"üí™\", \" \",string)\n",
        "   string = re.sub(\"üòÑ\", \" \",string)\n",
        "   string = re.sub(\"üßê\", \" \",string)\n",
        "   string = re.sub(\"üò†\", \" \",string)\n",
        "   string = re.sub(\"üéà\", \" \",string)\n",
        "   string = re.sub(\"üöÇ\", \" \",string)\n",
        "   string = re.sub(\"üòä\", \" \",string)\n",
        "   string = re.sub(\"üöá\", \" \",string)\n",
        "   string = re.sub(\"üöä\", \" \",string)\n",
        "   string = re.sub(\"ü§∑\", \" \",string)\n",
        "   string = re.sub(\"üò•\", \" \",string)\n",
        "   string = re.sub(\"üôÉ\", \" \",string)\n",
        "   string = re.sub(\"üî©\", \" \",string)\n",
        "   string = re.sub(\"üîß\", \" \",string)\n",
        "   string = re.sub(\"üî®\", \" \",string)\n",
        "   string = re.sub(\"üõ†\", \" \",string)\n",
        "   string = re.sub(\"üíì\", \" \",string)\n",
        "   string = re.sub(\"üí°\", \" \",string)\n",
        "   string = re.sub(\"üç∏\", \" \",string)\n",
        "   string = re.sub(\"ü•É\", \" \",string)\n",
        "   string = re.sub(\"ü•Ç\", \" \",string)\n",
        "   string = re.sub(\"üò∑\", \" \",string)\n",
        "   string = re.sub(\"ü§ê\", \" \",string)\n",
        "   string = re.sub(\"üåé\", \" \",string)\n",
        "   string = re.sub(\"üëë\", \" \",string)\n",
        "   string = re.sub(\"ü§õ\", \" \",string)\n",
        "   string = re.sub(\"üòÄ\", \" \",string)\n",
        "   string = re.sub(\"üõ§\", \" \",string)\n",
        "   string = re.sub(\"üéÑ\", \" \",string)\n",
        "   string = re.sub(\"üì¥\", \" \",string)\n",
        "   string = re.sub(\"üå≠\", \" \",string)\n",
        "   string = re.sub(\"ü§ï\", \" \",string)\n",
        "   string = re.sub(\"üò≠\", \" \",string)\n",
        "   string = re.sub(\"üçæ\", \" \",string)\n",
        "   string = re.sub(\"üçû\", \" \",string)\n",
        "   string = re.sub(\"ü§¶\", \" \",string)\n",
        "   string = re.sub(\"ü§Ø\", \" \",string)\n",
        "   string = re.sub(\"üïØÔ∏è\", \" \",string)\n",
        "\n",
        "   string = re.sub(\"OTHER|OFFENSE|ABUSE|INSULT\",\" \",string)\n",
        "   return string"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5asMgo4LtnRg"
      },
      "source": [
        "statementsForTraining = []\n",
        "sentimentsForTraining = []\n",
        "\n",
        "\n",
        "fileToRead = open(training_file, 'r')\n",
        "\n",
        "while True:\n",
        "  #next line in file\n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  findSentiment = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "\n",
        "\n",
        "  statementsForTraining.append(line)\n",
        "   #sentimentsForTraining.append(findSentiment.group(0))\n",
        "\n",
        "  if findSentiment.group(0) == \"OTHER\":  \n",
        "    sentimentsForTraining.append(0)\n",
        "  else:\n",
        "    sentimentsForTraining.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        " #print(\"{}: {}\".format(count,line.strip()))\n",
        "  \n",
        " # print(sentiment.group(0))\n",
        " \n",
        "fileToRead.close()\n",
        "\n",
        "training_sentences = statementsForTraining\n",
        "training_labels = sentimentsForTraining\n",
        "\n",
        "#print(training_sentences[9])\n",
        "#print(training_labels[9])\n",
        "\n",
        "#print(len(training_sentences))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsqZPENb98gD"
      },
      "source": [
        "##do the same with testdata\n",
        "statementsForTesting = []\n",
        "sentimentsForTesting = []\n",
        "\n",
        "fileToRead = open(testing_file, 'r')\n",
        "\n",
        "while True:\n",
        "  #next line in file\n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  sent = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "\n",
        "    \n",
        "\n",
        "  statementsForTesting.append(line)\n",
        "  #print(len(line))\n",
        "  #sentimentsForTesting.append(sent.group(0))\n",
        "\n",
        "  if sent.group(0) == \"OTHER\": \n",
        "    sentimentsForTesting.append(0)\n",
        "  else:\n",
        "    sentimentsForTesting.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        "\n",
        "fileToRead.close()\n",
        "\n",
        "\n",
        "testing_sentences = statementsForTesting\n",
        "testing_labels = sentimentsForTesting\n",
        "#print(len(testing_sentences))\n",
        "#print(testing_sentences)   \n",
        "#print(testing_labels)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRUvDLD5bMbO"
      },
      "source": [
        "Padding -> im Prinzip die S√§tze alle auf die gleiche L√§nge bringen (in Theorieteil n√§her drauf eingehen) -> maxlen-Paramter ist f√ºr pad_sequences vorhanden, wenn nicht gesetzt -> alles wird auf die L√§nge des l√§ngsten Satzes aufgef√ºllt -> print(padded(shape)) gibt aus, wie viele Datens√§tze padded wurden und gibt an, wie viele Tokens der l√§ngste Datensatz hat\n",
        "print(padded[x]) gibt einen Satz aus (bereits tokenisiert)\n",
        "\n",
        "Padding -> sowohl f√ºr Trainigs- als auch f√ºr Testdaten\n",
        "\n",
        "Und: Daten als numpy-Arrays speichern (notwendig f√ºr tensorflow).\n",
        "\n",
        " -> Tokenizer https://towardsdatascience.com/text-classification-in-keras-part-2-how-to-use-the-keras-tokenizer-word-representations-fd571674df23 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3hFi7waTv5m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae973047-dd75-4e40-dc2a-cb4f202bb13e"
      },
      "source": [
        "tokenizer = Tokenizer(oov_token=\"OOV\")\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "\n",
        "#creating a word index - nur die Trainigsdaten\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "validation_size = 500\n",
        "\n",
        "\n",
        "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "padded_training = pad_sequences(training_sequences, maxlen=max_length, padding='post')\n",
        "print(len(padded_training))\n",
        "\n",
        "validation_sequences = padded_training[0:validation_size]\n",
        "validation_labels = training_labels[0:validation_size]\n",
        "\n",
        "padded_training = padded_training[validation_size:]\n",
        "training_labels = training_labels[validation_size:]\n",
        "\n",
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
        "padded_testing = pad_sequences(testing_sequences, maxlen=max_length,  padding='post')\n",
        "\n",
        "#print(validation_sequences[499])\n",
        "print(padded_training[0])\n",
        "#print(len(validation_labels))\n",
        "#print(len(training_labels))\n",
        "\n",
        "\n",
        "nppadded_training = np.array(padded_training)\n",
        "nptraining_labels = np.array(training_labels)\n",
        "\n",
        "nppadded_validation = np.array(validation_sequences)\n",
        "npvalidation_labels = np.array(validation_labels)\n",
        "\n",
        "nppadded_testing = np.array(padded_testing)\n",
        "nptesting_labels = np.array(testing_labels)\n",
        "\n",
        "\n",
        "print(len(nppadded_training))\n",
        "print(len(nptraining_labels))\n",
        "print(len(word_index))\n",
        "\n",
        "#print(statementsForTraining[2])\n",
        "#print(nppadded_training[4])\n",
        "#print(nppadded_training.shape)\n",
        "#print(nptraining_labels[4])\n",
        "#print(nppadded_testing.shape)\n",
        "#print(word_index) \n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5009\n",
            "[  12 3982   11   41 6706 1040    4    5  202   39    3 2922   49 1360\n",
            "  810  495 3983    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0]\n",
            "4509\n",
            "4509\n",
            "15059\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tL3owrc8THkT"
      },
      "source": [
        "\n",
        "Dann: Embedding mit entweder word2vec oder glove\n",
        "Word2vec-Daten sind hier: http://vectors.nlpl.eu/repository/#\n",
        "Glove -> https://nlp.stanford.edu/projects/glove/ Da mal den Twitter-Vector runtergeladen\n",
        "Wenn Daten in GoogleDrive sind (w√§re auch via url m√∂glich..), muss Drive gemounted werden ( https://buomsoo-kim.github.io/colab/2020/05/09/Colab-mounting-google-drive.md/ ) aber auch hier https://enjoymachinelearning.com/posts/colab-with-google-drive/\n",
        "\n",
        "Die Word2vec vectors: http://vectors.nlpl.eu/repository/# \n",
        "\n",
        "glove-zitat:\n",
        "Citing GloVe\n",
        "\n",
        "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. [pdf] [bib]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zuO7T9ZTG57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af05c694-f019-4b97-986c-211d06b07478"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "os.listdir(\"/content/drive/MyDrive/Colab Notebooks\")\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['germeval_training.txt',\n",
              " 'glove.twitter.27B.50d.txt',\n",
              " 'glove.twitter.27B.200d.txt',\n",
              " 'glove.6B.200d.txt',\n",
              " 'glove.840B.300d.txt',\n",
              " 'tensorboard.gdoc',\n",
              " 'keras.gdoc',\n",
              " 'Vectorization CNN embedded_limited_vocab.ipynb',\n",
              " 'glove.42B.300d.txt',\n",
              " 'Embedding Glove Vergleich.ipynb',\n",
              " 'LSTM.ipynb',\n",
              " 'CNN embedded_limited_vocab.ipynb',\n",
              " 'LSTM_limited_vocab.ipynb',\n",
              " 'CNN embedded.ipynb']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7ToKO-sZLHK"
      },
      "source": [
        "\n",
        "Keras-Doc : https://keras.io/examples/nlp/pretrained_word_embeddings/#load-pretrained-word-embeddings \n",
        "embedding mit initializers.. weights m√ºsste auch funktionieren\n",
        "\n",
        "Diese erstellte Matrix mit Embedding dann in die Embedding-Schicht einbinden,  Trainable auf False, weil sich die Werte nicht durch Training anpassen sollen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AShIVfC7ZQAH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8cf1ae5-8a29-4c83-ea6b-c10f0e810c55"
      },
      "source": [
        "#Gr√∂√üe Vokabel -> wordindex + 2 (weil padding + OOV) \n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "vocabulary_size = len(word_index)+2\n",
        "\n",
        "# dann erstell ich ein W√∂rterbuch mit Namen \"embedding_vector\", dort sind dann\n",
        "#die keys drinnen, die in glove-Datei drinnen sind mit dem entsprechenden Key\n",
        "\n",
        "embedding_index_glove = {}\n",
        "f = open('/content/drive/MyDrive/Colab Notebooks/glove.twitter.27B.200d.txt')\n",
        "for line in f:\n",
        "  value = line.split()\n",
        "  word = value[0]\n",
        "  coef = np.asarray(value[1:],dtype='float32')\n",
        "  embedding_index_glove[word] = coef\n",
        "\n",
        "print(\"%d gefunden: \"% len(embedding_index_glove))\n",
        "\n",
        "#Dann noch eine Embedding-Matrix erstellen\n",
        "#zweiter Wert = Embedding-Dimension der Datei, in dem Fall 200\n",
        "\n",
        "glove_matrix = np.zeros((vocabulary_size,200))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    embedding_value = embedding_index_glove.get(word)\n",
        "    if embedding_value is not None:\n",
        "      glove_matrix[index] = embedding_value\n",
        "      hits+=1\n",
        "    else:\n",
        "      misses+=1\n",
        "\n",
        "print(\"hits %d and %d misses\"%(hits,misses))\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1193514 gefunden: \n",
            "hits 6747 and 8312 misses\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZmvOfwhV4N5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a39b86d1-6a1f-4dab-e400-420d92eb06ba"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "print(\"vocab size: %d\"%vocabulary_size)\n",
        "CNN16052104 = tf.keras.Sequential()\n",
        "#Embedding -> hier dann auf das embedding verweisen, Input_dim -> die Anzahl der W√∂rter im word_index, output -> in dem Fall passend zum verwendeten Vektor\n",
        "#input-length -> auf 60  gepadded, trainable -> nein, weil nichts ver√§ndert werden soll\n",
        "#embeddings_initializer=keras.initializers.Constant(glove_matrix) vs weights = [glove_matrix]\n",
        "#Convolutional layers => filters = neurons.. mit 100? 265?\n",
        "CNN16052104.add(tf.keras.layers.Embedding(vocabulary_size, output_dim=200, input_length=60, embeddings_initializer = keras.initializers.Constant(glove_matrix), trainable= False))\n",
        "CNN16052104.add(tf.keras.layers.Dropout(0.4))\n",
        "CNN16052104.add(tf.keras.layers.Conv1D(filters=120, kernel_size=3, padding=\"valid\", activation=\"relu\"))\n",
        "CNN16052104.add(tf.keras.layers.MaxPooling1D())\n",
        "CNN16052104.add(tf.keras.layers.Conv1D(filters=120, kernel_size=3, padding=\"valid\", activation=\"relu\"))\n",
        "CNN16052104.add(tf.keras.layers.GlobalAveragePooling1D())\n",
        "CNN16052104.add(tf.keras.layers.Flatten())\n",
        "CNN16052104.add(tf.keras.layers.Dense(260, activation=\"relu\"))\n",
        "CNN16052104.add(tf.keras.layers.Dropout(0.4))\n",
        "CNN16052104.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "CNN16052104.summary()\n",
        "\n",
        "#nppadded_training = np.asmatrix(nppadded_training) not necessary\n",
        "#nppadded_testing = np.asmatrix(nppadded_testing)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab size: 15061\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 60, 200)           3012200   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 60, 200)           0         \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 58, 120)           72120     \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 29, 120)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 27, 120)           43320     \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 120)               0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 120)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 260)               31460     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 260)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 261       \n",
            "=================================================================\n",
            "Total params: 3,159,361\n",
            "Trainable params: 147,161\n",
            "Non-trainable params: 3,012,200\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEr4OzT-iHDe"
      },
      "source": [
        "#model.layers[2].get_weights()[0].shape\n",
        "#weights=np.random.rand(5,200,100)\n",
        "#bias=np.random.rand(100)\n",
        "#model.layers[2].set_weights([weights, bias])\n",
        "\n",
        "#model.layers[2].get_weights()[0]\n",
        "#https://androidkt.com/set-custom-weights-keras-using-numpy-array/"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UB7_3VPYesr9"
      },
      "source": [
        "F1-Score f√ºr jede Epoche https://aakashgoel12.medium.com/how-to-add-user-defined-function-get-f1-score-in-keras-metrics-3013f979ce0d\n",
        "\n",
        "Sehr gute Ressource f√ºr die verschiedenen Scores und Metriken https://neptune.ai/blog/evaluation-metrics-binary-classification#10  das und aakas verwendet\n",
        "\n",
        "hier: je eine Funktion f√ºr Recall, Precision, f1 https://neptune.ai/blog/keras-metrics \n",
        "\n",
        "https://keras.rstudio.com/reference/k_ones_like.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygyrbFJaMV9B"
      },
      "source": [
        "import keras.backend as K\n",
        "\n",
        "def metrics_recall(data_true, data_pred):\n",
        "    data_true = K.ones_like(data_true)\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(data_true,0,1)))\n",
        "\n",
        "    recall = true_positives / (possible_positives+K.epsilon())\n",
        "    return recall\n",
        "\n",
        "\n",
        "def metrics_precision(data_true, data_pred):\n",
        "    data_true = K.ones_like(data_true)\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "\n",
        "    positives_predicted = K.sum(K.round(K.clip(data_pred,0,1)))\n",
        "    precision = true_positives / (positives_predicted+K.epsilon())\n",
        "    return precision\n",
        "\n",
        "\n",
        "def metrics_f1(data_true, data_pred):\n",
        "    precision_data = metrics_precision(data_true, data_pred)\n",
        "    recall_data = metrics_recall(data_true, data_pred)\n",
        "    return 2*(precision_data*recall_data)/(precision_data+recall_data+K.epsilon())"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AfPD3_bWCm0"
      },
      "source": [
        "CNN16052104.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',metrics_recall,metrics_precision,metrics_f1])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpChKUY-QEWI"
      },
      "source": [
        "https://www.tensorflow.org/tensorboard/tensorboard_in_notebooks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJfMgUhHBoD1"
      },
      "source": [
        "#%reload_ext tensorboard\n",
        "#nur einmal pro Sitzung notwendig\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ISmMXLqP8Hc"
      },
      "source": [
        "\n",
        "logs_base_dir = \"./logs\"\n",
        "callbackForTB = tf.keras.callbacks.TensorBoard(logs_base_dir)\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2CHbXiP1LsF"
      },
      "source": [
        "training_epochs = 30\n",
        "batch_size = 40\n",
        "validation_split=0.2"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abV-QAxfW48r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5831c80b-ee7b-4627-b085-794f4a15820b"
      },
      "source": [
        "#Werte der Convolutional-Schichten variieren (Filter), Batch-Size variieren, kernel-size..\n",
        "CNN16052104.fit(nppadded_training, nptraining_labels, batch_size=batch_size, validation_split=validation_split, epochs=training_epochs, callbacks=[callbackForTB])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "91/91 [==============================] - 5s 44ms/step - loss: 0.6580 - accuracy: 0.6480 - metrics_recall: 0.0250 - metrics_precision: 0.0584 - metrics_f1: 0.0346 - val_loss: 0.6269 - val_accuracy: 0.6718 - val_metrics_recall: 0.0000e+00 - val_metrics_precision: 0.0000e+00 - val_metrics_f1: 0.0000e+00\n",
            "Epoch 2/30\n",
            "91/91 [==============================] - 3s 37ms/step - loss: 0.6420 - accuracy: 0.6527 - metrics_recall: 0.0148 - metrics_precision: 0.1253 - metrics_f1: 0.0245 - val_loss: 0.6178 - val_accuracy: 0.6718 - val_metrics_recall: 0.0000e+00 - val_metrics_precision: 0.0000e+00 - val_metrics_f1: 0.0000e+00\n",
            "Epoch 3/30\n",
            "91/91 [==============================] - 3s 37ms/step - loss: 0.6146 - accuracy: 0.6635 - metrics_recall: 0.0294 - metrics_precision: 0.4412 - metrics_f1: 0.0527 - val_loss: 0.6015 - val_accuracy: 0.7029 - val_metrics_recall: 0.1814 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.3011\n",
            "Epoch 4/30\n",
            "91/91 [==============================] - 3s 38ms/step - loss: 0.5766 - accuracy: 0.6892 - metrics_recall: 0.1059 - metrics_precision: 0.8610 - metrics_f1: 0.1771 - val_loss: 0.5595 - val_accuracy: 0.7162 - val_metrics_recall: 0.1401 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.2410\n",
            "Epoch 5/30\n",
            "91/91 [==============================] - 3s 38ms/step - loss: 0.5547 - accuracy: 0.7141 - metrics_recall: 0.1981 - metrics_precision: 0.9740 - metrics_f1: 0.3098 - val_loss: 0.5509 - val_accuracy: 0.7273 - val_metrics_recall: 0.2519 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.3966\n",
            "Epoch 6/30\n",
            "91/91 [==============================] - 4s 39ms/step - loss: 0.5206 - accuracy: 0.7323 - metrics_recall: 0.2173 - metrics_precision: 1.0000 - metrics_f1: 0.3399 - val_loss: 0.5439 - val_accuracy: 0.7339 - val_metrics_recall: 0.1575 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.2646\n",
            "Epoch 7/30\n",
            "91/91 [==============================] - 4s 39ms/step - loss: 0.5001 - accuracy: 0.7456 - metrics_recall: 0.2018 - metrics_precision: 0.9998 - metrics_f1: 0.3239 - val_loss: 0.5403 - val_accuracy: 0.7129 - val_metrics_recall: 0.2678 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.4175\n",
            "Epoch 8/30\n",
            "91/91 [==============================] - 3s 38ms/step - loss: 0.4619 - accuracy: 0.7769 - metrics_recall: 0.2723 - metrics_precision: 0.9841 - metrics_f1: 0.4148 - val_loss: 0.5606 - val_accuracy: 0.6907 - val_metrics_recall: 0.4052 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.5720\n",
            "Epoch 9/30\n",
            "91/91 [==============================] - 4s 39ms/step - loss: 0.4352 - accuracy: 0.7940 - metrics_recall: 0.2971 - metrics_precision: 1.0000 - metrics_f1: 0.4500 - val_loss: 0.5395 - val_accuracy: 0.7206 - val_metrics_recall: 0.2837 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.4371\n",
            "Epoch 10/30\n",
            "91/91 [==============================] - 3s 38ms/step - loss: 0.4073 - accuracy: 0.8054 - metrics_recall: 0.2942 - metrics_precision: 1.0000 - metrics_f1: 0.4462 - val_loss: 0.5531 - val_accuracy: 0.7051 - val_metrics_recall: 0.3389 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.5003\n",
            "Epoch 11/30\n",
            "91/91 [==============================] - 4s 39ms/step - loss: 0.3815 - accuracy: 0.8221 - metrics_recall: 0.2874 - metrics_precision: 0.9998 - metrics_f1: 0.4383 - val_loss: 0.5679 - val_accuracy: 0.7328 - val_metrics_recall: 0.1865 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.3050\n",
            "Epoch 12/30\n",
            "91/91 [==============================] - 4s 39ms/step - loss: 0.3807 - accuracy: 0.8264 - metrics_recall: 0.3050 - metrics_precision: 1.0000 - metrics_f1: 0.4569 - val_loss: 0.5748 - val_accuracy: 0.6951 - val_metrics_recall: 0.3661 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.5309\n",
            "Epoch 13/30\n",
            "91/91 [==============================] - 4s 40ms/step - loss: 0.3382 - accuracy: 0.8459 - metrics_recall: 0.3174 - metrics_precision: 1.0000 - metrics_f1: 0.4757 - val_loss: 0.5768 - val_accuracy: 0.7073 - val_metrics_recall: 0.3446 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.5070\n",
            "Epoch 14/30\n",
            "91/91 [==============================] - 4s 39ms/step - loss: 0.2997 - accuracy: 0.8610 - metrics_recall: 0.3156 - metrics_precision: 1.0000 - metrics_f1: 0.4728 - val_loss: 0.6016 - val_accuracy: 0.7118 - val_metrics_recall: 0.2676 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.4153\n",
            "Epoch 15/30\n",
            "91/91 [==============================] - 4s 39ms/step - loss: 0.2702 - accuracy: 0.8926 - metrics_recall: 0.2995 - metrics_precision: 1.0000 - metrics_f1: 0.4515 - val_loss: 0.6276 - val_accuracy: 0.7007 - val_metrics_recall: 0.4172 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.5854\n",
            "Epoch 16/30\n",
            "91/91 [==============================] - 4s 39ms/step - loss: 0.2463 - accuracy: 0.8928 - metrics_recall: 0.3356 - metrics_precision: 1.0000 - metrics_f1: 0.4943 - val_loss: 0.6194 - val_accuracy: 0.6984 - val_metrics_recall: 0.3576 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.5225\n",
            "Epoch 17/30\n",
            "91/91 [==============================] - 4s 40ms/step - loss: 0.2465 - accuracy: 0.9020 - metrics_recall: 0.3377 - metrics_precision: 1.0000 - metrics_f1: 0.4994 - val_loss: 0.6580 - val_accuracy: 0.6807 - val_metrics_recall: 0.3741 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.5397\n",
            "Epoch 18/30\n",
            "91/91 [==============================] - 4s 40ms/step - loss: 0.2119 - accuracy: 0.9100 - metrics_recall: 0.3415 - metrics_precision: 1.0000 - metrics_f1: 0.5052 - val_loss: 0.6574 - val_accuracy: 0.6996 - val_metrics_recall: 0.3404 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.5041\n",
            "Epoch 19/30\n",
            "91/91 [==============================] - 4s 40ms/step - loss: 0.2132 - accuracy: 0.9139 - metrics_recall: 0.3070 - metrics_precision: 1.0000 - metrics_f1: 0.4638 - val_loss: 0.6942 - val_accuracy: 0.7118 - val_metrics_recall: 0.2806 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.4301\n",
            "Epoch 20/30\n",
            "91/91 [==============================] - 4s 40ms/step - loss: 0.2213 - accuracy: 0.9073 - metrics_recall: 0.3223 - metrics_precision: 1.0000 - metrics_f1: 0.4818 - val_loss: 0.7475 - val_accuracy: 0.6685 - val_metrics_recall: 0.4796 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.6445\n",
            "Epoch 21/30\n",
            "91/91 [==============================] - 4s 39ms/step - loss: 0.2297 - accuracy: 0.9079 - metrics_recall: 0.3347 - metrics_precision: 1.0000 - metrics_f1: 0.4939 - val_loss: 0.8134 - val_accuracy: 0.6563 - val_metrics_recall: 0.4990 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.6612\n",
            "Epoch 22/30\n",
            "91/91 [==============================] - 3s 38ms/step - loss: 0.2179 - accuracy: 0.9083 - metrics_recall: 0.3211 - metrics_precision: 1.0000 - metrics_f1: 0.4800 - val_loss: 0.6764 - val_accuracy: 0.7140 - val_metrics_recall: 0.2663 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.4114\n",
            "Epoch 23/30\n",
            "91/91 [==============================] - 4s 39ms/step - loss: 0.1638 - accuracy: 0.9360 - metrics_recall: 0.3427 - metrics_precision: 1.0000 - metrics_f1: 0.5054 - val_loss: 0.7424 - val_accuracy: 0.6796 - val_metrics_recall: 0.3013 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.4570\n",
            "Epoch 24/30\n",
            "91/91 [==============================] - 4s 39ms/step - loss: 0.1342 - accuracy: 0.9472 - metrics_recall: 0.3326 - metrics_precision: 1.0000 - metrics_f1: 0.4937 - val_loss: 0.7641 - val_accuracy: 0.7018 - val_metrics_recall: 0.2330 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.3717\n",
            "Epoch 25/30\n",
            "91/91 [==============================] - 4s 39ms/step - loss: 0.1670 - accuracy: 0.9314 - metrics_recall: 0.3291 - metrics_precision: 1.0000 - metrics_f1: 0.4920 - val_loss: 0.8213 - val_accuracy: 0.6896 - val_metrics_recall: 0.4125 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.5785\n",
            "Epoch 26/30\n",
            "91/91 [==============================] - 4s 40ms/step - loss: 0.1442 - accuracy: 0.9494 - metrics_recall: 0.3348 - metrics_precision: 1.0000 - metrics_f1: 0.4983 - val_loss: 0.7399 - val_accuracy: 0.6885 - val_metrics_recall: 0.3122 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.4685\n",
            "Epoch 27/30\n",
            "91/91 [==============================] - 3s 38ms/step - loss: 0.1599 - accuracy: 0.9373 - metrics_recall: 0.3304 - metrics_precision: 1.0000 - metrics_f1: 0.4898 - val_loss: 0.7453 - val_accuracy: 0.6807 - val_metrics_recall: 0.3719 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.5377\n",
            "Epoch 28/30\n",
            "91/91 [==============================] - 3s 38ms/step - loss: 0.1212 - accuracy: 0.9525 - metrics_recall: 0.3392 - metrics_precision: 1.0000 - metrics_f1: 0.5014 - val_loss: 0.7870 - val_accuracy: 0.6885 - val_metrics_recall: 0.3091 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.4666\n",
            "Epoch 29/30\n",
            "91/91 [==============================] - 4s 40ms/step - loss: 0.1202 - accuracy: 0.9549 - metrics_recall: 0.3487 - metrics_precision: 1.0000 - metrics_f1: 0.5119 - val_loss: 0.8058 - val_accuracy: 0.7029 - val_metrics_recall: 0.3811 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.5455\n",
            "Epoch 30/30\n",
            "91/91 [==============================] - 4s 40ms/step - loss: 0.1439 - accuracy: 0.9437 - metrics_recall: 0.3332 - metrics_precision: 0.9998 - metrics_f1: 0.4937 - val_loss: 0.8348 - val_accuracy: 0.6896 - val_metrics_recall: 0.4050 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.5705\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f10c8ace290>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJVL4SBLPB2P"
      },
      "source": [
        "#%tensorboard --logdir {logs_base_dir}"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_LnvWBcnoak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1a74b35-3b86-479d-8d12-37e85887630a"
      },
      "source": [
        "#results = model.evaluate(nppadded_testing, nptesting_labels, batch_size=batch_size)\n",
        "#print(\"test loss, test acc:\",results)\n",
        "\n",
        "(loss,accuracy, metrics_recall, metrics_precision,\n",
        "metrics_f1) = CNN16052104.evaluate(nppadded_testing, nptesting_labels, verbose=1)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "111/111 [==============================] - 1s 10ms/step - loss: 0.8782 - accuracy: 0.6560 - metrics_recall: 0.3792 - metrics_precision: 1.0000 - metrics_f1: 0.5446\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KgjIkhpKmHc"
      },
      "source": [
        "make some predictions of test data and save it to variable. verbose=0 -> do not generate output\n",
        "Gute Quelle: https://deeplizard.com/learn/video/2f-NjDUvZIE "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89GWuxryKlcM"
      },
      "source": [
        "CNN_predictions04 = CNN16052104.predict(x=nppadded_testing)\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3jPDaDJK_cN"
      },
      "source": [
        "#for p in CNN_predictions04:\n",
        " # print(p)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eC9efJy4Lp21"
      },
      "source": [
        "rounded predictions: give prediction value of most likely prediction (0 or 1). Printing the output of rounded prediction shows the prediction made by the model on the data (which output is most likely)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsG-TJuQLvtk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04f7f389-38ab-44ab-b577-6973e3b82ce8"
      },
      "source": [
        "prediction_rounded04 = np.round(CNN_predictions04)\n",
        "#np.argmax(CNN_predictions04,axis=-1)\n",
        "\n",
        "#for p in prediction_rounded04:\n",
        " # print(p)\n",
        "\n",
        "\n",
        "print(nptesting_labels[500:520])\n",
        "print(prediction_rounded04[500:520])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1]\n",
            "[[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egTtgpXgg8a2"
      },
      "source": [
        "https://deeplizard.com/learn/video/km7pxKy4UHU\n",
        "\n",
        "Quelle der def plot_confusion_matrix: https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSDXf7-_MITy"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0AMs1EzhBU1"
      },
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                        normalize=False,\n",
        "                        title='Confusion matrix',\n",
        "                        cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2JgEnlghCtl"
      },
      "source": [
        "cm = confusion_matrix(y_true=nptesting_labels, y_pred=prediction_rounded04)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckmF29whhFmX"
      },
      "source": [
        "plot_labels = ['no hatespeech','hatespeech']"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "2mpSE96rhK7K",
        "outputId": "8d87b71d-780d-40dc-9b7e-da1792c30b1a"
      },
      "source": [
        "plot_confusion_matrix(cm=cm, classes=plot_labels, title='CNN Confusion 120')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix, without normalization\n",
            "[[1655  675]\n",
            " [ 540  662]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}