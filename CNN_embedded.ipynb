{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN embedded.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPpPfSmm1XDAro1CF0Wm7Fa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BiancaStadl/ProjektarbeitML/blob/main/CNN_embedded.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXDOlIBymF0V"
      },
      "source": [
        "GloVe embeddings taken from:\n",
        "\n",
        "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. [pdf] [bib]\n",
        "\n",
        "hatespeechdata taken from (https://hatespeechdata.com/): Wiegand, M., Siegel, M. and Ruppenhofer, J., 2018. Overview of the GermEval 2018 Shared Task on the Identification of Offensive Language. In: Proceedings of GermEval 2018, 14th Conference on Natural Language Processing (KONVENS 2018). Vienna, Austria: Research Gate. available on: https://github.com/uds-lsv/GermEval-2018-Data (last checked: 09.05.2021)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlBmABDxfqII"
      },
      "source": [
        "wiki detox..https://colab.research.google.com/github/tensorflow/fairness-indicators/blob/master/g3doc/tutorials/Fairness_Indicators_TFCO_Wiki_Case_Study.ipynb#scrollTo=y6T5tlXcdW7J "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3xfitNdliBI"
      },
      "source": [
        "#import matplotlib.pyplot as plt -> für evtl Visualisierungen\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import string\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from keras import losses \n",
        "from keras import optimizers \n",
        "from keras import metrics \n",
        "\n",
        "#!pip install Tokenizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "#!pip install pad_sequences\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import preprocessing\n",
        "#from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTWJQ1iga_vS"
      },
      "source": [
        "Maximale Satzlänge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bq08Me5la_Cc"
      },
      "source": [
        "\n",
        "max_length = 60"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVYBMvYSotTH"
      },
      "source": [
        "url = \"https://github.com/uds-lsv/GermEval-2018-Data/archive/master.zip\"\n",
        "\n",
        "dataset = tf.keras.utils.get_file(\"GermEval-2018-Data-master.zip\", url, \n",
        "                                   extract=True, cache_dir='.',\n",
        "                                    cache_subdir='')\n",
        "\n",
        "dataset_dir = os.path.join(os.path.dirname(dataset), 'GermEval-2018-Data-master')\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cS14OUtfo34V"
      },
      "source": [
        "#os.listdir(dataset_dir)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2X429K6hpOVm"
      },
      "source": [
        "training_file = os.path.join(dataset_dir, 'germeval2018.training.txt')\n",
        "\n",
        "testing_file = os.path.join(dataset_dir, 'germeval2018.test.txt')\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uq8fG3LNtn_m"
      },
      "source": [
        "###Aufbereitung\n",
        "txt-Dateien lesen, und dabei jede Zeile splitten und teilen\n",
        "Twitter-Handler entfernen?\n",
        "Labels von Sätzen trennen, Labels in eigenen Array packen.\n",
        "\n",
        "####Ressourcen\n",
        "* https://www.w3schools.com/python/gloss_python_if_statement.asp\n",
        "* https://stackabuse.com/using-regex-for-text-manipulation-in-python/\n",
        "* https://www.tutorialspoint.com/python/string_splitlines.htm \n",
        "* https://note.nkmk.me/en/python-split-rsplit-splitlines-re/ \n",
        "* https://www.w3schools.com/python/python_regex.asp \n",
        "\n",
        "gäbe bei keras tf.keras.preprocessing.text_dataset_from_directory, aber dafür müssten die Daten auf bestimmte Weise in Verzeichnis organisiert sein, hier nicht der Fall.\n",
        "\n",
        "\n",
        "Einteilung der Daten: Testdaten\n",
        "Trainingsdaten -> noch ca 500 für Validierungsdaten\n",
        "\n",
        "labels -> \"other\", also nicht-negative Aussagen bekommen \"0\", negative Aussagen bekommen \"1\"\n",
        "\n",
        " Regex für Emojis  ->\n",
        "\n",
        "(\\u00a9|\\u00ae|[\\u2000-\\u3300]|\\ud83c[\\ud000-\\udfff]|\\ud83d[\\ud000-\\udfff]|\\ud83e[\\ud000-\\udfff])\n",
        "\n",
        "genommen von https://www.regextester.com/106421 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Py_cwD4eZkXo"
      },
      "source": [
        "def remove_clutter(string):\n",
        "   string = re.sub(\"@[^\\s]+\",\" \",string)\n",
        "   string = re.sub(\"#[^\\s]+\",\" \", string)\n",
        "   string = re.sub(\"\\u00a9\",\" \", string)\n",
        "   string = re.sub(\"\\u00ae\",\" \", string)\n",
        "   string = re.sub(\"[\\u2000-\\u3300]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83c[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83d[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83e[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"😜\", \" \",string)\n",
        "   string = re.sub(\"🍫\", \" \",string)\n",
        "   string = re.sub(\"😁\", \" \",string)\n",
        "   string = re.sub(\"🐖\", \" \",string)\n",
        "   string = re.sub(\"😡\", \" \",string)\n",
        "   string = re.sub(\"😇\", \" \",string)\n",
        "   string = re.sub(\"😬\", \" \",string)\n",
        "   string = re.sub(\"😃\", \" \",string)\n",
        "   string = re.sub(\"😂\", \" \",string)\n",
        "   string = re.sub(\"💙\", \" \",string)  \n",
        "   string = re.sub(\"😛\", \" \",string)\n",
        "   string = re.sub(\"🙏\", \" \",string)\n",
        "   string = re.sub(\"👍\", \" \",string)\n",
        "   string = re.sub(\"🖕\", \" \",string)\n",
        "   string = re.sub(\"😉\", \" \",string)\n",
        "   string = re.sub(\"💩\", \" \",string)\n",
        "   string = re.sub(\"🤢\", \" \",string)\n",
        "   string = re.sub(\"👏\", \" \",string)\n",
        "   string = re.sub(\"😨\", \" \",string)\n",
        "   string = re.sub(\"🤣\", \" \",string)\n",
        "   string = re.sub(\"🤡\", \" \",string)\n",
        "   string = re.sub(\"😈\", \" \",string)\n",
        "   string = re.sub(\"💃🏽\", \" \",string)\n",
        "   string = re.sub(\"👹\", \" \",string)\n",
        "   string = re.sub(\"🤘\", \" \",string)\n",
        "   string = re.sub(\"😱\", \" \",string)\n",
        "   string = re.sub(\"🤔\", \" \",string) \n",
        "   string = re.sub(\"🌈\", \" \",string) \n",
        "   string = re.sub(\"💕\", \" \",string) \n",
        "   string = re.sub(\"👩‍❤️‍👩\", \" \",string) \n",
        "   string = re.sub(\"😍\", \" \",string) \n",
        "   string = re.sub(\"👆\", \" \",string) \n",
        "   string = re.sub(\"😖\", \" \",string) \n",
        "   string = re.sub(\"👇\", \" \",string) \n",
        "   string = re.sub(\"🔥\", \" \",string) \n",
        "   string = re.sub(\"😘\", \" \",string) \n",
        "   string = re.sub(\"🎉\", \" \",string) \n",
        "   string = re.sub(\"🤬\", \" \",string) \n",
        "   string = re.sub(\"👊\", \" \",string)\n",
        "   string = re.sub(\"🇩🇪\", \" \",string)  \n",
        "   string = re.sub(\"💔\", \" \",string)\n",
        "   string = re.sub(\"🙈\", \" \",string)\n",
        "   string = re.sub(\"🤯\", \" \",string)\n",
        "   string = re.sub(\"🐟\", \" \",string)\n",
        "   string = re.sub(\"🛶\", \" \",string)\n",
        "   string = re.sub(\"😊\", \" \",string)\n",
        "   string = re.sub(\"😓\", \" \",string)\n",
        "   string = re.sub(\"😳\", \" \",string)\n",
        "   string = re.sub(\"🚀\", \" \",string)\n",
        "   string = re.sub(\"👎\", \" \",string)\n",
        "   string = re.sub(\"😎\", \" \",string)\n",
        "   string = re.sub(\"🐸\", \" \",string)\n",
        "   string = re.sub(\"📈\", \" \",string)\n",
        "   string = re.sub(\"🙂\", \" \",string)\n",
        "   string = re.sub(\"😅\", \" \",string)\n",
        "   string = re.sub(\"😆\", \" \",string)\n",
        "   string = re.sub(\"🙎🏿\", \" \",string)\n",
        "   string = re.sub(\"👎🏽\", \" \",string)\n",
        "   string = re.sub(\"🤭\", \" \",string)\n",
        "   string = re.sub(\"😤\", \" \",string)\n",
        "   string = re.sub(\"😚\", \" \",string)\n",
        "   string = re.sub(\"😊\", \" \",string)\n",
        "   string = re.sub(\"😲\", \" \",string)\n",
        "   string = re.sub(\"🤮\", \" \",string)\n",
        "   string = re.sub(\"🙄\", \" \",string)\n",
        "   string = re.sub(\"🤑\", \" \",string)\n",
        "   string = re.sub(\"🎅\", \" \",string)\n",
        "   string = re.sub(\"👋\", \" \",string)\n",
        "   string = re.sub(\"💪\", \" \",string)\n",
        "   string = re.sub(\"😄\", \" \",string)\n",
        "   string = re.sub(\"🧐\", \" \",string)\n",
        "   string = re.sub(\"😠\", \" \",string)\n",
        "   string = re.sub(\"🎈\", \" \",string)\n",
        "   string = re.sub(\"🚂\", \" \",string)\n",
        "   string = re.sub(\"😊\", \" \",string)\n",
        "   string = re.sub(\"🚇\", \" \",string)\n",
        "   string = re.sub(\"🚊\", \" \",string)\n",
        "   string = re.sub(\"🤷\", \" \",string)\n",
        "   string = re.sub(\"😥\", \" \",string)\n",
        "   string = re.sub(\"🙃\", \" \",string)\n",
        "   string = re.sub(\"🔩\", \" \",string)\n",
        "   string = re.sub(\"🔧\", \" \",string)\n",
        "   string = re.sub(\"🔨\", \" \",string)\n",
        "   string = re.sub(\"🛠\", \" \",string)\n",
        "   string = re.sub(\"💓\", \" \",string)\n",
        "   string = re.sub(\"💡\", \" \",string)\n",
        "   string = re.sub(\"🍸\", \" \",string)\n",
        "   string = re.sub(\"🥃\", \" \",string)\n",
        "   string = re.sub(\"🥂\", \" \",string)\n",
        "   string = re.sub(\"😷\", \" \",string)\n",
        "   string = re.sub(\"🤐\", \" \",string)\n",
        "   string = re.sub(\"🌎\", \" \",string)\n",
        "   string = re.sub(\"👑\", \" \",string)\n",
        "   string = re.sub(\"🤛\", \" \",string)\n",
        "   string = re.sub(\"😀\", \" \",string)\n",
        "   string = re.sub(\"🛤\", \" \",string)\n",
        "   string = re.sub(\"🎄\", \" \",string)\n",
        "   string = re.sub(\"📴\", \" \",string)\n",
        "   string = re.sub(\"🌭\", \" \",string)\n",
        "   string = re.sub(\"🤕\", \" \",string)\n",
        "   string = re.sub(\"😭\", \" \",string)\n",
        "   string = re.sub(\"🍾\", \" \",string)\n",
        "   string = re.sub(\"🍞\", \" \",string)\n",
        "   string = re.sub(\"🤦\", \" \",string)\n",
        "   string = re.sub(\"🤯\", \" \",string)\n",
        "   string = re.sub(\"🕯️\", \" \",string)\n",
        "\n",
        "   string = re.sub(\"OTHER|OFFENSE|ABUSE|INSULT\",\" \",string)\n",
        "   return string"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5asMgo4LtnRg"
      },
      "source": [
        "statementsForTraining = []\n",
        "sentimentsForTraining = []\n",
        "\n",
        "\n",
        "fileToRead = open(training_file, 'r')\n",
        "\n",
        "while True:\n",
        "  #next line in file\n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  findSentiment = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "\n",
        "\n",
        "  statementsForTraining.append(line)\n",
        "   #sentimentsForTraining.append(findSentiment.group(0))\n",
        "\n",
        "  if findSentiment.group(0) == \"OTHER\":  \n",
        "    sentimentsForTraining.append(0)\n",
        "  else:\n",
        "    sentimentsForTraining.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        " #print(\"{}: {}\".format(count,line.strip()))\n",
        "  \n",
        " # print(sentiment.group(0))\n",
        " \n",
        "fileToRead.close()\n",
        "\n",
        "training_sentences = statementsForTraining\n",
        "training_labels = sentimentsForTraining\n",
        "\n",
        "#print(training_sentences[9])\n",
        "#print(training_labels[9])\n",
        "\n",
        "#print(len(training_sentences))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsqZPENb98gD"
      },
      "source": [
        "##do the same with testdata\n",
        "statementsForTesting = []\n",
        "sentimentsForTesting = []\n",
        "\n",
        "fileToRead = open(testing_file, 'r')\n",
        "\n",
        "while True:\n",
        "  #next line in file\n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  sent = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "\n",
        "    \n",
        "\n",
        "  statementsForTesting.append(line)\n",
        "  #print(len(line))\n",
        "  #sentimentsForTesting.append(sent.group(0))\n",
        "\n",
        "  if sent.group(0) == \"OTHER\": \n",
        "    sentimentsForTesting.append(0)\n",
        "  else:\n",
        "    sentimentsForTesting.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        "\n",
        "fileToRead.close()\n",
        "\n",
        "\n",
        "testing_sentences = statementsForTesting\n",
        "testing_labels = sentimentsForTesting\n",
        "#print(len(testing_sentences))\n",
        "#print(testing_sentences)   \n",
        "#print(testing_labels)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRUvDLD5bMbO"
      },
      "source": [
        "Padding -> im Prinzip die Sätze alle auf die gleiche Länge bringen (in Theorieteil näher drauf eingehen) -> maxlen-Paramter ist für pad_sequences vorhanden, wenn nicht gesetzt -> alles wird auf die Länge des längsten Satzes aufgefüllt -> print(padded(shape)) gibt aus, wie viele Datensätze padded wurden und gibt an, wie viele Tokens der längste Datensatz hat\n",
        "print(padded[x]) gibt einen Satz aus (bereits tokenisiert)\n",
        "\n",
        "Padding -> sowohl für Trainigs- als auch für Testdaten\n",
        "\n",
        "Und: Daten als numpy-Arrays speichern (notwendig für tensorflow).\n",
        "\n",
        " -> Tokenizer https://towardsdatascience.com/text-classification-in-keras-part-2-how-to-use-the-keras-tokenizer-word-representations-fd571674df23 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3hFi7waTv5m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f009a83b-4ab3-4c6c-9249-6e53c8b11464"
      },
      "source": [
        "tokenizer = Tokenizer(oov_token=\"OOV\")\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "\n",
        "#creating a word index - nur die Trainigsdaten\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "validation_size = 500\n",
        "\n",
        "\n",
        "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "padded_training = pad_sequences(training_sequences, maxlen=max_length, padding='post')\n",
        "print(len(padded_training))\n",
        "\n",
        "validation_sequences = padded_training[0:validation_size]\n",
        "validation_labels = training_labels[0:validation_size]\n",
        "\n",
        "padded_training = padded_training[validation_size:]\n",
        "training_labels = training_labels[validation_size:]\n",
        "\n",
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
        "padded_testing = pad_sequences(testing_sequences, maxlen=max_length,  padding='post')\n",
        "\n",
        "#print(validation_sequences[499])\n",
        "print(padded_training[0])\n",
        "#print(len(validation_labels))\n",
        "#print(len(training_labels))\n",
        "\n",
        "\n",
        "nppadded_training = np.array(padded_training)\n",
        "nptraining_labels = np.array(training_labels)\n",
        "\n",
        "nppadded_validation = np.array(validation_sequences)\n",
        "npvalidation_labels = np.array(validation_labels)\n",
        "\n",
        "nppadded_testing = np.array(padded_testing)\n",
        "nptesting_labels = np.array(testing_labels)\n",
        "\n",
        "\n",
        "print(len(nppadded_training))\n",
        "print(len(nptraining_labels))\n",
        "print(len(word_index))\n",
        "\n",
        "#print(statementsForTraining[2])\n",
        "#print(nppadded_training[4])\n",
        "#print(nppadded_training.shape)\n",
        "#print(nptraining_labels[4])\n",
        "#print(nppadded_testing.shape)\n",
        "#print(word_index) \n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5009\n",
            "[  12 3982   11   41 6706 1040    4    5  202   39    3 2922   49 1360\n",
            "  810  495 3983    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0]\n",
            "4509\n",
            "4509\n",
            "15059\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tL3owrc8THkT"
      },
      "source": [
        "\n",
        "Dann: Embedding mit entweder word2vec oder glove\n",
        "Word2vec-Daten sind hier: http://vectors.nlpl.eu/repository/#\n",
        "Glove -> https://nlp.stanford.edu/projects/glove/ Da mal den Twitter-Vector runtergeladen\n",
        "Wenn Daten in GoogleDrive sind (wäre auch via url möglich..), muss Drive gemounted werden ( https://buomsoo-kim.github.io/colab/2020/05/09/Colab-mounting-google-drive.md/ ) aber auch hier https://enjoymachinelearning.com/posts/colab-with-google-drive/\n",
        "\n",
        "Die Word2vec vectors: http://vectors.nlpl.eu/repository/# \n",
        "\n",
        "glove-zitat:\n",
        "Citing GloVe\n",
        "\n",
        "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. [pdf] [bib]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zuO7T9ZTG57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e393cea3-91e6-4d26-fcd8-3e423ef9b2bf"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "os.listdir(\"/content/drive/MyDrive/Colab Notebooks\")\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['germeval_training.txt',\n",
              " 'glove.twitter.27B.50d.txt',\n",
              " 'glove.twitter.27B.200d.txt',\n",
              " 'glove.6B.200d.txt',\n",
              " 'glove.840B.300d.txt',\n",
              " 'tensorboard.gdoc',\n",
              " 'keras.gdoc',\n",
              " 'Vectorization CNN embedded_limited_vocab.ipynb',\n",
              " 'glove.42B.300d.txt',\n",
              " 'Embedding Glove Vergleich.ipynb',\n",
              " 'LSTM.ipynb',\n",
              " 'CNN embedded_limited_vocab.ipynb',\n",
              " 'LSTM_limited_vocab.ipynb',\n",
              " 'CNN embedded.ipynb']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7ToKO-sZLHK"
      },
      "source": [
        "\n",
        "Keras-Doc : https://keras.io/examples/nlp/pretrained_word_embeddings/#load-pretrained-word-embeddings \n",
        "embedding mit initializers.. weights müsste auch funktionieren\n",
        "\n",
        "Diese erstellte Matrix mit Embedding dann in die Embedding-Schicht einbinden,  Trainable auf False, weil sich die Werte nicht durch Training anpassen sollen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AShIVfC7ZQAH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad658c72-29ed-4ccb-8307-47e46f552d1a"
      },
      "source": [
        "#Größe Vokabel -> wordindex + 2 (weil padding + OOV) \n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "vocabulary_size = len(word_index)+2\n",
        "\n",
        "# dann erstell ich ein Wörterbuch mit Namen \"embedding_vector\", dort sind dann\n",
        "#die keys drinnen, die in glove-Datei drinnen sind mit dem entsprechenden Key\n",
        "\n",
        "embedding_index_glove = {}\n",
        "f = open('/content/drive/MyDrive/Colab Notebooks/glove.twitter.27B.200d.txt')\n",
        "for line in f:\n",
        "  value = line.split()\n",
        "  word = value[0]\n",
        "  coef = np.asarray(value[1:],dtype='float32')\n",
        "  embedding_index_glove[word] = coef\n",
        "\n",
        "print(\"%d gefunden: \"% len(embedding_index_glove))\n",
        "\n",
        "#Dann noch eine Embedding-Matrix erstellen\n",
        "#zweiter Wert = Embedding-Dimension der Datei, in dem Fall 200\n",
        "\n",
        "glove_matrix = np.zeros((vocabulary_size,200))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    embedding_value = embedding_index_glove.get(word)\n",
        "    if embedding_value is not None:\n",
        "      glove_matrix[index] = embedding_value\n",
        "      hits+=1\n",
        "    else:\n",
        "      misses+=1\n",
        "\n",
        "print(\"hits %d and %d misses\"%(hits,misses))\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1193514 gefunden: \n",
            "hits 6747 and 8312 misses\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZmvOfwhV4N5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8481295-1156-44b2-91fc-d1749c4f2eeb"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "print(\"vocab size: %d\"%vocabulary_size)\n",
        "CNN16052107 = tf.keras.Sequential()\n",
        "#Embedding -> hier dann auf das embedding verweisen, Input_dim -> die Anzahl der Wörter im word_index, output -> in dem Fall passend zum verwendeten Vektor\n",
        "#input-length -> auf 60  gepadded, trainable -> nein, weil nichts verändert werden soll\n",
        "#embeddings_initializer=keras.initializers.Constant(glove_matrix) vs weights = [glove_matrix]\n",
        "#Convolutional layers => filters = neurons.. mit 100? 265?\n",
        "CNN16052107.add(tf.keras.layers.Embedding(vocabulary_size, output_dim=200, input_length=60, embeddings_initializer = keras.initializers.Constant(glove_matrix), trainable= False))\n",
        "CNN16052107.add(tf.keras.layers.Dropout(0.4))\n",
        "CNN16052107.add(tf.keras.layers.Conv1D(filters=50, kernel_size=3, padding=\"valid\", activation=\"relu\"))\n",
        "CNN16052107.add(tf.keras.layers.MaxPooling1D())\n",
        "CNN16052107.add(tf.keras.layers.Conv1D(filters=50, kernel_size=3, padding=\"valid\", activation=\"relu\"))\n",
        "CNN16052107.add(tf.keras.layers.GlobalAveragePooling1D())\n",
        "CNN16052107.add(tf.keras.layers.Flatten())\n",
        "CNN16052107.add(tf.keras.layers.Dense(50, activation=\"relu\"))\n",
        "CNN16052107.add(tf.keras.layers.Dropout(0.4))\n",
        "CNN16052107.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "CNN16052107.summary()\n",
        "\n",
        "#nppadded_training = np.asmatrix(nppadded_training) not necessary\n",
        "#nppadded_testing = np.asmatrix(nppadded_testing)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab size: 15061\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 60, 200)           3012200   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 60, 200)           0         \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 58, 50)            30050     \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 29, 50)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 27, 50)            7550      \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 50)                2550      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 3,052,401\n",
            "Trainable params: 40,201\n",
            "Non-trainable params: 3,012,200\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEr4OzT-iHDe"
      },
      "source": [
        "#model.layers[2].get_weights()[0].shape\n",
        "#weights=np.random.rand(5,200,100)\n",
        "#bias=np.random.rand(100)\n",
        "#model.layers[2].set_weights([weights, bias])\n",
        "\n",
        "#model.layers[2].get_weights()[0]\n",
        "#https://androidkt.com/set-custom-weights-keras-using-numpy-array/"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UB7_3VPYesr9"
      },
      "source": [
        "F1-Score für jede Epoche https://aakashgoel12.medium.com/how-to-add-user-defined-function-get-f1-score-in-keras-metrics-3013f979ce0d\n",
        "\n",
        "Sehr gute Ressource für die verschiedenen Scores und Metriken https://neptune.ai/blog/evaluation-metrics-binary-classification#10  das und aakas verwendet\n",
        "\n",
        "hier: je eine Funktion für Recall, Precision, f1 https://neptune.ai/blog/keras-metrics \n",
        "\n",
        "https://keras.rstudio.com/reference/k_ones_like.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygyrbFJaMV9B"
      },
      "source": [
        "import keras.backend as K\n",
        "\n",
        "def metrics_recall(data_true, data_pred):\n",
        "    data_true = K.ones_like(data_true)\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(data_true,0,1)))\n",
        "\n",
        "    recall = true_positives / (possible_positives+K.epsilon())\n",
        "    return recall\n",
        "\n",
        "\n",
        "def metrics_precision(data_true, data_pred):\n",
        "    data_true = K.ones_like(data_true)\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "\n",
        "    positives_predicted = K.sum(K.round(K.clip(data_pred,0,1)))\n",
        "    precision = true_positives / (positives_predicted+K.epsilon())\n",
        "    return precision\n",
        "\n",
        "\n",
        "def metrics_f1(data_true, data_pred):\n",
        "    precision_data = metrics_precision(data_true, data_pred)\n",
        "    recall_data = metrics_recall(data_true, data_pred)\n",
        "    return 2*(precision_data*recall_data)/(precision_data+recall_data+K.epsilon())"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AfPD3_bWCm0"
      },
      "source": [
        "CNN16052107.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',metrics_recall,metrics_precision,metrics_f1])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpChKUY-QEWI"
      },
      "source": [
        "https://www.tensorflow.org/tensorboard/tensorboard_in_notebooks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJfMgUhHBoD1"
      },
      "source": [
        "#%reload_ext tensorboard\n",
        "#nur einmal pro Sitzung notwendig\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ISmMXLqP8Hc"
      },
      "source": [
        "\n",
        "logs_base_dir = \"./logs\"\n",
        "callbackForTB = tf.keras.callbacks.TensorBoard(logs_base_dir)\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2CHbXiP1LsF"
      },
      "source": [
        "training_epochs = 30\n",
        "batch_size = 40\n",
        "validation_split=0.2"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abV-QAxfW48r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "587e94ed-4663-4822-be95-564e5a6f5cff"
      },
      "source": [
        "#Werte der Convolutional-Schichten variieren (Filter), Batch-Size variieren, kernel-size..\n",
        "CNN16052107.fit(nppadded_training, nptraining_labels, batch_size=batch_size, validation_split=validation_split, epochs=training_epochs, callbacks=[callbackForTB])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "91/91 [==============================] - 4s 32ms/step - loss: 0.6727 - accuracy: 0.6058 - metrics_recall: 0.1484 - metrics_precision: 0.3493 - metrics_f1: 0.1710 - val_loss: 0.6418 - val_accuracy: 0.6718 - val_metrics_recall: 0.0000e+00 - val_metrics_precision: 0.0000e+00 - val_metrics_f1: 0.0000e+00\n",
            "Epoch 2/30\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.6335 - accuracy: 0.6752 - metrics_recall: 3.0151e-04 - metrics_precision: 0.0121 - metrics_f1: 5.8831e-04 - val_loss: 0.6306 - val_accuracy: 0.6718 - val_metrics_recall: 0.0000e+00 - val_metrics_precision: 0.0000e+00 - val_metrics_f1: 0.0000e+00\n",
            "Epoch 3/30\n",
            "91/91 [==============================] - 3s 28ms/step - loss: 0.6264 - accuracy: 0.6748 - metrics_recall: 0.0010 - metrics_precision: 0.0237 - metrics_f1: 0.0019 - val_loss: 0.5959 - val_accuracy: 0.6785 - val_metrics_recall: 0.0174 - val_metrics_precision: 0.5217 - val_metrics_f1: 0.0334\n",
            "Epoch 4/30\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.6150 - accuracy: 0.6577 - metrics_recall: 0.0659 - metrics_precision: 0.7502 - metrics_f1: 0.1138 - val_loss: 0.6029 - val_accuracy: 0.6718 - val_metrics_recall: 0.0000e+00 - val_metrics_precision: 0.0000e+00 - val_metrics_f1: 0.0000e+00\n",
            "Epoch 5/30\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.5947 - accuracy: 0.6734 - metrics_recall: 0.0426 - metrics_precision: 0.5281 - metrics_f1: 0.0750 - val_loss: 0.5775 - val_accuracy: 0.7051 - val_metrics_recall: 0.1405 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.2425\n",
            "Epoch 6/30\n",
            "91/91 [==============================] - 3s 30ms/step - loss: 0.5700 - accuracy: 0.6924 - metrics_recall: 0.1512 - metrics_precision: 1.0000 - metrics_f1: 0.2564 - val_loss: 0.5778 - val_accuracy: 0.6951 - val_metrics_recall: 0.0293 - val_metrics_precision: 0.6522 - val_metrics_f1: 0.0557\n",
            "Epoch 7/30\n",
            "91/91 [==============================] - 3s 30ms/step - loss: 0.5630 - accuracy: 0.7005 - metrics_recall: 0.1627 - metrics_precision: 0.9554 - metrics_f1: 0.2696 - val_loss: 0.5800 - val_accuracy: 0.6907 - val_metrics_recall: 0.3630 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.5258\n",
            "Epoch 8/30\n",
            "91/91 [==============================] - 3s 30ms/step - loss: 0.5508 - accuracy: 0.7205 - metrics_recall: 0.2048 - metrics_precision: 1.0000 - metrics_f1: 0.3274 - val_loss: 0.5671 - val_accuracy: 0.7062 - val_metrics_recall: 0.3413 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.5012\n",
            "Epoch 9/30\n",
            "91/91 [==============================] - 3s 30ms/step - loss: 0.5240 - accuracy: 0.7334 - metrics_recall: 0.2016 - metrics_precision: 0.9468 - metrics_f1: 0.3232 - val_loss: 0.5492 - val_accuracy: 0.7118 - val_metrics_recall: 0.2741 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.4230\n",
            "Epoch 10/30\n",
            "91/91 [==============================] - 3s 30ms/step - loss: 0.5162 - accuracy: 0.7532 - metrics_recall: 0.2465 - metrics_precision: 1.0000 - metrics_f1: 0.3844 - val_loss: 0.5438 - val_accuracy: 0.7273 - val_metrics_recall: 0.2223 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.3570\n",
            "Epoch 11/30\n",
            "91/91 [==============================] - 3s 30ms/step - loss: 0.5037 - accuracy: 0.7628 - metrics_recall: 0.2690 - metrics_precision: 1.0000 - metrics_f1: 0.4104 - val_loss: 0.5798 - val_accuracy: 0.6652 - val_metrics_recall: 0.4568 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.6216\n",
            "Epoch 12/30\n",
            "91/91 [==============================] - 3s 30ms/step - loss: 0.4718 - accuracy: 0.7804 - metrics_recall: 0.2999 - metrics_precision: 1.0000 - metrics_f1: 0.4528 - val_loss: 0.5512 - val_accuracy: 0.7084 - val_metrics_recall: 0.3817 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.5490\n",
            "Epoch 13/30\n",
            "91/91 [==============================] - 3s 30ms/step - loss: 0.4647 - accuracy: 0.7864 - metrics_recall: 0.2948 - metrics_precision: 1.0000 - metrics_f1: 0.4462 - val_loss: 0.5372 - val_accuracy: 0.7173 - val_metrics_recall: 0.3022 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.4579\n",
            "Epoch 14/30\n",
            "91/91 [==============================] - 3s 30ms/step - loss: 0.4580 - accuracy: 0.7855 - metrics_recall: 0.2723 - metrics_precision: 1.0000 - metrics_f1: 0.4145 - val_loss: 0.5349 - val_accuracy: 0.7328 - val_metrics_recall: 0.1877 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.3101\n",
            "Epoch 15/30\n",
            "91/91 [==============================] - 3s 30ms/step - loss: 0.4236 - accuracy: 0.8039 - metrics_recall: 0.2752 - metrics_precision: 1.0000 - metrics_f1: 0.4234 - val_loss: 0.5438 - val_accuracy: 0.7228 - val_metrics_recall: 0.3864 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.5522\n",
            "Epoch 16/30\n",
            "91/91 [==============================] - 3s 30ms/step - loss: 0.4313 - accuracy: 0.7959 - metrics_recall: 0.3087 - metrics_precision: 1.0000 - metrics_f1: 0.4555 - val_loss: 0.5454 - val_accuracy: 0.7173 - val_metrics_recall: 0.3004 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.4586\n",
            "Epoch 17/30\n",
            "91/91 [==============================] - 3s 30ms/step - loss: 0.4070 - accuracy: 0.8180 - metrics_recall: 0.2986 - metrics_precision: 0.9998 - metrics_f1: 0.4478 - val_loss: 0.5572 - val_accuracy: 0.7118 - val_metrics_recall: 0.3489 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.5138\n",
            "Epoch 18/30\n",
            "91/91 [==============================] - 3s 30ms/step - loss: 0.3774 - accuracy: 0.8304 - metrics_recall: 0.3128 - metrics_precision: 1.0000 - metrics_f1: 0.4692 - val_loss: 0.5455 - val_accuracy: 0.7251 - val_metrics_recall: 0.2615 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.4105\n",
            "Epoch 19/30\n",
            "91/91 [==============================] - 3s 30ms/step - loss: 0.3793 - accuracy: 0.8259 - metrics_recall: 0.3006 - metrics_precision: 1.0000 - metrics_f1: 0.4513 - val_loss: 0.5641 - val_accuracy: 0.7151 - val_metrics_recall: 0.2386 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.3793\n",
            "Epoch 20/30\n",
            "91/91 [==============================] - 3s 30ms/step - loss: 0.3570 - accuracy: 0.8486 - metrics_recall: 0.3018 - metrics_precision: 1.0000 - metrics_f1: 0.4528 - val_loss: 0.5663 - val_accuracy: 0.7284 - val_metrics_recall: 0.2543 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.3976\n",
            "Epoch 21/30\n",
            "91/91 [==============================] - 3s 30ms/step - loss: 0.3804 - accuracy: 0.8327 - metrics_recall: 0.2967 - metrics_precision: 1.0000 - metrics_f1: 0.4470 - val_loss: 0.5901 - val_accuracy: 0.6973 - val_metrics_recall: 0.3761 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.5426\n",
            "Epoch 22/30\n",
            "91/91 [==============================] - 3s 30ms/step - loss: 0.3302 - accuracy: 0.8577 - metrics_recall: 0.3278 - metrics_precision: 1.0000 - metrics_f1: 0.4866 - val_loss: 0.5623 - val_accuracy: 0.7284 - val_metrics_recall: 0.2891 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.4444\n",
            "Epoch 23/30\n",
            "91/91 [==============================] - 3s 30ms/step - loss: 0.3311 - accuracy: 0.8535 - metrics_recall: 0.3071 - metrics_precision: 1.0000 - metrics_f1: 0.4619 - val_loss: 0.5893 - val_accuracy: 0.7106 - val_metrics_recall: 0.3583 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.5225\n",
            "Epoch 24/30\n",
            "91/91 [==============================] - 3s 31ms/step - loss: 0.3345 - accuracy: 0.8556 - metrics_recall: 0.2998 - metrics_precision: 1.0000 - metrics_f1: 0.4515 - val_loss: 0.5886 - val_accuracy: 0.7062 - val_metrics_recall: 0.3800 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.5467\n",
            "Epoch 25/30\n",
            "91/91 [==============================] - 3s 31ms/step - loss: 0.3148 - accuracy: 0.8564 - metrics_recall: 0.3188 - metrics_precision: 1.0000 - metrics_f1: 0.4779 - val_loss: 0.6010 - val_accuracy: 0.6829 - val_metrics_recall: 0.3777 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.5433\n",
            "Epoch 26/30\n",
            "91/91 [==============================] - 3s 31ms/step - loss: 0.2900 - accuracy: 0.8849 - metrics_recall: 0.2791 - metrics_precision: 1.0000 - metrics_f1: 0.4312 - val_loss: 0.6775 - val_accuracy: 0.6918 - val_metrics_recall: 0.4211 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.5880\n",
            "Epoch 27/30\n",
            "91/91 [==============================] - 3s 31ms/step - loss: 0.2887 - accuracy: 0.8872 - metrics_recall: 0.3336 - metrics_precision: 1.0000 - metrics_f1: 0.4943 - val_loss: 0.6054 - val_accuracy: 0.7018 - val_metrics_recall: 0.3840 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.5481\n",
            "Epoch 28/30\n",
            "91/91 [==============================] - 3s 32ms/step - loss: 0.3082 - accuracy: 0.8713 - metrics_recall: 0.3206 - metrics_precision: 1.0000 - metrics_f1: 0.4775 - val_loss: 0.6182 - val_accuracy: 0.7239 - val_metrics_recall: 0.2413 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.3815\n",
            "Epoch 29/30\n",
            "91/91 [==============================] - 3s 32ms/step - loss: 0.2800 - accuracy: 0.8853 - metrics_recall: 0.3273 - metrics_precision: 1.0000 - metrics_f1: 0.4884 - val_loss: 0.6020 - val_accuracy: 0.7195 - val_metrics_recall: 0.2931 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.4446\n",
            "Epoch 30/30\n",
            "91/91 [==============================] - 3s 32ms/step - loss: 0.2747 - accuracy: 0.8902 - metrics_recall: 0.3378 - metrics_precision: 0.9998 - metrics_f1: 0.5000 - val_loss: 0.6428 - val_accuracy: 0.7073 - val_metrics_recall: 0.3568 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.5186\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4699683d90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJVL4SBLPB2P"
      },
      "source": [
        "#%tensorboard --logdir {logs_base_dir}"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_LnvWBcnoak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8e2d0e9-e6b8-43b5-de95-c2e26a0098c6"
      },
      "source": [
        "#results = model.evaluate(nppadded_testing, nptesting_labels, batch_size=batch_size)\n",
        "#print(\"test loss, test acc:\",results)\n",
        "\n",
        "(loss,accuracy, metrics_recall, metrics_precision,\n",
        "metrics_f1) = CNN16052107.evaluate(nppadded_testing, nptesting_labels, verbose=1)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "111/111 [==============================] - 1s 7ms/step - loss: 0.7078 - accuracy: 0.6659 - metrics_recall: 0.3079 - metrics_precision: 1.0000 - metrics_f1: 0.4651\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KgjIkhpKmHc"
      },
      "source": [
        "make some predictions of test data and save it to variable. verbose=0 -> do not generate output\n",
        "Gute Quelle: https://deeplizard.com/learn/video/2f-NjDUvZIE "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89GWuxryKlcM"
      },
      "source": [
        "CNN_predictions07 = CNN16052107.predict(x=nppadded_testing)\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3jPDaDJK_cN"
      },
      "source": [
        "#for p in CNN_predictions07:\n",
        " # print(p)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eC9efJy4Lp21"
      },
      "source": [
        "rounded predictions: give prediction value of most likely prediction (0 or 1). Printing the output of rounded prediction shows the prediction made by the model on the data (which output is most likely)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsG-TJuQLvtk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11bf4032-ba83-4376-a7c0-7bcbaaaa279c"
      },
      "source": [
        "prediction_rounded07 = np.round(CNN_predictions07)\n",
        "#np.argmax(CNN_predictions07,axis=-1)\n",
        "\n",
        "#for p in prediction_rounded07:\n",
        " # print(p)\n",
        "\n",
        "\n",
        "print(nptesting_labels[500:520])\n",
        "print(prediction_rounded07[500:520])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1]\n",
            "[[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egTtgpXgg8a2"
      },
      "source": [
        "https://deeplizard.com/learn/video/km7pxKy4UHU\n",
        "\n",
        "Quelle der def plot_confusion_matrix: https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSDXf7-_MITy"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0AMs1EzhBU1"
      },
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                        normalize=False,\n",
        "                        title='Confusion matrix',\n",
        "                        cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2JgEnlghCtl"
      },
      "source": [
        "cm = confusion_matrix(y_true=nptesting_labels, y_pred=prediction_rounded07)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckmF29whhFmX"
      },
      "source": [
        "plot_labels = ['no hatespeech','hatespeech']"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "2mpSE96rhK7K",
        "outputId": "65b131a1-71cd-450c-c26a-65153124194b"
      },
      "source": [
        "plot_confusion_matrix(cm=cm, classes=plot_labels, title='CNN Confusion 50Dense50')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix, without normalization\n",
            "[[1800  530]\n",
            " [ 650  552]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}