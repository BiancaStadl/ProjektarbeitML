{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN embedded.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMVDmpxpi3F78/XKqJGE5su",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BiancaStadl/ProjektarbeitML/blob/main/CNN_embedded.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXDOlIBymF0V"
      },
      "source": [
        "GloVe embeddings taken from:\n",
        "\n",
        "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. [pdf] [bib]\n",
        "\n",
        "hatespeechdata taken from (https://hatespeechdata.com/): Wiegand, M., Siegel, M. and Ruppenhofer, J., 2018. Overview of the GermEval 2018 Shared Task on the Identification of Offensive Language. In: Proceedings of GermEval 2018, 14th Conference on Natural Language Processing (KONVENS 2018). Vienna, Austria: Research Gate. available on: https://github.com/uds-lsv/GermEval-2018-Data (last checked: 09.05.2021)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlBmABDxfqII"
      },
      "source": [
        "wiki detox..https://colab.research.google.com/github/tensorflow/fairness-indicators/blob/master/g3doc/tutorials/Fairness_Indicators_TFCO_Wiki_Case_Study.ipynb#scrollTo=y6T5tlXcdW7J "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3xfitNdliBI"
      },
      "source": [
        "#import matplotlib.pyplot as plt -> für evtl Visualisierungen\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import string\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from keras import losses \n",
        "from keras import optimizers \n",
        "from keras import metrics \n",
        "\n",
        "#!pip install Tokenizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "#!pip install pad_sequences\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import preprocessing\n",
        "#from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTWJQ1iga_vS"
      },
      "source": [
        "Maximale Satzlänge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bq08Me5la_Cc"
      },
      "source": [
        "\n",
        "max_length = 60"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVYBMvYSotTH"
      },
      "source": [
        "url = \"https://github.com/uds-lsv/GermEval-2018-Data/archive/master.zip\"\n",
        "\n",
        "dataset = tf.keras.utils.get_file(\"GermEval-2018-Data-master.zip\", url, \n",
        "                                   extract=True, cache_dir='.',\n",
        "                                    cache_subdir='')\n",
        "\n",
        "dataset_dir = os.path.join(os.path.dirname(dataset), 'GermEval-2018-Data-master')\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cS14OUtfo34V"
      },
      "source": [
        "#os.listdir(dataset_dir)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2X429K6hpOVm"
      },
      "source": [
        "training_file = os.path.join(dataset_dir, 'germeval2018.training.txt')\n",
        "\n",
        "testing_file = os.path.join(dataset_dir, 'germeval2018.test.txt')\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uq8fG3LNtn_m"
      },
      "source": [
        "###Aufbereitung\n",
        "txt-Dateien lesen, und dabei jede Zeile splitten und teilen\n",
        "Twitter-Handler entfernen?\n",
        "Labels von Sätzen trennen, Labels in eigenen Array packen.\n",
        "\n",
        "####Ressourcen\n",
        "* https://www.w3schools.com/python/gloss_python_if_statement.asp\n",
        "* https://stackabuse.com/using-regex-for-text-manipulation-in-python/\n",
        "* https://www.tutorialspoint.com/python/string_splitlines.htm \n",
        "* https://note.nkmk.me/en/python-split-rsplit-splitlines-re/ \n",
        "* https://www.w3schools.com/python/python_regex.asp \n",
        "\n",
        "gäbe bei keras tf.keras.preprocessing.text_dataset_from_directory, aber dafür müssten die Daten auf bestimmte Weise in Verzeichnis organisiert sein, hier nicht der Fall.\n",
        "\n",
        "\n",
        "Einteilung der Daten: Testdaten\n",
        "Trainingsdaten -> noch ca 500 für Validierungsdaten\n",
        "\n",
        "labels -> \"other\", also nicht-negative Aussagen bekommen \"0\", negative Aussagen bekommen \"1\"\n",
        "\n",
        " Regex für Emojis  ->\n",
        "\n",
        "(\\u00a9|\\u00ae|[\\u2000-\\u3300]|\\ud83c[\\ud000-\\udfff]|\\ud83d[\\ud000-\\udfff]|\\ud83e[\\ud000-\\udfff])\n",
        "\n",
        "genommen von https://www.regextester.com/106421 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Py_cwD4eZkXo"
      },
      "source": [
        "def remove_clutter(string):\n",
        "   string = re.sub(\"@[^\\s]+\",\" \",string)\n",
        "   string = re.sub(\"#[^\\s]+\",\" \", string)\n",
        "   string = re.sub(\"\\u00a9\",\" \", string)\n",
        "   string = re.sub(\"\\u00ae\",\" \", string)\n",
        "   string = re.sub(\"[\\u2000-\\u3300]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83c[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83d[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83e[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"😜\", \" \",string)\n",
        "   string = re.sub(\"🍫\", \" \",string)\n",
        "   string = re.sub(\"😁\", \" \",string)\n",
        "   string = re.sub(\"🐖\", \" \",string)\n",
        "   string = re.sub(\"😡\", \" \",string)\n",
        "   string = re.sub(\"😇\", \" \",string)\n",
        "   string = re.sub(\"😬\", \" \",string)\n",
        "   string = re.sub(\"😃\", \" \",string)\n",
        "   string = re.sub(\"😂\", \" \",string)\n",
        "   string = re.sub(\"💙\", \" \",string)  \n",
        "   string = re.sub(\"😛\", \" \",string)\n",
        "   string = re.sub(\"🙏\", \" \",string)\n",
        "   string = re.sub(\"👍\", \" \",string)\n",
        "   string = re.sub(\"🖕\", \" \",string)\n",
        "   string = re.sub(\"😉\", \" \",string)\n",
        "   string = re.sub(\"💩\", \" \",string)\n",
        "   string = re.sub(\"🤢\", \" \",string)\n",
        "   string = re.sub(\"👏\", \" \",string)\n",
        "   string = re.sub(\"😨\", \" \",string)\n",
        "   string = re.sub(\"🤣\", \" \",string)\n",
        "   string = re.sub(\"🤡\", \" \",string)\n",
        "   string = re.sub(\"😈\", \" \",string)\n",
        "   string = re.sub(\"💃🏽\", \" \",string)\n",
        "   string = re.sub(\"👹\", \" \",string)\n",
        "   string = re.sub(\"🤘\", \" \",string)\n",
        "   string = re.sub(\"😱\", \" \",string)\n",
        "   string = re.sub(\"🤔\", \" \",string) \n",
        "   string = re.sub(\"🌈\", \" \",string) \n",
        "   string = re.sub(\"💕\", \" \",string) \n",
        "   string = re.sub(\"👩‍❤️‍👩\", \" \",string) \n",
        "   string = re.sub(\"😍\", \" \",string) \n",
        "   string = re.sub(\"👆\", \" \",string) \n",
        "   string = re.sub(\"😖\", \" \",string) \n",
        "   string = re.sub(\"👇\", \" \",string) \n",
        "   string = re.sub(\"🔥\", \" \",string) \n",
        "   string = re.sub(\"😘\", \" \",string) \n",
        "   string = re.sub(\"🎉\", \" \",string) \n",
        "   string = re.sub(\"🤬\", \" \",string) \n",
        "   string = re.sub(\"👊\", \" \",string)\n",
        "   string = re.sub(\"🇩🇪\", \" \",string)  \n",
        "   string = re.sub(\"💔\", \" \",string)\n",
        "   string = re.sub(\"🙈\", \" \",string)\n",
        "   string = re.sub(\"🤯\", \" \",string)\n",
        "   string = re.sub(\"🐟\", \" \",string)\n",
        "   string = re.sub(\"🛶\", \" \",string)\n",
        "   string = re.sub(\"😊\", \" \",string)\n",
        "   string = re.sub(\"😓\", \" \",string)\n",
        "   string = re.sub(\"😳\", \" \",string)\n",
        "   string = re.sub(\"🚀\", \" \",string)\n",
        "   string = re.sub(\"👎\", \" \",string)\n",
        "   string = re.sub(\"😎\", \" \",string)\n",
        "   string = re.sub(\"🐸\", \" \",string)\n",
        "   string = re.sub(\"📈\", \" \",string)\n",
        "   string = re.sub(\"🙂\", \" \",string)\n",
        "   string = re.sub(\"😅\", \" \",string)\n",
        "   string = re.sub(\"😆\", \" \",string)\n",
        "   string = re.sub(\"🙎🏿\", \" \",string)\n",
        "   string = re.sub(\"👎🏽\", \" \",string)\n",
        "   string = re.sub(\"🤭\", \" \",string)\n",
        "   string = re.sub(\"😤\", \" \",string)\n",
        "   string = re.sub(\"😚\", \" \",string)\n",
        "   string = re.sub(\"😊\", \" \",string)\n",
        "   string = re.sub(\"😲\", \" \",string)\n",
        "   string = re.sub(\"🤮\", \" \",string)\n",
        "   string = re.sub(\"🙄\", \" \",string)\n",
        "   string = re.sub(\"🤑\", \" \",string)\n",
        "   string = re.sub(\"🎅\", \" \",string)\n",
        "   string = re.sub(\"👋\", \" \",string)\n",
        "   string = re.sub(\"💪\", \" \",string)\n",
        "   string = re.sub(\"😄\", \" \",string)\n",
        "   string = re.sub(\"🧐\", \" \",string)\n",
        "   string = re.sub(\"😠\", \" \",string)\n",
        "   string = re.sub(\"🎈\", \" \",string)\n",
        "   string = re.sub(\"🚂\", \" \",string)\n",
        "   string = re.sub(\"😊\", \" \",string)\n",
        "   string = re.sub(\"🚇\", \" \",string)\n",
        "   string = re.sub(\"🚊\", \" \",string)\n",
        "   string = re.sub(\"🤷\", \" \",string)\n",
        "   string = re.sub(\"😥\", \" \",string)\n",
        "   string = re.sub(\"🙃\", \" \",string)\n",
        "   string = re.sub(\"🔩\", \" \",string)\n",
        "   string = re.sub(\"🔧\", \" \",string)\n",
        "   string = re.sub(\"🔨\", \" \",string)\n",
        "   string = re.sub(\"🛠\", \" \",string)\n",
        "   string = re.sub(\"💓\", \" \",string)\n",
        "   string = re.sub(\"💡\", \" \",string)\n",
        "   string = re.sub(\"🍸\", \" \",string)\n",
        "   string = re.sub(\"🥃\", \" \",string)\n",
        "   string = re.sub(\"🥂\", \" \",string)\n",
        "   string = re.sub(\"😷\", \" \",string)\n",
        "   string = re.sub(\"🤐\", \" \",string)\n",
        "   string = re.sub(\"🌎\", \" \",string)\n",
        "   string = re.sub(\"👑\", \" \",string)\n",
        "   string = re.sub(\"🤛\", \" \",string)\n",
        "   string = re.sub(\"😀\", \" \",string)\n",
        "   string = re.sub(\"🛤\", \" \",string)\n",
        "   string = re.sub(\"🎄\", \" \",string)\n",
        "   string = re.sub(\"📴\", \" \",string)\n",
        "   string = re.sub(\"🌭\", \" \",string)\n",
        "   string = re.sub(\"🤕\", \" \",string)\n",
        "   string = re.sub(\"😭\", \" \",string)\n",
        "   string = re.sub(\"🍾\", \" \",string)\n",
        "   string = re.sub(\"🍞\", \" \",string)\n",
        "   string = re.sub(\"🤦\", \" \",string)\n",
        "   string = re.sub(\"🤯\", \" \",string)\n",
        "   string = re.sub(\"🕯️\", \" \",string)\n",
        "\n",
        "   string = re.sub(\"OTHER|OFFENSE|ABUSE|INSULT\",\" \",string)\n",
        "   return string"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5asMgo4LtnRg"
      },
      "source": [
        "statementsForTraining = []\n",
        "sentimentsForTraining = []\n",
        "\n",
        "\n",
        "fileToRead = open(training_file, 'r')\n",
        "\n",
        "while True:\n",
        "  #next line in file\n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  findSentiment = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "\n",
        "\n",
        "  statementsForTraining.append(line)\n",
        "   #sentimentsForTraining.append(findSentiment.group(0))\n",
        "\n",
        "  if findSentiment.group(0) == \"OTHER\":  \n",
        "    sentimentsForTraining.append(0)\n",
        "  else:\n",
        "    sentimentsForTraining.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        " #print(\"{}: {}\".format(count,line.strip()))\n",
        "  \n",
        " # print(sentiment.group(0))\n",
        " \n",
        "fileToRead.close()\n",
        "\n",
        "training_sentences = statementsForTraining\n",
        "training_labels = sentimentsForTraining\n",
        "\n",
        "#print(training_sentences[9])\n",
        "#print(training_labels[9])\n",
        "\n",
        "#print(len(training_sentences))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsqZPENb98gD"
      },
      "source": [
        "##do the same with testdata\n",
        "statementsForTesting = []\n",
        "sentimentsForTesting = []\n",
        "\n",
        "fileToRead = open(testing_file, 'r')\n",
        "\n",
        "while True:\n",
        "  #next line in file\n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  sent = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "\n",
        "    \n",
        "\n",
        "  statementsForTesting.append(line)\n",
        "  #print(len(line))\n",
        "  #sentimentsForTesting.append(sent.group(0))\n",
        "\n",
        "  if sent.group(0) == \"OTHER\": \n",
        "    sentimentsForTesting.append(0)\n",
        "  else:\n",
        "    sentimentsForTesting.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        "\n",
        "fileToRead.close()\n",
        "\n",
        "\n",
        "testing_sentences = statementsForTesting\n",
        "testing_labels = sentimentsForTesting\n",
        "#print(len(testing_sentences))\n",
        "#print(testing_sentences)   \n",
        "#print(testing_labels)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRUvDLD5bMbO"
      },
      "source": [
        "Padding -> im Prinzip die Sätze alle auf die gleiche Länge bringen (in Theorieteil näher drauf eingehen) -> maxlen-Paramter ist für pad_sequences vorhanden, wenn nicht gesetzt -> alles wird auf die Länge des längsten Satzes aufgefüllt -> print(padded(shape)) gibt aus, wie viele Datensätze padded wurden und gibt an, wie viele Tokens der längste Datensatz hat\n",
        "print(padded[x]) gibt einen Satz aus (bereits tokenisiert)\n",
        "\n",
        "Padding -> sowohl für Trainigs- als auch für Testdaten\n",
        "\n",
        "Und: Daten als numpy-Arrays speichern (notwendig für tensorflow).\n",
        "\n",
        " -> Tokenizer https://towardsdatascience.com/text-classification-in-keras-part-2-how-to-use-the-keras-tokenizer-word-representations-fd571674df23 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3hFi7waTv5m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "467efebc-9e07-4f3c-8035-00baae14ab33"
      },
      "source": [
        "tokenizer = Tokenizer(oov_token=\"OOV\")\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "\n",
        "#creating a word index - nur die Trainigsdaten\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "validation_size = 500\n",
        "\n",
        "\n",
        "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "padded_training = pad_sequences(training_sequences, maxlen=max_length, padding='post')\n",
        "print(len(padded_training))\n",
        "\n",
        "validation_sequences = padded_training[0:validation_size]\n",
        "validation_labels = training_labels[0:validation_size]\n",
        "\n",
        "padded_training = padded_training[validation_size:]\n",
        "training_labels = training_labels[validation_size:]\n",
        "\n",
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
        "padded_testing = pad_sequences(testing_sequences, maxlen=max_length,  padding='post')\n",
        "\n",
        "#print(validation_sequences[499])\n",
        "print(padded_training[0])\n",
        "#print(len(validation_labels))\n",
        "#print(len(training_labels))\n",
        "\n",
        "\n",
        "nppadded_training = np.array(padded_training)\n",
        "nptraining_labels = np.array(training_labels)\n",
        "\n",
        "nppadded_validation = np.array(validation_sequences)\n",
        "npvalidation_labels = np.array(validation_labels)\n",
        "\n",
        "nppadded_testing = np.array(padded_testing)\n",
        "nptesting_labels = np.array(testing_labels)\n",
        "\n",
        "\n",
        "print(len(nppadded_training))\n",
        "print(len(nptraining_labels))\n",
        "print(len(word_index))\n",
        "\n",
        "#print(statementsForTraining[2])\n",
        "#print(nppadded_training[4])\n",
        "#print(nppadded_training.shape)\n",
        "#print(nptraining_labels[4])\n",
        "#print(nppadded_testing.shape)\n",
        "#print(word_index) \n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5009\n",
            "[  12 3982   11   41 6706 1040    4    5  202   39    3 2922   49 1360\n",
            "  810  495 3983    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0]\n",
            "4509\n",
            "4509\n",
            "15059\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tL3owrc8THkT"
      },
      "source": [
        "\n",
        "Dann: Embedding mit entweder word2vec oder glove\n",
        "Word2vec-Daten sind hier: http://vectors.nlpl.eu/repository/#\n",
        "Glove -> https://nlp.stanford.edu/projects/glove/ Da mal den Twitter-Vector runtergeladen\n",
        "Wenn Daten in GoogleDrive sind (wäre auch via url möglich..), muss Drive gemounted werden ( https://buomsoo-kim.github.io/colab/2020/05/09/Colab-mounting-google-drive.md/ ) aber auch hier https://enjoymachinelearning.com/posts/colab-with-google-drive/\n",
        "\n",
        "Die Word2vec vectors: http://vectors.nlpl.eu/repository/# \n",
        "\n",
        "glove-zitat:\n",
        "Citing GloVe\n",
        "\n",
        "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. [pdf] [bib]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zuO7T9ZTG57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dae611ad-dfd2-4349-f32a-419c8da4b5bb"
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount(\"/content/drive\")\n",
        "os.listdir(\"/content/drive/MyDrive/Colab Notebooks\")\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['germeval_training.txt',\n",
              " 'glove.twitter.27B.50d.txt',\n",
              " 'glove.twitter.27B.200d.txt',\n",
              " 'glove.6B.200d.txt',\n",
              " 'glove.840B.300d.txt',\n",
              " 'tensorboard.gdoc',\n",
              " 'keras.gdoc',\n",
              " 'Vectorization CNN embedded_limited_vocab.ipynb',\n",
              " 'glove.42B.300d.txt',\n",
              " 'Embedding Glove Vergleich.ipynb',\n",
              " 'CNN embedded_limited_vocab.ipynb',\n",
              " 'LSTM_limited_vocab.ipynb',\n",
              " 'LSTM.ipynb',\n",
              " 'CNN embedded.ipynb']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7ToKO-sZLHK"
      },
      "source": [
        "\n",
        "Keras-Doc : https://keras.io/examples/nlp/pretrained_word_embeddings/#load-pretrained-word-embeddings \n",
        "embedding mit initializers.. weights müsste auch funktionieren\n",
        "\n",
        "Diese erstellte Matrix mit Embedding dann in die Embedding-Schicht einbinden,  Trainable auf False, weil sich die Werte nicht durch Training anpassen sollen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AShIVfC7ZQAH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35bfe168-0cc3-47a9-d544-fa2097cf9a71"
      },
      "source": [
        "#Größe Vokabel -> wordindex + 2 (weil padding + OOV) \n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "vocabulary_size = len(word_index)+2\n",
        "\n",
        "# dann erstell ich ein Wörterbuch mit Namen \"embedding_vector\", dort sind dann\n",
        "#die keys drinnen, die in glove-Datei drinnen sind mit dem entsprechenden Key\n",
        "\n",
        "embedding_index_glove = {}\n",
        "f = open('/content/drive/MyDrive/Colab Notebooks/glove.twitter.27B.200d.txt')\n",
        "for line in f:\n",
        "  value = line.split()\n",
        "  word = value[0]\n",
        "  coef = np.asarray(value[1:],dtype='float32')\n",
        "  embedding_index_glove[word] = coef\n",
        "\n",
        "print(\"%d gefunden: \"% len(embedding_index_glove))\n",
        "\n",
        "#Dann noch eine Embedding-Matrix erstellen\n",
        "#zweiter Wert = Embedding-Dimension der Datei, in dem Fall 200\n",
        "\n",
        "glove_matrix = np.zeros((vocabulary_size,200))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    embedding_value = embedding_index_glove.get(word)\n",
        "    if embedding_value is not None:\n",
        "      glove_matrix[index] = embedding_value\n",
        "      hits+=1\n",
        "    else:\n",
        "      misses+=1\n",
        "\n",
        "print(\"hits %d and %d misses\"%(hits,misses))\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1193514 gefunden: \n",
            "hits 6747 and 8312 misses\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZmvOfwhV4N5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ac863d5-dc6b-4831-cef2-f7134612a2bc"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "print(\"vocab size: %d\"%vocabulary_size)\n",
        "CNN1605210290AEBN = tf.keras.Sequential()\n",
        "#Embedding -> hier dann auf das embedding verweisen, Input_dim -> die Anzahl der Wörter im word_index, output -> in dem Fall passend zum verwendeten Vektor\n",
        "#input-length -> auf 60  gepadded, trainable -> nein, weil nichts verändert werden soll\n",
        "#embeddings_initializer=keras.initializers.Constant(glove_matrix) vs weights = [glove_matrix]\n",
        "#Convolutional layers => filters = neurons.. mit 100? 265?\n",
        "#CNN1605210290AEBN.add(tf.keras.layers.Embedding(input_dim=vocabulary_size, output_dim=200, input_length=max_length))\n",
        "CNN1605210290AEBN.add(tf.keras.layers.Embedding(vocabulary_size, output_dim=200, input_length=60, embeddings_initializer = keras.initializers.Constant(glove_matrix), trainable= False))\n",
        "#CNN1605210290AEBN.add(tf.keras.layers.BatchNormalization())\n",
        "CNN1605210290AEBN.add(tf.keras.layers.Dropout(0.4))\n",
        "CNN1605210290AEBN.add(tf.keras.layers.Conv1D(filters=90, kernel_size=3, padding=\"valid\", activation=\"relu\"))\n",
        "#CNN1605210290AEBN.add(tf.keras.layers.BatchNormalization())\n",
        "CNN1605210290AEBN.add(tf.keras.layers.MaxPooling1D())\n",
        "CNN1605210290AEBN.add(tf.keras.layers.Conv1D(filters=90, kernel_size=3, padding=\"valid\", activation=\"relu\"))\n",
        "#CNN1605210290AEBN.add(tf.keras.layers.BatchNormalization())\n",
        "CNN1605210290AEBN.add(tf.keras.layers.MaxPooling1D())\n",
        "#CNN1605210290AEBN.add(tf.keras.layers.BatchNormalization())\n",
        "CNN1605210290AEBN.add(tf.keras.layers.Conv1D(filters=90, kernel_size=3, padding=\"valid\", activation=\"relu\"))\n",
        "#CNN1605210290AEBN.add(tf.keras.layers.BatchNormalization())\n",
        "CNN1605210290AEBN.add(tf.keras.layers.GlobalAveragePooling1D())\n",
        "#CNN1605210290AEBN.add(tf.keras.layers.BatchNormalization())\n",
        "CNN1605210290AEBN.add(tf.keras.layers.Flatten())\n",
        "#CNN1605210290AEBN.add(tf.keras.layers.BatchNormalization())\n",
        "CNN1605210290AEBN.add(tf.keras.layers.Dense(260, activation=\"relu\"))\n",
        "#CNN1605210290AEBN.add(tf.keras.layers.BatchNormalization())\n",
        "CNN1605210290AEBN.add(tf.keras.layers.Dropout(0.4))\n",
        "CNN1605210290AEBN.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "CNN1605210290AEBN.summary()\n",
        "\n",
        "#nppadded_training = np.asmatrix(nppadded_training) not necessary\n",
        "#nppadded_testing = np.asmatrix(nppadded_testing)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab size: 15061\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 60, 200)           3012200   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 60, 200)           0         \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 58, 90)            54090     \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 29, 90)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 27, 90)            24390     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 13, 90)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 11, 90)            24390     \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 90)                0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 90)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 260)               23660     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 260)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 261       \n",
            "=================================================================\n",
            "Total params: 3,138,991\n",
            "Trainable params: 126,791\n",
            "Non-trainable params: 3,012,200\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEr4OzT-iHDe"
      },
      "source": [
        "#model.layers[2].get_weights()[0].shape\n",
        "#weights=np.random.rand(5,200,100)\n",
        "#bias=np.random.rand(100)\n",
        "#model.layers[2].set_weights([weights, bias])\n",
        "\n",
        "#model.layers[2].get_weights()[0]\n",
        "#https://androidkt.com/set-custom-weights-keras-using-numpy-array/"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UB7_3VPYesr9"
      },
      "source": [
        "F1-Score für jede Epoche https://aakashgoel12.medium.com/how-to-add-user-defined-function-get-f1-score-in-keras-metrics-3013f979ce0d\n",
        "\n",
        "Sehr gute Ressource für die verschiedenen Scores und Metriken https://neptune.ai/blog/evaluation-metrics-binary-classification#10  das und aakas verwendet\n",
        "\n",
        "hier: je eine Funktion für Recall, Precision, f1 https://neptune.ai/blog/keras-metrics \n",
        "\n",
        "https://keras.rstudio.com/reference/k_ones_like.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygyrbFJaMV9B"
      },
      "source": [
        "import keras.backend as K\n",
        "\n",
        "def metrics_recall(data_true, data_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(data_true,0,1)))\n",
        "\n",
        "    recall = true_positives / (possible_positives+K.epsilon())\n",
        "    return recall\n",
        "\n",
        "\n",
        "def metrics_precision(data_true, data_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "\n",
        "    positives_predicted = K.sum(K.round(K.clip(data_pred,0,1)))\n",
        "    precision = true_positives / (positives_predicted+K.epsilon())\n",
        "    return precision\n",
        "\n",
        "\n",
        "def metrics_f1(data_true, data_pred):\n",
        "    precision_data = metrics_precision(data_true, data_pred)\n",
        "    recall_data = metrics_recall(data_true, data_pred)\n",
        "    return 2*(precision_data*recall_data)/(precision_data+recall_data+K.epsilon())"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1ctlBrnuYJz"
      },
      "source": [
        "https://aakashgoel12.medium.com/how-to-add-user-defined-function-get-f1-score-in-keras-metrics-3013f979ce0d"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AfPD3_bWCm0"
      },
      "source": [
        "#CNN1605210290AEBN.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',metrics_recall,metrics_precision,metrics_f1])\n",
        "CNN1605210290AEBN.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',metrics_recall,metrics_precision,metrics_f1])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpChKUY-QEWI"
      },
      "source": [
        "https://www.tensorflow.org/tensorboard/tensorboard_in_notebooks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJfMgUhHBoD1"
      },
      "source": [
        "#%load_ext tensorboard\n",
        "#nur einmal pro Sitzung notwendig\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ISmMXLqP8Hc"
      },
      "source": [
        "\n",
        "logs_base_dir = \"./logs\"\n",
        "callbackForTB = tf.keras.callbacks.TensorBoard(logs_base_dir)\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ehh-EMXUQh8r"
      },
      "source": [
        "Early Stopping as defined in keras tensorflow documentation\n",
        "https://www.tensorflow.org/guide/keras/train_and_evaluate "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BY_t-PeQEjy"
      },
      "source": [
        "callbackEarlyStopping = [\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_loss\",\n",
        "        mode=\"min\",\n",
        "        patience=3,\n",
        "        verbose=1,\n",
        "    )\n",
        "]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2CHbXiP1LsF"
      },
      "source": [
        "training_epochs = 14\n",
        "batch_size = 90\n",
        "validation_split=0.2"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abV-QAxfW48r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4eea3ed-e3c0-4c9e-9320-d3b2c5dba89e"
      },
      "source": [
        "#Werte der Convolutional-Schichten variieren (Filter), Batch-Size variieren, kernel-size..\n",
        "CNN1605210290AEBN.fit(nppadded_training, nptraining_labels, batch_size=batch_size, validation_split=validation_split, epochs=training_epochs, callbacks=[callbackForTB])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/14\n",
            "41/41 [==============================] - 5s 85ms/step - loss: 0.6529 - accuracy: 0.6543 - metrics_recall: 0.0249 - metrics_precision: 0.0126 - metrics_f1: 0.0156 - val_loss: 0.6377 - val_accuracy: 0.6718 - val_metrics_recall: 0.0000e+00 - val_metrics_precision: 0.0000e+00 - val_metrics_f1: 0.0000e+00\n",
            "Epoch 2/14\n",
            "41/41 [==============================] - 3s 76ms/step - loss: 0.6368 - accuracy: 0.6626 - metrics_recall: 0.0000e+00 - metrics_precision: 0.0000e+00 - metrics_f1: 0.0000e+00 - val_loss: 0.6243 - val_accuracy: 0.6718 - val_metrics_recall: 0.0000e+00 - val_metrics_precision: 0.0000e+00 - val_metrics_f1: 0.0000e+00\n",
            "Epoch 3/14\n",
            "41/41 [==============================] - 3s 81ms/step - loss: 0.6346 - accuracy: 0.6626 - metrics_recall: 0.0000e+00 - metrics_precision: 0.0000e+00 - metrics_f1: 0.0000e+00 - val_loss: 0.6195 - val_accuracy: 0.6718 - val_metrics_recall: 0.0000e+00 - val_metrics_precision: 0.0000e+00 - val_metrics_f1: 0.0000e+00\n",
            "Epoch 4/14\n",
            "41/41 [==============================] - 3s 78ms/step - loss: 0.6202 - accuracy: 0.6620 - metrics_recall: 0.0071 - metrics_precision: 0.0813 - metrics_f1: 0.0127 - val_loss: 0.6214 - val_accuracy: 0.6718 - val_metrics_recall: 0.0000e+00 - val_metrics_precision: 0.0000e+00 - val_metrics_f1: 0.0000e+00\n",
            "Epoch 5/14\n",
            "41/41 [==============================] - 3s 80ms/step - loss: 0.6191 - accuracy: 0.6634 - metrics_recall: 0.0162 - metrics_precision: 0.1610 - metrics_f1: 0.0278 - val_loss: 0.5926 - val_accuracy: 0.6774 - val_metrics_recall: 0.0191 - val_metrics_precision: 0.4545 - val_metrics_f1: 0.0364\n",
            "Epoch 6/14\n",
            "41/41 [==============================] - 3s 78ms/step - loss: 0.5892 - accuracy: 0.6767 - metrics_recall: 0.0921 - metrics_precision: 0.6430 - metrics_f1: 0.1472 - val_loss: 0.6093 - val_accuracy: 0.6486 - val_metrics_recall: 0.5547 - val_metrics_precision: 0.4782 - val_metrics_f1: 0.5029\n",
            "Epoch 7/14\n",
            "41/41 [==============================] - 3s 79ms/step - loss: 0.5603 - accuracy: 0.6964 - metrics_recall: 0.3309 - metrics_precision: 0.5963 - metrics_f1: 0.4101 - val_loss: 0.5717 - val_accuracy: 0.6818 - val_metrics_recall: 0.3563 - val_metrics_precision: 0.4832 - val_metrics_f1: 0.4041\n",
            "Epoch 8/14\n",
            "41/41 [==============================] - 3s 78ms/step - loss: 0.5313 - accuracy: 0.7253 - metrics_recall: 0.4172 - metrics_precision: 0.6346 - metrics_f1: 0.4832 - val_loss: 0.5517 - val_accuracy: 0.7084 - val_metrics_recall: 0.3821 - val_metrics_precision: 0.6442 - val_metrics_f1: 0.4664\n",
            "Epoch 9/14\n",
            "41/41 [==============================] - 3s 79ms/step - loss: 0.5220 - accuracy: 0.7297 - metrics_recall: 0.4388 - metrics_precision: 0.6512 - metrics_f1: 0.5006 - val_loss: 0.5625 - val_accuracy: 0.7029 - val_metrics_recall: 0.5168 - val_metrics_precision: 0.5950 - val_metrics_f1: 0.5503\n",
            "Epoch 10/14\n",
            "41/41 [==============================] - 3s 80ms/step - loss: 0.4799 - accuracy: 0.7646 - metrics_recall: 0.5422 - metrics_precision: 0.6805 - metrics_f1: 0.5922 - val_loss: 0.5471 - val_accuracy: 0.7162 - val_metrics_recall: 0.3958 - val_metrics_precision: 0.6633 - val_metrics_f1: 0.4845\n",
            "Epoch 11/14\n",
            "41/41 [==============================] - 3s 82ms/step - loss: 0.4760 - accuracy: 0.7610 - metrics_recall: 0.5133 - metrics_precision: 0.7329 - metrics_f1: 0.5802 - val_loss: 0.5666 - val_accuracy: 0.6840 - val_metrics_recall: 0.6094 - val_metrics_precision: 0.5613 - val_metrics_f1: 0.5806\n",
            "Epoch 12/14\n",
            "41/41 [==============================] - 3s 80ms/step - loss: 0.4521 - accuracy: 0.7779 - metrics_recall: 0.5971 - metrics_precision: 0.7028 - metrics_f1: 0.6328 - val_loss: 0.5774 - val_accuracy: 0.6918 - val_metrics_recall: 0.6633 - val_metrics_precision: 0.5714 - val_metrics_f1: 0.6082\n",
            "Epoch 13/14\n",
            "41/41 [==============================] - 3s 82ms/step - loss: 0.4247 - accuracy: 0.7968 - metrics_recall: 0.6303 - metrics_precision: 0.7614 - metrics_f1: 0.6713 - val_loss: 0.5629 - val_accuracy: 0.6951 - val_metrics_recall: 0.6217 - val_metrics_precision: 0.5753 - val_metrics_f1: 0.5926\n",
            "Epoch 14/14\n",
            "41/41 [==============================] - 3s 79ms/step - loss: 0.3965 - accuracy: 0.8106 - metrics_recall: 0.6448 - metrics_precision: 0.7710 - metrics_f1: 0.6914 - val_loss: 0.5796 - val_accuracy: 0.6962 - val_metrics_recall: 0.6420 - val_metrics_precision: 0.5809 - val_metrics_f1: 0.6062\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f439cc891d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJVL4SBLPB2P"
      },
      "source": [
        "#%tensorboard --logdir {logs_base_dir}"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_LnvWBcnoak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8261067-f6d2-4f6b-b3c2-fdc590bb8a8f"
      },
      "source": [
        "#results = model.evaluate(nppadded_testing, nptesting_labels, batch_size=batch_size)\n",
        "#print(\"test loss, test acc:\",results)\n",
        "\n",
        "(loss,accuracy, metrics_recall,metrics_precision,\n",
        "metrics_f1) = CNN1605210290AEBN.evaluate(nppadded_testing, nptesting_labels, verbose=1)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "111/111 [==============================] - 1s 9ms/step - loss: 0.6479 - accuracy: 0.6520 - metrics_recall: 0.4926 - metrics_precision: 0.4850 - metrics_f1: 0.4787\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KgjIkhpKmHc"
      },
      "source": [
        "make some predictions of test data and save it to variable. verbose=0 -> do not generate output\n",
        "Gute Quelle: https://deeplizard.com/learn/video/2f-NjDUvZIE "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89GWuxryKlcM"
      },
      "source": [
        "CNN_predictions90AEBN = CNN1605210290AEBN.predict(x=nppadded_testing)\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3jPDaDJK_cN"
      },
      "source": [
        "#for p in CNN_predictions90AEBN:\n",
        " # print(p)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eC9efJy4Lp21"
      },
      "source": [
        "rounded predictions: give prediction value of most likely prediction (0 or 1). Printing the output of rounded prediction shows the prediction made by the model on the data (which output is most likely)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsG-TJuQLvtk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "810e86fe-4b40-4cad-b8fe-b74b26b0b64b"
      },
      "source": [
        "prediction_rounded90AEBN = np.round(CNN_predictions90AEBN)\n",
        "#np.argmax(CNN_predictions90AEBN,axis=-1)\n",
        "\n",
        "#for p in prediction_rounded90AEBN:\n",
        " # print(p)\n",
        "\n",
        "\n",
        "print(nptesting_labels[500:520])\n",
        "print(prediction_rounded90AEBN[500:520])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1]\n",
            "[[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egTtgpXgg8a2"
      },
      "source": [
        "https://deeplizard.com/learn/video/km7pxKy4UHU\n",
        "\n",
        "Quelle der def plot_confusion_matrix: https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSDXf7-_MITy"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0AMs1EzhBU1"
      },
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                        normalize=False,\n",
        "                        title='Confusion matrix',\n",
        "                        cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2JgEnlghCtl"
      },
      "source": [
        "cm = confusion_matrix(y_true=nptesting_labels, y_pred=prediction_rounded90AEBN)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckmF29whhFmX"
      },
      "source": [
        "plot_labels = ['no hatespeech','hatespeech']"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mpSE96rhK7K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "outputId": "f930904e-15f6-42a0-e39b-dafe6da98d88"
      },
      "source": [
        "plot_confusion_matrix(cm=cm, classes=plot_labels, title='CNN Confusion 90 14 Epochs Batch size 90, tieferes NEtz')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix, without normalization\n",
            "[[1711  619]\n",
            " [ 610  592]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}