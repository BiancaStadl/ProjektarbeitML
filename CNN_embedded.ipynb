{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN embedded.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM5/dndOteyLWjm89i1esxf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BiancaStadl/ProjektarbeitML/blob/main/CNN_embedded.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXDOlIBymF0V"
      },
      "source": [
        "GloVe embeddings taken from:\n",
        "\n",
        "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. [pdf] [bib]\n",
        "\n",
        "hatespeechdata taken from (https://hatespeechdata.com/): Wiegand, M., Siegel, M. and Ruppenhofer, J., 2018. Overview of the GermEval 2018 Shared Task on the Identification of Offensive Language. In: Proceedings of GermEval 2018, 14th Conference on Natural Language Processing (KONVENS 2018). Vienna, Austria: Research Gate. available on: https://github.com/uds-lsv/GermEval-2018-Data (last checked: 09.05.2021)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlBmABDxfqII"
      },
      "source": [
        "wiki detox..https://colab.research.google.com/github/tensorflow/fairness-indicators/blob/master/g3doc/tutorials/Fairness_Indicators_TFCO_Wiki_Case_Study.ipynb#scrollTo=y6T5tlXcdW7J "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3xfitNdliBI"
      },
      "source": [
        "#import matplotlib.pyplot as plt -> für evtl Visualisierungen\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import string\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from keras import losses \n",
        "from keras import optimizers \n",
        "from keras import metrics \n",
        "\n",
        "#!pip install Tokenizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "#!pip install pad_sequences\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import preprocessing\n",
        "#from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTWJQ1iga_vS"
      },
      "source": [
        "Maximale Satzlänge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bq08Me5la_Cc"
      },
      "source": [
        "\n",
        "max_length = 60"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVYBMvYSotTH"
      },
      "source": [
        "url = \"https://github.com/uds-lsv/GermEval-2018-Data/archive/master.zip\"\n",
        "\n",
        "dataset = tf.keras.utils.get_file(\"GermEval-2018-Data-master.zip\", url, \n",
        "                                   extract=True, cache_dir='.',\n",
        "                                    cache_subdir='')\n",
        "\n",
        "dataset_dir = os.path.join(os.path.dirname(dataset), 'GermEval-2018-Data-master')\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cS14OUtfo34V"
      },
      "source": [
        "#os.listdir(dataset_dir)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2X429K6hpOVm"
      },
      "source": [
        "training_file = os.path.join(dataset_dir, 'germeval2018.training.txt')\n",
        "\n",
        "testing_file = os.path.join(dataset_dir, 'germeval2018.test.txt')\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uq8fG3LNtn_m"
      },
      "source": [
        "###Aufbereitung\n",
        "txt-Dateien lesen, und dabei jede Zeile splitten und teilen\n",
        "Twitter-Handler entfernen?\n",
        "Labels von Sätzen trennen, Labels in eigenen Array packen.\n",
        "\n",
        "####Ressourcen\n",
        "* https://www.w3schools.com/python/gloss_python_if_statement.asp\n",
        "* https://stackabuse.com/using-regex-for-text-manipulation-in-python/\n",
        "* https://www.tutorialspoint.com/python/string_splitlines.htm \n",
        "* https://note.nkmk.me/en/python-split-rsplit-splitlines-re/ \n",
        "* https://www.w3schools.com/python/python_regex.asp \n",
        "\n",
        "gäbe bei keras tf.keras.preprocessing.text_dataset_from_directory, aber dafür müssten die Daten auf bestimmte Weise in Verzeichnis organisiert sein, hier nicht der Fall.\n",
        "\n",
        "\n",
        "Einteilung der Daten: Testdaten\n",
        "Trainingsdaten -> noch ca 500 für Validierungsdaten\n",
        "\n",
        "labels -> \"other\", also nicht-negative Aussagen bekommen \"0\", negative Aussagen bekommen \"1\"\n",
        "\n",
        " Regex für Emojis  ->\n",
        "\n",
        "(\\u00a9|\\u00ae|[\\u2000-\\u3300]|\\ud83c[\\ud000-\\udfff]|\\ud83d[\\ud000-\\udfff]|\\ud83e[\\ud000-\\udfff])\n",
        "\n",
        "genommen von https://www.regextester.com/106421 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Py_cwD4eZkXo"
      },
      "source": [
        "def remove_clutter(string):\n",
        "   string = re.sub(\"@[^\\s]+\",\" \",string)\n",
        "   string = re.sub(\"#[^\\s]+\",\" \", string)\n",
        "   string = re.sub(\"\\u00a9\",\" \", string)\n",
        "   string = re.sub(\"\\u00ae\",\" \", string)\n",
        "   string = re.sub(\"[\\u2000-\\u3300]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83c[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83d[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83e[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"😜\", \" \",string)\n",
        "   string = re.sub(\"🍫\", \" \",string)\n",
        "   string = re.sub(\"😁\", \" \",string)\n",
        "   string = re.sub(\"🐖\", \" \",string)\n",
        "   string = re.sub(\"😡\", \" \",string)\n",
        "   string = re.sub(\"😇\", \" \",string)\n",
        "   string = re.sub(\"😬\", \" \",string)\n",
        "   string = re.sub(\"😃\", \" \",string)\n",
        "   string = re.sub(\"😂\", \" \",string)\n",
        "   string = re.sub(\"💙\", \" \",string)  \n",
        "   string = re.sub(\"😛\", \" \",string)\n",
        "   string = re.sub(\"🙏\", \" \",string)\n",
        "   string = re.sub(\"👍\", \" \",string)\n",
        "   string = re.sub(\"🖕\", \" \",string)\n",
        "   string = re.sub(\"😉\", \" \",string)\n",
        "   string = re.sub(\"💩\", \" \",string)\n",
        "   string = re.sub(\"🤢\", \" \",string)\n",
        "   string = re.sub(\"👏\", \" \",string)\n",
        "   string = re.sub(\"😨\", \" \",string)\n",
        "   string = re.sub(\"🤣\", \" \",string)\n",
        "   string = re.sub(\"🤡\", \" \",string)\n",
        "   string = re.sub(\"😈\", \" \",string)\n",
        "   string = re.sub(\"💃🏽\", \" \",string)\n",
        "   string = re.sub(\"👹\", \" \",string)\n",
        "   string = re.sub(\"🤘\", \" \",string)\n",
        "   string = re.sub(\"😱\", \" \",string)\n",
        "   string = re.sub(\"🤔\", \" \",string) \n",
        "   string = re.sub(\"🌈\", \" \",string) \n",
        "   string = re.sub(\"💕\", \" \",string) \n",
        "   string = re.sub(\"👩‍❤️‍👩\", \" \",string) \n",
        "   string = re.sub(\"😍\", \" \",string) \n",
        "   string = re.sub(\"👆\", \" \",string) \n",
        "   string = re.sub(\"😖\", \" \",string) \n",
        "   string = re.sub(\"👇\", \" \",string) \n",
        "   string = re.sub(\"🔥\", \" \",string) \n",
        "   string = re.sub(\"😘\", \" \",string) \n",
        "   string = re.sub(\"🎉\", \" \",string) \n",
        "   string = re.sub(\"🤬\", \" \",string) \n",
        "   string = re.sub(\"👊\", \" \",string)\n",
        "   string = re.sub(\"🇩🇪\", \" \",string)  \n",
        "   string = re.sub(\"💔\", \" \",string)\n",
        "   string = re.sub(\"🙈\", \" \",string)\n",
        "   string = re.sub(\"🤯\", \" \",string)\n",
        "   string = re.sub(\"🐟\", \" \",string)\n",
        "   string = re.sub(\"🛶\", \" \",string)\n",
        "   string = re.sub(\"😊\", \" \",string)\n",
        "   string = re.sub(\"😓\", \" \",string)\n",
        "   string = re.sub(\"😳\", \" \",string)\n",
        "   string = re.sub(\"🚀\", \" \",string)\n",
        "   string = re.sub(\"👎\", \" \",string)\n",
        "   string = re.sub(\"😎\", \" \",string)\n",
        "   string = re.sub(\"🐸\", \" \",string)\n",
        "   string = re.sub(\"📈\", \" \",string)\n",
        "   string = re.sub(\"🙂\", \" \",string)\n",
        "   string = re.sub(\"😅\", \" \",string)\n",
        "   string = re.sub(\"😆\", \" \",string)\n",
        "   string = re.sub(\"🙎🏿\", \" \",string)\n",
        "   string = re.sub(\"👎🏽\", \" \",string)\n",
        "   string = re.sub(\"🤭\", \" \",string)\n",
        "   string = re.sub(\"😤\", \" \",string)\n",
        "   string = re.sub(\"😚\", \" \",string)\n",
        "   string = re.sub(\"😊\", \" \",string)\n",
        "   string = re.sub(\"😲\", \" \",string)\n",
        "   string = re.sub(\"🤮\", \" \",string)\n",
        "   string = re.sub(\"🙄\", \" \",string)\n",
        "   string = re.sub(\"🤑\", \" \",string)\n",
        "   string = re.sub(\"🎅\", \" \",string)\n",
        "   string = re.sub(\"👋\", \" \",string)\n",
        "   string = re.sub(\"💪\", \" \",string)\n",
        "   string = re.sub(\"😄\", \" \",string)\n",
        "   string = re.sub(\"🧐\", \" \",string)\n",
        "   string = re.sub(\"😠\", \" \",string)\n",
        "   string = re.sub(\"🎈\", \" \",string)\n",
        "   string = re.sub(\"🚂\", \" \",string)\n",
        "   string = re.sub(\"😊\", \" \",string)\n",
        "   string = re.sub(\"🚇\", \" \",string)\n",
        "   string = re.sub(\"🚊\", \" \",string)\n",
        "   string = re.sub(\"🤷\", \" \",string)\n",
        "   string = re.sub(\"😥\", \" \",string)\n",
        "   string = re.sub(\"🙃\", \" \",string)\n",
        "   string = re.sub(\"🔩\", \" \",string)\n",
        "   string = re.sub(\"🔧\", \" \",string)\n",
        "   string = re.sub(\"🔨\", \" \",string)\n",
        "   string = re.sub(\"🛠\", \" \",string)\n",
        "   string = re.sub(\"💓\", \" \",string)\n",
        "   string = re.sub(\"💡\", \" \",string)\n",
        "   string = re.sub(\"🍸\", \" \",string)\n",
        "   string = re.sub(\"🥃\", \" \",string)\n",
        "   string = re.sub(\"🥂\", \" \",string)\n",
        "   string = re.sub(\"😷\", \" \",string)\n",
        "   string = re.sub(\"🤐\", \" \",string)\n",
        "   string = re.sub(\"🌎\", \" \",string)\n",
        "   string = re.sub(\"👑\", \" \",string)\n",
        "   string = re.sub(\"🤛\", \" \",string)\n",
        "   string = re.sub(\"😀\", \" \",string)\n",
        "   string = re.sub(\"🛤\", \" \",string)\n",
        "   string = re.sub(\"🎄\", \" \",string)\n",
        "   string = re.sub(\"📴\", \" \",string)\n",
        "   string = re.sub(\"🌭\", \" \",string)\n",
        "   string = re.sub(\"🤕\", \" \",string)\n",
        "   string = re.sub(\"😭\", \" \",string)\n",
        "   string = re.sub(\"🍾\", \" \",string)\n",
        "   string = re.sub(\"🍞\", \" \",string)\n",
        "   string = re.sub(\"🤦\", \" \",string)\n",
        "   string = re.sub(\"🤯\", \" \",string)\n",
        "   string = re.sub(\"🕯️\", \" \",string)\n",
        "\n",
        "   string = re.sub(\"OTHER|OFFENSE|ABUSE|INSULT\",\" \",string)\n",
        "   return string"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5asMgo4LtnRg"
      },
      "source": [
        "statementsForTraining = []\n",
        "sentimentsForTraining = []\n",
        "\n",
        "\n",
        "fileToRead = open(training_file, 'r')\n",
        "\n",
        "while True:\n",
        "  #next line in file\n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  findSentiment = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "\n",
        "\n",
        "  statementsForTraining.append(line)\n",
        "   #sentimentsForTraining.append(findSentiment.group(0))\n",
        "\n",
        "  if findSentiment.group(0) == \"OTHER\":  \n",
        "    sentimentsForTraining.append(0)\n",
        "  else:\n",
        "    sentimentsForTraining.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        " #print(\"{}: {}\".format(count,line.strip()))\n",
        "  \n",
        " # print(sentiment.group(0))\n",
        " \n",
        "fileToRead.close()\n",
        "\n",
        "training_sentences = statementsForTraining\n",
        "training_labels = sentimentsForTraining\n",
        "\n",
        "#print(training_sentences[9])\n",
        "#print(training_labels[9])\n",
        "\n",
        "#print(len(training_sentences))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsqZPENb98gD"
      },
      "source": [
        "##do the same with testdata\n",
        "statementsForTesting = []\n",
        "sentimentsForTesting = []\n",
        "\n",
        "fileToRead = open(testing_file, 'r')\n",
        "\n",
        "while True:\n",
        "  #next line in file\n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  sent = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "\n",
        "    \n",
        "\n",
        "  statementsForTesting.append(line)\n",
        "  #print(len(line))\n",
        "  #sentimentsForTesting.append(sent.group(0))\n",
        "\n",
        "  if sent.group(0) == \"OTHER\": \n",
        "    sentimentsForTesting.append(0)\n",
        "  else:\n",
        "    sentimentsForTesting.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        "\n",
        "fileToRead.close()\n",
        "\n",
        "\n",
        "testing_sentences = statementsForTesting\n",
        "testing_labels = sentimentsForTesting\n",
        "#print(len(testing_sentences))\n",
        "#print(testing_sentences)   \n",
        "#print(testing_labels)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRUvDLD5bMbO"
      },
      "source": [
        "Padding -> im Prinzip die Sätze alle auf die gleiche Länge bringen (in Theorieteil näher drauf eingehen) -> maxlen-Paramter ist für pad_sequences vorhanden, wenn nicht gesetzt -> alles wird auf die Länge des längsten Satzes aufgefüllt -> print(padded(shape)) gibt aus, wie viele Datensätze padded wurden und gibt an, wie viele Tokens der längste Datensatz hat\n",
        "print(padded[x]) gibt einen Satz aus (bereits tokenisiert)\n",
        "\n",
        "Padding -> sowohl für Trainigs- als auch für Testdaten\n",
        "\n",
        "Und: Daten als numpy-Arrays speichern (notwendig für tensorflow).\n",
        "\n",
        " -> Tokenizer https://towardsdatascience.com/text-classification-in-keras-part-2-how-to-use-the-keras-tokenizer-word-representations-fd571674df23 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3hFi7waTv5m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4247d06-966a-4663-f1db-35acf3766cca"
      },
      "source": [
        "tokenizer = Tokenizer(oov_token=\"OOV\")\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "\n",
        "#creating a word index - nur die Trainigsdaten\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "validation_size = 500\n",
        "\n",
        "\n",
        "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "padded_training = pad_sequences(training_sequences, maxlen=max_length, padding='post')\n",
        "print(len(padded_training))\n",
        "\n",
        "validation_sequences = padded_training[0:validation_size]\n",
        "validation_labels = training_labels[0:validation_size]\n",
        "\n",
        "padded_training = padded_training[validation_size:]\n",
        "training_labels = training_labels[validation_size:]\n",
        "\n",
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
        "padded_testing = pad_sequences(testing_sequences, maxlen=max_length,  padding='post')\n",
        "\n",
        "#print(validation_sequences[499])\n",
        "print(padded_training[0])\n",
        "#print(len(validation_labels))\n",
        "#print(len(training_labels))\n",
        "\n",
        "\n",
        "nppadded_training = np.array(padded_training)\n",
        "nptraining_labels = np.array(training_labels)\n",
        "\n",
        "nppadded_validation = np.array(validation_sequences)\n",
        "npvalidation_labels = np.array(validation_labels)\n",
        "\n",
        "nppadded_testing = np.array(padded_testing)\n",
        "nptesting_labels = np.array(testing_labels)\n",
        "\n",
        "\n",
        "print(len(nppadded_training))\n",
        "print(len(nptraining_labels))\n",
        "print(len(word_index))\n",
        "\n",
        "#print(statementsForTraining[2])\n",
        "#print(nppadded_training[4])\n",
        "#print(nppadded_training.shape)\n",
        "#print(nptraining_labels[4])\n",
        "#print(nppadded_testing.shape)\n",
        "#print(word_index) \n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5009\n",
            "[  12 3982   11   41 6706 1040    4    5  202   39    3 2922   49 1360\n",
            "  810  495 3983    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0]\n",
            "4509\n",
            "4509\n",
            "15059\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tL3owrc8THkT"
      },
      "source": [
        "\n",
        "Dann: Embedding mit entweder word2vec oder glove\n",
        "Word2vec-Daten sind hier: http://vectors.nlpl.eu/repository/#\n",
        "Glove -> https://nlp.stanford.edu/projects/glove/ Da mal den Twitter-Vector runtergeladen\n",
        "Wenn Daten in GoogleDrive sind (wäre auch via url möglich..), muss Drive gemounted werden ( https://buomsoo-kim.github.io/colab/2020/05/09/Colab-mounting-google-drive.md/ ) aber auch hier https://enjoymachinelearning.com/posts/colab-with-google-drive/\n",
        "\n",
        "Die Word2vec vectors: http://vectors.nlpl.eu/repository/# \n",
        "\n",
        "glove-zitat:\n",
        "Citing GloVe\n",
        "\n",
        "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. [pdf] [bib]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zuO7T9ZTG57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e593d7c-65c6-42db-a192-008a265f5ee0"
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount(\"/content/drive\")\n",
        "os.listdir(\"/content/drive/MyDrive/Colab Notebooks\")\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['germeval_training.txt',\n",
              " 'glove.twitter.27B.50d.txt',\n",
              " 'glove.twitter.27B.200d.txt',\n",
              " 'glove.6B.200d.txt',\n",
              " 'glove.840B.300d.txt',\n",
              " 'tensorboard.gdoc',\n",
              " 'keras.gdoc',\n",
              " 'Vectorization CNN embedded_limited_vocab.ipynb',\n",
              " 'glove.42B.300d.txt',\n",
              " 'Embedding Glove Vergleich.ipynb',\n",
              " 'CNN embedded_limited_vocab.ipynb',\n",
              " 'LSTM_limited_vocab.ipynb',\n",
              " 'LSTM.ipynb',\n",
              " 'CNN embedded.ipynb']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7ToKO-sZLHK"
      },
      "source": [
        "\n",
        "Keras-Doc : https://keras.io/examples/nlp/pretrained_word_embeddings/#load-pretrained-word-embeddings \n",
        "embedding mit initializers.. weights müsste auch funktionieren\n",
        "\n",
        "Diese erstellte Matrix mit Embedding dann in die Embedding-Schicht einbinden,  Trainable auf False, weil sich die Werte nicht durch Training anpassen sollen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AShIVfC7ZQAH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3078a33b-7952-4e09-c8e0-6a8d4ef2c28b"
      },
      "source": [
        "#Größe Vokabel -> wordindex + 2 (weil padding + OOV) \n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "vocabulary_size = len(word_index)+2\n",
        "\n",
        "# dann erstell ich ein Wörterbuch mit Namen \"embedding_vector\", dort sind dann\n",
        "#die keys drinnen, die in glove-Datei drinnen sind mit dem entsprechenden Key\n",
        "\n",
        "embedding_index_glove = {}\n",
        "f = open('/content/drive/MyDrive/Colab Notebooks/glove.twitter.27B.200d.txt')\n",
        "for line in f:\n",
        "  value = line.split()\n",
        "  word = value[0]\n",
        "  coef = np.asarray(value[1:],dtype='float32')\n",
        "  embedding_index_glove[word] = coef\n",
        "\n",
        "print(\"%d gefunden: \"% len(embedding_index_glove))\n",
        "\n",
        "#Dann noch eine Embedding-Matrix erstellen\n",
        "#zweiter Wert = Embedding-Dimension der Datei, in dem Fall 200\n",
        "\n",
        "glove_matrix = np.zeros((vocabulary_size,200))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    embedding_value = embedding_index_glove.get(word)\n",
        "    if embedding_value is not None:\n",
        "      glove_matrix[index] = embedding_value\n",
        "      hits+=1\n",
        "    else:\n",
        "      misses+=1\n",
        "\n",
        "print(\"hits %d and %d misses\"%(hits,misses))\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1193514 gefunden: \n",
            "hits 6747 and 8312 misses\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZmvOfwhV4N5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75d83586-611c-4754-a331-10619bad2edc"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "print(\"vocab size: %d\"%vocabulary_size)\n",
        "CNN16052102ES06 = tf.keras.Sequential()\n",
        "#Embedding -> hier dann auf das embedding verweisen, Input_dim -> die Anzahl der Wörter im word_index, output -> in dem Fall passend zum verwendeten Vektor\n",
        "#input-length -> auf 60  gepadded, trainable -> nein, weil nichts verändert werden soll\n",
        "#embeddings_initializer=keras.initializers.Constant(glove_matrix) vs weights = [glove_matrix]\n",
        "#Convolutional layers => filters = neurons.. mit 100? 265?\n",
        "#CNN16052102ES06.add(tf.keras.layers.Embedding(input_dim=vocabulary_size, output_dim=200, input_length=max_length))\n",
        "CNN16052102ES06.add(tf.keras.layers.Embedding(vocabulary_size, output_dim=200, input_length=60, embeddings_initializer = keras.initializers.Constant(glove_matrix), trainable= False))\n",
        "CNN16052102ES06.add(tf.keras.layers.Dropout(0.4))\n",
        "CNN16052102ES06.add(tf.keras.layers.Conv1D(filters=120, kernel_size=3, padding=\"valid\", activation=\"relu\"))\n",
        "CNN16052102ES06.add(tf.keras.layers.MaxPooling1D())\n",
        "CNN16052102ES06.add(tf.keras.layers.Conv1D(filters=120, kernel_size=3, padding=\"valid\", activation=\"relu\"))\n",
        "CNN16052102ES06.add(tf.keras.layers.GlobalAveragePooling1D())\n",
        "CNN16052102ES06.add(tf.keras.layers.Flatten())\n",
        "CNN16052102ES06.add(tf.keras.layers.Dense(260, activation=\"relu\"))\n",
        "CNN16052102ES06.add(tf.keras.layers.Dropout(0.4))\n",
        "CNN16052102ES06.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "CNN16052102ES06.summary()\n",
        "\n",
        "#nppadded_training = np.asmatrix(nppadded_training) not necessary\n",
        "#nppadded_testing = np.asmatrix(nppadded_testing)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab size: 15061\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 60, 200)           3012200   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 60, 200)           0         \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 58, 120)           72120     \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 29, 120)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 27, 120)           43320     \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 120)               0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 120)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 260)               31460     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 260)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 261       \n",
            "=================================================================\n",
            "Total params: 3,159,361\n",
            "Trainable params: 147,161\n",
            "Non-trainable params: 3,012,200\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEr4OzT-iHDe"
      },
      "source": [
        "#model.layers[2].get_weights()[0].shape\n",
        "#weights=np.random.rand(5,200,100)\n",
        "#bias=np.random.rand(100)\n",
        "#model.layers[2].set_weights([weights, bias])\n",
        "\n",
        "#model.layers[2].get_weights()[0]\n",
        "#https://androidkt.com/set-custom-weights-keras-using-numpy-array/"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UB7_3VPYesr9"
      },
      "source": [
        "F1-Score für jede Epoche https://aakashgoel12.medium.com/how-to-add-user-defined-function-get-f1-score-in-keras-metrics-3013f979ce0d\n",
        "\n",
        "Sehr gute Ressource für die verschiedenen Scores und Metriken https://neptune.ai/blog/evaluation-metrics-binary-classification#10  das und aakas verwendet\n",
        "\n",
        "hier: je eine Funktion für Recall, Precision, f1 https://neptune.ai/blog/keras-metrics \n",
        "\n",
        "https://keras.rstudio.com/reference/k_ones_like.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygyrbFJaMV9B"
      },
      "source": [
        "import keras.backend as K\n",
        "\n",
        "def metrics_recall(data_true, data_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(data_true,0,1)))\n",
        "\n",
        "    recall = true_positives / (possible_positives+K.epsilon())\n",
        "    return recall\n",
        "\n",
        "\n",
        "def metrics_precision(data_true, data_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "\n",
        "    positives_predicted = K.sum(K.round(K.clip(data_pred,0,1)))\n",
        "    precision = true_positives / (positives_predicted+K.epsilon())\n",
        "    return precision\n",
        "\n",
        "\n",
        "def metrics_f1(data_true, data_pred):\n",
        "    precision_data = metrics_precision(data_true, data_pred)\n",
        "    recall_data = metrics_recall(data_true, data_pred)\n",
        "    return 2*(precision_data*recall_data)/(precision_data+recall_data+K.epsilon())"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1ctlBrnuYJz"
      },
      "source": [
        "https://aakashgoel12.medium.com/how-to-add-user-defined-function-get-f1-score-in-keras-metrics-3013f979ce0d"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AfPD3_bWCm0"
      },
      "source": [
        "CNN16052102ES06.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',metrics_recall,metrics_precision,metrics_f1])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpChKUY-QEWI"
      },
      "source": [
        "https://www.tensorflow.org/tensorboard/tensorboard_in_notebooks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJfMgUhHBoD1"
      },
      "source": [
        "#%load_ext tensorboard\n",
        "#nur einmal pro Sitzung notwendig\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ISmMXLqP8Hc"
      },
      "source": [
        "\n",
        "logs_base_dir = \"./logs\"\n",
        "callbackForTB = tf.keras.callbacks.TensorBoard(logs_base_dir)\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ehh-EMXUQh8r"
      },
      "source": [
        "Early Stopping as defined in keras tensorflow documentation\n",
        "https://www.tensorflow.org/guide/keras/train_and_evaluate "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BY_t-PeQEjy"
      },
      "source": [
        "callbackEarlyStopping = [\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_loss\",\n",
        "        mode=\"min\",\n",
        "        patience=3,\n",
        "        verbose=1,\n",
        "    )\n",
        "]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2CHbXiP1LsF"
      },
      "source": [
        "training_epochs = 30\n",
        "batch_size = 40\n",
        "validation_split=0.2"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abV-QAxfW48r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77ef1cfb-5e81-4085-fe77-c1899a112cff"
      },
      "source": [
        "#Werte der Convolutional-Schichten variieren (Filter), Batch-Size variieren, kernel-size..\n",
        "CNN16052102ES06.fit(nppadded_training, nptraining_labels, batch_size=batch_size, validation_split=validation_split, epochs=training_epochs, callbacks=[callbackForTB,callbackEarlyStopping])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "91/91 [==============================] - 5s 44ms/step - loss: 0.6552 - accuracy: 0.6555 - metrics_recall: 0.0107 - metrics_precision: 0.0334 - metrics_f1: 0.0160 - val_loss: 0.6425 - val_accuracy: 0.6718 - val_metrics_recall: 0.0000e+00 - val_metrics_precision: 0.0000e+00 - val_metrics_f1: 0.0000e+00\n",
            "Epoch 2/30\n",
            "91/91 [==============================] - 3s 38ms/step - loss: 0.6388 - accuracy: 0.6569 - metrics_recall: 3.3445e-04 - metrics_precision: 0.0035 - metrics_f1: 5.8854e-04 - val_loss: 0.6042 - val_accuracy: 0.6707 - val_metrics_recall: 0.0000e+00 - val_metrics_precision: 0.0000e+00 - val_metrics_f1: 0.0000e+00\n",
            "Epoch 3/30\n",
            "91/91 [==============================] - 4s 39ms/step - loss: 0.5861 - accuracy: 0.6814 - metrics_recall: 0.1351 - metrics_precision: 0.4957 - metrics_f1: 0.1891 - val_loss: 0.5932 - val_accuracy: 0.7062 - val_metrics_recall: 0.3967 - val_metrics_precision: 0.5815 - val_metrics_f1: 0.4577\n",
            "Epoch 4/30\n",
            "91/91 [==============================] - 4s 39ms/step - loss: 0.5769 - accuracy: 0.7014 - metrics_recall: 0.3104 - metrics_precision: 0.6136 - metrics_f1: 0.3648 - val_loss: 0.5757 - val_accuracy: 0.6929 - val_metrics_recall: 0.5720 - val_metrics_precision: 0.5354 - val_metrics_f1: 0.5397\n",
            "Epoch 5/30\n",
            "91/91 [==============================] - 3s 38ms/step - loss: 0.5492 - accuracy: 0.7087 - metrics_recall: 0.4071 - metrics_precision: 0.6421 - metrics_f1: 0.4617 - val_loss: 0.5554 - val_accuracy: 0.7284 - val_metrics_recall: 0.2951 - val_metrics_precision: 0.7434 - val_metrics_f1: 0.4009\n",
            "Epoch 6/30\n",
            "91/91 [==============================] - 4s 39ms/step - loss: 0.5315 - accuracy: 0.7398 - metrics_recall: 0.4443 - metrics_precision: 0.7110 - metrics_f1: 0.5244 - val_loss: 0.5789 - val_accuracy: 0.6630 - val_metrics_recall: 0.6837 - val_metrics_precision: 0.4931 - val_metrics_f1: 0.5604\n",
            "Epoch 7/30\n",
            "91/91 [==============================] - 4s 39ms/step - loss: 0.4986 - accuracy: 0.7509 - metrics_recall: 0.5822 - metrics_precision: 0.6993 - metrics_f1: 0.6016 - val_loss: 0.5458 - val_accuracy: 0.7239 - val_metrics_recall: 0.2798 - val_metrics_precision: 0.7409 - val_metrics_f1: 0.3867\n",
            "Epoch 8/30\n",
            "91/91 [==============================] - 4s 39ms/step - loss: 0.4637 - accuracy: 0.7690 - metrics_recall: 0.5359 - metrics_precision: 0.7214 - metrics_f1: 0.5869 - val_loss: 0.5548 - val_accuracy: 0.6940 - val_metrics_recall: 0.6207 - val_metrics_precision: 0.5271 - val_metrics_f1: 0.5575\n",
            "Epoch 9/30\n",
            "91/91 [==============================] - 4s 39ms/step - loss: 0.4340 - accuracy: 0.7934 - metrics_recall: 0.6222 - metrics_precision: 0.7270 - metrics_f1: 0.6510 - val_loss: 0.5905 - val_accuracy: 0.6818 - val_metrics_recall: 0.6960 - val_metrics_precision: 0.5020 - val_metrics_f1: 0.5737\n",
            "Epoch 10/30\n",
            "91/91 [==============================] - 4s 39ms/step - loss: 0.3963 - accuracy: 0.8145 - metrics_recall: 0.6906 - metrics_precision: 0.7744 - metrics_f1: 0.7119 - val_loss: 0.5567 - val_accuracy: 0.7073 - val_metrics_recall: 0.6632 - val_metrics_precision: 0.5387 - val_metrics_f1: 0.5833\n",
            "Epoch 00010: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7887800a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJVL4SBLPB2P"
      },
      "source": [
        "#%tensorboard --logdir {logs_base_dir}"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_LnvWBcnoak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6132bf1e-ff4a-48a3-b27c-182f4670466e"
      },
      "source": [
        "#results = model.evaluate(nppadded_testing, nptesting_labels, batch_size=batch_size)\n",
        "#print(\"test loss, test acc:\",results)\n",
        "\n",
        "(loss,accuracy, metrics_recall,metrics_precision,\n",
        "metrics_f1) = CNN16052102ES06.evaluate(nppadded_testing, nptesting_labels, verbose=1)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "111/111 [==============================] - 1s 10ms/step - loss: 0.6196 - accuracy: 0.6560 - metrics_recall: 0.4567 - metrics_precision: 0.5002 - metrics_f1: 0.4639\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KgjIkhpKmHc"
      },
      "source": [
        "make some predictions of test data and save it to variable. verbose=0 -> do not generate output\n",
        "Gute Quelle: https://deeplizard.com/learn/video/2f-NjDUvZIE "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89GWuxryKlcM"
      },
      "source": [
        "CNN_predictions06 = CNN16052102ES06.predict(x=nppadded_testing)\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3jPDaDJK_cN"
      },
      "source": [
        "#for p in CNN_predictions06:\n",
        " # print(p)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eC9efJy4Lp21"
      },
      "source": [
        "rounded predictions: give prediction value of most likely prediction (0 or 1). Printing the output of rounded prediction shows the prediction made by the model on the data (which output is most likely)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsG-TJuQLvtk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3569dbe0-da57-45d7-de63-268f206aa6a6"
      },
      "source": [
        "prediction_rounded06 = np.round(CNN_predictions06)\n",
        "#np.argmax(CNN_predictions06,axis=-1)\n",
        "\n",
        "#for p in prediction_rounded06:\n",
        " # print(p)\n",
        "\n",
        "\n",
        "print(nptesting_labels[500:520])\n",
        "print(prediction_rounded06[500:520])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1]\n",
            "[[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egTtgpXgg8a2"
      },
      "source": [
        "https://deeplizard.com/learn/video/km7pxKy4UHU\n",
        "\n",
        "Quelle der def plot_confusion_matrix: https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSDXf7-_MITy"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0AMs1EzhBU1"
      },
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                        normalize=False,\n",
        "                        title='Confusion matrix',\n",
        "                        cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2JgEnlghCtl"
      },
      "source": [
        "cm = confusion_matrix(y_true=nptesting_labels, y_pred=prediction_rounded06)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckmF29whhFmX"
      },
      "source": [
        "plot_labels = ['no hatespeech','hatespeech']"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "2mpSE96rhK7K",
        "outputId": "33e2891e-da49-4a55-d8aa-9cafbd7e4baf"
      },
      "source": [
        "plot_confusion_matrix(cm=cm, classes=plot_labels, title='CNN Confusion 120 EarlyStopping min loss')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix, without normalization\n",
            "[[1770  560]\n",
            " [ 655  547]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}