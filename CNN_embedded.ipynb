{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN embedded.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPWQ1UP6oziMTxezEl9QZ40",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BiancaStadl/ProjektarbeitML/blob/main/CNN_embedded.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXDOlIBymF0V"
      },
      "source": [
        "GloVe embeddings taken from:\n",
        "\n",
        "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. [pdf] [bib]\n",
        "\n",
        "hatespeechdata taken from (https://hatespeechdata.com/): Wiegand, M., Siegel, M. and Ruppenhofer, J., 2018. Overview of the GermEval 2018 Shared Task on the Identification of Offensive Language. In: Proceedings of GermEval 2018, 14th Conference on Natural Language Processing (KONVENS 2018). Vienna, Austria: Research Gate. available on: https://github.com/uds-lsv/GermEval-2018-Data (last checked: 09.05.2021)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlBmABDxfqII"
      },
      "source": [
        "wiki detox..https://colab.research.google.com/github/tensorflow/fairness-indicators/blob/master/g3doc/tutorials/Fairness_Indicators_TFCO_Wiki_Case_Study.ipynb#scrollTo=y6T5tlXcdW7J "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3xfitNdliBI"
      },
      "source": [
        "#import matplotlib.pyplot as plt -> f√ºr evtl Visualisierungen\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import string\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from keras import losses \n",
        "from keras import optimizers \n",
        "from keras import metrics \n",
        "\n",
        "#!pip install Tokenizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "#!pip install pad_sequences\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import preprocessing\n",
        "#from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTWJQ1iga_vS"
      },
      "source": [
        "Maximale Satzl√§nge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bq08Me5la_Cc"
      },
      "source": [
        "\n",
        "max_length = 60"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVYBMvYSotTH"
      },
      "source": [
        "url = \"https://github.com/uds-lsv/GermEval-2018-Data/archive/master.zip\"\n",
        "\n",
        "dataset = tf.keras.utils.get_file(\"GermEval-2018-Data-master.zip\", url, \n",
        "                                   extract=True, cache_dir='.',\n",
        "                                    cache_subdir='')\n",
        "\n",
        "dataset_dir = os.path.join(os.path.dirname(dataset), 'GermEval-2018-Data-master')\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cS14OUtfo34V"
      },
      "source": [
        "#os.listdir(dataset_dir)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2X429K6hpOVm"
      },
      "source": [
        "training_file = os.path.join(dataset_dir, 'germeval2018.training.txt')\n",
        "\n",
        "testing_file = os.path.join(dataset_dir, 'germeval2018.test.txt')\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uq8fG3LNtn_m"
      },
      "source": [
        "###Aufbereitung\n",
        "txt-Dateien lesen, und dabei jede Zeile splitten und teilen\n",
        "Twitter-Handler entfernen?\n",
        "Labels von S√§tzen trennen, Labels in eigenen Array packen.\n",
        "\n",
        "####Ressourcen\n",
        "* https://www.w3schools.com/python/gloss_python_if_statement.asp\n",
        "* https://stackabuse.com/using-regex-for-text-manipulation-in-python/\n",
        "* https://www.tutorialspoint.com/python/string_splitlines.htm \n",
        "* https://note.nkmk.me/en/python-split-rsplit-splitlines-re/ \n",
        "* https://www.w3schools.com/python/python_regex.asp \n",
        "\n",
        "g√§be bei keras tf.keras.preprocessing.text_dataset_from_directory, aber daf√ºr m√ºssten die Daten auf bestimmte Weise in Verzeichnis organisiert sein, hier nicht der Fall.\n",
        "\n",
        "\n",
        "Einteilung der Daten: Testdaten\n",
        "Trainingsdaten -> noch ca 500 f√ºr Validierungsdaten\n",
        "\n",
        "labels -> \"other\", also nicht-negative Aussagen bekommen \"0\", negative Aussagen bekommen \"1\"\n",
        "\n",
        " Regex f√ºr Emojis  ->\n",
        "\n",
        "(\\u00a9|\\u00ae|[\\u2000-\\u3300]|\\ud83c[\\ud000-\\udfff]|\\ud83d[\\ud000-\\udfff]|\\ud83e[\\ud000-\\udfff])\n",
        "\n",
        "genommen von https://www.regextester.com/106421 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Py_cwD4eZkXo"
      },
      "source": [
        "def remove_clutter(string):\n",
        "   string = re.sub(\"@[^\\s]+\",\" \",string)\n",
        "   string = re.sub(\"#[^\\s]+\",\" \", string)\n",
        "   string = re.sub(\"\\u00a9\",\" \", string)\n",
        "   string = re.sub(\"\\u00ae\",\" \", string)\n",
        "   string = re.sub(\"[\\u2000-\\u3300]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83c[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83d[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83e[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"üòú\", \" \",string)\n",
        "   string = re.sub(\"üç´\", \" \",string)\n",
        "   string = re.sub(\"üòÅ\", \" \",string)\n",
        "   string = re.sub(\"üêñ\", \" \",string)\n",
        "   string = re.sub(\"üò°\", \" \",string)\n",
        "   string = re.sub(\"üòá\", \" \",string)\n",
        "   string = re.sub(\"üò¨\", \" \",string)\n",
        "   string = re.sub(\"üòÉ\", \" \",string)\n",
        "   string = re.sub(\"üòÇ\", \" \",string)\n",
        "   string = re.sub(\"üíô\", \" \",string)  \n",
        "   string = re.sub(\"üòõ\", \" \",string)\n",
        "   string = re.sub(\"üôè\", \" \",string)\n",
        "   string = re.sub(\"üëç\", \" \",string)\n",
        "   string = re.sub(\"üñï\", \" \",string)\n",
        "   string = re.sub(\"üòâ\", \" \",string)\n",
        "   string = re.sub(\"üí©\", \" \",string)\n",
        "   string = re.sub(\"ü§¢\", \" \",string)\n",
        "   string = re.sub(\"üëè\", \" \",string)\n",
        "   string = re.sub(\"üò®\", \" \",string)\n",
        "   string = re.sub(\"ü§£\", \" \",string)\n",
        "   string = re.sub(\"ü§°\", \" \",string)\n",
        "   string = re.sub(\"üòà\", \" \",string)\n",
        "   string = re.sub(\"üíÉüèΩ\", \" \",string)\n",
        "   string = re.sub(\"üëπ\", \" \",string)\n",
        "   string = re.sub(\"ü§ò\", \" \",string)\n",
        "   string = re.sub(\"üò±\", \" \",string)\n",
        "   string = re.sub(\"ü§î\", \" \",string) \n",
        "   string = re.sub(\"üåà\", \" \",string) \n",
        "   string = re.sub(\"üíï\", \" \",string) \n",
        "   string = re.sub(\"üë©‚Äç‚ù§Ô∏è‚Äçüë©\", \" \",string) \n",
        "   string = re.sub(\"üòç\", \" \",string) \n",
        "   string = re.sub(\"üëÜ\", \" \",string) \n",
        "   string = re.sub(\"üòñ\", \" \",string) \n",
        "   string = re.sub(\"üëá\", \" \",string) \n",
        "   string = re.sub(\"üî•\", \" \",string) \n",
        "   string = re.sub(\"üòò\", \" \",string) \n",
        "   string = re.sub(\"üéâ\", \" \",string) \n",
        "   string = re.sub(\"ü§¨\", \" \",string) \n",
        "   string = re.sub(\"üëä\", \" \",string)\n",
        "   string = re.sub(\"üá©üá™\", \" \",string)  \n",
        "   string = re.sub(\"üíî\", \" \",string)\n",
        "   string = re.sub(\"üôà\", \" \",string)\n",
        "   string = re.sub(\"ü§Ø\", \" \",string)\n",
        "   string = re.sub(\"üêü\", \" \",string)\n",
        "   string = re.sub(\"üõ∂\", \" \",string)\n",
        "   string = re.sub(\"üòä\", \" \",string)\n",
        "   string = re.sub(\"üòì\", \" \",string)\n",
        "   string = re.sub(\"üò≥\", \" \",string)\n",
        "   string = re.sub(\"üöÄ\", \" \",string)\n",
        "   string = re.sub(\"üëé\", \" \",string)\n",
        "   string = re.sub(\"üòé\", \" \",string)\n",
        "   string = re.sub(\"üê∏\", \" \",string)\n",
        "   string = re.sub(\"üìà\", \" \",string)\n",
        "   string = re.sub(\"üôÇ\", \" \",string)\n",
        "   string = re.sub(\"üòÖ\", \" \",string)\n",
        "   string = re.sub(\"üòÜ\", \" \",string)\n",
        "   string = re.sub(\"üôéüèø\", \" \",string)\n",
        "   string = re.sub(\"üëéüèΩ\", \" \",string)\n",
        "   string = re.sub(\"ü§≠\", \" \",string)\n",
        "   string = re.sub(\"üò§\", \" \",string)\n",
        "   string = re.sub(\"üòö\", \" \",string)\n",
        "   string = re.sub(\"üòä\", \" \",string)\n",
        "   string = re.sub(\"üò≤\", \" \",string)\n",
        "   string = re.sub(\"ü§Æ\", \" \",string)\n",
        "   string = re.sub(\"üôÑ\", \" \",string)\n",
        "   string = re.sub(\"ü§ë\", \" \",string)\n",
        "   string = re.sub(\"üéÖ\", \" \",string)\n",
        "   string = re.sub(\"üëã\", \" \",string)\n",
        "   string = re.sub(\"üí™\", \" \",string)\n",
        "   string = re.sub(\"üòÑ\", \" \",string)\n",
        "   string = re.sub(\"üßê\", \" \",string)\n",
        "   string = re.sub(\"üò†\", \" \",string)\n",
        "   string = re.sub(\"üéà\", \" \",string)\n",
        "   string = re.sub(\"üöÇ\", \" \",string)\n",
        "   string = re.sub(\"üòä\", \" \",string)\n",
        "   string = re.sub(\"üöá\", \" \",string)\n",
        "   string = re.sub(\"üöä\", \" \",string)\n",
        "   string = re.sub(\"ü§∑\", \" \",string)\n",
        "   string = re.sub(\"üò•\", \" \",string)\n",
        "   string = re.sub(\"üôÉ\", \" \",string)\n",
        "   string = re.sub(\"üî©\", \" \",string)\n",
        "   string = re.sub(\"üîß\", \" \",string)\n",
        "   string = re.sub(\"üî®\", \" \",string)\n",
        "   string = re.sub(\"üõ†\", \" \",string)\n",
        "   string = re.sub(\"üíì\", \" \",string)\n",
        "   string = re.sub(\"üí°\", \" \",string)\n",
        "   string = re.sub(\"üç∏\", \" \",string)\n",
        "   string = re.sub(\"ü•É\", \" \",string)\n",
        "   string = re.sub(\"ü•Ç\", \" \",string)\n",
        "   string = re.sub(\"üò∑\", \" \",string)\n",
        "   string = re.sub(\"ü§ê\", \" \",string)\n",
        "   string = re.sub(\"üåé\", \" \",string)\n",
        "   string = re.sub(\"üëë\", \" \",string)\n",
        "   string = re.sub(\"ü§õ\", \" \",string)\n",
        "   string = re.sub(\"üòÄ\", \" \",string)\n",
        "   string = re.sub(\"üõ§\", \" \",string)\n",
        "   string = re.sub(\"üéÑ\", \" \",string)\n",
        "   string = re.sub(\"üì¥\", \" \",string)\n",
        "   string = re.sub(\"üå≠\", \" \",string)\n",
        "   string = re.sub(\"ü§ï\", \" \",string)\n",
        "   string = re.sub(\"üò≠\", \" \",string)\n",
        "   string = re.sub(\"üçæ\", \" \",string)\n",
        "   string = re.sub(\"üçû\", \" \",string)\n",
        "   string = re.sub(\"ü§¶\", \" \",string)\n",
        "   string = re.sub(\"ü§Ø\", \" \",string)\n",
        "   string = re.sub(\"üïØÔ∏è\", \" \",string)\n",
        "\n",
        "   string = re.sub(\"OTHER|OFFENSE|ABUSE|INSULT\",\" \",string)\n",
        "   return string"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5asMgo4LtnRg"
      },
      "source": [
        "statementsForTraining = []\n",
        "sentimentsForTraining = []\n",
        "\n",
        "\n",
        "fileToRead = open(training_file, 'r')\n",
        "\n",
        "while True:\n",
        "  #next line in file\n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  findSentiment = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "\n",
        "\n",
        "  statementsForTraining.append(line)\n",
        "   #sentimentsForTraining.append(findSentiment.group(0))\n",
        "\n",
        "  if findSentiment.group(0) == \"OTHER\":  \n",
        "    sentimentsForTraining.append(0)\n",
        "  else:\n",
        "    sentimentsForTraining.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        " #print(\"{}: {}\".format(count,line.strip()))\n",
        "  \n",
        " # print(sentiment.group(0))\n",
        " \n",
        "fileToRead.close()\n",
        "\n",
        "training_sentences = statementsForTraining\n",
        "training_labels = sentimentsForTraining\n",
        "\n",
        "#print(training_sentences[9])\n",
        "#print(training_labels[9])\n",
        "\n",
        "#print(len(training_sentences))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsqZPENb98gD"
      },
      "source": [
        "##do the same with testdata\n",
        "statementsForTesting = []\n",
        "sentimentsForTesting = []\n",
        "\n",
        "fileToRead = open(testing_file, 'r')\n",
        "\n",
        "while True:\n",
        "  #next line in file\n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  sent = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "\n",
        "    \n",
        "\n",
        "  statementsForTesting.append(line)\n",
        "  #print(len(line))\n",
        "  #sentimentsForTesting.append(sent.group(0))\n",
        "\n",
        "  if sent.group(0) == \"OTHER\": \n",
        "    sentimentsForTesting.append(0)\n",
        "  else:\n",
        "    sentimentsForTesting.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        "\n",
        "fileToRead.close()\n",
        "\n",
        "\n",
        "testing_sentences = statementsForTesting\n",
        "testing_labels = sentimentsForTesting\n",
        "#print(len(testing_sentences))\n",
        "#print(testing_sentences)   \n",
        "#print(testing_labels)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRUvDLD5bMbO"
      },
      "source": [
        "Padding -> im Prinzip die S√§tze alle auf die gleiche L√§nge bringen (in Theorieteil n√§her drauf eingehen) -> maxlen-Paramter ist f√ºr pad_sequences vorhanden, wenn nicht gesetzt -> alles wird auf die L√§nge des l√§ngsten Satzes aufgef√ºllt -> print(padded(shape)) gibt aus, wie viele Datens√§tze padded wurden und gibt an, wie viele Tokens der l√§ngste Datensatz hat\n",
        "print(padded[x]) gibt einen Satz aus (bereits tokenisiert)\n",
        "\n",
        "Padding -> sowohl f√ºr Trainigs- als auch f√ºr Testdaten\n",
        "\n",
        "Und: Daten als numpy-Arrays speichern (notwendig f√ºr tensorflow).\n",
        "\n",
        " -> Tokenizer https://towardsdatascience.com/text-classification-in-keras-part-2-how-to-use-the-keras-tokenizer-word-representations-fd571674df23 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3hFi7waTv5m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "827636a3-0074-46fd-9373-d6ba1e553a1a"
      },
      "source": [
        "tokenizer = Tokenizer(oov_token=\"OOV\")\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "\n",
        "#creating a word index - nur die Trainigsdaten\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "validation_size = 500\n",
        "\n",
        "\n",
        "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "padded_training = pad_sequences(training_sequences, maxlen=max_length, padding='post')\n",
        "print(len(padded_training))\n",
        "\n",
        "validation_sequences = padded_training[0:validation_size]\n",
        "validation_labels = training_labels[0:validation_size]\n",
        "\n",
        "padded_training = padded_training[validation_size:]\n",
        "training_labels = training_labels[validation_size:]\n",
        "\n",
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
        "padded_testing = pad_sequences(testing_sequences, maxlen=max_length,  padding='post')\n",
        "\n",
        "#print(validation_sequences[499])\n",
        "print(padded_training[0])\n",
        "#print(len(validation_labels))\n",
        "#print(len(training_labels))\n",
        "\n",
        "\n",
        "nppadded_training = np.array(padded_training)\n",
        "nptraining_labels = np.array(training_labels)\n",
        "\n",
        "nppadded_validation = np.array(validation_sequences)\n",
        "npvalidation_labels = np.array(validation_labels)\n",
        "\n",
        "nppadded_testing = np.array(padded_testing)\n",
        "nptesting_labels = np.array(testing_labels)\n",
        "\n",
        "\n",
        "print(len(nppadded_training))\n",
        "print(len(nptraining_labels))\n",
        "print(len(word_index))\n",
        "\n",
        "#print(statementsForTraining[2])\n",
        "#print(nppadded_training[4])\n",
        "#print(nppadded_training.shape)\n",
        "#print(nptraining_labels[4])\n",
        "#print(nppadded_testing.shape)\n",
        "#print(word_index) \n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5009\n",
            "[  12 3982   11   41 6706 1040    4    5  202   39    3 2922   49 1360\n",
            "  810  495 3983    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0]\n",
            "4509\n",
            "4509\n",
            "15059\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tL3owrc8THkT"
      },
      "source": [
        "\n",
        "Dann: Embedding mit entweder word2vec oder glove\n",
        "Word2vec-Daten sind hier: http://vectors.nlpl.eu/repository/#\n",
        "Glove -> https://nlp.stanford.edu/projects/glove/ Da mal den Twitter-Vector runtergeladen\n",
        "Wenn Daten in GoogleDrive sind (w√§re auch via url m√∂glich..), muss Drive gemounted werden ( https://buomsoo-kim.github.io/colab/2020/05/09/Colab-mounting-google-drive.md/ ) aber auch hier https://enjoymachinelearning.com/posts/colab-with-google-drive/\n",
        "\n",
        "Die Word2vec vectors: http://vectors.nlpl.eu/repository/# \n",
        "\n",
        "glove-zitat:\n",
        "Citing GloVe\n",
        "\n",
        "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. [pdf] [bib]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zuO7T9ZTG57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d587949f-d669-442c-ceee-5083cadf7d99"
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount(\"/content/drive\")\n",
        "os.listdir(\"/content/drive/MyDrive/Colab Notebooks\")\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['germeval_training.txt',\n",
              " 'glove.twitter.27B.50d.txt',\n",
              " 'glove.twitter.27B.200d.txt',\n",
              " 'glove.6B.200d.txt',\n",
              " 'glove.840B.300d.txt',\n",
              " 'tensorboard.gdoc',\n",
              " 'keras.gdoc',\n",
              " 'Vectorization CNN embedded_limited_vocab.ipynb',\n",
              " 'glove.42B.300d.txt',\n",
              " 'Embedding Glove Vergleich.ipynb',\n",
              " 'CNN embedded_limited_vocab.ipynb',\n",
              " 'LSTM_limited_vocab.ipynb',\n",
              " 'LSTM.ipynb',\n",
              " 'CNN embedded.ipynb']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7ToKO-sZLHK"
      },
      "source": [
        "\n",
        "Keras-Doc : https://keras.io/examples/nlp/pretrained_word_embeddings/#load-pretrained-word-embeddings \n",
        "embedding mit initializers.. weights m√ºsste auch funktionieren\n",
        "\n",
        "Diese erstellte Matrix mit Embedding dann in die Embedding-Schicht einbinden,  Trainable auf False, weil sich die Werte nicht durch Training anpassen sollen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AShIVfC7ZQAH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e0c5398-47c7-4dde-9d6f-45f22a154988"
      },
      "source": [
        "#Gr√∂√üe Vokabel -> wordindex + 2 (weil padding + OOV) \n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "vocabulary_size = len(word_index)+2\n",
        "\n",
        "# dann erstell ich ein W√∂rterbuch mit Namen \"embedding_vector\", dort sind dann\n",
        "#die keys drinnen, die in glove-Datei drinnen sind mit dem entsprechenden Key\n",
        "\n",
        "embedding_index_glove = {}\n",
        "f = open('/content/drive/MyDrive/Colab Notebooks/glove.twitter.27B.200d.txt')\n",
        "for line in f:\n",
        "  value = line.split()\n",
        "  word = value[0]\n",
        "  coef = np.asarray(value[1:],dtype='float32')\n",
        "  embedding_index_glove[word] = coef\n",
        "\n",
        "print(\"%d gefunden: \"% len(embedding_index_glove))\n",
        "\n",
        "#Dann noch eine Embedding-Matrix erstellen\n",
        "#zweiter Wert = Embedding-Dimension der Datei, in dem Fall 200\n",
        "\n",
        "glove_matrix = np.zeros((vocabulary_size,200))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    embedding_value = embedding_index_glove.get(word)\n",
        "    if embedding_value is not None:\n",
        "      glove_matrix[index] = embedding_value\n",
        "      hits+=1\n",
        "    else:\n",
        "      misses+=1\n",
        "\n",
        "print(\"hits %d and %d misses\"%(hits,misses))\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1193514 gefunden: \n",
            "hits 6747 and 8312 misses\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZmvOfwhV4N5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1101b789-4ed6-4174-926f-f02ab8855008"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "print(\"vocab size: %d\"%vocabulary_size)\n",
        "CNN1605210250AE = tf.keras.Sequential()\n",
        "#Embedding -> hier dann auf das embedding verweisen, Input_dim -> die Anzahl der W√∂rter im word_index, output -> in dem Fall passend zum verwendeten Vektor\n",
        "#input-length -> auf 60  gepadded, trainable -> nein, weil nichts ver√§ndert werden soll\n",
        "#embeddings_initializer=keras.initializers.Constant(glove_matrix) vs weights = [glove_matrix]\n",
        "#Convolutional layers => filters = neurons.. mit 100? 265?\n",
        "#CNN1605210250AE.add(tf.keras.layers.Embedding(input_dim=vocabulary_size, output_dim=200, input_length=max_length))\n",
        "CNN1605210250AE.add(tf.keras.layers.Embedding(vocabulary_size, output_dim=200, input_length=60, embeddings_initializer = keras.initializers.Constant(glove_matrix), trainable= False))\n",
        "CNN1605210250AE.add(tf.keras.layers.Dropout(0.4))\n",
        "CNN1605210250AE.add(tf.keras.layers.Conv1D(filters=50, kernel_size=3, padding=\"valid\", activation=\"relu\"))\n",
        "CNN1605210250AE.add(tf.keras.layers.MaxPooling1D())\n",
        "CNN1605210250AE.add(tf.keras.layers.Conv1D(filters=50, kernel_size=3, padding=\"valid\", activation=\"relu\"))\n",
        "CNN1605210250AE.add(tf.keras.layers.GlobalAveragePooling1D())\n",
        "CNN1605210250AE.add(tf.keras.layers.Flatten())\n",
        "CNN1605210250AE.add(tf.keras.layers.Dense(260, activation=\"relu\"))\n",
        "CNN1605210250AE.add(tf.keras.layers.Dropout(0.4))\n",
        "CNN1605210250AE.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "CNN1605210250AE.summary()\n",
        "\n",
        "#nppadded_training = np.asmatrix(nppadded_training) not necessary\n",
        "#nppadded_testing = np.asmatrix(nppadded_testing)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab size: 15061\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 60, 200)           3012200   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 60, 200)           0         \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 58, 50)            30050     \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 29, 50)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 27, 50)            7550      \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 260)               13260     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 260)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 261       \n",
            "=================================================================\n",
            "Total params: 3,063,321\n",
            "Trainable params: 51,121\n",
            "Non-trainable params: 3,012,200\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEr4OzT-iHDe"
      },
      "source": [
        "#model.layers[2].get_weights()[0].shape\n",
        "#weights=np.random.rand(5,200,100)\n",
        "#bias=np.random.rand(100)\n",
        "#model.layers[2].set_weights([weights, bias])\n",
        "\n",
        "#model.layers[2].get_weights()[0]\n",
        "#https://androidkt.com/set-custom-weights-keras-using-numpy-array/"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UB7_3VPYesr9"
      },
      "source": [
        "F1-Score f√ºr jede Epoche https://aakashgoel12.medium.com/how-to-add-user-defined-function-get-f1-score-in-keras-metrics-3013f979ce0d\n",
        "\n",
        "Sehr gute Ressource f√ºr die verschiedenen Scores und Metriken https://neptune.ai/blog/evaluation-metrics-binary-classification#10  das und aakas verwendet\n",
        "\n",
        "hier: je eine Funktion f√ºr Recall, Precision, f1 https://neptune.ai/blog/keras-metrics \n",
        "\n",
        "https://keras.rstudio.com/reference/k_ones_like.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygyrbFJaMV9B"
      },
      "source": [
        "import keras.backend as K\n",
        "\n",
        "def metrics_recall(data_true, data_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(data_true,0,1)))\n",
        "\n",
        "    recall = true_positives / (possible_positives+K.epsilon())\n",
        "    return recall\n",
        "\n",
        "\n",
        "def metrics_precision(data_true, data_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "\n",
        "    positives_predicted = K.sum(K.round(K.clip(data_pred,0,1)))\n",
        "    precision = true_positives / (positives_predicted+K.epsilon())\n",
        "    return precision\n",
        "\n",
        "\n",
        "def metrics_f1(data_true, data_pred):\n",
        "    precision_data = metrics_precision(data_true, data_pred)\n",
        "    recall_data = metrics_recall(data_true, data_pred)\n",
        "    return 2*(precision_data*recall_data)/(precision_data+recall_data+K.epsilon())"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1ctlBrnuYJz"
      },
      "source": [
        "https://aakashgoel12.medium.com/how-to-add-user-defined-function-get-f1-score-in-keras-metrics-3013f979ce0d"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AfPD3_bWCm0"
      },
      "source": [
        "#CNN1605210250AE.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',metrics_recall,metrics_precision,metrics_f1])\n",
        "CNN1605210250AE.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',metrics_recall,metrics_precision,metrics_f1])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpChKUY-QEWI"
      },
      "source": [
        "https://www.tensorflow.org/tensorboard/tensorboard_in_notebooks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJfMgUhHBoD1"
      },
      "source": [
        "#%load_ext tensorboard\n",
        "#nur einmal pro Sitzung notwendig\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ISmMXLqP8Hc"
      },
      "source": [
        "\n",
        "logs_base_dir = \"./logs\"\n",
        "callbackForTB = tf.keras.callbacks.TensorBoard(logs_base_dir)\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ehh-EMXUQh8r"
      },
      "source": [
        "Early Stopping as defined in keras tensorflow documentation\n",
        "https://www.tensorflow.org/guide/keras/train_and_evaluate "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BY_t-PeQEjy"
      },
      "source": [
        "callbackEarlyStopping = [\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_loss\",\n",
        "        mode=\"min\",\n",
        "        patience=3,\n",
        "        verbose=1,\n",
        "    )\n",
        "]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2CHbXiP1LsF"
      },
      "source": [
        "training_epochs = 25\n",
        "batch_size = 40\n",
        "validation_split=0.2"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abV-QAxfW48r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5aad7184-6f03-4b9b-e017-bbb06624eda7"
      },
      "source": [
        "#Werte der Convolutional-Schichten variieren (Filter), Batch-Size variieren, kernel-size..\n",
        "CNN1605210250AE.fit(nppadded_training, nptraining_labels, batch_size=batch_size, validation_split=validation_split, epochs=training_epochs, callbacks=[callbackForTB])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "91/91 [==============================] - 4s 32ms/step - loss: 0.6495 - accuracy: 0.6615 - metrics_recall: 0.0082 - metrics_precision: 0.0093 - metrics_f1: 0.0083 - val_loss: 0.6328 - val_accuracy: 0.6718 - val_metrics_recall: 0.0000e+00 - val_metrics_precision: 0.0000e+00 - val_metrics_f1: 0.0000e+00\n",
            "Epoch 2/25\n",
            "91/91 [==============================] - 3s 33ms/step - loss: 0.6392 - accuracy: 0.6626 - metrics_recall: 0.0000e+00 - metrics_precision: 0.0000e+00 - metrics_f1: 0.0000e+00 - val_loss: 0.6271 - val_accuracy: 0.6718 - val_metrics_recall: 0.0000e+00 - val_metrics_precision: 0.0000e+00 - val_metrics_f1: 0.0000e+00\n",
            "Epoch 3/25\n",
            "91/91 [==============================] - 3s 33ms/step - loss: 0.6197 - accuracy: 0.6637 - metrics_recall: 0.0445 - metrics_precision: 0.1480 - metrics_f1: 0.0597 - val_loss: 0.5995 - val_accuracy: 0.7051 - val_metrics_recall: 0.1776 - val_metrics_precision: 0.7663 - val_metrics_f1: 0.2807\n",
            "Epoch 4/25\n",
            "91/91 [==============================] - 3s 33ms/step - loss: 0.5943 - accuracy: 0.6795 - metrics_recall: 0.1923 - metrics_precision: 0.5477 - metrics_f1: 0.2399 - val_loss: 0.6089 - val_accuracy: 0.6929 - val_metrics_recall: 0.4125 - val_metrics_precision: 0.5539 - val_metrics_f1: 0.4589\n",
            "Epoch 5/25\n",
            "91/91 [==============================] - 3s 33ms/step - loss: 0.5753 - accuracy: 0.6973 - metrics_recall: 0.2801 - metrics_precision: 0.5656 - metrics_f1: 0.3351 - val_loss: 0.5714 - val_accuracy: 0.6996 - val_metrics_recall: 0.2709 - val_metrics_precision: 0.6193 - val_metrics_f1: 0.3629\n",
            "Epoch 6/25\n",
            "91/91 [==============================] - 3s 31ms/step - loss: 0.5465 - accuracy: 0.7186 - metrics_recall: 0.3847 - metrics_precision: 0.6768 - metrics_f1: 0.4602 - val_loss: 0.5574 - val_accuracy: 0.7007 - val_metrics_recall: 0.4912 - val_metrics_precision: 0.5600 - val_metrics_f1: 0.5056\n",
            "Epoch 7/25\n",
            "91/91 [==============================] - 3s 33ms/step - loss: 0.5358 - accuracy: 0.7286 - metrics_recall: 0.4478 - metrics_precision: 0.6474 - metrics_f1: 0.4912 - val_loss: 0.5530 - val_accuracy: 0.7129 - val_metrics_recall: 0.4430 - val_metrics_precision: 0.5942 - val_metrics_f1: 0.4912\n",
            "Epoch 8/25\n",
            "91/91 [==============================] - 3s 31ms/step - loss: 0.5191 - accuracy: 0.7416 - metrics_recall: 0.4644 - metrics_precision: 0.7019 - metrics_f1: 0.5255 - val_loss: 0.5706 - val_accuracy: 0.6807 - val_metrics_recall: 0.6356 - val_metrics_precision: 0.5107 - val_metrics_f1: 0.5555\n",
            "Epoch 9/25\n",
            "91/91 [==============================] - 3s 33ms/step - loss: 0.4997 - accuracy: 0.7533 - metrics_recall: 0.5221 - metrics_precision: 0.6834 - metrics_f1: 0.5676 - val_loss: 0.5295 - val_accuracy: 0.7228 - val_metrics_recall: 0.3538 - val_metrics_precision: 0.6676 - val_metrics_f1: 0.4318\n",
            "Epoch 10/25\n",
            "91/91 [==============================] - 3s 33ms/step - loss: 0.4814 - accuracy: 0.7666 - metrics_recall: 0.5477 - metrics_precision: 0.7263 - metrics_f1: 0.6022 - val_loss: 0.5302 - val_accuracy: 0.7151 - val_metrics_recall: 0.4331 - val_metrics_precision: 0.6078 - val_metrics_f1: 0.4866\n",
            "Epoch 11/25\n",
            "91/91 [==============================] - 3s 31ms/step - loss: 0.4568 - accuracy: 0.7810 - metrics_recall: 0.5940 - metrics_precision: 0.7211 - metrics_f1: 0.6266 - val_loss: 0.5376 - val_accuracy: 0.7284 - val_metrics_recall: 0.3733 - val_metrics_precision: 0.6268 - val_metrics_f1: 0.4527\n",
            "Epoch 12/25\n",
            "91/91 [==============================] - 3s 31ms/step - loss: 0.4437 - accuracy: 0.7923 - metrics_recall: 0.6190 - metrics_precision: 0.7553 - metrics_f1: 0.6547 - val_loss: 0.5981 - val_accuracy: 0.6608 - val_metrics_recall: 0.7507 - val_metrics_precision: 0.4838 - val_metrics_f1: 0.5811\n",
            "Epoch 13/25\n",
            "91/91 [==============================] - 3s 33ms/step - loss: 0.4166 - accuracy: 0.8062 - metrics_recall: 0.6455 - metrics_precision: 0.7758 - metrics_f1: 0.6815 - val_loss: 0.6274 - val_accuracy: 0.6508 - val_metrics_recall: 0.7682 - val_metrics_precision: 0.4737 - val_metrics_f1: 0.5781\n",
            "Epoch 14/25\n",
            "91/91 [==============================] - 3s 31ms/step - loss: 0.4017 - accuracy: 0.8151 - metrics_recall: 0.6562 - metrics_precision: 0.7615 - metrics_f1: 0.6822 - val_loss: 0.5539 - val_accuracy: 0.7184 - val_metrics_recall: 0.3853 - val_metrics_precision: 0.6324 - val_metrics_f1: 0.4605\n",
            "Epoch 15/25\n",
            "91/91 [==============================] - 3s 33ms/step - loss: 0.3835 - accuracy: 0.8240 - metrics_recall: 0.6743 - metrics_precision: 0.7858 - metrics_f1: 0.7081 - val_loss: 0.5582 - val_accuracy: 0.7129 - val_metrics_recall: 0.6111 - val_metrics_precision: 0.5545 - val_metrics_f1: 0.5695\n",
            "Epoch 16/25\n",
            "91/91 [==============================] - 3s 37ms/step - loss: 0.3756 - accuracy: 0.8228 - metrics_recall: 0.7031 - metrics_precision: 0.7839 - metrics_f1: 0.7155 - val_loss: 0.5501 - val_accuracy: 0.7184 - val_metrics_recall: 0.5057 - val_metrics_precision: 0.5899 - val_metrics_f1: 0.5252\n",
            "Epoch 17/25\n",
            "91/91 [==============================] - 3s 33ms/step - loss: 0.3471 - accuracy: 0.8459 - metrics_recall: 0.7356 - metrics_precision: 0.8014 - metrics_f1: 0.7557 - val_loss: 0.5650 - val_accuracy: 0.7195 - val_metrics_recall: 0.6018 - val_metrics_precision: 0.5696 - val_metrics_f1: 0.5698\n",
            "Epoch 18/25\n",
            "91/91 [==============================] - 3s 33ms/step - loss: 0.3373 - accuracy: 0.8450 - metrics_recall: 0.7264 - metrics_precision: 0.7932 - metrics_f1: 0.7452 - val_loss: 0.5641 - val_accuracy: 0.7273 - val_metrics_recall: 0.5735 - val_metrics_precision: 0.5889 - val_metrics_f1: 0.5637\n",
            "Epoch 19/25\n",
            "91/91 [==============================] - 3s 33ms/step - loss: 0.3331 - accuracy: 0.8544 - metrics_recall: 0.7598 - metrics_precision: 0.8078 - metrics_f1: 0.7723 - val_loss: 0.5815 - val_accuracy: 0.7284 - val_metrics_recall: 0.4801 - val_metrics_precision: 0.6214 - val_metrics_f1: 0.5208\n",
            "Epoch 20/25\n",
            "91/91 [==============================] - 3s 35ms/step - loss: 0.3151 - accuracy: 0.8608 - metrics_recall: 0.7745 - metrics_precision: 0.8210 - metrics_f1: 0.7846 - val_loss: 0.5899 - val_accuracy: 0.7129 - val_metrics_recall: 0.5226 - val_metrics_precision: 0.5650 - val_metrics_f1: 0.5279\n",
            "Epoch 21/25\n",
            "91/91 [==============================] - 3s 33ms/step - loss: 0.3053 - accuracy: 0.8675 - metrics_recall: 0.7881 - metrics_precision: 0.8167 - metrics_f1: 0.7908 - val_loss: 0.6145 - val_accuracy: 0.7140 - val_metrics_recall: 0.5069 - val_metrics_precision: 0.5675 - val_metrics_f1: 0.5189\n",
            "Epoch 22/25\n",
            "91/91 [==============================] - 3s 33ms/step - loss: 0.3005 - accuracy: 0.8678 - metrics_recall: 0.7800 - metrics_precision: 0.8340 - metrics_f1: 0.7938 - val_loss: 0.5921 - val_accuracy: 0.7129 - val_metrics_recall: 0.5202 - val_metrics_precision: 0.5652 - val_metrics_f1: 0.5276\n",
            "Epoch 23/25\n",
            "91/91 [==============================] - 3s 34ms/step - loss: 0.2808 - accuracy: 0.8794 - metrics_recall: 0.7961 - metrics_precision: 0.8303 - metrics_f1: 0.8051 - val_loss: 0.7023 - val_accuracy: 0.7173 - val_metrics_recall: 0.3275 - val_metrics_precision: 0.6176 - val_metrics_f1: 0.4107\n",
            "Epoch 24/25\n",
            "91/91 [==============================] - 3s 35ms/step - loss: 0.2834 - accuracy: 0.8775 - metrics_recall: 0.7930 - metrics_precision: 0.8496 - metrics_f1: 0.8062 - val_loss: 0.6263 - val_accuracy: 0.6973 - val_metrics_recall: 0.5932 - val_metrics_precision: 0.5373 - val_metrics_f1: 0.5490\n",
            "Epoch 25/25\n",
            "91/91 [==============================] - 3s 34ms/step - loss: 0.2918 - accuracy: 0.8794 - metrics_recall: 0.8030 - metrics_precision: 0.8475 - metrics_f1: 0.8085 - val_loss: 0.6295 - val_accuracy: 0.6996 - val_metrics_recall: 0.6985 - val_metrics_precision: 0.5333 - val_metrics_f1: 0.5921\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa62fc64bd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJVL4SBLPB2P"
      },
      "source": [
        "#%tensorboard --logdir {logs_base_dir}"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_LnvWBcnoak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d5db453-27f9-4b43-c893-05ee06f90237"
      },
      "source": [
        "#results = model.evaluate(nppadded_testing, nptesting_labels, batch_size=batch_size)\n",
        "#print(\"test loss, test acc:\",results)\n",
        "\n",
        "(loss,accuracy, metrics_recall,metrics_precision,\n",
        "metrics_f1) = CNN1605210250AE.evaluate(nppadded_testing, nptesting_labels, verbose=1)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "111/111 [==============================] - 1s 7ms/step - loss: 0.6834 - accuracy: 0.6430 - metrics_recall: 0.5570 - metrics_precision: 0.4818 - metrics_f1: 0.5042\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KgjIkhpKmHc"
      },
      "source": [
        "make some predictions of test data and save it to variable. verbose=0 -> do not generate output\n",
        "Gute Quelle: https://deeplizard.com/learn/video/2f-NjDUvZIE "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89GWuxryKlcM"
      },
      "source": [
        "CNN_predictions50AE = CNN1605210250AE.predict(x=nppadded_testing)\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3jPDaDJK_cN"
      },
      "source": [
        "#for p in CNN_predictions50AE:\n",
        " # print(p)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eC9efJy4Lp21"
      },
      "source": [
        "rounded predictions: give prediction value of most likely prediction (0 or 1). Printing the output of rounded prediction shows the prediction made by the model on the data (which output is most likely)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsG-TJuQLvtk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "899f12c6-d5f4-4e20-9ee2-653866d7bb3e"
      },
      "source": [
        "prediction_rounded50AE = np.round(CNN_predictions50AE)\n",
        "#np.argmax(CNN_predictions50AE,axis=-1)\n",
        "\n",
        "#for p in prediction_rounded50AE:\n",
        " # print(p)\n",
        "\n",
        "\n",
        "print(nptesting_labels[500:520])\n",
        "print(prediction_rounded50AE[500:520])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1]\n",
            "[[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egTtgpXgg8a2"
      },
      "source": [
        "https://deeplizard.com/learn/video/km7pxKy4UHU\n",
        "\n",
        "Quelle der def plot_confusion_matrix: https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSDXf7-_MITy"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0AMs1EzhBU1"
      },
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                        normalize=False,\n",
        "                        title='Confusion matrix',\n",
        "                        cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2JgEnlghCtl"
      },
      "source": [
        "cm = confusion_matrix(y_true=nptesting_labels, y_pred=prediction_rounded50AE)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckmF29whhFmX"
      },
      "source": [
        "plot_labels = ['no hatespeech','hatespeech']"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mpSE96rhK7K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "outputId": "dfbb62c1-b249-48bd-dde2-e1ce120b504d"
      },
      "source": [
        "plot_confusion_matrix(cm=cm, classes=plot_labels, title='CNN Confusion 50 25 Epochs')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix, without normalization\n",
            "[[1611  719]\n",
            " [ 542  660]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAAEmCAYAAACzoiEDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZwUxf3/8dd7uVXkRjlEVFCDFwoCSjTeihcaT9SfZzTe5jDeEc9o1Hw1Jh7BAzRGVDxREUEMIogCIqB4oqKcAqJGAYXFz++PqsVm3Z2dXXa3t3c/zzzmwUx1dXfNbPxMzaerqmVmOOecS0dB2g1wzrm6zIOwc86lyIOwc86lyIOwc86lyIOwc86lyIOwc86lyIOwS52kJpKelfSNpGHrcJzjJY2qzLa5tUm6StJDabejNvEgnEGSjpM0RdJ3khZIekHSL+O2qySZpKMT9evHss7x9ZD4uleiThdJOQeN5zrvOjoS2AhoZWZHVfQgZvYfM9uvEtqzFkmd4+f1XeLx58T2RpLul/Q/SQsl/SHHsQ6SNF7S17HuvZKaJrYPkbSy2LnqlXKskyWtLlb3O0ntK/cTcFXJg3DGxP/AbwP+QghcnYA7gf6JakuBq0v7jzdR57pKPm9FbQp8aGaFlXCsqtTczDaIj2sT5VcBXQnvY0/gIkkHlHKMZoTPvT3wC6ADcHOxOjclzrOBma3O0aaJxepuYGbzK/LmXDo8CGeIpGbANcA5ZvakmS0zs1Vm9qyZ/SlRdSSwEjghx+EeALaX9KvKOG/sDd4maX583CapUdy2h6S5kv4oaVHsRZ8St10NXAkcE3txpxX/yZvoidaPr0+W9ImkbyV9Kun4RPn4xH67Spoc0xyTJe2a2DZW0rWSJsTjjJLUuqzPohQnAdea2Vdm9h5wD3BySRXN7GEzG2lmy83sq1i3bwXPm5Ok2ZIulfSupK8kDZbUOLH9dEmzJC2VNDzZg5a0jaTRcdsXki5LHLqhpAfj5zZTUs/EfhdLmhe3fSBp76p4b7WJB+Fs2QVoDDxVRj0D/gwMlNSglDrLCb3a6yvpvJcDfYDuwA5AL+CKxPaNCb3ADsBpwB2SWpjZwNiOR2Mv7r5cDZG0PnA70M/MmgK7AtNKqNcSeD7WbQX8H/C8pFaJascBpwBtgYbAhbnODXwWv0wGFwVsSS2AdsD0RL3pwDZlHKvI7sDMYmVnx+D3pqQj8jxOaY4H9ge2ALYk/k0k7QXcABxNaP9nwCNxW1PgJcKXeXugCzAmccxDY93mwHDgn3G/rYBzgZ3j32Z/YPY6tr/W8yCcLa2AJfn8bDez4cBi4Dc5qv0L6CSpXyWc93jgGjNbZGaLgauB/5fYvipuX2VmI4DvgK3Keh+l+BHYVlITM1tgZsWDGMBBwEdm9m8zKzSzocD7wCGJOoPN7EMzWwE8RvgCKckSYGdCuqEH0BT4T9y2Qfz3m0T9b2KdnCTtS+hFX5kovp2Q2mhL+CIdIilXT7lPzC8XPT4utv2fZjbHzJYSvnAHxPLjgfvNbKqZ/QBcCuyicN3gYGChmf3NzL43s2/N7I3EMceb2YiYJvk34UsXYDXQCOgmqYGZzTaz4u1xxXgQzpYvgdZFP8vzcAWhh9q4pI3xP75r42Ndz9ue0Jsq8lksW3OMYkF8OT8FsLyZ2TLgGOBMYIGk5yVtnUd7itrUIfF6YT7tMbPvzGxKDOZfEHp7+8Ue43ex2oaJXTYEvs31PiT1AR4GjjSzDxPnmmpmX8ZzjSAE+1/nONTrZtY88dii2PY5iefJv8lan4+ZfUf4O3cANgFyBc/in1tjSfXNbBbwO0KOfJGkR/wiYdk8CGfLROAH4LB8KpvZaGAWcHaOaoMJPytz/Yeez3nnE3qKRTrFsopYBqyXeL1xcqOZvWhm+xJ+Rr9PyKuW1Z6iNs2rYJvWakL8tyDmdRfwU2+Q+Lyk3jkAknYk/Iw/1czGlFYvcS6tQ1s3STxP/k3W+nximqcV4fOZA2xekZPFnPcv47EN+GtFjlOXeBDOEDP7hvDT9Q5Jh0laT1IDSf0k3VTKbpcDF+U4ZiEwELh4Hc87FLhCUpuYL70SqOh40mnA7pI6xYuClxZtkLSRpP4xaPxA6In+WMIxRgBbKgyrqy/pGKAb8Fx5GyOpt6StJBXEnPLtwNj4uQA8SHjvLWKv/HRgSCnH2paQaz3PzJ4tYfuRkjaI59qPcHF1eHnbnHCOpI4xR3458GgsHwqcIqm7wgXUvwBvmNlswmfUTtLvFC64NpXUu6wTxc9or3i874EVlPy3cQkehDPGzP4G/IGQalhM6LWcCzxdSv0JwKQyDjuU0Jtbl/NeB0wBZgBvA1MpxxC4YucaTQgWM4A3WTtwFsR2zCcMs/sVcFYJx/iSkNv8I+Fn9kXAwWa2pAJN2pwQOL8F3iEE/wGJ7QMJP98/A14BbjazkaUc649AG+A+/TSuN9lrvoDQG/2aMHTtdDMbm6Ntu+jn44R3Tmx/GBgFfBLbeB2Amb1EyDk/QfjbbwEcG7d9C+xLyJ8vBD4iDL0rSyPgRkIOfSEhr31pzj0c8kXdnaudJM0GfhMDrquhvCfsnHMp8iDsnHMp8nSEc86lyHvCzrk6T2EBpkWS3ilWfp6k9+P07JsS5ZfGKd8fSNo/UX5ALJsl6ZK8zu094ZpJ9ZuYGpY56cpVkm5dO6bdhDpl3pzP+WrpknUZ/7xGvQ03NStckbOOrVj8opmVtqgSknYnDHd80My2jWV7Eob1HWRmP0hqa2aLJHUjjCjqRZj08hJhSjjAh4SRJXOBycAAM3s3V9vynXnlqpkaNqXRVkeXXdFVimHP+5yC6nRUv90q7VhWuKLM/1a+n3ZHzsWZzGxcnLKddBZwY5xZipktiuX9gUdi+aeSZhECMsAsM/sEQNIjsW7OIOzpCOdctklQUC/3I0y7n5J4nJHHkbcEdpP0hqRXEuOvO7D2dPC5say08py8J+ycyz6V2Z9cYmY9y6pUTH2gJWF1wJ2BxyRVaDp3WSdxzrkMU1Fvt7LNBZ60cOFskqQfgdaEGY3JNTk68tOaJKWVl8rTEc657JNyPyrmaeJ0bUlbEtacXkJYy+PYuK7GZoSlRycRLsR1lbSZpIaEaeBlrvvhPWHnXLaJfNIRuQ8hDQX2IOSO5xLWA7kfuD8OW1sJnBR7xTMlPUa44FZIuOPM6nicc4EXgXqE9ZpLXU2viAdh51zGrXs6wswGlLKpxFuEmdn1lHBXmrgG9IjynNuDsHMu+yqeckidB2HnXMZpndMRafIg7JzLNlFVoyOqhQdh51zGeU/YOefSI6Ce94Sdcy49fmHOOefS4ukI55xLl1+Yc865lKzb1OTUeRB2zmWf94Sdcy4tnhN2zrl0eTrCOedSIkFBdkNZdlvunHNFvCfsnHMp8gtzzjmXEvmFOeecS5enI5xzLh0CCgq8J+ycc+lQfGSUB2HnXMYJeTrCOefS4+kI55xLkfeEnXMuJZJQgQdh55xLjfeEnXMuRR6EnXMuLSLT6YjsXlJ0zrlIUs5HHvvfL2mRpHdK2PZHSSapdXwtSbdLmiVphqSdEnVPkvRRfJyUT9s9CDvnMk2IgoKCnI88DAEO+NmxpU2A/YDPE8X9gK7xcQZwV6zbEhgI9AZ6AQMltSjrxB6EnXPZpzIeZTCzccDSEjbdClwEWKKsP/CgBa8DzSW1A/YHRpvZUjP7ChhNCYG9OM8JO+eyTXldmGstaUri9SAzG5TzsFJ/YJ6ZTS92/A7AnMTrubGstPKcPAg75zIvj5TDEjPrme/xJK0HXEZIRVQpT0e4nO4eeDyfjbmBKcMuW6v8rGN/xbQnr+DNxy/n+gv6A9Cy2fqMHHQ+iyf8jVsvPmqt+ledcwgfvXAtiyf8rdrannWfzvqQw/fdZc1j563a8eA9dzDy2Sc5ZM+ebNOxKe9Mn7qm/sqVK7ns92fSf+9eHL5PHya9Ni7F1lcfkfuiXAWHr20BbAZMlzQb6AhMlbQxMA/YJFG3YywrrTwn7wm7nP797Ovc/egr3HvtiWvKdu/ZlYP32I5ex9zIylWFtGmxAQDf/7CKa+58jm5d2rPNFu3WOs6IcW9z96Ov8PYzA6u1/Vm2WZcteWr0RABWr17NHj26sne/Q/h+xXJuv+dhrrrk/LXqP/7wYACeGTOJL5cs4rcn/JrHRozL9LoKeamCIWpm9jbQds0pQiDuaWZLJA0HzpX0COEi3DdmtkDSi8BfEhfj9gMuLetcHoRdThOmfkyndi3XKjvjqN24ZfBoVq4qBGDxV98BsPz7lbw27RM236TNz44z6e3ZVd7W2uz18WPptOnmdOjYqdQ6H3/4Pn36/gqAVq3b0nTDZrwzfSrb75j3r/DMWtfJGpKGAnsQcsdzgYFmdl8p1UcABwKzgOXAKQBmtlTStcDkWO8aMyvpYt9aavlXpKsKXTZtS98dt2Dcgxcy6t4L6NGt9MDgKseIZx7nwMOOzFlnq27b8fKo5yksLGTu57N59+1pLJw/t5pamK51TUeY2QAza2dmDcysY/EAbGadzWxJfG5mdo6ZbWFm25nZlES9+82sS3wMzqftNTIISxoiKff/49au31zS2VXZpnUhaXbRQO/aoH69Alo2W5/dT7yFy259moduOjXtJtVqK1eu5L+jnmf/gw/PWe/Xx57Ixu06cFS/3bhh4MV079mbgnrZvQFmeahAOR81WW1JRzQHzgbuTLshdcG8L77m6THTAJgy8zN+/NFo3WIDlsS0hKtcr/53FN22607rNhvlrFe/fn0uufqva14fd+jedN68S1U3L3XrcPGtRqiSnrCkzpLek3SPpJmSRklqErd1l/R6nO73VI4ZJbtLek3SJ0W9YkkbSBojaaqkt+M4PoAbgS0kTZN0c6z7J0mT43mujmXrS3pe0nRJ70g6JpbPlnRTPOYkSV1ieRtJT8TjTJbUN3Gc+2Pdt4raIamepFvisWdIOi/xfs5LtHvryv3Eq9ezY2fwq523BKBLp7Y0bFDfA3AVGvH0MA487Kgy661YsZzly5cB8Nq4l6lXvx5dtvxFVTevRqiC0RHVpip7wl2BAWZ2uqTHgCOAh4AHgfPM7BVJ1xCm+f2uhP3bAb8EtgaGA48D3wOHm9n/4s/71+OVykuAbc2sO4Ck/eL5exHmywyXtDvQBphvZgfFes0S5/vGzLaTdCJwG3Aw8HfgVjMbL6kT8CLwC+By4GUzO1VSc2CSpJeAE4HOQHczK4zTGIssMbOdYtrkQuA3xd+wpDMI0yChwQb5fMZV7oEbTma3Hl1p3XwDZo28lmvvHsEDT0/kX1cdz5Rhl7Fy1Wp+c+W/19R///mrabp+Yxo2qM8he27PwWffwfufLOT6C/pzTL+erNe4AbNGXsvgpyZy/b9GpPjOsmH58mW8Nu6/XPXX29eUvfTCcK6/4kKWLl3CWScewdbbbM89Dz/D0iWLOf24wygoEG03bs+Nt9+bYsurV01POeQiMyu7VnkPKnUmTN/rGl9fDDQA/gG8bWadYvkWwDAz26nY/kPi/v+Jr781s6aSGhCmEe4O/AhsRRjL1xh4zsy2jfVvAY4Evo6H3AC4AXgVGAU8Guu/GuvPBvYys0/iORaaWStJi4D5iaa1ieccG89ZGMtbEqYsXgfcbWaji72f2UBfM5snqTdwvZntk+szLFivrTXa6uhcVVwlmvr8X8uu5CrNUf12453pUyslcjbaqKt1OP7vOet8eutBb5ZnskZ1qsqe8A+J56uBJuuwf9Ef63hCIOxhZqticGtcwr4CbjCzf/1sQ1jx6EDgOkljzOyauCn5bVT0vADoY2bfFzuGgCPM7INi5fm8n9XUnly8c6mToCDDPeFqHR1hZt8AX0naLRb9P+CVchyiGbAoBuA9gU1j+bdA00S9F4FTJW0AIKmDpLaS2gPLzewh4GYg2QM/JvHvxPh8FLAmryupe+L458VgjKQdY/lo4LeS6sfytQfYOueqQJXMmKs2afTITgLuVpib/QlxoHOe/gM8K+ltYArwPoCZfSlpgsJaoC+Y2Z8k/QKYGP8A3wEnAF2AmyX9CKwCzkocu4WkGYQe64BYdj5wRyyvD4wDzgSuJeSNZ0gqAD4l5JDvBbaM5auAe4B/luP9OecqoIbH2ZyqJCecNUpMSUy7LUU8J1y9PCdcvSozJ9y43ZbW+aR/5KzzwV8PqJM5Yeecq3Ii2zlhD8KEKYlpt8E5V3EehJ1zLi3Kdk7Yg7BzLtOE3/LeOedSJE9HOOdcmrwn7JxzKcn6jDkPws65zMtwR9iDsHMu+zwd4ZxzafF0hHPOpScMUUu7FRXnQdg5l3E1f6W0XDwIO+cyz9MRzjmXFp+27Jxz6QmrqFXr/SkqlQdh51zmZbknnN2vD+eci9b19kaS7pe0KN6dp6jsZknvS5oh6al4Z/WibZdKmiXpA0n7J8oPiGWzJF2ST9s9CDvnMk0KC/jkeuRhCHBAsbLRwLZmtj3wIXBpPF834Fhgm7jPnZLqSaoH3AH0A7oBA2LdnDwIO+cyT8r9KIuZjQOWFisbZWaF8eXrQMf4vD/wiJn9YGafArOAXvExy8w+MbOVwCOxbk6l5oQl/YO1bwNfvNHnl3Vw55yrDvXK7u22ljQl8XqQmQ0qxylOBR6NzzsQgnKRubEMYE6x8t5lHTjXhbkpObY551yNEHq7ZQbhJRW90aeky4FCwt3eK12pQdjMHijWkPXMbHlVNMI559ZFVc3VkHQycDCwt/10a/p5wCaJah1jGTnKS1VmTljSLpLeBd6Pr3eQdGeZrXfOuWpSCRfmfkbSAcBFwKHFOqDDgWMlNZK0GdAVmARMBrpK2kxSQ8LFu+FlnSefccK3AfsXHczMpkvavVzvxjnnqogAsW5dYUlDgT0IueO5wEDCaIhGwOiY7njdzM40s5mSHgPeJaQpzjGz1fE45wIvAvWA+81sZlnnzmuyhpnNKZZzWZ3ne3POuaol5XNhLiczG1BC8X056l8PXF9C+QhgRHnOnU8QniNpV8AkNQAuAN4rz0mcc64qZXnGXD5B+Ezg74QhGPMJXe1zqrJRzjmXLwEFGY7CZQZhM1sCHF8NbXHOuQrJ8lKW+YyO2FzSs5IWx7nVz0javDoa55xzZSlrtlxN7yTnM235YeAxoB3QHhgGDK3KRjnnXHkUSDkfNVk+QXg9M/u3mRXGx0NA46pumHPO5SvLQTjX2hEt49MX4pJsjxDWkjiGcg7BcM65qhIuzKXdiorLdWHuTULQLXp7v01sM+Kybs45lypVfFZcTZBr7YjNqrMhzjlXUbX+bsuStiUsUrwmF2xmD1ZVo5xzLl+1OR0BgKSBhDnV3Qi54H7AeMCDsHOuRqjpF99yyWd0xJHA3sBCMzsF2AFoVqWtcs65PEm1dHREwgoz+1FSoaQNgUWsvWamc86lqlZemEuYEu8yeg9hxMR3wMQqbZVzzpVDDe/s5pTP2hFnx6d3SxoJbGhmM6q2Wc45lx9R81MOueSarLFTrm1mNrVqmuQAdvxFJya88c+0m1FnLPrm+7SbUKdUatBU7U1H/C3HNgP2quS2OOdcheQzwqCmyjVZY8/qbIhzzlWEyOuW9zVWXpM1nHOuJstwDPYg7JzLtrBmcHajsAdh51zm1ctwUjifO2tI0gmSroyvO0nqVfVNc865shXdYy6rM+by+f64E9gFKLol9LfAHVXWIuecK6eCMh41WT7piN5mtpOktwDM7CtJDau4Xc45lxdJtX50xCpJ9Qhjg5HUBvixSlvlnHPlUMMzDjnlE4RvB54C2kq6nrCq2hVV2irnnMuTgPoZ7gmXmS4xs/8AFwE3AAuAw8xsWFU3zDnn8rWut7yXdL+kRZLeSZS1lDRa0kfx3xaxXJJulzRL0ozkEg+STor1P5J0Uj5tz2d0RCdgOfAsMBxYFsuccy59CpM1cj3yMAQ4oFjZJcAYM+sKjImvIdzYomt8nAHcBWtujjwQ6A30AgYWBe5c8klHPM9PN/xsDGwGfABsk8e+zjlXpQTUW8eksJmNk9S5WHF/wl2FAB4AxgIXx/IHzcyA1yU1l9Qu1h1tZksBJI0mBPahuc6dz1KW2yVfx6732aVUd865apdHb7e1pCmJ14PMbFAZ+2xkZgvi84XARvF5B2BOot7cWFZaeU7lnjFnZlMl9S7vfs45VxXyXMBniZn1rOg5zMwkWUX3zyWfG33+IfGyANgJmF8VjXHOuXLL8+JbBXwhqZ2ZLYjphkWxfB5r3+KtYyybx0/pi6LysWWdJJ/JJE0Tj0aEHHH/PPZzzrlqUUXTlocDRSMcTgKeSZSfGEdJ9AG+iWmLF4H9JLWIF+T2i2U55ewJx0kaTc3swgq+Ceecq1IhHbGOx5CGEnqxrSXNJYxyuBF4TNJpwGfA0bH6COBAYBZh5NgpAGa2VNK1wORY75qii3S55Lq9UX0zK5TUt0LvyjnnqoUoYJ1HRwwoZdPeJdQ14JxSjnM/cH95zp2rJzyJkP+dJmk4MAxYljjZk+U5kXPOVQUp20tZ5jM6ojHwJeGeckXjhQ3wIOycqxFq+nKVueQKwm3jyIh3+Cn4FqmSoRrOOVdeovYu4FMP2ABKTLZ4EHbO1Ri1dSnLBWZ2TbW1xDnnKkDU/IXbc8kVhLP71eKcqztq8Y0+fzY0wznnaprKWMAnTaUG4XwGGTvnXE2Q3RDst7x3zmWeKKilF+acc67Gq80X5pxzLhNq64U555yr+VR7Z8w551yN5+kI55xLmfeEnXMuRRmOwR6EnXPZFtIR2Y3CHoSdcxm3TrcwSp0HYedc5mU4BnsQds5lm5TttSOyPLLDpWCrLp3p2X07evfoTt/ePdfadtutf6NJA7FkyRIAhj78H3becXt6dt+OPXbblRnTp6fR5Ez75puvOfOUAezVZwf22qU7b05+HYDB99zJXn12YJ++O/GXqy5bU/+O225m9523Yc/e2/PKy6PTana1k3I/ajLvCbtyG/nSf2nduvVaZXPmzGHM6FFs0qnTmrLOnTdj1Muv0KJFC14c+QLnnHUGr772RnU3N9OuvuxCfrXXftw9eCgrV65kxYrlvPbqK4x+4TleeGUSjRo1YsniRQB8+MF7PPvUMEaPn8oXCxdw/BEHMvaNt6lXr17K76LqKcMX5rwn7CrFRRf+nutvuGmt6aO77LorLVq0AKBX7z7Mmzc3reZl0v/+9w1vTBzPsSecDEDDhg1p1qw5Dw0ZxNkXXEijRo0AaN2mLQCjX3iOQw4/ikaNGtFp08503mwLpk2dXNrha42ipSxzPWoyD8KuXCRxSL/92LVXD+67ZxAAzw5/hvbtO7D9DjuUut+Qwfex//79qquZtcKcz2bTqlVrLjzvDPrt2YeLLjiL5cuW8enHs5g0cQL999uNow/Zl+lTpwCwcME82rXvuGb/jdt3YOGC+Wk1v1p5OqIKSOoMPGdm2+ZZ/zDgQzN7tyrbVRGSTgZ6mtm5abdlXY0ZO54OHTqwaNEiDj5gX7baemtuuvEvPPfCqFL3eWXsf3lg8H2MGTu+GluafasLC3lnxjSuvvH/2LFHL6667I/cefstFBYW8vXXS3n6xXFMf2sKZ//mBMa/+V7azU2VpyNqhsOAbmk3orbr0KEDAG3btuXQww7n1XGv8NnsT+nVYwe26tKZeXPnskuvnVi4cCEAb8+YwVm//Q3DnniGVq1apdn0zNm4fQfate/Ajj16AXDgIYfzzvRptGvfgQMOOgxJdN9pZwoKClj65RI2bteBBfN/SvksnD+Pjdu1T6v51UbkTkV4OmLd1JN0j6SZkkZJaiLpdEmTJU2X9ISk9STtChwK3CxpmqQt4mOkpDclvSppawBJR0l6J+4/LpadLOkZSWMlfSRpYFEDJJ0gaVI87r8k1Yvl+0maKGmqpGGSNojlO0t6LR5/kqSm8VDtY3s+knRTtX6KlWTZsmV8++23a56/NHoUPXruzOfzF/HBrNl8MGs2HTp2ZOKkqWy88cZ8/vnnHHv0r7lv8L/puuWWKbc+e9putDHtOnTk448+BGDCuLF03Wpr9ut3CBPHvwLAJ7M+YtXKlbRs1Zp9DziIZ58axg8//MDnn83m009m0X2nndN8C9WjjFREvjFY0u9jrHlH0lBJjSVtJukNSbMkPSqpYazbKL6eFbd3rmjza2w6IuoKDDCz0yU9BhwBPGlm9wBIug44zcz+IWk4IX3xeNw2BjjTzD6S1Bu4E9gLuBLY38zmSWqeOFcvYFtgOTBZ0vPAMuAYoK+ZrZJ0J3C8pBHAFcA+ZrZM0sXAHyTdCDwKHGNmkyVtCKyIx+8O7Aj8AHwg6R9mNqdqPraqseiLLzjmyMMBKFxdyDHHHsd++x9Qav0brruGpV9+ye/OOxuA+vXrM+GNKdXS1tri6hv+jwvOPIVVq1bSadPO3PKPQTRZb33+dP5v2feXPWjQoCF/++e9SGLLrbtxUP8j2KfvjtSvV59r/3pbHRkZse7jhCV1AM4HupnZihhvjgUOBG41s0ck3Q2cBtwV//3KzLpIOhb4KyFWlFtND8Kfmtm0+PxNoDOwbQy+zYENgBeL7xR7pbsCwxJX6xvFfycAQ+KH/GRit9Fm9mXc/0ngl0Ah0IMQlAGaAIuAPoTUx4RY3hCYCGwFLDCzyQBm9r94PIAxZvZNfP0usCmwVhCWdAZwBrDWUK+aYrPNN2fS1NxjfT+YNXvN87sG3ctdg+6t4lbVbttstwPPjZnws/K/3z24xPrn/eFizvvDxVXdrBqnkhIO9YEmklYB6wELCB234+L2B4CrCEG4f3wO8DjwT0kyM6vISWuyHxLPVxOC4BDgMDObHi947VHCfgXA12bWvfgGMzsz9owPAt6U1KNoU/GqhL/tA2Z2aXKDpEMIQXtAsfLtyvFefvbZm9kgYBBAjx49y/3HdK7OKjsKt5aU/Bk2KP73BkD8ZXwL8Dnh1+soQsfvazMrjNXmAh3i8w7ETpSZFUr6BmgFLClv02t6TrgkTYEFkhoAxyfKv43binqgn0o6CkDBDvH5Fmb2hpldCSwGNon77yuppaQmhIt8E4AxwJGS2sZ9W0raFHgd6CupSyxfX9KWwAdAO0k7x/KmkmJj4HMAABKnSURBVGr6F51zmVcg5XwAS8ysZ+IxKLm/pBaE3u1mQHtgfaD0XFtltr06TlLJ/gy8QQiS7yfKHwH+JOktSVsQAvRpkqYDMwkfMISLd29Legd4DSj6fT0JeAKYATxhZlPicLcrgFGSZgCjgXZmthg4GRgayycCW5vZSkJe6B/xvKOBxlXyKTjn1lAZjzzsQ0h/LjazVYRUZV+geaIj1RGYF5/PI3bg4vZmwJcVaXuN7aWZ2WzChbKi17ckNt9VQv0J/HyI2s++yczs18XLYs52rpkdVkL9RwkX24qXvwz87NJzzAf3KVY8JD6K6hxcfD/nXMWISrnR5+dAH0nrEdIRewNTgP8CRxI6eScBz8T6w+PriXH7yxXJB0MNDsLOOZeXSpgVZ2ZvSHocmEq4IP8W4frM88AjcTDAW8B9cZf7gH9LmgUsJYykqBAPwoCZDSHRU3XOZUtljI4ws4HAwGLFnxCGrxav+z1wVCWc1oOwcy7rVBnpiNR4EHbOZV6GY7AHYedctoULc2m3ouI8CDvnMi/Lq6h5EHbOZZ73hJ1zLi0ZWLg9Fw/CzrnM83SEc86lREBBdmOwB2HnXC3gQdg559Lj6QjnnEuRpyOccy5NHoSdcy4dYc3g7EZhD8LOuWyTpyOccy5dHoSdcy4ta+4jl0kehJ1zmVaO+8jVSB6EnXPZl+Eo7EHYOZd5no5wzrkUZTcEexB2zmWdKuWW96nxIOycyzS/vZFzzqUswzHYg7BzLvv8wpxzzqUpuzGYgrQb4Jxz60Jx7Yhcj/yOo+aSHpf0vqT3JO0iqaWk0ZI+iv+2iHUl6XZJsyTNkLRTRdvvQdg5l3kq4395+jsw0sy2BnYA3gMuAcaYWVdgTHwN0A/oGh9nAHdVtO0ehJ1z2acyHmXtLjUDdgfuAzCzlWb2NdAfeCBWewA4LD7vDzxowetAc0ntKtJ0D8LOucyrhHTEZsBiYLCktyTdK2l9YCMzWxDrLAQ2is87AHMS+8+NZeVve0V2cs65mqOsZIQAWkuaknicUewg9YGdgLvMbEdgGT+lHgAwMwOsslvvoyOcc5mW52SNJWbWM8f2ucBcM3sjvn6cEIS/kNTOzBbEdMOiuH0esEli/46xrNy8J+ycyzwp96MsZrYQmCNpq1i0N/AuMBw4KZadBDwTnw8HToyjJPoA3yTSFuXiPWHnXOZV0j3mzgP+I6kh8AlwCqGj+pik04DPgKNj3RHAgcAsYHmsWyEehJ1zmab8L77lZGbTgJJSFnuXUNeAc9b9rB6EnXO1QYZnzHkQds5lnt/y3jnnUuS3vHfOuTR5EHbOuXSIbC9lqXCRz9U0khYThsRkTWtgSdqNqEOy+nlvamZtKuNAkkYSPodclpjZAZVxvsrmQdhVKklTypiZ5CqRf97Z5zPmnHMuRR6EnXMuRR6EXWUblHYD6hj/vDPOc8LOOZci7wk751yKPAg751yKPAg751yKPAg751yKPAi7GktSvfjvxpKapN2e2kZSQbHX2Z37m2EehF2NI2kzSX3NbLWkQ4BXgdslXZ9222oDSesBmNmPknpIOkJSY/OhUqnwIWquxpE0ALgDOAPYi3Bfr68Jt5/50swuSLF5mSapOTAQeBpYCTwAzAdWAH8GpplZYXotrHu8J+xqHDMbCpwL3Ao0MbMXgTeB64CWkv6VZvsybn1gAXAMcBnQ38z2AN4Czge6S/LVFauRB2FXYxTlJCV1NbOHgd8Be0naI/bOPgRuBJpL6pZiUzNJksxsHvAQ8B7QBegNYGaXAZ8TbvO+U2qNrIM8CLsaw8xM0qHAPZK6m9kTwFXAvZJ+ZWY/EoLHqWb2bpptzZoYgE3SPkBH4BHgHqCvpH4AZnYF8DHwQ3otrXs8J+xqjNi7/Tdwhpm9mSg/EbgZGGBmL6fVvqyLwfZW4AIze1HSJkB/YBtghJk9m2oD6yjP/biapBnweVEAltTAzFaZ2YOSCgHvMVRQHBHxO+AsM/tv7BnPkfQs0Ag4XNLrhMXP/XOuRh6EXWoSP5ELYqphPvC9pF8AH5nZKkm7Azua2d+T+6TZ7oyqBzQkfMYQAu/3wFfAYGBDM1ucUtvqNM8Ju1QkAvDBwPWS/kYYMrUIOAc4U1J/QoCYWbSfB+D8JC5ybiqpkZl9C7wI3CiphZl9H7/gRgKY2ez0Wlu3eU/YpSIG4D2Ba4BjgRcI6YaLgFOBLYCdgXPN7KXUGppR8fM9ELgceEVSW+B2YENggqTBwEnAZWa2NMWm1nl+Yc6lRtJVwHhC8L0OOM7MPk1sb2JmK1JqXqbFi5wPA4cSflnsBBxhZv+TdAzhV8cSM3vVUzzp8p6wS9MCwqy4dsAJZvappFOATmZ2NT5UqtwSAbUxIQh3AfYAjo8BuCfwpJmtKtrHA3C6PCfsqkUiR9lH0t6SegCjgO2Be4HPYtkfgDcgrG2QVnuzJrH4TlHH6nPgOMK05APMbFYcI3wp0CKFJrpSeDrCVRtJ+xPGqd4M3Af0BDoBpxF6vRsBN5vZcP+JnL/ERc59gaOBqcAsoA0hHTEWmE2YbTjQzJ5JqamuBJ6OcFUu9tJaAhcAhwGbEEY8LDSzqZL+SxhC1dTMPvMAXD4xAO8F3EYYC3w5YS2IWwhD0n5H6BlfYWbP+edbs3hP2FUbSVcC3wFHAieb2YeSjgPeNrO3021ddsV1l88FJgGFwL+AQ81srqT1zGx5oq4H4BrGe8KuSiR+Im8EfBsDQUtCL61NvEi0E/An4PQ025p1cd3lrwhrQfwAHGhmC+NazB0k3Vu0PKUH4JrHg7CrEomJGDcBb0kqNLOTJG0BPCBpNuGq/VVmNiXFpmZO4gtuR2AzwoXMGcBkYHYMwL0IOeA/+vrANZunI1yVkLQNIRc5lBAg7gbWM7MD40y4AmCBmb3uP5HLL16Eu5OwqpwBrxDG/m4O9AVWATeZ2fDUGuny4kHYVTpJrYDpwNuECQLLY/lzwDAzeyDN9mVdXFvj78DFZvZW/FLrAUw2s2clbQqsMLNF/gVX8/k4YVcpEuOAO5vZl8CZQFdg30S1N4ANUmhe5iXGAQPsSVh+cneAOORsOXBifP2ZmS2Kzz0A13CeE3brLJGjPBT4o6Rz41CoxsBtknYGphDWKjgn1cZmUOLz3Rv4krDmMkAvSUfExe9fAXaRtKGZ/S+1xrpy8yDs1lkMELsAVxPWf3hPUjMze1zSAuBRwtjgQ+I2/4lcDokvuBuAP5nZNElPEHLBf47btgD+6gE4ezwIu8rSmtDbbR9nxh0oaTVh+NkZhIkEmxIuJLlykNQauBg4PI6t3h5oBTxJmOTSF3jU74yRTR6EXYUkfiK3JvxE/hD4grBc4k2EJSr3ALqa2QhJLYEbJI03s+/SandG1SMswH6ApEsIefXdgQsJa0OsBPaU9JGZjUyvma4ifHSEq7D4M/gUYC5hjOpzwCoz+zZOxHgION3MJsT6TePi4i6HxBfcDoTgu5gw+uEQ4HkL94c7GtjLzM6U1AnYGxhpZgvSa7mrCA/CrkLikoj3AP2AuwARVu0yYAfCHTEuikOmCszsR88F50/hppw3AUMIC93vYmafxG17Av8kTMQYGcvqmdnqlJrr1oGnI1xeSgigGxGWoOxGWA94gJktj72yxcBRZvZO3O9H8OFS+YhD0ToQpncfSlhpbgHwXdzWDriCMEZ4ZNHfxQNwdnlP2JUpDjU70MyejD+RuwAfEyYMtIjb5ko6HDgYOC+5aIzLTVIDoL6ZrYifdUPCinOfEBbmOSlekOtPWIO5iZkt9V8WtYP3hF0+VgGdJH0Qnx9KuBj3NvAN0E1SZ8IQtcs9AOdPUn1gL2BZnOn2S0L6YT/CLYlamNlKSb2BS4APzOx98F8WtYX3hF1e4mIxzwCLzaxHomw3wgyuVcBD5guyl1tcC/h6YGPgQjN7QtLGhLsjTySMPPl/hMWOfEH2WsaDsCtVMpjGn8wdCdORexNyvoslbWJmc4rWrfUAnL9in+8Qwud7K/CWmc2X1JRwu6clwHtm9rJ/vrWPB2FXosQwqYOAXYDVZjZQUgHwf4QLRn8hTEP+rZnNTbG5mZP4fDsC84BGhFTEqcAIM3tIUhuggZnNT7Otrmr5Aj6uRDFAHEgItE8AJ0l6HGhmZr8jrFVwMXCnB+DyS3zBDSN8xucC4wjrQvSTdDPwPmG6t6vFvCfsSiSpCWEc8C1Ae+Aywq2JGhGmz34tqXn8138il5OkXxLWAz6ckHLoA7xK+GLrBuwIfGZmY1JrpKsWHoTdGkWTKhKvmwFtCb2zPeMQqq+B5wnDpvyODeWQnFARh5t9CHQGrgMGEtbY+By42swWJ/bzL7lazIeouaJeb6GZrZLUlzAh4FMze1NSc8JkgU0krU9YNOZ+D8D5K5qubeFecHsSAu9Mwuf6W+BUM5su6UigOeGLb00Q9gBcu3kQruMU7oLxJ2B4DMYPEPKU90o6Ia4LPAu4lrBa16lmNt57Z/mRtB7wvKTbCXcbuQN4l3ARbibhouc8SQ2BXwCnmdnMtNrrqp+nI+q4OPTsJsJKXQXAU2Y2Js5+ewA42MzGSepGuEec35SznOJneQmwFLgk9nqPI/SI2xPGWn8MDDWzYak11KXCg3AdllhYpwFhPYI9CSMhBsX876+Bx4HDzG8YuU4Ubsz5GPAXM7s5zpQ7BtiKsFLa3T4VuW7yIWp1WAzABWa2inBxaDRhXYidJTU0syeBo4Ef0mxnbWBmownLfp4saUDMqT8CfED49bE01vMAXMd4T7iOKjZbq76ZFca85JVAU2A48KqZrSxe31VcHHt9LXC7+V2nHd4TrnPicoiQ+NvHANwgBtxrCHdqOILEnZE9AFcOMxtBWOjoYknt4wxEV4d5T7gOSUyV3YewIMwnwMdm9lDc3iAOU2sIdDazD9Nsb20mqU1yLLCru/xbuA6JAfhXwD+AsYQ1C86R9Me4fVXMEa/0AFy1PAC7Ij5OuO7pCNxjZoMBJL0B3CxppJnNTM6Yc85VPe8J13KJHHCRJsAJidczCXdJ9ryUcynwIFzLFaUgJJ0tqZuZ3Qu8IWmMwm3oewLbAw3SbalzdZNfmKulEhfhegP3E6bKLgfGA/8hzJLrDLQCbvDJGM6lw4NwLSapF2HI2UVmNkPSAMKSiTPM7L44PKq5z9RyLj2ejqjdmgP7APvG18OACUAfSRcAAr4CHwfsXFp8dEQtZmaj4voPN0iab2ZD490x6gHTi9a2dc6lx4NwLWfh7seFwLVxPYgHgKFpt8s5F3hOuI6QdChwIyE9sdDHAztXM3gQrkN8qqxzNY8HYeecS5GPjnDOuRR5EHbOuRR5EHbOuRR5EHbOuRR5EHapkLRa0jRJ70gaFm8NX9FjDZF0ZHx+b7wzdGl195C0awXOMVtS63zLi9X5rpznukrSheVto8smD8IuLSvMrLuZbUu4ndKZyY3xbsTlZma/MbN3c1TZAyh3EHauqngQdjXBq0CX2Et9VdJw4F1J9STdLGmypBmSfgthhThJ/5T0gaSXgLZFB5I0VlLP+PwASVMlTY9Ld3YmBPvfx174bpLaSHoinmOypL5x31aSRkmaKelewjobOUl6WtKbcZ8zim27NZaPkdQmlm0haWTc51VJW1fGh+myxactu1TFHm8/YGQs2gnY1sw+jYHsGzPbWVIjYIKkUcCOwFZAN2AjwjKd9xc7bhvgHmD3eKyWcbW4u4HvzOyWWO9h4FYzGy+pE/Ai8AtgIDDezK6RdBBwWh5v59R4jibAZElPmNmXwPrAFDP7vaQr47HPBQYBZ5rZR3HJ0TuBvSrwMboM8yDs0tJE0rT4/FXgPkKaYJKZfRrL9wO2L8r3As2ArsDuwNC4ANF8SS+XcPw+wLiiY5nZ0lLasQ/QLXEDkg0lbRDP8eu47/OSvsrjPZ0v6fD4fJPY1i+BH4FHY/lDwJPxHLsCwxLnbpTHOVwt40HYpWWFmXVPFsRgtCxZBJxnZi8Wq3dgJbajAOhjZt+X0Ja8SdqDENB3MbPlksYCjUupbvG8Xxf/DFzd4zlhV5O9CJwlqQGApC0lrQ+MA46JOeN2wJ4l7Ps6sLukzeK+LWP5t0DTRL1RwHlFLyQVBcVxwHGxrB/Qooy2NgO+igF4a0JPvEgBUNSbP46Q5vgf8Kmko+I5JGmHMs7haiEPwq4mu5eQ750q6R3gX4Rfb08BH8VtDwITi+8YFyo6g/DTfzo/pQOeBQ4vujAHnA/0jBf+3uWnURpXE4L4TEJa4vMy2joSqC/pPcJqda8nti0DesX3sBfhbicAxwOnxfbNBPrn8Zm4WsYX8HHOuRR5T9g551LkQdg551LkQdg551LkQdg551LkQdg551LkQdg551LkQdg551L0/wGFPXXJY0UI1wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}