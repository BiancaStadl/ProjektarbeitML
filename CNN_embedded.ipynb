{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN embedded.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNJr9K8u3h99EPKu8fCPvMZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BiancaStadl/ProjektarbeitML/blob/main/CNN_embedded.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXDOlIBymF0V"
      },
      "source": [
        "GloVe embeddings taken from:\n",
        "\n",
        "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. [pdf] [bib]\n",
        "\n",
        "hatespeechdata taken from (https://hatespeechdata.com/): Wiegand, M., Siegel, M. and Ruppenhofer, J., 2018. Overview of the GermEval 2018 Shared Task on the Identification of Offensive Language. In: Proceedings of GermEval 2018, 14th Conference on Natural Language Processing (KONVENS 2018). Vienna, Austria: Research Gate. available on: https://github.com/uds-lsv/GermEval-2018-Data (last checked: 09.05.2021)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlBmABDxfqII"
      },
      "source": [
        "wiki detox..https://colab.research.google.com/github/tensorflow/fairness-indicators/blob/master/g3doc/tutorials/Fairness_Indicators_TFCO_Wiki_Case_Study.ipynb#scrollTo=y6T5tlXcdW7J "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3xfitNdliBI"
      },
      "source": [
        "#import matplotlib.pyplot as plt -> f√ºr evtl Visualisierungen\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import string\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from keras import losses \n",
        "from keras import optimizers \n",
        "from keras import metrics \n",
        "\n",
        "#!pip install Tokenizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "#!pip install pad_sequences\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import preprocessing\n",
        "#from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTWJQ1iga_vS"
      },
      "source": [
        "Maximale Satzl√§nge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bq08Me5la_Cc"
      },
      "source": [
        "\n",
        "max_length = 60"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVYBMvYSotTH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b045f01-9277-4587-b757-ac1396bb3c33"
      },
      "source": [
        "url = \"https://github.com/uds-lsv/GermEval-2018-Data/archive/master.zip\"\n",
        "\n",
        "dataset = tf.keras.utils.get_file(\"GermEval-2018-Data-master.zip\", url, \n",
        "                                   extract=True, cache_dir='.',\n",
        "                                    cache_subdir='')\n",
        "\n",
        "dataset_dir = os.path.join(os.path.dirname(dataset), 'GermEval-2018-Data-master')\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/uds-lsv/GermEval-2018-Data/archive/master.zip\n",
            "15360000/Unknown - 1s 0us/step"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cS14OUtfo34V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e744e0c5-feaa-481d-9685-567cbf72c145"
      },
      "source": [
        "os.listdir(dataset_dir)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['submissions.tgz',\n",
              " 'README.md',\n",
              " 'LICENSE.md',\n",
              " 'guidelines-iggsa-shared.pdf',\n",
              " 'evaluationScriptGermeval2018.pl',\n",
              " 'results.pdf',\n",
              " 'germeval2018.test.txt',\n",
              " 'germeval2018.training.txt',\n",
              " 'survey.pdf']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2X429K6hpOVm"
      },
      "source": [
        "training_file = os.path.join(dataset_dir, 'germeval2018.training.txt')\n",
        "\n",
        "testing_file = os.path.join(dataset_dir, 'germeval2018.test.txt')\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uq8fG3LNtn_m"
      },
      "source": [
        "###Aufbereitung\n",
        "txt-Dateien lesen, und dabei jede Zeile splitten und teilen\n",
        "Twitter-Handler entfernen?\n",
        "Labels von S√§tzen trennen, Labels in eigenen Array packen.\n",
        "\n",
        "####Ressourcen\n",
        "* https://www.w3schools.com/python/gloss_python_if_statement.asp\n",
        "* https://stackabuse.com/using-regex-for-text-manipulation-in-python/\n",
        "* https://www.tutorialspoint.com/python/string_splitlines.htm \n",
        "* https://note.nkmk.me/en/python-split-rsplit-splitlines-re/ \n",
        "* https://www.w3schools.com/python/python_regex.asp \n",
        "\n",
        "g√§be bei keras tf.keras.preprocessing.text_dataset_from_directory, aber daf√ºr m√ºssten die Daten auf bestimmte Weise in Verzeichnis organisiert sein, hier nicht der Fall.\n",
        "\n",
        "\n",
        "Einteilung der Daten: Testdaten\n",
        "Trainingsdaten -> noch ca 500 f√ºr Validierungsdaten\n",
        "\n",
        "labels -> \"other\", also nicht-negative Aussagen bekommen \"0\", negative Aussagen bekommen \"1\"\n",
        "\n",
        " Regex f√ºr Emojis  ->\n",
        "\n",
        "(\\u00a9|\\u00ae|[\\u2000-\\u3300]|\\ud83c[\\ud000-\\udfff]|\\ud83d[\\ud000-\\udfff]|\\ud83e[\\ud000-\\udfff])\n",
        "\n",
        "genommen von https://www.regextester.com/106421 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Py_cwD4eZkXo"
      },
      "source": [
        "def remove_clutter(string):\n",
        "   string = re.sub(\"@[^\\s]+\",\" \",string)\n",
        "   string = re.sub(\"#[^\\s]+\",\" \", string)\n",
        "   string = re.sub(\"\\u00a9\",\" \", string)\n",
        "   string = re.sub(\"\\u00ae\",\" \", string)\n",
        "   string = re.sub(\"[\\u2000-\\u3300]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83c[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83d[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83e[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"üòú\", \" \",string)\n",
        "   string = re.sub(\"üç´\", \" \",string)\n",
        "   string = re.sub(\"üòÅ\", \" \",string)\n",
        "   string = re.sub(\"üêñ\", \" \",string)\n",
        "   string = re.sub(\"üò°\", \" \",string)\n",
        "   string = re.sub(\"üòá\", \" \",string)\n",
        "   string = re.sub(\"üò¨\", \" \",string)\n",
        "   string = re.sub(\"üòÉ\", \" \",string)\n",
        "   string = re.sub(\"üòÇ\", \" \",string)\n",
        "   string = re.sub(\"üíô\", \" \",string)  \n",
        "   string = re.sub(\"üòõ\", \" \",string)\n",
        "   string = re.sub(\"üôè\", \" \",string)\n",
        "   string = re.sub(\"üëç\", \" \",string)\n",
        "   string = re.sub(\"üñï\", \" \",string)\n",
        "   string = re.sub(\"üòâ\", \" \",string)\n",
        "   string = re.sub(\"üí©\", \" \",string)\n",
        "   string = re.sub(\"ü§¢\", \" \",string)\n",
        "   string = re.sub(\"üëè\", \" \",string)\n",
        "   string = re.sub(\"üò®\", \" \",string)\n",
        "   string = re.sub(\"ü§£\", \" \",string)\n",
        "   string = re.sub(\"ü§°\", \" \",string)\n",
        "   string = re.sub(\"üòà\", \" \",string)\n",
        "   string = re.sub(\"üíÉüèΩ\", \" \",string)\n",
        "   string = re.sub(\"üëπ\", \" \",string)\n",
        "   string = re.sub(\"ü§ò\", \" \",string)\n",
        "   string = re.sub(\"üò±\", \" \",string)\n",
        "   string = re.sub(\"ü§î\", \" \",string) \n",
        "   string = re.sub(\"üåà\", \" \",string) \n",
        "   string = re.sub(\"üíï\", \" \",string) \n",
        "   string = re.sub(\"üë©‚Äç‚ù§Ô∏è‚Äçüë©\", \" \",string) \n",
        "   string = re.sub(\"üòç\", \" \",string) \n",
        "   string = re.sub(\"üëÜ\", \" \",string) \n",
        "   string = re.sub(\"üòñ\", \" \",string) \n",
        "   string = re.sub(\"üëá\", \" \",string) \n",
        "   string = re.sub(\"üî•\", \" \",string) \n",
        "   string = re.sub(\"üòò\", \" \",string) \n",
        "   string = re.sub(\"üéâ\", \" \",string) \n",
        "   string = re.sub(\"ü§¨\", \" \",string) \n",
        "   string = re.sub(\"üëä\", \" \",string)\n",
        "   string = re.sub(\"üá©üá™\", \" \",string)  \n",
        "   string = re.sub(\"üíî\", \" \",string)\n",
        "   string = re.sub(\"üôà\", \" \",string)\n",
        "   string = re.sub(\"ü§Ø\", \" \",string)\n",
        "   string = re.sub(\"üêü\", \" \",string)\n",
        "   string = re.sub(\"üõ∂\", \" \",string)\n",
        "   string = re.sub(\"üòä\", \" \",string)\n",
        "   string = re.sub(\"üòì\", \" \",string)\n",
        "   string = re.sub(\"üò≥\", \" \",string)\n",
        "   string = re.sub(\"üöÄ\", \" \",string)\n",
        "   string = re.sub(\"üëé\", \" \",string)\n",
        "   string = re.sub(\"üòé\", \" \",string)\n",
        "   string = re.sub(\"üê∏\", \" \",string)\n",
        "   string = re.sub(\"üìà\", \" \",string)\n",
        "   string = re.sub(\"üôÇ\", \" \",string)\n",
        "   string = re.sub(\"üòÖ\", \" \",string)\n",
        "   string = re.sub(\"üòÜ\", \" \",string)\n",
        "   string = re.sub(\"üôéüèø\", \" \",string)\n",
        "   string = re.sub(\"üëéüèΩ\", \" \",string)\n",
        "   string = re.sub(\"ü§≠\", \" \",string)\n",
        "   string = re.sub(\"üò§\", \" \",string)\n",
        "   string = re.sub(\"üòö\", \" \",string)\n",
        "   string = re.sub(\"üòä\", \" \",string)\n",
        "   string = re.sub(\"üò≤\", \" \",string)\n",
        "   string = re.sub(\"ü§Æ\", \" \",string)\n",
        "   string = re.sub(\"üôÑ\", \" \",string)\n",
        "   string = re.sub(\"ü§ë\", \" \",string)\n",
        "   string = re.sub(\"üéÖ\", \" \",string)\n",
        "   string = re.sub(\"üëã\", \" \",string)\n",
        "   string = re.sub(\"üí™\", \" \",string)\n",
        "   string = re.sub(\"üòÑ\", \" \",string)\n",
        "   string = re.sub(\"üßê\", \" \",string)\n",
        "   string = re.sub(\"üò†\", \" \",string)\n",
        "   string = re.sub(\"üéà\", \" \",string)\n",
        "   string = re.sub(\"üöÇ\", \" \",string)\n",
        "   string = re.sub(\"üòä\", \" \",string)\n",
        "   string = re.sub(\"üöá\", \" \",string)\n",
        "   string = re.sub(\"üöä\", \" \",string)\n",
        "   string = re.sub(\"ü§∑\", \" \",string)\n",
        "   string = re.sub(\"üò•\", \" \",string)\n",
        "   string = re.sub(\"üôÉ\", \" \",string)\n",
        "   string = re.sub(\"üî©\", \" \",string)\n",
        "   string = re.sub(\"üîß\", \" \",string)\n",
        "   string = re.sub(\"üî®\", \" \",string)\n",
        "   string = re.sub(\"üõ†\", \" \",string)\n",
        "   string = re.sub(\"üíì\", \" \",string)\n",
        "   string = re.sub(\"üí°\", \" \",string)\n",
        "   string = re.sub(\"üç∏\", \" \",string)\n",
        "   string = re.sub(\"ü•É\", \" \",string)\n",
        "   string = re.sub(\"ü•Ç\", \" \",string)\n",
        "   string = re.sub(\"üò∑\", \" \",string)\n",
        "   string = re.sub(\"ü§ê\", \" \",string)\n",
        "   string = re.sub(\"üåé\", \" \",string)\n",
        "   string = re.sub(\"üëë\", \" \",string)\n",
        "   string = re.sub(\"ü§õ\", \" \",string)\n",
        "   string = re.sub(\"üòÄ\", \" \",string)\n",
        "   string = re.sub(\"üõ§\", \" \",string)\n",
        "   string = re.sub(\"üéÑ\", \" \",string)\n",
        "   string = re.sub(\"üì¥\", \" \",string)\n",
        "   string = re.sub(\"üå≠\", \" \",string)\n",
        "   string = re.sub(\"ü§ï\", \" \",string)\n",
        "   string = re.sub(\"üò≠\", \" \",string)\n",
        "   string = re.sub(\"üçæ\", \" \",string)\n",
        "   string = re.sub(\"üçû\", \" \",string)\n",
        "   string = re.sub(\"ü§¶\", \" \",string)\n",
        "   string = re.sub(\"ü§Ø\", \" \",string)\n",
        "   string = re.sub(\"üïØÔ∏è\", \" \",string)\n",
        "\n",
        "   string = re.sub(\"OTHER|OFFENSE|ABUSE|INSULT\",\" \",string)\n",
        "   return string"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5asMgo4LtnRg"
      },
      "source": [
        "statementsForTraining = []\n",
        "sentimentsForTraining = []\n",
        "\n",
        "\n",
        "fileToRead = open(training_file, 'r')\n",
        "\n",
        "while True:\n",
        "  #next line in file\n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  findSentiment = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "\n",
        "\n",
        "  statementsForTraining.append(line)\n",
        "   #sentimentsForTraining.append(findSentiment.group(0))\n",
        "\n",
        "  if findSentiment.group(0) == \"OTHER\":  \n",
        "    sentimentsForTraining.append(0)\n",
        "  else:\n",
        "    sentimentsForTraining.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        " #print(\"{}: {}\".format(count,line.strip()))\n",
        "  \n",
        " # print(sentiment.group(0))\n",
        " \n",
        "fileToRead.close()\n",
        "\n",
        "training_sentences = statementsForTraining\n",
        "training_labels = sentimentsForTraining\n",
        "\n",
        "#print(training_sentences[9])\n",
        "#print(training_labels[9])\n",
        "\n",
        "#print(len(training_sentences))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsqZPENb98gD"
      },
      "source": [
        "##do the same with testdata\n",
        "statementsForTesting = []\n",
        "sentimentsForTesting = []\n",
        "\n",
        "fileToRead = open(testing_file, 'r')\n",
        "\n",
        "while True:\n",
        "  #next line in file\n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  sent = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "\n",
        "    \n",
        "\n",
        "  statementsForTesting.append(line)\n",
        "  #print(len(line))\n",
        "  #sentimentsForTesting.append(sent.group(0))\n",
        "\n",
        "  if sent.group(0) == \"OTHER\": \n",
        "    sentimentsForTesting.append(0)\n",
        "  else:\n",
        "    sentimentsForTesting.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        "\n",
        "fileToRead.close()\n",
        "\n",
        "\n",
        "testing_sentences = statementsForTesting\n",
        "testing_labels = sentimentsForTesting\n",
        "#print(len(testing_sentences))\n",
        "#print(testing_sentences)   \n",
        "#print(testing_labels)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRUvDLD5bMbO"
      },
      "source": [
        "Padding -> im Prinzip die S√§tze alle auf die gleiche L√§nge bringen (in Theorieteil n√§her drauf eingehen) -> maxlen-Paramter ist f√ºr pad_sequences vorhanden, wenn nicht gesetzt -> alles wird auf die L√§nge des l√§ngsten Satzes aufgef√ºllt -> print(padded(shape)) gibt aus, wie viele Datens√§tze padded wurden und gibt an, wie viele Tokens der l√§ngste Datensatz hat\n",
        "print(padded[x]) gibt einen Satz aus (bereits tokenisiert)\n",
        "\n",
        "Padding -> sowohl f√ºr Trainigs- als auch f√ºr Testdaten\n",
        "\n",
        "Und: Daten als numpy-Arrays speichern (notwendig f√ºr tensorflow).\n",
        "\n",
        " -> Tokenizer https://towardsdatascience.com/text-classification-in-keras-part-2-how-to-use-the-keras-tokenizer-word-representations-fd571674df23 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3hFi7waTv5m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e64aba67-f042-433d-a231-21ea571ca6fa"
      },
      "source": [
        "tokenizer = Tokenizer(oov_token=\"OOV\")\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "\n",
        "#creating a word index - nur die Trainigsdaten\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "validation_size = 500\n",
        "\n",
        "\n",
        "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "padded_training = pad_sequences(training_sequences, maxlen=max_length, padding='post')\n",
        "print(len(padded_training))\n",
        "\n",
        "validation_sequences = padded_training[0:validation_size]\n",
        "validation_labels = training_labels[0:validation_size]\n",
        "\n",
        "padded_training = padded_training[validation_size:]\n",
        "training_labels = training_labels[validation_size:]\n",
        "\n",
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
        "padded_testing = pad_sequences(testing_sequences, maxlen=max_length,  padding='post')\n",
        "\n",
        "#print(validation_sequences[499])\n",
        "print(padded_training[0])\n",
        "#print(len(validation_labels))\n",
        "#print(len(training_labels))\n",
        "\n",
        "\n",
        "nppadded_training = np.array(padded_training)\n",
        "nptraining_labels = np.array(training_labels)\n",
        "\n",
        "nppadded_validation = np.array(validation_sequences)\n",
        "npvalidation_labels = np.array(validation_labels)\n",
        "\n",
        "nppadded_testing = np.array(padded_testing)\n",
        "nptesting_labels = np.array(testing_labels)\n",
        "\n",
        "\n",
        "print(len(nppadded_training))\n",
        "print(len(nptraining_labels))\n",
        "print(len(word_index))\n",
        "\n",
        "#print(statementsForTraining[2])\n",
        "#print(nppadded_training[4])\n",
        "#print(nppadded_training.shape)\n",
        "#print(nptraining_labels[4])\n",
        "#print(nppadded_testing.shape)\n",
        "#print(word_index) \n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5009\n",
            "[  12 3982   11   41 6706 1040    4    5  202   39    3 2922   49 1360\n",
            "  810  495 3983    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0]\n",
            "4509\n",
            "4509\n",
            "15059\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tL3owrc8THkT"
      },
      "source": [
        "\n",
        "Dann: Embedding mit entweder word2vec oder glove\n",
        "Word2vec-Daten sind hier: http://vectors.nlpl.eu/repository/#\n",
        "Glove -> https://nlp.stanford.edu/projects/glove/ Da mal den Twitter-Vector runtergeladen\n",
        "Wenn Daten in GoogleDrive sind (w√§re auch via url m√∂glich..), muss Drive gemounted werden ( https://buomsoo-kim.github.io/colab/2020/05/09/Colab-mounting-google-drive.md/ ) aber auch hier https://enjoymachinelearning.com/posts/colab-with-google-drive/\n",
        "\n",
        "Die Word2vec vectors: http://vectors.nlpl.eu/repository/# \n",
        "\n",
        "glove-zitat:\n",
        "Citing GloVe\n",
        "\n",
        "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. [pdf] [bib]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zuO7T9ZTG57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9369d7c2-bb46-43ca-8135-250ee0d12a56"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "os.listdir(\"/content/drive/MyDrive/Colab Notebooks\")\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['germeval_training.txt',\n",
              " 'glove.twitter.27B.50d.txt',\n",
              " 'glove.twitter.27B.200d.txt',\n",
              " 'glove.6B.200d.txt',\n",
              " 'glove.840B.300d.txt',\n",
              " 'tensorboard.gdoc',\n",
              " 'keras.gdoc',\n",
              " 'Vectorization CNN embedded_limited_vocab.ipynb',\n",
              " 'glove.42B.300d.txt',\n",
              " 'Embedding Glove Vergleich.ipynb',\n",
              " 'LSTM.ipynb',\n",
              " 'CNN embedded_limited_vocab.ipynb',\n",
              " 'LSTM_limited_vocab.ipynb',\n",
              " 'CNN embedded.ipynb']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7ToKO-sZLHK"
      },
      "source": [
        "\n",
        "Keras-Doc : https://keras.io/examples/nlp/pretrained_word_embeddings/#load-pretrained-word-embeddings \n",
        "embedding mit initializers.. weights m√ºsste auch funktionieren\n",
        "\n",
        "Diese erstellte Matrix mit Embedding dann in die Embedding-Schicht einbinden,  Trainable auf False, weil sich die Werte nicht durch Training anpassen sollen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AShIVfC7ZQAH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "950f9863-aa13-4411-eea0-ec6b3e72e989"
      },
      "source": [
        "#Gr√∂√üe Vokabel -> wordindex + 2 (weil padding + OOV) \n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "vocabulary_size = len(word_index)+2\n",
        "\n",
        "# dann erstell ich ein W√∂rterbuch mit Namen \"embedding_vector\", dort sind dann\n",
        "#die keys drinnen, die in glove-Datei drinnen sind mit dem entsprechenden Key\n",
        "\n",
        "embedding_index_glove = {}\n",
        "f = open('/content/drive/MyDrive/Colab Notebooks/glove.twitter.27B.200d.txt')\n",
        "for line in f:\n",
        "  value = line.split()\n",
        "  word = value[0]\n",
        "  coef = np.asarray(value[1:],dtype='float32')\n",
        "  embedding_index_glove[word] = coef\n",
        "\n",
        "print(\"%d gefunden: \"% len(embedding_index_glove))\n",
        "\n",
        "#Dann noch eine Embedding-Matrix erstellen\n",
        "#zweiter Wert = Embedding-Dimension der Datei, in dem Fall 200\n",
        "\n",
        "glove_matrix = np.zeros((vocabulary_size,200))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    embedding_value = embedding_index_glove.get(word)\n",
        "    if embedding_value is not None:\n",
        "      glove_matrix[index] = embedding_value\n",
        "      hits+=1\n",
        "    else:\n",
        "      misses+=1\n",
        "\n",
        "print(\"hits %d and %d misses\"%(hits,misses))\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1193514 gefunden: \n",
            "hits 6747 and 8312 misses\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZmvOfwhV4N5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36c0aaa4-4731-464a-87f9-958f8455ac57"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "print(\"vocab size: %d\"%vocabulary_size)\n",
        "CNN16052101 = tf.keras.Sequential()\n",
        "#Embedding -> hier dann auf das embedding verweisen, Input_dim -> die Anzahl der W√∂rter im word_index, output -> in dem Fall passend zum verwendeten Vektor\n",
        "#input-length -> auf 60  gepadded, trainable -> nein, weil nichts ver√§ndert werden soll\n",
        "#embeddings_initializer=keras.initializers.Constant(glove_matrix) vs weights = [glove_matrix]\n",
        "#Convolutional layers => filters = neurons.. mit 100? 265?\n",
        "CNN16052101.add(tf.keras.layers.Embedding(vocabulary_size, output_dim=200, input_length=60, embeddings_initializer = keras.initializers.Constant(glove_matrix), trainable= False))\n",
        "CNN16052101.add(tf.keras.layers.Dropout(0.4))\n",
        "CNN16052101.add(tf.keras.layers.Conv1D(filters=30, kernel_size=3, padding=\"valid\", activation=\"relu\"))\n",
        "CNN16052101.add(tf.keras.layers.MaxPooling1D())\n",
        "CNN16052101.add(tf.keras.layers.Conv1D(filters=30, kernel_size=3, padding=\"valid\", activation=\"relu\"))\n",
        "CNN16052101.add(tf.keras.layers.GlobalAveragePooling1D())\n",
        "CNN16052101.add(tf.keras.layers.Flatten())\n",
        "CNN16052101.add(tf.keras.layers.Dense(260, activation=\"relu\"))\n",
        "CNN16052101.add(tf.keras.layers.Dropout(0.4))\n",
        "CNN16052101.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "CNN16052101.summary()\n",
        "\n",
        "#nppadded_training = np.asmatrix(nppadded_training) not necessary\n",
        "#nppadded_testing = np.asmatrix(nppadded_testing)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab size: 15061\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 60, 200)           3012200   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 60, 200)           0         \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 58, 30)            18030     \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 29, 30)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 27, 30)            2730      \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 30)                0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 30)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 260)               8060      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 260)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 261       \n",
            "=================================================================\n",
            "Total params: 3,041,281\n",
            "Trainable params: 29,081\n",
            "Non-trainable params: 3,012,200\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEr4OzT-iHDe"
      },
      "source": [
        "#model.layers[2].get_weights()[0].shape\n",
        "#weights=np.random.rand(5,200,100)\n",
        "#bias=np.random.rand(100)\n",
        "#model.layers[2].set_weights([weights, bias])\n",
        "\n",
        "#model.layers[2].get_weights()[0]\n",
        "#https://androidkt.com/set-custom-weights-keras-using-numpy-array/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UB7_3VPYesr9"
      },
      "source": [
        "F1-Score f√ºr jede Epoche https://aakashgoel12.medium.com/how-to-add-user-defined-function-get-f1-score-in-keras-metrics-3013f979ce0d\n",
        "\n",
        "Sehr gute Ressource f√ºr die verschiedenen Scores und Metriken https://neptune.ai/blog/evaluation-metrics-binary-classification#10  das und aakas verwendet\n",
        "\n",
        "hier: je eine Funktion f√ºr Recall, Precision, f1 https://neptune.ai/blog/keras-metrics \n",
        "\n",
        "https://keras.rstudio.com/reference/k_ones_like.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygyrbFJaMV9B"
      },
      "source": [
        "import keras.backend as K\n",
        "\n",
        "def metrics_recall(data_true, data_pred):\n",
        "    data_true = K.ones_like(data_true)\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(data_true,0,1)))\n",
        "\n",
        "    recall = true_positives / (possible_positives+K.epsilon())\n",
        "    return recall\n",
        "\n",
        "\n",
        "def metrics_precision(data_true, data_pred):\n",
        "    data_true = K.ones_like(data_true)\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "\n",
        "    positives_predicted = K.sum(K.round(K.clip(data_pred,0,1)))\n",
        "    precision = true_positives / (positives_predicted+K.epsilon())\n",
        "    return precision\n",
        "\n",
        "\n",
        "def metrics_f1(data_true, data_pred):\n",
        "    precision_data = metrics_precision(data_true, data_pred)\n",
        "    recall_data = metrics_recall(data_true, data_pred)\n",
        "    return 2*(precision_data*recall_data)/(precision_data+recall_data+K.epsilon())"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AfPD3_bWCm0"
      },
      "source": [
        "CNN16052101.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',metrics_recall,metrics_precision,metrics_f1])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpChKUY-QEWI"
      },
      "source": [
        "https://www.tensorflow.org/tensorboard/tensorboard_in_notebooks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJfMgUhHBoD1"
      },
      "source": [
        "#%reload_ext tensorboard\n",
        "#nur einmal pro Sitzung notwendig\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ISmMXLqP8Hc"
      },
      "source": [
        "\n",
        "logs_base_dir = \"./logs\"\n",
        "callbackForTB = tf.keras.callbacks.TensorBoard(logs_base_dir)\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2CHbXiP1LsF"
      },
      "source": [
        "training_epochs = 30\n",
        "batch_size = 40\n",
        "validation_split=0.2"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abV-QAxfW48r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9690b72-aade-4f1a-ce2d-3da1ef861169"
      },
      "source": [
        "#Werte der Convolutional-Schichten variieren (Filter), Batch-Size variieren, kernel-size..\n",
        "CNN16052101.fit(nppadded_training, nptraining_labels, batch_size=batch_size, validation_split=validation_split, epochs=training_epochs, callbacks=[callbackForTB])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "91/91 [==============================] - 4s 28ms/step - loss: 0.6556 - accuracy: 0.6630 - metrics_recall: 0.0055 - metrics_precision: 0.0555 - metrics_f1: 0.0101 - val_loss: 0.6418 - val_accuracy: 0.6718 - val_metrics_recall: 0.0000e+00 - val_metrics_precision: 0.0000e+00 - val_metrics_f1: 0.0000e+00\n",
            "Epoch 2/30\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.6413 - accuracy: 0.6634 - metrics_recall: 0.0000e+00 - metrics_precision: 0.0000e+00 - metrics_f1: 0.0000e+00 - val_loss: 0.6263 - val_accuracy: 0.6718 - val_metrics_recall: 0.0000e+00 - val_metrics_precision: 0.0000e+00 - val_metrics_f1: 0.0000e+00\n",
            "Epoch 3/30\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.6248 - accuracy: 0.6679 - metrics_recall: 0.0063 - metrics_precision: 0.1063 - metrics_f1: 0.0111 - val_loss: 0.5974 - val_accuracy: 0.6707 - val_metrics_recall: 0.0120 - val_metrics_precision: 0.3913 - val_metrics_f1: 0.0231\n",
            "Epoch 4/30\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.5910 - accuracy: 0.6776 - metrics_recall: 0.0744 - metrics_precision: 0.7147 - metrics_f1: 0.1291 - val_loss: 0.5836 - val_accuracy: 0.6973 - val_metrics_recall: 0.1912 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.3164\n",
            "Epoch 5/30\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.5946 - accuracy: 0.6704 - metrics_recall: 0.1550 - metrics_precision: 0.9962 - metrics_f1: 0.2594 - val_loss: 0.5643 - val_accuracy: 0.7106 - val_metrics_recall: 0.1908 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.3137\n",
            "Epoch 6/30\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.5670 - accuracy: 0.6974 - metrics_recall: 0.2210 - metrics_precision: 1.0000 - metrics_f1: 0.3481 - val_loss: 0.5523 - val_accuracy: 0.7228 - val_metrics_recall: 0.1941 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.3187\n",
            "Epoch 7/30\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.5448 - accuracy: 0.7217 - metrics_recall: 0.1817 - metrics_precision: 0.9998 - metrics_f1: 0.2946 - val_loss: 0.5472 - val_accuracy: 0.7228 - val_metrics_recall: 0.2515 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.3965\n",
            "Epoch 8/30\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.5228 - accuracy: 0.7328 - metrics_recall: 0.2282 - metrics_precision: 1.0000 - metrics_f1: 0.3613 - val_loss: 0.5419 - val_accuracy: 0.7195 - val_metrics_recall: 0.2913 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.4447\n",
            "Epoch 9/30\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.5142 - accuracy: 0.7431 - metrics_recall: 0.2622 - metrics_precision: 1.0000 - metrics_f1: 0.4009 - val_loss: 0.5393 - val_accuracy: 0.7273 - val_metrics_recall: 0.2589 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.4033\n",
            "Epoch 10/30\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.5160 - accuracy: 0.7379 - metrics_recall: 0.2650 - metrics_precision: 1.0000 - metrics_f1: 0.4060 - val_loss: 0.5340 - val_accuracy: 0.7206 - val_metrics_recall: 0.2937 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.4474\n",
            "Epoch 11/30\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.4898 - accuracy: 0.7452 - metrics_recall: 0.2860 - metrics_precision: 1.0000 - metrics_f1: 0.4313 - val_loss: 0.5329 - val_accuracy: 0.7173 - val_metrics_recall: 0.3065 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.4638\n",
            "Epoch 12/30\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.4814 - accuracy: 0.7629 - metrics_recall: 0.2955 - metrics_precision: 1.0000 - metrics_f1: 0.4479 - val_loss: 0.5281 - val_accuracy: 0.7262 - val_metrics_recall: 0.2578 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.4022\n",
            "Epoch 13/30\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.4370 - accuracy: 0.7854 - metrics_recall: 0.2637 - metrics_precision: 1.0000 - metrics_f1: 0.4123 - val_loss: 0.5319 - val_accuracy: 0.7184 - val_metrics_recall: 0.3194 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.4776\n",
            "Epoch 14/30\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.4418 - accuracy: 0.7901 - metrics_recall: 0.3051 - metrics_precision: 1.0000 - metrics_f1: 0.4584 - val_loss: 0.5316 - val_accuracy: 0.7140 - val_metrics_recall: 0.2793 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.4297\n",
            "Epoch 15/30\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.4230 - accuracy: 0.7974 - metrics_recall: 0.2872 - metrics_precision: 1.0000 - metrics_f1: 0.4399 - val_loss: 0.5512 - val_accuracy: 0.7095 - val_metrics_recall: 0.3641 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.5300\n",
            "Epoch 16/30\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.4158 - accuracy: 0.8093 - metrics_recall: 0.3046 - metrics_precision: 1.0000 - metrics_f1: 0.4560 - val_loss: 0.5461 - val_accuracy: 0.7151 - val_metrics_recall: 0.3183 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.4755\n",
            "Epoch 17/30\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.4002 - accuracy: 0.8137 - metrics_recall: 0.3168 - metrics_precision: 1.0000 - metrics_f1: 0.4742 - val_loss: 0.5640 - val_accuracy: 0.7062 - val_metrics_recall: 0.3944 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.5611\n",
            "Epoch 18/30\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.3912 - accuracy: 0.8220 - metrics_recall: 0.3228 - metrics_precision: 1.0000 - metrics_f1: 0.4780 - val_loss: 0.5738 - val_accuracy: 0.7284 - val_metrics_recall: 0.1577 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.2649\n",
            "Epoch 19/30\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.3861 - accuracy: 0.8189 - metrics_recall: 0.2774 - metrics_precision: 1.0000 - metrics_f1: 0.4254 - val_loss: 0.5715 - val_accuracy: 0.6929 - val_metrics_recall: 0.3857 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.5520\n",
            "Epoch 20/30\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.3710 - accuracy: 0.8330 - metrics_recall: 0.3017 - metrics_precision: 1.0000 - metrics_f1: 0.4567 - val_loss: 0.5852 - val_accuracy: 0.6984 - val_metrics_recall: 0.3837 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.5501\n",
            "Epoch 21/30\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.3607 - accuracy: 0.8371 - metrics_recall: 0.3117 - metrics_precision: 1.0000 - metrics_f1: 0.4687 - val_loss: 0.5515 - val_accuracy: 0.7251 - val_metrics_recall: 0.2793 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.4287\n",
            "Epoch 22/30\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.3620 - accuracy: 0.8436 - metrics_recall: 0.3225 - metrics_precision: 1.0000 - metrics_f1: 0.4783 - val_loss: 0.6168 - val_accuracy: 0.6718 - val_metrics_recall: 0.4742 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.6387\n",
            "Epoch 23/30\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.3516 - accuracy: 0.8383 - metrics_recall: 0.3315 - metrics_precision: 1.0000 - metrics_f1: 0.4912 - val_loss: 0.5713 - val_accuracy: 0.7051 - val_metrics_recall: 0.3641 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.5280\n",
            "Epoch 24/30\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.3350 - accuracy: 0.8480 - metrics_recall: 0.3173 - metrics_precision: 1.0000 - metrics_f1: 0.4725 - val_loss: 0.5910 - val_accuracy: 0.7151 - val_metrics_recall: 0.2457 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.3851\n",
            "Epoch 25/30\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.3716 - accuracy: 0.8352 - metrics_recall: 0.3102 - metrics_precision: 1.0000 - metrics_f1: 0.4605 - val_loss: 0.5886 - val_accuracy: 0.7140 - val_metrics_recall: 0.2976 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.4514\n",
            "Epoch 26/30\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.3251 - accuracy: 0.8538 - metrics_recall: 0.3024 - metrics_precision: 1.0000 - metrics_f1: 0.4583 - val_loss: 0.6294 - val_accuracy: 0.6718 - val_metrics_recall: 0.4542 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.6222\n",
            "Epoch 27/30\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.3371 - accuracy: 0.8567 - metrics_recall: 0.3450 - metrics_precision: 1.0000 - metrics_f1: 0.5062 - val_loss: 0.5984 - val_accuracy: 0.6973 - val_metrics_recall: 0.3487 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.5116\n",
            "Epoch 28/30\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.3240 - accuracy: 0.8546 - metrics_recall: 0.3427 - metrics_precision: 1.0000 - metrics_f1: 0.5060 - val_loss: 0.6432 - val_accuracy: 0.6774 - val_metrics_recall: 0.4574 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.6245\n",
            "Epoch 29/30\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.3153 - accuracy: 0.8568 - metrics_recall: 0.3227 - metrics_precision: 1.0000 - metrics_f1: 0.4804 - val_loss: 0.5961 - val_accuracy: 0.7073 - val_metrics_recall: 0.3293 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.4884\n",
            "Epoch 30/30\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.2955 - accuracy: 0.8641 - metrics_recall: 0.3039 - metrics_precision: 1.0000 - metrics_f1: 0.4571 - val_loss: 0.6092 - val_accuracy: 0.7051 - val_metrics_recall: 0.3120 - val_metrics_precision: 1.0000 - val_metrics_f1: 0.4681\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f49a5dc5d90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJVL4SBLPB2P"
      },
      "source": [
        "#%tensorboard --logdir {logs_base_dir}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_LnvWBcnoak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42768290-427f-438b-d82b-0e7f114204bc"
      },
      "source": [
        "#results = model.evaluate(nppadded_testing, nptesting_labels, batch_size=batch_size)\n",
        "#print(\"test loss, test acc:\",results)\n",
        "\n",
        "(loss,accuracy, metrics_recall, metrics_precision,\n",
        "metrics_f1) = CNN16052101.evaluate(nppadded_testing, nptesting_labels, verbose=1)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6672 - accuracy: 0.6837 - metrics_recall: 0.2681 - metrics_precision: 1.0000 - metrics_f1: 0.4143\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KgjIkhpKmHc"
      },
      "source": [
        "make some predictions of test data and save it to variable. verbose=0 -> do not generate output\n",
        "Gute Quelle: https://deeplizard.com/learn/video/2f-NjDUvZIE "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89GWuxryKlcM"
      },
      "source": [
        "CNN_predictions = CNN16052101.predict(x=nppadded_testing)\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3jPDaDJK_cN"
      },
      "source": [
        "#for p in CNN_predictions:\n",
        " # print(p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eC9efJy4Lp21"
      },
      "source": [
        "rounded predictions: give prediction value of most likely prediction (0 or 1). Printing the output of rounded prediction shows the prediction made by the model on the data (which output is most likely)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsG-TJuQLvtk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afa071e7-b59b-42e3-d9fb-b8bf7f5f592f"
      },
      "source": [
        "prediction_rounded = np.round(CNN_predictions)\n",
        "#np.argmax(CNN_predictions,axis=-1)\n",
        "\n",
        "#for p in prediction_rounded:\n",
        " # print(p)\n",
        "\n",
        "\n",
        "print(nptesting_labels[500:520])\n",
        "print(prediction_rounded[500:520])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1]\n",
            "[[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egTtgpXgg8a2"
      },
      "source": [
        "https://deeplizard.com/learn/video/km7pxKy4UHU\n",
        "\n",
        "Quelle der def plot_confusion_matrix: https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSDXf7-_MITy"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0AMs1EzhBU1"
      },
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                        normalize=False,\n",
        "                        title='Confusion matrix',\n",
        "                        cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2JgEnlghCtl"
      },
      "source": [
        "cm = confusion_matrix(y_true=nptesting_labels, y_pred=prediction_rounded)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckmF29whhFmX"
      },
      "source": [
        "plot_labels = ['no hatespeech','hatespeech']"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "2mpSE96rhK7K",
        "outputId": "2b453399-7312-44e1-a2b8-d9abbb24db69"
      },
      "source": [
        "plot_confusion_matrix(cm=cm, classes=plot_labels, title='CNN Confusion 30')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix, without normalization\n",
            "[[1898  432]\n",
            " [ 685  517]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}