{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN embedded.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMbN6b6aPaZXWhc5c18anBO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BiancaStadl/ProjektarbeitML/blob/main/CNN_embedded.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXDOlIBymF0V"
      },
      "source": [
        "GloVe embeddings taken from:\n",
        "\n",
        "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. [pdf] [bib]\n",
        "\n",
        "hatespeechdata taken from (https://hatespeechdata.com/): Wiegand, M., Siegel, M. and Ruppenhofer, J., 2018. Overview of the GermEval 2018 Shared Task on the Identification of Offensive Language. In: Proceedings of GermEval 2018, 14th Conference on Natural Language Processing (KONVENS 2018). Vienna, Austria: Research Gate. available on: https://github.com/uds-lsv/GermEval-2018-Data (last checked: 09.05.2021)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlBmABDxfqII"
      },
      "source": [
        "wiki detox..https://colab.research.google.com/github/tensorflow/fairness-indicators/blob/master/g3doc/tutorials/Fairness_Indicators_TFCO_Wiki_Case_Study.ipynb#scrollTo=y6T5tlXcdW7J "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3xfitNdliBI"
      },
      "source": [
        "#import matplotlib.pyplot as plt -> für evtl Visualisierungen\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import string\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from keras import losses \n",
        "from keras import optimizers \n",
        "from keras import metrics \n",
        "\n",
        "#!pip install Tokenizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "#!pip install pad_sequences\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import preprocessing\n",
        "#from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTWJQ1iga_vS"
      },
      "source": [
        "Maximale Satzlänge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bq08Me5la_Cc"
      },
      "source": [
        "\n",
        "max_length = 60"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVYBMvYSotTH"
      },
      "source": [
        "url = \"https://github.com/uds-lsv/GermEval-2018-Data/archive/master.zip\"\n",
        "\n",
        "dataset = tf.keras.utils.get_file(\"GermEval-2018-Data-master.zip\", url, \n",
        "                                   extract=True, cache_dir='.',\n",
        "                                    cache_subdir='')\n",
        "\n",
        "dataset_dir = os.path.join(os.path.dirname(dataset), 'GermEval-2018-Data-master')\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cS14OUtfo34V"
      },
      "source": [
        "#os.listdir(dataset_dir)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2X429K6hpOVm"
      },
      "source": [
        "training_file = os.path.join(dataset_dir, 'germeval2018.training.txt')\n",
        "\n",
        "testing_file = os.path.join(dataset_dir, 'germeval2018.test.txt')\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uq8fG3LNtn_m"
      },
      "source": [
        "###Aufbereitung\n",
        "txt-Dateien lesen, und dabei jede Zeile splitten und teilen\n",
        "Twitter-Handler entfernen?\n",
        "Labels von Sätzen trennen, Labels in eigenen Array packen.\n",
        "\n",
        "####Ressourcen\n",
        "* https://www.w3schools.com/python/gloss_python_if_statement.asp\n",
        "* https://stackabuse.com/using-regex-for-text-manipulation-in-python/\n",
        "* https://www.tutorialspoint.com/python/string_splitlines.htm \n",
        "* https://note.nkmk.me/en/python-split-rsplit-splitlines-re/ \n",
        "* https://www.w3schools.com/python/python_regex.asp \n",
        "\n",
        "gäbe bei keras tf.keras.preprocessing.text_dataset_from_directory, aber dafür müssten die Daten auf bestimmte Weise in Verzeichnis organisiert sein, hier nicht der Fall.\n",
        "\n",
        "\n",
        "Einteilung der Daten: Testdaten\n",
        "Trainingsdaten -> noch ca 500 für Validierungsdaten\n",
        "\n",
        "labels -> \"other\", also nicht-negative Aussagen bekommen \"0\", negative Aussagen bekommen \"1\"\n",
        "\n",
        " Regex für Emojis  ->\n",
        "\n",
        "(\\u00a9|\\u00ae|[\\u2000-\\u3300]|\\ud83c[\\ud000-\\udfff]|\\ud83d[\\ud000-\\udfff]|\\ud83e[\\ud000-\\udfff])\n",
        "\n",
        "genommen von https://www.regextester.com/106421 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Py_cwD4eZkXo"
      },
      "source": [
        "def remove_clutter(string):\n",
        "   string = re.sub(\"@[^\\s]+\",\" \",string)\n",
        "   string = re.sub(\"#[^\\s]+\",\" \", string)\n",
        "   string = re.sub(\"\\u00a9\",\" \", string)\n",
        "   string = re.sub(\"\\u00ae\",\" \", string)\n",
        "   string = re.sub(\"[\\u2000-\\u3300]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83c[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83d[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83e[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"😜\", \" \",string)\n",
        "   string = re.sub(\"🍫\", \" \",string)\n",
        "   string = re.sub(\"😁\", \" \",string)\n",
        "   string = re.sub(\"🐖\", \" \",string)\n",
        "   string = re.sub(\"😡\", \" \",string)\n",
        "   string = re.sub(\"😇\", \" \",string)\n",
        "   string = re.sub(\"😬\", \" \",string)\n",
        "   string = re.sub(\"😃\", \" \",string)\n",
        "   string = re.sub(\"😂\", \" \",string)\n",
        "   string = re.sub(\"💙\", \" \",string)  \n",
        "   string = re.sub(\"😛\", \" \",string)\n",
        "   string = re.sub(\"🙏\", \" \",string)\n",
        "   string = re.sub(\"👍\", \" \",string)\n",
        "   string = re.sub(\"🖕\", \" \",string)\n",
        "   string = re.sub(\"😉\", \" \",string)\n",
        "   string = re.sub(\"💩\", \" \",string)\n",
        "   string = re.sub(\"🤢\", \" \",string)\n",
        "   string = re.sub(\"👏\", \" \",string)\n",
        "   string = re.sub(\"😨\", \" \",string)\n",
        "   string = re.sub(\"🤣\", \" \",string)\n",
        "   string = re.sub(\"🤡\", \" \",string)\n",
        "   string = re.sub(\"😈\", \" \",string)\n",
        "   string = re.sub(\"💃🏽\", \" \",string)\n",
        "   string = re.sub(\"👹\", \" \",string)\n",
        "   string = re.sub(\"🤘\", \" \",string)\n",
        "   string = re.sub(\"😱\", \" \",string)\n",
        "   string = re.sub(\"🤔\", \" \",string) \n",
        "   string = re.sub(\"🌈\", \" \",string) \n",
        "   string = re.sub(\"💕\", \" \",string) \n",
        "   string = re.sub(\"👩‍❤️‍👩\", \" \",string) \n",
        "   string = re.sub(\"😍\", \" \",string) \n",
        "   string = re.sub(\"👆\", \" \",string) \n",
        "   string = re.sub(\"😖\", \" \",string) \n",
        "   string = re.sub(\"👇\", \" \",string) \n",
        "   string = re.sub(\"🔥\", \" \",string) \n",
        "   string = re.sub(\"😘\", \" \",string) \n",
        "   string = re.sub(\"🎉\", \" \",string) \n",
        "   string = re.sub(\"🤬\", \" \",string) \n",
        "   string = re.sub(\"👊\", \" \",string)\n",
        "   string = re.sub(\"🇩🇪\", \" \",string)  \n",
        "   string = re.sub(\"💔\", \" \",string)\n",
        "   string = re.sub(\"🙈\", \" \",string)\n",
        "   string = re.sub(\"🤯\", \" \",string)\n",
        "   string = re.sub(\"🐟\", \" \",string)\n",
        "   string = re.sub(\"🛶\", \" \",string)\n",
        "   string = re.sub(\"😊\", \" \",string)\n",
        "   string = re.sub(\"😓\", \" \",string)\n",
        "   string = re.sub(\"😳\", \" \",string)\n",
        "   string = re.sub(\"🚀\", \" \",string)\n",
        "   string = re.sub(\"👎\", \" \",string)\n",
        "   string = re.sub(\"😎\", \" \",string)\n",
        "   string = re.sub(\"🐸\", \" \",string)\n",
        "   string = re.sub(\"📈\", \" \",string)\n",
        "   string = re.sub(\"🙂\", \" \",string)\n",
        "   string = re.sub(\"😅\", \" \",string)\n",
        "   string = re.sub(\"😆\", \" \",string)\n",
        "   string = re.sub(\"🙎🏿\", \" \",string)\n",
        "   string = re.sub(\"👎🏽\", \" \",string)\n",
        "   string = re.sub(\"🤭\", \" \",string)\n",
        "   string = re.sub(\"😤\", \" \",string)\n",
        "   string = re.sub(\"😚\", \" \",string)\n",
        "   string = re.sub(\"😊\", \" \",string)\n",
        "   string = re.sub(\"😲\", \" \",string)\n",
        "   string = re.sub(\"🤮\", \" \",string)\n",
        "   string = re.sub(\"🙄\", \" \",string)\n",
        "   string = re.sub(\"🤑\", \" \",string)\n",
        "   string = re.sub(\"🎅\", \" \",string)\n",
        "   string = re.sub(\"👋\", \" \",string)\n",
        "   string = re.sub(\"💪\", \" \",string)\n",
        "   string = re.sub(\"😄\", \" \",string)\n",
        "   string = re.sub(\"🧐\", \" \",string)\n",
        "   string = re.sub(\"😠\", \" \",string)\n",
        "   string = re.sub(\"🎈\", \" \",string)\n",
        "   string = re.sub(\"🚂\", \" \",string)\n",
        "   string = re.sub(\"😊\", \" \",string)\n",
        "   string = re.sub(\"🚇\", \" \",string)\n",
        "   string = re.sub(\"🚊\", \" \",string)\n",
        "   string = re.sub(\"🤷\", \" \",string)\n",
        "   string = re.sub(\"😥\", \" \",string)\n",
        "   string = re.sub(\"🙃\", \" \",string)\n",
        "   string = re.sub(\"🔩\", \" \",string)\n",
        "   string = re.sub(\"🔧\", \" \",string)\n",
        "   string = re.sub(\"🔨\", \" \",string)\n",
        "   string = re.sub(\"🛠\", \" \",string)\n",
        "   string = re.sub(\"💓\", \" \",string)\n",
        "   string = re.sub(\"💡\", \" \",string)\n",
        "   string = re.sub(\"🍸\", \" \",string)\n",
        "   string = re.sub(\"🥃\", \" \",string)\n",
        "   string = re.sub(\"🥂\", \" \",string)\n",
        "   string = re.sub(\"😷\", \" \",string)\n",
        "   string = re.sub(\"🤐\", \" \",string)\n",
        "   string = re.sub(\"🌎\", \" \",string)\n",
        "   string = re.sub(\"👑\", \" \",string)\n",
        "   string = re.sub(\"🤛\", \" \",string)\n",
        "   string = re.sub(\"😀\", \" \",string)\n",
        "   string = re.sub(\"🛤\", \" \",string)\n",
        "   string = re.sub(\"🎄\", \" \",string)\n",
        "   string = re.sub(\"📴\", \" \",string)\n",
        "   string = re.sub(\"🌭\", \" \",string)\n",
        "   string = re.sub(\"🤕\", \" \",string)\n",
        "   string = re.sub(\"😭\", \" \",string)\n",
        "   string = re.sub(\"🍾\", \" \",string)\n",
        "   string = re.sub(\"🍞\", \" \",string)\n",
        "   string = re.sub(\"🤦\", \" \",string)\n",
        "   string = re.sub(\"🤯\", \" \",string)\n",
        "   string = re.sub(\"🕯️\", \" \",string)\n",
        "\n",
        "   string = re.sub(\"OTHER|OFFENSE|ABUSE|INSULT\",\" \",string)\n",
        "   return string"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5asMgo4LtnRg"
      },
      "source": [
        "statementsForTraining = []\n",
        "sentimentsForTraining = []\n",
        "\n",
        "\n",
        "fileToRead = open(training_file, 'r')\n",
        "\n",
        "while True:\n",
        "  #next line in file\n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  findSentiment = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "\n",
        "\n",
        "  statementsForTraining.append(line)\n",
        "   #sentimentsForTraining.append(findSentiment.group(0))\n",
        "\n",
        "  if findSentiment.group(0) == \"OTHER\":  \n",
        "    sentimentsForTraining.append(0)\n",
        "  else:\n",
        "    sentimentsForTraining.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        " #print(\"{}: {}\".format(count,line.strip()))\n",
        "  \n",
        " # print(sentiment.group(0))\n",
        " \n",
        "fileToRead.close()\n",
        "\n",
        "training_sentences = statementsForTraining\n",
        "training_labels = sentimentsForTraining\n",
        "\n",
        "#print(training_sentences[9])\n",
        "#print(training_labels[9])\n",
        "\n",
        "#print(len(training_sentences))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsqZPENb98gD"
      },
      "source": [
        "##do the same with testdata\n",
        "statementsForTesting = []\n",
        "sentimentsForTesting = []\n",
        "\n",
        "fileToRead = open(testing_file, 'r')\n",
        "\n",
        "while True:\n",
        "  #next line in file\n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  sent = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "\n",
        "    \n",
        "\n",
        "  statementsForTesting.append(line)\n",
        "  #print(len(line))\n",
        "  #sentimentsForTesting.append(sent.group(0))\n",
        "\n",
        "  if sent.group(0) == \"OTHER\": \n",
        "    sentimentsForTesting.append(0)\n",
        "  else:\n",
        "    sentimentsForTesting.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        "\n",
        "fileToRead.close()\n",
        "\n",
        "\n",
        "testing_sentences = statementsForTesting\n",
        "testing_labels = sentimentsForTesting\n",
        "#print(len(testing_sentences))\n",
        "#print(testing_sentences)   \n",
        "#print(testing_labels)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRUvDLD5bMbO"
      },
      "source": [
        "Padding -> im Prinzip die Sätze alle auf die gleiche Länge bringen (in Theorieteil näher drauf eingehen) -> maxlen-Paramter ist für pad_sequences vorhanden, wenn nicht gesetzt -> alles wird auf die Länge des längsten Satzes aufgefüllt -> print(padded(shape)) gibt aus, wie viele Datensätze padded wurden und gibt an, wie viele Tokens der längste Datensatz hat\n",
        "print(padded[x]) gibt einen Satz aus (bereits tokenisiert)\n",
        "\n",
        "Padding -> sowohl für Trainigs- als auch für Testdaten\n",
        "\n",
        "Und: Daten als numpy-Arrays speichern (notwendig für tensorflow).\n",
        "\n",
        " -> Tokenizer https://towardsdatascience.com/text-classification-in-keras-part-2-how-to-use-the-keras-tokenizer-word-representations-fd571674df23 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3hFi7waTv5m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26d7e5aa-caa6-416e-dcf1-4dee3588b847"
      },
      "source": [
        "tokenizer = Tokenizer(oov_token=\"OOV\")\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "\n",
        "#creating a word index - nur die Trainigsdaten\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "validation_size = 500\n",
        "\n",
        "\n",
        "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "padded_training = pad_sequences(training_sequences, maxlen=max_length, padding='post')\n",
        "print(len(padded_training))\n",
        "\n",
        "validation_sequences = padded_training[0:validation_size]\n",
        "validation_labels = training_labels[0:validation_size]\n",
        "\n",
        "padded_training = padded_training[validation_size:]\n",
        "training_labels = training_labels[validation_size:]\n",
        "\n",
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
        "padded_testing = pad_sequences(testing_sequences, maxlen=max_length,  padding='post')\n",
        "\n",
        "#print(validation_sequences[499])\n",
        "print(padded_training[0])\n",
        "#print(len(validation_labels))\n",
        "#print(len(training_labels))\n",
        "\n",
        "\n",
        "nppadded_training = np.array(padded_training)\n",
        "nptraining_labels = np.array(training_labels)\n",
        "\n",
        "nppadded_validation = np.array(validation_sequences)\n",
        "npvalidation_labels = np.array(validation_labels)\n",
        "\n",
        "nppadded_testing = np.array(padded_testing)\n",
        "nptesting_labels = np.array(testing_labels)\n",
        "\n",
        "\n",
        "print(len(nppadded_training))\n",
        "print(len(nptraining_labels))\n",
        "print(len(word_index))\n",
        "\n",
        "#print(statementsForTraining[2])\n",
        "#print(nppadded_training[4])\n",
        "#print(nppadded_training.shape)\n",
        "#print(nptraining_labels[4])\n",
        "#print(nppadded_testing.shape)\n",
        "#print(word_index) \n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5009\n",
            "[  12 3982   11   41 6706 1040    4    5  202   39    3 2922   49 1360\n",
            "  810  495 3983    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0]\n",
            "4509\n",
            "4509\n",
            "15059\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tL3owrc8THkT"
      },
      "source": [
        "\n",
        "Dann: Embedding mit entweder word2vec oder glove\n",
        "Word2vec-Daten sind hier: http://vectors.nlpl.eu/repository/#\n",
        "Glove -> https://nlp.stanford.edu/projects/glove/ Da mal den Twitter-Vector runtergeladen\n",
        "Wenn Daten in GoogleDrive sind (wäre auch via url möglich..), muss Drive gemounted werden ( https://buomsoo-kim.github.io/colab/2020/05/09/Colab-mounting-google-drive.md/ ) aber auch hier https://enjoymachinelearning.com/posts/colab-with-google-drive/\n",
        "\n",
        "Die Word2vec vectors: http://vectors.nlpl.eu/repository/# \n",
        "\n",
        "glove-zitat:\n",
        "Citing GloVe\n",
        "\n",
        "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. [pdf] [bib]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zuO7T9ZTG57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "794f3cb9-41fc-4683-bac5-efb92886db90"
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount(\"/content/drive\")\n",
        "os.listdir(\"/content/drive/MyDrive/Colab Notebooks\")\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['germeval_training.txt',\n",
              " 'glove.twitter.27B.50d.txt',\n",
              " 'glove.twitter.27B.200d.txt',\n",
              " 'glove.6B.200d.txt',\n",
              " 'glove.840B.300d.txt',\n",
              " 'tensorboard.gdoc',\n",
              " 'keras.gdoc',\n",
              " 'Vectorization CNN embedded_limited_vocab.ipynb',\n",
              " 'glove.42B.300d.txt',\n",
              " 'Embedding Glove Vergleich.ipynb',\n",
              " 'CNN embedded_limited_vocab.ipynb',\n",
              " 'LSTM_limited_vocab.ipynb',\n",
              " 'LSTM.ipynb',\n",
              " 'CNN embedded.ipynb']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7ToKO-sZLHK"
      },
      "source": [
        "\n",
        "Keras-Doc : https://keras.io/examples/nlp/pretrained_word_embeddings/#load-pretrained-word-embeddings \n",
        "embedding mit initializers.. weights müsste auch funktionieren\n",
        "\n",
        "Diese erstellte Matrix mit Embedding dann in die Embedding-Schicht einbinden,  Trainable auf False, weil sich die Werte nicht durch Training anpassen sollen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AShIVfC7ZQAH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3747acac-3f36-427b-a520-58bc8735a165"
      },
      "source": [
        "#Größe Vokabel -> wordindex + 2 (weil padding + OOV) \n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "vocabulary_size = len(word_index)+2\n",
        "\n",
        "# dann erstell ich ein Wörterbuch mit Namen \"embedding_vector\", dort sind dann\n",
        "#die keys drinnen, die in glove-Datei drinnen sind mit dem entsprechenden Key\n",
        "\n",
        "embedding_index_glove = {}\n",
        "f = open('/content/drive/MyDrive/Colab Notebooks/glove.twitter.27B.200d.txt')\n",
        "for line in f:\n",
        "  value = line.split()\n",
        "  word = value[0]\n",
        "  coef = np.asarray(value[1:],dtype='float32')\n",
        "  embedding_index_glove[word] = coef\n",
        "\n",
        "print(\"%d gefunden: \"% len(embedding_index_glove))\n",
        "\n",
        "#Dann noch eine Embedding-Matrix erstellen\n",
        "#zweiter Wert = Embedding-Dimension der Datei, in dem Fall 200\n",
        "\n",
        "glove_matrix = np.zeros((vocabulary_size,200))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    embedding_value = embedding_index_glove.get(word)\n",
        "    if embedding_value is not None:\n",
        "      glove_matrix[index] = embedding_value\n",
        "      hits+=1\n",
        "    else:\n",
        "      misses+=1\n",
        "\n",
        "print(\"hits %d and %d misses\"%(hits,misses))\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1193514 gefunden: \n",
            "hits 6747 and 8312 misses\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZmvOfwhV4N5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8182aa63-870f-4fcb-ddf1-08a5a3eaf9e3"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "print(\"vocab size: %d\"%vocabulary_size)\n",
        "CNN16052102ES03 = tf.keras.Sequential()\n",
        "#Embedding -> hier dann auf das embedding verweisen, Input_dim -> die Anzahl der Wörter im word_index, output -> in dem Fall passend zum verwendeten Vektor\n",
        "#input-length -> auf 60  gepadded, trainable -> nein, weil nichts verändert werden soll\n",
        "#embeddings_initializer=keras.initializers.Constant(glove_matrix) vs weights = [glove_matrix]\n",
        "#Convolutional layers => filters = neurons.. mit 100? 265?\n",
        "#CNN16052102ES03.add(tf.keras.layers.Embedding(input_dim=vocabulary_size, output_dim=200, input_length=max_length))\n",
        "CNN16052102ES03.add(tf.keras.layers.Embedding(vocabulary_size, output_dim=200, input_length=60, embeddings_initializer = keras.initializers.Constant(glove_matrix), trainable= False))\n",
        "CNN16052102ES03.add(tf.keras.layers.Dropout(0.4))\n",
        "CNN16052102ES03.add(tf.keras.layers.Conv1D(filters=120, kernel_size=3, padding=\"valid\", activation=\"relu\"))\n",
        "CNN16052102ES03.add(tf.keras.layers.MaxPooling1D())\n",
        "CNN16052102ES03.add(tf.keras.layers.Conv1D(filters=120, kernel_size=3, padding=\"valid\", activation=\"relu\"))\n",
        "CNN16052102ES03.add(tf.keras.layers.GlobalAveragePooling1D())\n",
        "CNN16052102ES03.add(tf.keras.layers.Flatten())\n",
        "CNN16052102ES03.add(tf.keras.layers.Dense(260, activation=\"relu\"))\n",
        "CNN16052102ES03.add(tf.keras.layers.Dropout(0.4))\n",
        "CNN16052102ES03.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "CNN16052102ES03.summary()\n",
        "\n",
        "#nppadded_training = np.asmatrix(nppadded_training) not necessary\n",
        "#nppadded_testing = np.asmatrix(nppadded_testing)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab size: 15061\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 60, 200)           3012200   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 60, 200)           0         \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 58, 120)           72120     \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 29, 120)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 27, 120)           43320     \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 120)               0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 120)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 260)               31460     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 260)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 261       \n",
            "=================================================================\n",
            "Total params: 3,159,361\n",
            "Trainable params: 147,161\n",
            "Non-trainable params: 3,012,200\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEr4OzT-iHDe"
      },
      "source": [
        "#model.layers[2].get_weights()[0].shape\n",
        "#weights=np.random.rand(5,200,100)\n",
        "#bias=np.random.rand(100)\n",
        "#model.layers[2].set_weights([weights, bias])\n",
        "\n",
        "#model.layers[2].get_weights()[0]\n",
        "#https://androidkt.com/set-custom-weights-keras-using-numpy-array/"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UB7_3VPYesr9"
      },
      "source": [
        "F1-Score für jede Epoche https://aakashgoel12.medium.com/how-to-add-user-defined-function-get-f1-score-in-keras-metrics-3013f979ce0d\n",
        "\n",
        "Sehr gute Ressource für die verschiedenen Scores und Metriken https://neptune.ai/blog/evaluation-metrics-binary-classification#10  das und aakas verwendet\n",
        "\n",
        "hier: je eine Funktion für Recall, Precision, f1 https://neptune.ai/blog/keras-metrics \n",
        "\n",
        "https://keras.rstudio.com/reference/k_ones_like.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygyrbFJaMV9B"
      },
      "source": [
        "import keras.backend as K\n",
        "\n",
        "def metrics_recall(data_true, data_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(data_true,0,1)))\n",
        "\n",
        "    recall = true_positives / (possible_positives+K.epsilon())\n",
        "    return recall\n",
        "\n",
        "\n",
        "def metrics_precision(data_true, data_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "\n",
        "    positives_predicted = K.sum(K.round(K.clip(data_pred,0,1)))\n",
        "    precision = true_positives / (positives_predicted+K.epsilon())\n",
        "    return precision\n",
        "\n",
        "\n",
        "def metrics_f1(data_true, data_pred):\n",
        "    precision_data = metrics_precision(data_true, data_pred)\n",
        "    recall_data = metrics_recall(data_true, data_pred)\n",
        "    return 2*(precision_data*recall_data)/(precision_data+recall_data+K.epsilon())"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1ctlBrnuYJz"
      },
      "source": [
        "https://aakashgoel12.medium.com/how-to-add-user-defined-function-get-f1-score-in-keras-metrics-3013f979ce0d"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AfPD3_bWCm0"
      },
      "source": [
        "CNN16052102ES03.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',metrics_recall,metrics_precision,metrics_f1])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpChKUY-QEWI"
      },
      "source": [
        "https://www.tensorflow.org/tensorboard/tensorboard_in_notebooks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJfMgUhHBoD1"
      },
      "source": [
        "#%load_ext tensorboard\n",
        "#nur einmal pro Sitzung notwendig\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ISmMXLqP8Hc"
      },
      "source": [
        "\n",
        "logs_base_dir = \"./logs\"\n",
        "callbackForTB = tf.keras.callbacks.TensorBoard(logs_base_dir)\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ehh-EMXUQh8r"
      },
      "source": [
        "Early Stopping as defined in keras tensorflow documentation\n",
        "https://www.tensorflow.org/guide/keras/train_and_evaluate "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BY_t-PeQEjy"
      },
      "source": [
        "callbackEarlyStopping = [\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_loss\",\n",
        "        min_delta=0.0001,\n",
        "        patience=3,\n",
        "        verbose=1,\n",
        "    )\n",
        "]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2CHbXiP1LsF"
      },
      "source": [
        "training_epochs = 30\n",
        "batch_size = 40\n",
        "validation_split=0.2"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abV-QAxfW48r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da85fb57-d413-468d-8501-53b66d3eedcf"
      },
      "source": [
        "#Werte der Convolutional-Schichten variieren (Filter), Batch-Size variieren, kernel-size..\n",
        "CNN16052102ES03.fit(nppadded_training, nptraining_labels, batch_size=batch_size, validation_split=validation_split, epochs=training_epochs, callbacks=[callbackForTB,callbackEarlyStopping])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "91/91 [==============================] - 5s 45ms/step - loss: 0.6526 - accuracy: 0.6661 - metrics_recall: 0.0063 - metrics_precision: 0.0143 - metrics_f1: 0.0087 - val_loss: 0.6291 - val_accuracy: 0.6718 - val_metrics_recall: 0.0000e+00 - val_metrics_precision: 0.0000e+00 - val_metrics_f1: 0.0000e+00\n",
            "Epoch 2/30\n",
            "91/91 [==============================] - 3s 38ms/step - loss: 0.6502 - accuracy: 0.6371 - metrics_recall: 5.0736e-04 - metrics_precision: 0.0021 - metrics_f1: 7.4304e-04 - val_loss: 0.6317 - val_accuracy: 0.6774 - val_metrics_recall: 0.0201 - val_metrics_precision: 0.2391 - val_metrics_f1: 0.0367\n",
            "Epoch 3/30\n",
            "91/91 [==============================] - 4s 38ms/step - loss: 0.6259 - accuracy: 0.6487 - metrics_recall: 0.0152 - metrics_precision: 0.0708 - metrics_f1: 0.0228 - val_loss: 0.5956 - val_accuracy: 0.6718 - val_metrics_recall: 0.0000e+00 - val_metrics_precision: 0.0000e+00 - val_metrics_f1: 0.0000e+00\n",
            "Epoch 4/30\n",
            "91/91 [==============================] - 4s 39ms/step - loss: 0.5909 - accuracy: 0.6722 - metrics_recall: 0.1537 - metrics_precision: 0.4768 - metrics_f1: 0.2086 - val_loss: 0.5679 - val_accuracy: 0.7095 - val_metrics_recall: 0.2300 - val_metrics_precision: 0.7226 - val_metrics_f1: 0.3328\n",
            "Epoch 5/30\n",
            "91/91 [==============================] - 4s 39ms/step - loss: 0.5653 - accuracy: 0.7066 - metrics_recall: 0.3021 - metrics_precision: 0.6641 - metrics_f1: 0.3743 - val_loss: 0.5480 - val_accuracy: 0.7206 - val_metrics_recall: 0.3149 - val_metrics_precision: 0.7025 - val_metrics_f1: 0.4123\n",
            "Epoch 6/30\n",
            "91/91 [==============================] - 3s 38ms/step - loss: 0.5270 - accuracy: 0.7374 - metrics_recall: 0.4352 - metrics_precision: 0.6654 - metrics_f1: 0.4965 - val_loss: 0.5456 - val_accuracy: 0.7140 - val_metrics_recall: 0.5183 - val_metrics_precision: 0.5780 - val_metrics_f1: 0.5319\n",
            "Epoch 7/30\n",
            "91/91 [==============================] - 3s 38ms/step - loss: 0.5165 - accuracy: 0.7497 - metrics_recall: 0.4790 - metrics_precision: 0.7155 - metrics_f1: 0.5302 - val_loss: 0.5357 - val_accuracy: 0.7262 - val_metrics_recall: 0.4328 - val_metrics_precision: 0.6379 - val_metrics_f1: 0.4993\n",
            "Epoch 8/30\n",
            "91/91 [==============================] - 3s 38ms/step - loss: 0.4804 - accuracy: 0.7600 - metrics_recall: 0.5342 - metrics_precision: 0.7109 - metrics_f1: 0.5956 - val_loss: 0.5393 - val_accuracy: 0.7062 - val_metrics_recall: 0.4479 - val_metrics_precision: 0.5764 - val_metrics_f1: 0.4886\n",
            "Epoch 9/30\n",
            "91/91 [==============================] - 3s 38ms/step - loss: 0.4511 - accuracy: 0.7842 - metrics_recall: 0.5948 - metrics_precision: 0.7515 - metrics_f1: 0.6366 - val_loss: 0.5617 - val_accuracy: 0.6840 - val_metrics_recall: 0.6407 - val_metrics_precision: 0.5192 - val_metrics_f1: 0.5611\n",
            "Epoch 10/30\n",
            "91/91 [==============================] - 4s 39ms/step - loss: 0.4279 - accuracy: 0.7972 - metrics_recall: 0.6065 - metrics_precision: 0.7562 - metrics_f1: 0.6500 - val_loss: 0.5308 - val_accuracy: 0.7206 - val_metrics_recall: 0.4033 - val_metrics_precision: 0.6211 - val_metrics_f1: 0.4649\n",
            "Epoch 11/30\n",
            "91/91 [==============================] - 3s 38ms/step - loss: 0.4047 - accuracy: 0.8140 - metrics_recall: 0.6481 - metrics_precision: 0.7652 - metrics_f1: 0.6796 - val_loss: 0.5574 - val_accuracy: 0.7018 - val_metrics_recall: 0.6119 - val_metrics_precision: 0.5451 - val_metrics_f1: 0.5606\n",
            "Epoch 12/30\n",
            "91/91 [==============================] - 3s 38ms/step - loss: 0.3506 - accuracy: 0.8495 - metrics_recall: 0.7280 - metrics_precision: 0.8268 - metrics_f1: 0.7591 - val_loss: 0.5696 - val_accuracy: 0.7118 - val_metrics_recall: 0.5896 - val_metrics_precision: 0.5586 - val_metrics_f1: 0.5586\n",
            "Epoch 13/30\n",
            "91/91 [==============================] - 3s 38ms/step - loss: 0.3318 - accuracy: 0.8568 - metrics_recall: 0.7584 - metrics_precision: 0.8153 - metrics_f1: 0.7702 - val_loss: 0.6133 - val_accuracy: 0.7106 - val_metrics_recall: 0.4434 - val_metrics_precision: 0.5895 - val_metrics_f1: 0.4866\n",
            "Epoch 00013: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f59cc4a01d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJVL4SBLPB2P"
      },
      "source": [
        "#%tensorboard --logdir {logs_base_dir}"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_LnvWBcnoak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f698f5ab-ea97-46b3-9de2-34b759cdc16c"
      },
      "source": [
        "#results = model.evaluate(nppadded_testing, nptesting_labels, batch_size=batch_size)\n",
        "#print(\"test loss, test acc:\",results)\n",
        "\n",
        "(loss,accuracy, metrics_recall,metrics_precision,\n",
        "metrics_f1) = CNN16052102ES03.evaluate(nppadded_testing, nptesting_labels, verbose=1)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "111/111 [==============================] - 1s 10ms/step - loss: 0.6196 - accuracy: 0.6948 - metrics_recall: 0.3764 - metrics_precision: 0.5744 - metrics_f1: 0.4416\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KgjIkhpKmHc"
      },
      "source": [
        "make some predictions of test data and save it to variable. verbose=0 -> do not generate output\n",
        "Gute Quelle: https://deeplizard.com/learn/video/2f-NjDUvZIE "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89GWuxryKlcM"
      },
      "source": [
        "CNN_predictions06 = CNN16052102ES03.predict(x=nppadded_testing)\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3jPDaDJK_cN"
      },
      "source": [
        "#for p in CNN_predictions06:\n",
        " # print(p)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eC9efJy4Lp21"
      },
      "source": [
        "rounded predictions: give prediction value of most likely prediction (0 or 1). Printing the output of rounded prediction shows the prediction made by the model on the data (which output is most likely)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsG-TJuQLvtk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ebbc4fd-dcb8-442c-fc66-30a7caef0cab"
      },
      "source": [
        "prediction_rounded06 = np.round(CNN_predictions06)\n",
        "#np.argmax(CNN_predictions06,axis=-1)\n",
        "\n",
        "#for p in prediction_rounded06:\n",
        " # print(p)\n",
        "\n",
        "\n",
        "print(nptesting_labels[500:520])\n",
        "print(prediction_rounded06[500:520])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1]\n",
            "[[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egTtgpXgg8a2"
      },
      "source": [
        "https://deeplizard.com/learn/video/km7pxKy4UHU\n",
        "\n",
        "Quelle der def plot_confusion_matrix: https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSDXf7-_MITy"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0AMs1EzhBU1"
      },
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                        normalize=False,\n",
        "                        title='Confusion matrix',\n",
        "                        cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2JgEnlghCtl"
      },
      "source": [
        "cm = confusion_matrix(y_true=nptesting_labels, y_pred=prediction_rounded06)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckmF29whhFmX"
      },
      "source": [
        "plot_labels = ['no hatespeech','hatespeech']"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "2mpSE96rhK7K",
        "outputId": "1510c3c0-6c9b-4cc4-edcd-985acbcbe12f"
      },
      "source": [
        "plot_confusion_matrix(cm=cm, classes=plot_labels, title='CNN Confusion 120 EarlyStopping 0.0001')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix, without normalization\n",
            "[[2003  327]\n",
            " [ 751  451]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}